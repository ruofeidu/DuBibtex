<h2>Behavior Change</h2>
<h3>SoniWeight Shoes: Investigating Effects and Personalization of a Wearable Sound Device for Altering Body Perception, Behavior and Emotion</h3>
<p>Authors: Amar D'Adamo, Ana Tajadura-Jiménez, Marte Roel Lesur, Luis Antonio Azpicueta-Ruiz, Mohammad Mahdi Dehshibi, Aleksander Väljamäe, Joaquin Diaz Duran, Daniel De La Prida, Laia Turmo Vidal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148202">Link</a></p>
<h3>EcoSanté Lifestyle Intervention: Encourage Reflections on the Connections between Health and Environment</h3>
<p>Authors: Mike Horn, Pei-Yi (Patricia) Kuo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150654">Link</a></p>
<h3>Exploring the Lived Experience of Behavior Change Technologies: Towards an Existential Model of Behavior Change for HCI</h3>
<p>Authors: Amon Rapp, Arianna Boldi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150910">Link</a></p>
<h3>Me, My Health, and My Watch: How Children with ADHD Understand Smartwatch Health Data</h3>
<p>Authors: Kimberley Lakes, Jesus Beltran, Lucas Silva, Gillian Hayes, Franceli Cibrian, Sabrina Schuck, Arya Tavakoulnia, Elizabeth Ankrah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150927">Link</a></p>
<h2>Hand and Gaze</h2>
<h3>GazePointAR: A Context-Aware Multimodal Voice Assistant for Pronoun Disambiguation in Wearable Augmented Reality</h3>
<p>Authors: Sebastian Rodriguez, Liam Chu, Jon Froehlich, Jun Wang, Jaewook Lee, Elizabeth Brown</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147184">Link</a></p>
<p>Abstract: Voice assistants (VAs) like Siri and Alexa are transforming human-computer interaction; however, they lack awareness of users' spatiotemporal context, resulting in limited performance and unnatural dialogue. We introduce GazePointAR, a fully-functional context-aware VA for wearable augmented reality that leverages eye gaze, pointing gestures, and conversation history to disambiguate speech queries. With GazePointAR, users can ask "what's over there?" or "how do I solve this math problem?" simply by looking and/or pointing. We evaluated GazePointAR in a three-part lab study (N=12): (1) comparing GazePointAR to two commercial systems, (2) examining GazePointAR's pronoun disambiguation across three tasks; (3) and an open-ended phase where participants could suggest and try their own context-sensitive queries. Participants appreciated the naturalness and human-like nature of pronoun-driven queries, although sometimes pronoun use was counter-intuitive. We then iterated on GazePointAR and conducted a first-person diary study examining how GazePointAR performs in-the-wild. We conclude by enumerating limitations and design considerations for future context-aware VAs.</p>
<h3>QuadStretcher: A Forearm-Worn Skin Stretch Display for Bare-Hand Interaction in AR/VR</h3>
<p>Authors: Sunbum Kim, Taejun Kim, Geehyuk Lee, Jaeyeon Lee, YoungIn Kim, Youngbo Shim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148253">Link</a></p>
<p>Abstract: The paradigm of bare-hand interaction has become increasingly prevalent in Augmented Reality (AR) and Virtual Reality (VR) environments, propelled by advancements in hand tracking technology. However, a significant challenge arises in delivering haptic feedback to users’ hands, due to the necessity for the hands to remain bare. In response to this challenge, recent research has proposed an indirect solution of providing haptic feedback to the forearm. In this work, we present QuadStretcher, a skin stretch display featuring four independently controlled stretching units surrounding the forearm. While achieving rich haptic expression, our device also eliminates the need for a grounding base on the forearm by using a pair of counteracting tactors, thereby reducing bulkiness. To assess the effectiveness of QuadStretcher in facilitating immersive barehand experiences, we conducted a comparative user evaluation (n = 20) with a baseline solution, Squeezer. The results confirmed that QuadStretcher outperformed Squeezer in terms of expressing force direction and heightening the sense of realism, particularly in 3-DoF VR interactions such as pulling a rubber band, hooking a fishing rod, and swinging a tennis racket. We further discuss the design insights gained from qualitative user interviews, presenting key takeaways for future forearm-haptic systems aimed at advancing AR/VR bare-hand experiences.</p>
<h3>ArmDeformation: Inducing the Sensation of Arm Deformation in Virtual Reality Using Skin-Stretching</h3>
<p>Authors: Yilong Lin, Peng Zhang, Eyal Ofek, Seungwoo Je</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147750">Link</a></p>
<p>Abstract: With the development of virtual reality (VR) technology, research is being actively conducted on how incorporating multisensory feedback can create the illusion that virtual avatars are perceived as an extension of the body in VR. In line with this research direction, we introduce ArmDeformation, a wearable device employing skin-stretching to enhance virtual forearm ownership during arm deformation illusion. We conducted five user studies with 98 participants. Using a developed tabletop device, we confirmed the optimal number of actuators and the ideal skin-stretching design effectively increases the user's body ownership. Additionally, we explored the maximum visual threshold for forearm bending and the minimum detectable bending direction angle when using skin-stretching in VR. Finally, our study demonstrates that using ArmDeformation in VR applications enhances user realism and enjoyment compared to relying on visual feedback alone.</p>
<h3>CLERA: A Unified Model for Joint Cognitive Load and Eye Region Analysis in the Wild</h3>
<p>Authors: Meng Wang, Bryan Reimer, Jack Terwilliger, Aishni Parab, Li Ding, Lex Fridman, Bruce Mehler</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150827">Link</a></p>
<p>Abstract: Non-intrusive, real-time analysis of the dynamics of the eye region allows us to monitor humans’ visual attention allocation and estimate their mental state during the performance of real-world tasks, which can potentially benefit a wide range of human-computer interaction (HCI) applications. While commercial eye-tracking devices have been frequently employed, the difficulty of customizing these devices places unnecessary constraints on the exploration of more efficient, end-to-end models of eye dynamics. In this work, we propose CLERA, a unified model for Cognitive Load and Eye Region Analysis, which achieves precise keypoint detection and spatiotemporal tracking in a joint-learning framework. Our method demonstrates significant efficiency and outperforms prior work on tasks including cognitive load estimation, eye landmark detection, and blink estimation. We also introduce a large-scale dataset of 30k human faces with joint pupil, eye-openness, and landmark annotation, which aims to support future HCI research on human factors and eye-related analysis.</p>
<h3>How Gaze Visualization Facilitates Initiation of Informal Communication in 3D Virtual Spaces</h3>
<p>Authors: Takehito Yoshiki, Junko Ichino, daisuke okabe, Masahiro Ide, Hirotoshi Asano, Hideo Miyachi, Hitomi Yokoyama</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150879">Link</a></p>
<p>Abstract: This study explores how gaze visualization in virtual spaces facilitates the initiation of informal communication. Three styles of gaze cue visualization (arrow, bubbles, and miniature avatar) with two types of gaze behavior (one-sided gaze and joint gaze) were evaluated. 96 participants used either a non-visualized gaze cue or one of the three visualized gaze cues. The results showed that all visualized gaze cues facilitated the initiation of informal communication more effectively than the non-visualized gaze cue. For one-sided gaze, overall, bubbles had more positive effects on the gaze receiver’s behaviors and experiences than the other two visualized gaze cues, although the only statistically significant difference was in the verbal reaction rates. For joint gaze, all three visualized gaze cues had positive effects on the receiver’s behaviors and experiences. The design implications of the gaze visualization and the confederate-based evaluation method contribute to research on informal communication and social virtual reality.</p>
<h2>Privacy for Immersive Tracking</h2>
<h3>Privacy in Immersive Extended Reality: Exploring User Perceptions, Concerns, and Coping Strategies</h3>
<p>Authors: Derrick Wang, Lennart Nacke, Leah Zhang-Kennedy, Hilda Hadan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147162">Link</a></p>
<p>Abstract: Extended Reality (XR) technology is changing online interactions, but its granular data collection sensors may be more invasive to user privacy than web, mobile, and the Internet of Things technologies. Despite an increased interest in studying developers' concerns about XR device privacy, user perceptions have rarely been addressed. We surveyed 464 XR users to assess their awareness, concerns, and coping strategies around XR data in 18 scenarios. Our findings demonstrate that many factors, such as data types and sensitivity, affect users' perceptions of privacy in XR. However, users' limited awareness of XR sensors' granular data collection capabilities, such as involuntary body signals of emotional responses, restricted the range of privacy-protective strategies they used. Our results highlight a need to enhance users' awareness of data privacy threats in XR, design privacy-choice interfaces tailored to XR environments, and develop transparent XR data practices.</p>
<h3>"I know even if you don't tell me": Understanding Users' Privacy Preferences Regarding AI-based Inferences of Sensitive Information for Personalization</h3>
<p>Authors: Nikola Banovic, Zhe Chen, Sumit Asthana, Jane Im</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148250">Link</a></p>
<p>Abstract: Personalization improves user experience by tailoring interactions relevant to each user's background and preferences. However, personalization requires information about users that platforms often collect without their awareness or their enthusiastic consent. Here, we study how the transparency of AI inferences on users' personal data affects their privacy decisions and sentiments when sharing data for personalization. We conducted two experiments where participants (N=877) answered questions about themselves for personalized public arts recommendations. Participants indicated their consent to let the system use their inferred data and explicitly provided data after awareness of inferences. Our results show that participants chose restrictive consent decisions for sensitive and incorrect inferences about them and for their answers that led to such inferences. Our findings expand existing privacy discourse to inferences and inform future directions for shaping existing consent mechanisms in light of increasingly pervasive AI inferences.</p>
<h3>Kinetic Signatures: A Systematic Investigation of Movement-Based User Identification in Virtual Reality</h3>
<p>Authors: Stefan Schneegass, Leon Sabel, Uwe Gruenefeld, Patrick Laskowski, Jordan Hoppen, Jonathan Liebers, Florian Rademaker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147796">Link</a></p>
<p>Abstract: Behavioral Biometrics in Virtual Reality (VR) enable implicit user identification by leveraging the motion data of users' heads and hands from their interactions in VR. This spatiotemporal data forms a Kinetic Signature, which is a user-dependent behavioral biometric trait. Although kinetic signatures have been widely used in recent research, the factors contributing to their degree of identifiability remain mostly unexplored. Drawing from existing literature, this work systematically examines the influence of static and dynamic components in human motion. We conducted a user study (N = 24) with two sessions to reidentify users across different VR sports and exercises after one week. We found that the identifiability of a kinetic signature depends on its inherent static and dynamic factors, with the best combination allowing for 90.91 % identification accuracy after one week had passed. Therefore, this work lays a foundation for designing and refining movement-based identification protocols in immersive environments.</p>
<h3>Awareness, Intention, (In)Action: Individuals' Reactions to Data Breaches</h3>
<p>Authors: Florian Schaub, Peter Mayer, Adam Aviv, Khue Le, Hunter Dyer, Yixin Zou, Byron M. Lowens, PhD</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150899">Link</a></p>
<p>Abstract: Data breaches are prevalent. We provide novel insights into individuals’ awareness, perception, and responses to breaches that affect them through two online surveys: a main survey (𝑛=413) in which we presented participants with up to three breaches that affected them, and a follow-up survey (𝑛=108) in which we investigated whether the main study participants followed through with their intentions to act. Overall, 73% of participants were affected by at least one breach, but participants were unaware of 74% of breaches affecting them. While some reported intention to take action, most participants believed the breach would not impact them. We also found a sizeable intention-behavior gap. Participants did not follow through with their intention when they were apathetic about breaches, considered potential costs, forgot, or felt resigned about taking action. Our findings suggest that breached organizations should be held accountable for more proactively informing and protecting affected consumers.</p>
<h3>Don't Accept All and Continue: Exploring Nudges for More Deliberate Interaction With Tracking Consent Notices</h3>
<p>Authors: Alina Stöver, Verena Zimmermann, Justin Peschke, Nina Gerber</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150877">Link</a></p>
<p>Abstract: Legal frameworks rely on users to make an informed decision about data collection, e.g., by accepting or declining the use of tracking technologies. In practice, however, users hardly interact with tracking consent notices on a deliberate website per website level, but usually accept or decline optional tracking technologies altogether in a habituated behavior.We explored the potential of three different nudge types (color highlighting, social cue, timer) and default settings to interrupt this auto-response in an experimental between-subject design with 167 participants.We did not find statistically significant differences regarding the buttons clicked. Our results showed that opt-in default settings significantly decrease tracking technology use acceptance rates. These results are a first step towards understanding the effects of different nudging concepts on users’ interaction with tracking consent notices.</p>
<h2>Privacy and Trust</h2>
<h3>Computing and the Stigmatized: Trust, Surveillance, and Spatial Politics with the Sex Workers in Bangladesh</h3>
<p>BEST_PAPER</p>
<p>Authors: S M Taiabul Haque, Ayien Utshob Baidya, Syed Ishtiaque Ahmed, Nadira Nowsher, Pratyasha Saha, Nusrat Jahan Mim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148106">Link</a></p>
<h3>Lies, Deceit, and Hallucinations: Player Perception and Expectations Regarding Trust and Deception in Games</h3>
<p>Authors: Chuoxi Ng, Michael Yin, Emi Wang, Robert Xiao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146790">Link</a></p>
<h3>Reliability Criteria for News Websites</h3>
<p>Authors: Hendrik Heuer, Elena Glassman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150911">Link</a></p>
<h3>Un-Paradoxing Privacy: Considering Hopeful Trust</h3>
<p>Authors: Bran Knowles, Stacey Conchie</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150903">Link</a></p>
<h3>“I Can’t Believe It’s Not Custodial!”: Usable Trustless Decentralized Key Management</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Tanusree Sharma, Vivek Nair, Yang Wang, Henry Wang, Dawn Song</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147386">Link</a></p>
<h2>Bodies and Movement in Immersive Realities</h2>
<h3>ShareYourReality: Investigating Haptic Feedback and Agency in Virtual Avatar Co-embodiment</h3>
<p>Authors: Monica Perusquia-Hernandez, Gijs Huisman, Abdallah El Ali, Wo Meijer, Karthikeya Puttur Venkatraj</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147264">Link</a></p>
<p>Abstract: Virtual co-embodiment enables two users to share a single avatar in Virtual Reality (VR). During such experiences, the illusion of shared motion control can break during joint-action activities, highlighting the need for position-aware feedback mechanisms. Drawing on the perceptual crossing paradigm, we explore how haptics can enable non-verbal coordination between co-embodied participants. In a within-subjects study (20 participant pairs), we examined the effects of vibrotactile haptic feedback (None, Present) and avatar control distribution (25-75%, 50-50%, 75-25%) across two VR reaching tasks (Targeted, Free-choice) on participants’ Sense of Agency (SoA), co-presence, body ownership, and motion synchrony. We found (a) lower SoA in the free-choice with haptics than without, (b) higher SoA during the shared targeted task, (c) co-presence and body ownership were significantly higher in the free-choice task, (d) players’ hand motions synchronized more in the targeted task. We provide cautionary considerations when including haptic feedback mechanisms for avatar co-embodiment experiences.</p>
<h3>Process, Roles, Tools, and Team: Understanding the Emerging Medium of Virtual Reality Theatre</h3>
<p>Authors: T.C. Nicholas Graham, Laura Levin, Michaelah Wales, Michael Wheeler, Gabriele Cimolino, Jayna Mees</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147875">Link</a></p>
<p>Abstract: Virtual reality (VR) theatre artists are combining theatre production and game development practices to create live performances in VR. To date, little is known about VR theatre creators' experiences of this process or how staging a play in VR might affect the audience's experience. To capture the experience of developing a VR theatre production we interviewed the production team behind the VR play You Should Have Stayed Home. Members of this team felt the process was a learning experience and shared the lessons they plan to incorporate into their future work. We report on the team's efforts to understand the VR theatre medium, how this team was constructed, and challenges that they encountered. In this paper we present the opportunities that the production team members identified for creating novel experiences for VR audiences, and their own needs as creators.</p>
<h3>TimeTunnel: Integrating Spatial and Temporal Motion Editing for Character Animation in Virtual Reality</h3>
<p>Authors: Qian Zhou, George Fitzmaurice, Fraser Anderson, David Ledo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147369">Link</a></p>
<p>Abstract: Editing character motion in Virtual Reality is challenging as it requires working with both spatial and temporal data using controls with multiple degrees of freedom. The spatial and temporal controls are separated, making it difficult to adjust poses over time and predict the effects across adjacent frames. To address this challenge, we propose TimeTunnel, an immersive motion editing interface that integrates spatial and temporal control for 3D character animation in VR. TimeTunnel provides an approachable editing experience via KeyPoses and Trajectories. KeyPoses are a set of representative poses automatically computed to concisely depict motion. Trajectories are 3D animation curves that pass through the joints of KeyPoses to represent in-betweens. TimeTunnel integrates spatial and temporal control by superimposing Trajectories and KeyPoses onto a 3D character. We conducted two studies to evaluate TimeTunnel. In our quantitative study, TimeTunnel reduced the amount of time required for editing motion, and saved effort in locating target poses. Our qualitative study with domain experts demonstrated how TimeTunnel is an approachable interface that can simplify motion editing, while still preserving a direct representation of motion.</p>
<h3>A Systematic Review and Meta-analysis of the Effectiveness of Body Ownership Illusions in Virtual Reality</h3>
<p>Authors: Kasper Hornbæk, Guido Makransky, Aske Mottelson, Andreea Muresan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150754">Link</a></p>
<p>Abstract: Body ownership illusions (BOIs) occur when participants experience that their actual body is replaced by a body shown in virtual reality (VR). Based on a systematic review of the cumulative evidence on BOIs from 111 research articles published in 2010 to 2021, this article summarizes the findings of empirical studies of BOIs. Following the PRISMA guidelines, the review points to diverse experimental practices for inducing and measuring body ownership. The two major components of embodiment measurement, body ownership and agency, are examined. The embodiment of virtual avatars generally leads to modest body ownership and slightly higher agency. We also find that BOI research lacks statistical power and standardization across tasks, measurement instruments, and analysis approaches. Furthermore, the reviewed studies showed a lack of clarity in fundamental terminology, constructs, and theoretical underpinnings. These issues restrict scientific advances on the major components of BOIs, and together impede scientific rigor and theory-building.</p>
<h2>Children and Family B</h2>
<h3>CHAITok: A Proof-of-Concept System Supporting Children's Sense of Data Autonomy on Social Media</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Nigel Shadbolt, Ge Wang, Max Van Kleek, Zhilin Zhang, Jun Zhao, Samantha-Kaye Johnston</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147781">Link</a></p>
<h3>"It's Not a Replacement:'' Enabling Parent-Robot Collaboration to Support In-Home Learning Experiences of Young Children</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Edward Hubbard, Bilge Mutlu, Hui-Ru Ho</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147068">Link</a></p>
<h3>Cuddling Up With a Print-Braille Book: How Intimacy and Access Shape Parents' Reading Practices with Children</h3>
<p>Authors: Emory Edwards, Jin Seo Kim, Stacy Branham, Sohyeon Park, Cameron Cassidy, Isabela Figueira</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146954">Link</a></p>
<h3>“It looks useful, works just fine, but will it replace me ?" Understanding Special Educators’ Perception of Social Robots for Autism Care in India</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: B Ashwini, Venkata Ratnadeep Suri, Krishnaveni Achary, Jainendra Shukla, ATMADEEP GHOSHAL</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147134">Link</a></p>
<h2>Communication and Collaboration</h2>
<h3>Understanding Entrainment in Human Groups: Optimising Human-Robot Collaboration from Lessons Learned during Human-Human Collaboration</h3>
<p>Authors: Stanley Celestin, Julie Shah, Eike Schneiders, Malte Jung, Christopher Fourie</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147674">Link</a></p>
<p>Abstract: Successful entrainment during collaboration positively affects trust, willingness to collaborate, and likeability towards collaborators. In this paper, we present a mixed-method study to investigate characteristics of successful entrainment leading to pair and group-based synchronisation. Drawing inspiration from industrial settings, we designed a fast-paced, short-cycle repetitive task. Using motion tracking, we investigated entrainment in both dyadic and triadic task completion. Furthermore, we utilise audio-video recordings and semi-structured interviews to contextualise participants' experiences. This paper contributes to the Human-Computer/Robot Interaction (HCI/HRI) literature using a human-centred approach to identify entrainment characteristics during pair- and group-based collaboration. We present five characteristics related to successful entrainment. These are related to the occurrence of entrainment, leader-follower patterns, interpersonal communication, the importance of the point-of-assembly, and the value of acoustic feedback. Finally, based on our findings, we present three design considerations for future research and design on collaboration with robots.</p>
<h3>Investigating the Potential of Group Recommendation Systems As a Medium of Social Interactions: A Case of Spotify Blend Experiences between Two Users</h3>
<p>Authors: Soobin Park, Hankyung Kim, Daehyun Kwak, Youn-kyung Lim, Inha Cha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147752">Link</a></p>
<p>Abstract: Designing user experiences for group recommendation systems (GRS) is challenging, requiring a nuanced understanding of the influence of social interactions between users. Using Spotify Blend as a real-world case of music GRS, we conducted empirical studies to investigate intricate social interactions among South Korean users in GRS. Through a preliminary survey about Blend experiences in general, we narrowed the focus for the main study to relationships between two users who are acquainted or close. Building on this, we conducted a 21-day diary study and interviews with 30 participants (15 pairs) to probe more in-depth interpersonal dynamics within Blend. Our findings reveal that users engaged in implicit social interactions, including tacit understanding of their companions and indirect communication. We conclude by discussing the newly discovered value of GRS as a social catalyst, along with design attributes and challenges for the social experiences it mediates.</p>
<h3>Mitigating Barriers to Public Social Interaction with Meronymous Communication</h3>
<p>BEST_PAPER</p>
<p>Authors: Nouran Soliman, Matt Latzke, Hyeonsu Kang, David Karger, Joseph Chee Chang, Jonathan Bragg, Amy Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147447">Link</a></p>
<p>Abstract: In communities with social hierarchies, fear of judgment can discourage communication. While anonymity may alleviate some social pressure, fully anonymous spaces enable toxic behavior and hide the social context that motivates people to participate and helps them tailor their communication. We explore a design space of meronymous communication, where people can reveal carefully chosen aspects of their identity and also leverage trusted endorsers to gain credibility. We implemented these ideas in a system for scholars to meronymously seek and receive paper recommendations on Twitter and Mastodon. A formative study with 20 scholars confirmed that scholars see benefits to participating but are deterred due to social anxiety. From a month-long public deployment, we found that with meronymity, junior scholars could comfortably ask "newbie" questions and get responses from senior scholars who they normally found intimidating. Responses were also tailored to the aspects about themselves that junior scholars chose to reveal. </p>
<h3>Examining Voice Community Use</h3>
<p>Authors: Robin Brewer, Manahil Hashmi, Pooja Upadhyay, Sam Ankenbauer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150925">Link</a></p>
<p>Abstract: Visual online communities can present accessibility challenges to older adults or people with vision and motor disabilities. Motivated by this challenge, accessibility and HCI researchers have called for voice-based communities to support aging and disability. This paper extends prior work on voice community design and short-term use by providing empirical data on how people interact with voice communities over time and intentional instances of non-use. We conducted a one-year study with 43 blind and low vision older adults, of whom 21 used a voice-based community. We use vignettes to unpack five different voice community member roles - the obligatory poster, routine poster, cross-platform lurker, busy socialite, and visual expertise seeker - and discuss community interactions over time. Findings show how participation varied based on engagement in other communities and ways that participants sought interaction. We discuss (1) how to design voice communities for member roles and (2) the implications of synchronous and asynchronous voice community interaction in voice-only communities.</p>
<h3>Engaged and Affective Virtual Agents: Their Impact on Social Presence, Trustworthiness, and Decision-Making in the Group Discussion</h3>
<p>Authors: Hanseob Kim, MUHAMMAD FIRDAUS LUBIS, Jae-In Hwang, Jieun Kim, Gerard Kim, Bin Han</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147980">Link</a></p>
<p>Abstract: This study investigates how different virtual agent (VA) behaviors influence subjects' perceptions and group decision-making.</p>
<p>Participants carried out </p>
<p>experimental group discussions with a VA exhibiting varying levels of engagement and affective behavior.</p>
<p>Engagement refers to the VA's focus on the group task, whereas affective behavior reflects the VA's emotional state.</p>
<p>The findings revealed that VA's engagements effectively captured participants' attention even in the group setting and enhanced group synergy, thereby facilitating more in-depth discussion and producing better consensus.</p>
<p>On the other hand, VA's affective behavior negatively affected the</p>
<p>perceived social presence and trustworthiness. Consequently, </p>
<p>in the context of group discussion, participants preferred the engaged and non-affective VA to the non-engaged and affective VA.</p>
<p>The study provides valuable insights for improving the VA's behavioral design as a team member for collaborative tasks.</p>
<h2>Emotions and User Experience</h2>
<h3>EmoWear: Exploring Emotional Teasers for Voice Message Interaction on Smartwatches</h3>
<p>Authors: Zibo Zhang, Qingyuan Ma, Jiawen Zhu, Linghao Du, Che Yan, Jian Zhao, Pengcheng An, Yifei Yin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147276">Link</a></p>
<h3>ReactGenie: A Development Framework for Complex Multimodal Interactions Using Large Language Models</h3>
<p>Authors: Yuhan Zhang, Tianshi Li, Daniel Wan Rosli, Monica Lam, Yingtian Shi, James Landay, Karina Li, Jackie Yang, Shuning Zhang, Anisha Jain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147488">Link</a></p>
<h3>Investigating the Effects of Self-selected Pleasant Scents on Text Composition and Transcription Performance</h3>
<p>Authors: Wendy Haw, Kianna Ng, Yuan Ren, Ahmed Arif</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147458">Link</a></p>
<h3>Digital Knick-Knacks: Standalone Audiovisual Digital Possessions or Embellishments in Digital Environments</h3>
<p>Authors: Matthew Lakier, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147325">Link</a></p>
<h3>Frustration: Still a Common User Experience</h3>
<p>Authors: Kasper Hornbæk, Morten Hertzum</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150750">Link</a></p>
<h2>Environmental Activism</h2>
<h3>Eternagram: Probing Player Attitudes Towards Climate Change Using a ChatGPT-driven Text-based Adventure</h3>
<p>Authors: Jussi Holopainen, Qinshi Zhang, Latisha Besariani Hendra, Suifang Zhou, Pengfei Zhou, RAY LC</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147145">Link</a></p>
<h3>Technical Mentality: Principles for HCI Research and Practice</h3>
<p>Authors: Nadya Peek, Gabrielle Benabdallah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148115">Link</a></p>
<h3>Promoting Eco-Friendly Behaviour through Virtual Reality - Implementation and Evaluation of Immersive Feedback Conditions of a Virtual CO2 Calculator</h3>
<p>Authors: Stephanie Vogt, Nina Döllinger, Carolin Wienrich, David Obremski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148025">Link</a></p>
<h3>From Surplus and Scarcity towards Abundance: Understanding the Use of ICT in Food Resource Sharing Practices</h3>
<p>Authors: Volker Wulf, Dave Randall, Gunnar Stevens, Philip Engelbutzeder, Marvin Landwehr, Konstantin Aal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150852">Link</a></p>
<h3>Post-growth Human–Computer Interaction</h3>
<p>Authors: Neha Kumar, Bonnie Nardi, Vishal Sharma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150905">Link</a></p>
<h2>Health Ecosystems</h2>
<h3>Towards AI-Driven Healthcare: Systematic Optimization, Linguistic Analysis, and Clinicians’ Evaluation of Large Language Models for Smoking Cessation Interventions</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Emily Hébert, Michael Businelle, Chongle Pan, Darla Kendzor, Ruosi Shao, Jordan Neil, Yunlong Liu, Paul Calle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147450">Link</a></p>
<h3>PsiNet: Toward Understanding the Design of Brain-to-Brain Interfaces for Augmenting Inter-Brain Synchrony</h3>
<p>BEST_PAPER</p>
<p>Authors: Florian Mueller, Don Samitha Elvitigala, Nathan Semertzidis, Michaela Vranic-Peters, Aryan Saini, Xiao Fang, Rakesh Patibanda</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146996">Link</a></p>
<h3>Societal-Scale Human-AI Interaction Design? How Hospitals and Companies are Integrating Pervasive Sensing into Mental Healthcare</h3>
<p>Authors: Qian Yang, Meir Friedenberg, Angel Hsing-Chi Hwang, Dan Adler</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148145">Link</a></p>
<h3>Clinician-Facing AI in the Wild: Taking Stock of the Sociotechnical Challenges and Opportunities for HCI</h3>
<p>Authors: Tariq Andersen, Xiang Dai, Dana Li, Hubert Zając, Jonathan Frederik Carlsen, Finn Kensing</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150869">Link</a></p>
<h3>“We are Researchers, but we are also Humans”: Creating a Design Space for Managing Graduate Student Stress</h3>
<p>Authors: Stephen Voida, Fujiko Robledo Yamamoto, Amy Voida</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150823">Link</a></p>
<h2>Hybrid and Immersive Experiences</h2>
<h3>Factors Influencing Engagement in Hybrid Virtual and Augmented Reality</h3>
<p>Authors: Yue Li, Eugene Ch'ng, Sue Cobb</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150873">Link</a></p>
<p>Abstract: Hybridity in immersive technologies has not been studied for factors that are likely to influence engagement. A noticeable factor is the spatial enclosure that defines where users meet. This involves a mutual object of interest, contents that the users may generate around the object, and the proximity between users. This study examines these factors, namely how object interactivity, user-generated contents (UGC) and avatar proximity influence engagement. We designed a Hybrid Virtual and Augmented Reality (HVAR) environment that supports paired users to experience cultural heritage in both Virtual Reality (VR) and Augmented Reality (AR). A user study was conducted with 60 participants, providing assessments of engagement and presence via questionnaires, together with mobile electroencephalogram (mEEG) and user activity data that measures VR user engagement in real-time. Our findings provide insights into how engagement between users can occur in HVAR environments for the future hybrid reality with multi-device connectivity.</p>
<h3>Visual Noise Cancellation: Exploring Visual Discomfort and Opportunities for Vision Augmentations</h3>
<p>Authors: Jonathan Sutton, Tobias Langlotz, Holger Regenbrecht, Junlei Hong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150772">Link</a></p>
<p>Abstract: Acoustic noise control or cancellation (ANC) is a commonplace component of modern audio headphones. ANC aims to actively mitigate disturbing environmental noise for a quieter and improved listening experience. ANC is digitally controlling frequency and amplitude characteristics of sound. Much less explored is visual noise and active visual noise control, which we address here. We first explore visual noise and scenarios in which visual noise arises based on findings from four workshops we conducted. We then introduce the concept of visual noise cancellation (VNC) and how it can be used to reduce identified effects of visual noise. In addition, we developed head-worn demonstration prototypes to practically explore the concept of active VNC with selected scenarios in a user study. Finally, we discuss the application of VNC, including vision augmentations that moderate the user's view of the environment to address perceptual needs and to provide augmented reality content.</p>
<h3>\textit{Cohabitant}: The Design, Implementation, and Evaluation of a Virtual Reality Application for Interfaith Learning and Empathy Building</h3>
<p>Authors: Hasan Shahid Ferdous, Mohammad Rashidujjaman Rifat, Dina Sabie, Syed Ishtiaque Ahmed, Reem Ayad, Robert Soden, Bingjian Huang, Selin Okman, Ashratuz Zavin Asha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147831">Link</a></p>
<p>Abstract: Lack of interfaith communication often gives rise to prejudice and group-based conflict in multi-faith societies. Nurturing this communication via interfaith learning may reduce this conflict by fostering interfaith empathy. HCI has a dearth of knowledge on interfaith coexistence and empathy building. To address this gap, we present the design, implementation, and usability of \textit{Cohabitant}: a virtual reality (VR) application that promotes interfaith learning and empathy. \textit{Cohabitant}'s design is theoretically underpinned by Allport's intergroup contact theory and informed by insights from a participatory workshop we ran with members of three religious groups: Christians, Hindus, and Muslims. Our evaluation study, combining quantitative and qualitative data from 30 participants, suggests that \textit{Cohabitant} may enhance general interpersonal empathy, but falls short for ethnocultural empathy. We discuss the possible design and policy implications of using this kind of VR technology for interfaith learning and empathy building.</p>
<h3>Navigating the Virtual Gaze: Social Anxiety's Role in VR proxemics</h3>
<p>Authors: Pascal Knierim, Marissa Verbokkem, Beatriz Mello, Martin Dechant, Robin Welsch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148238">Link</a></p>
<p>Abstract: For individuals with Social Anxiety (SA), interacting with others can be a challenging experience, a concern that extends into the virtual world. While technology has made significant strides in creating more realistic virtual human agents (VHA), the interplay of gaze and interpersonal distance when interacting with VHAs is often neglected. This paper investigates the effect of dynamic and static Gaze animations in VHAs on interpersonal distance and their relation to SA. A Bayesian analysis shows that static centered and dynamic centering gaze led participants to stand closer to VHAs than static averted and dynamic averting gaze, respectively. In the static gaze conditions, this pattern was found to be reversed in SA: participants with higher SA kept larger distances for static-centered gaze than for averted gaze VHAs. These findings update theory, elucidate how nuanced interactions with VHAs must be designed, and offer renewed guidelines for pleasant VHA interaction design.</p>
<h2>Assistive Interactions: Audio Interactions and d/Deaf and Hard of Hearing Users</h2>
<h3>Audio Engineering by People Who Are deaf and Hard of Hearing: Balancing Confidence and Limitations</h3>
<p>Authors: Mark Cartwright, Keita Ohshiro</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146895">Link</a></p>
<h3>Look Once to Hear: Target Speech Hearing with Noisy Examples</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Bandhav Veluri, Takuya Yoshioka, Shyamnath Gollakota, Malek Itani, Tuochao Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147319">Link</a></p>
<h3>Communication, Collaboration, and Coordination in a Co-located Shared Augmented Reality Game: Perspectives From Deaf and Hard of Hearing People</h3>
<p>Authors: Nicolas LaLone, Garreth Tigwell, Samuli Laato, Jiangnan Xu, Michael Saker, Sanzida Mojib Luna, John Dunham, Alan Chamberlain, Yihong Wang, Konstantinos Papangelis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147649">Link</a></p>
<h3>"Voices Help Correlate Signs and Words": Analyzing Deaf and Hard-of-Hearing (DHH) TikTokers’ Content, Practices, and Pitfalls</h3>
<p>Authors: Jiaxun Cao, Fan Liang, Xin Tong, Xuening Peng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148325">Link</a></p>
<h2>Online Toxicity</h2>
<h3>Counterspeakers’ Perspectives: Unveiling Barriers and AI Needs in the Fight against Online Hate</h3>
<p>Authors: Jimin Mun, Cathy Buerger, Joshua Garland, Maarten Sap, Jenny Liang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147002">Link</a></p>
<h3>“Vulnerable, Victimized, and Objectified”: Understanding Ableist Hate and Harassment Experienced by Disabled Content Creators on Social Media</h3>
<p>Authors: Sharon Heung, Lucy Jiang, Shiri Azenkot, Aditya Vashistha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147153">Link</a></p>
<h3>"It’s Not What We Were Trying to Get At, but I Think Maybe It Should Be": Learning How to Do Trauma-Informed Design With a Data Donation Platform for Online Dating Sexual Violence</h3>
<p>Authors: Michele Parkhill, Emma Walquist, Isha Datey, Dongxiao Zhu, Douglas Zytko, Xiangyu Zhou, Kelly Berishaj, Melissa McDonald, Wenqi Zheng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147295">Link</a></p>
<h3>"I Got Flagged for Supposed Bullying, Even Though It Was in Response to Someone Harassing Me About My Disability.": A Study of Blind TikTokers’ Content Moderation Experiences</h3>
<p>Authors: Kelley Cotter, Anisa Callis, Yao Lyu, Jie Cai, John Carroll</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146733">Link</a></p>
<h3>Malicious Selling Strategies in Livestream E-commerce: A Case Study of Alibaba’s Taobao and ByteDance’s TikTok</h3>
<p>Authors: Zhicong Lu, Dakuo Wang, Qunfang Wu, Yisi Sang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150847">Link</a></p>
<h2>Knowledge Workers and Crowdworkers</h2>
<h3>"Are we all in the same boat?" Customizable and Evolving Avatars to Improve Worker Engagement and Foster a Sense of Community in Online Crowd Work</h3>
<p>Authors: Esra de Groot, Ujwal Gadiraju</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146646">Link</a></p>
<h3>How Low is Low? Crowdworker Perceptions of Microtask Payments in Work versus Leisure Situations</h3>
<p>Authors: Ling Jiang, Christian Wagner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147248">Link</a></p>
<h3>LabelAId: Just-in-time AI Interventions for Improving Human Labeling Quality and Domain Knowledge in Crowdsourcing Systems</h3>
<p>Authors: Zhihan Zhang, Michael Saugstad, Tim Althoff, Jon Froehlich, Vikram Iyer, Xiaoyu Huang, Esteban Safranchik, Chaitanyashareef Kulkarni, Chu Li, Shwetak Patel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147498">Link</a></p>
<h3>How Knowledge Workers Think Generative AI Will (Not) Transform Their Industries</h3>
<p>Authors: Jamila Smith-Loud, Patrick Kelley, Allison Woodruff, Renee Shelby, Lauren Wilcox, Steven Rousso-Schindler</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147564">Link</a></p>
<h3>“Sometimes it’s Like Putting the Track in Front of the Rushing Train”: Having to Be ‘On Call’ for Work Limits the Temporal Flexibility of Crowdworkers</h3>
<p>Authors: Duncan Brumby, Anna Cox, Sandy Gould, Laura Lascau</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150655">Link</a></p>
<h2>Mid-air Haptics</h2>
<h3>Designing Distinguishable Mid-Air Ultrasound Tactons with Temporal Parameters</h3>
<p>Authors: Gunhyuk Park, Hasti Seifi, Chungman Lim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147761">Link</a></p>
<h3>Controlled-STM: A two-stage model to predict user’s Perceived Intensity for Multi-point Spatiotemporal Modulation in Ultrasonic Mid-air Haptics</h3>
<p>Authors: Zhouyang Shen, Madhan Kumar Vasudevan, Diego Martinez Plasencia, Zak Morgan, Marianna Obrist</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147738">Link</a></p>
<h3>Designing Haptic Feedback for Sequential Gestural Inputs</h3>
<p>Authors: Shan Xu, Tovi Grossman, Carine Rognon, Daylon Walden, Sarah Sykes, Michael Glueck, Parastoo Abtahi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147360">Link</a></p>
<h3>Expressive, Scalable, Mid-Air Haptics with Synthetic Jets</h3>
<p>Authors: Vivian Shen, Chris Harrison, Craig Shultz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150752">Link</a></p>
<h2>Workers, Work Practices and AI</h2>
<h3>The Role of Inclusion, Control, and Ownership in Workplace AI-Mediated Communication</h3>
<p>Authors: Christin Munsch, Kowe Kadoma, Xiyu Fu, Marianne Aubin Le Quere, Danaë Metaxa, Mor Naaman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147700">Link</a></p>
<p>Abstract: Given large language models' (LLMs) increasing integration into workplace software, it is important to examine how biases in the models may impact workers. For example, stylistic biases in the language suggested by LLMs may cause feelings of alienation and result in increased labor for individuals or groups whose style does not match. We examine how such writer-style bias impacts inclusion, control, and ownership over the work when co-writing with LLMs. In an online experiment, participants wrote hypothetical job promotion requests using either hesitant or self-assured autocomplete suggestions from an LLM and reported their subsequent perceptions. We found that the style of the AI model did not impact perceived inclusion. However, individuals with higher perceived inclusion did perceive greater agency and ownership, an effect more strongly impacting participants of minoritized genders. Feelings of inclusion mitigated a loss of control and agency when accepting more AI suggestions.</p>
<h3>“There is a Job Prepared for Me Here”: Understanding How Short Video and Live-streaming Platforms Empower Ageing Job Seekers in China</h3>
<p>Authors: Bo Wen, PiaoHong Wang, Zhicong Lu, Siying Hu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147237">Link</a></p>
<p>Abstract: In recent years, the global unemployment rate has remained persistently high. Compounding this issue, the ageing population in China often encounters additional challenges in finding employment due to prevalent age discrimination in daily life. However, with the advent of social media, there has been a rise in the popularity of short videos and live-streams for recruiting ageing workers. To better understand the motivations of ageing job seekers to engage with these video-based recruitment methods and to explore the extent to which such platforms can empower them, we conducted an interview-based study with ageing job seekers who have had exposure to these short recruitment videos and live-streaming channels. Our findings reveal that these platforms can provide a job-seeking choice that is particularly friendly to ageing job seekers, effectively improving their disadvantaged situation.</p>
<h3>Deconstructing the Veneer of Simplicity: Co-Designing Introductory Generative AI Workshops with Local Entrepreneurs</h3>
<p>Authors: Glenn Ford, Michael Skirpan, Jeffrey Bigham, Angel Anderson, Yasmine Kotturi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147681">Link</a></p>
<p>Abstract: Generative AI platforms and features are permeating many aspects of work. Entrepreneurs from lean economies in particular are well positioned to outsource tasks to generative AI given limited resources. In this paper, we work to address a growing disparity in use of these technologies by building on a four-year partnership with a local entrepreneurial hub dedicated to equity in tech and entrepreneurship. Together, we co-designed an interactive workshops series aimed to onboard local entrepreneurs to generative AI platforms. Alongside four community-driven and iterative workshops with entrepreneurs across five months, we conducted interviews with 15 local entrepreneurs and community providers. We detail the importance of communal and supportive exposure to generative AI tools for local entrepreneurs, scaffolding actionable use (and supporting non-use), demystifying generative AI technologies by emphasizing entrepreneurial power, while simultaneously deconstructing the veneer of simplicity to address the many operational skills needed for successful application.</p>
<h3>How Do Data Analysts Respond to AI Assistance? A Wizard-of-Oz Study</h3>
<p>Authors: Tim Althoff, Jeffrey Heer, Madeleine Grunde-McLaughlin, Ken Gu, Andrew McNutt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146787">Link</a></p>
<p>Abstract: Data analysis is challenging as analysts must navigate nuanced decisions that may yield divergent conclusions. AI assistants have the potential to support analysts in planning their analyses, enabling more robust decision making. Though AI-based assistants that target code execution (e.g., Github Copilot) have received significant attention, limited research addresses assistance for both analysis execution and planning. In this work, we characterize helpful planning suggestions and their impacts on analysts’ workflows. We first review the analysis planning literature and crowd-sourced analysis studies to categorize suggestion content. We then conduct a Wizard-of-Oz study (n=13) to observe analysts’ preferences and reactions to planning assistance in a realistic scenario. Our findings highlight subtleties in contextual factors that impact suggestion helpfulness, emphasizing design implications for supporting different abstractions of assistance, forms of initiative, increased engagement, and alignment of goals between analysts and assistants.</p>
<h3>Building Knowledge through Action: Considerations for Machine Learning in the Workplace</h3>
<p>Authors: Siân Lindley, Denise Wilkins</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150819">Link</a></p>
<p>Abstract: Innovations in machine learning are enabling organisational knowledge bases to be automatically generated from working people’s activities. The potential for these to shift the ways in which knowledge is produced and shared raises questions about what types of knowledge might be inferred from working people’s actions, how these can be used to support work, and what the broader ramifications of this might be. This paper draws on findings from studies of (i) collaborative actions, and (ii) knowledge actions, to explore how these actions might (i) inform automatically generated knowledge bases, and (ii) be better supported through technological innovation. We triangulate findings to develop a framework of actions that are performed as part of everyday work, and use this to explore how mining those actions could result in knowledge being explicitly and implicitly contributed to a knowledge base. We draw on these possibilities to highlight implications and considerations for responsible design.</p>
<h2>Learning and Working</h2>
<h3>Contrasting Perspectives of Workers: Exploring Labor Relations in Workplace Automation and Potential Interventions</h3>
<p>Authors: Hee Rin Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147381">Link</a></p>
<h3>Designing Instructions using Self-Determination Theory to Improve Motivation and Engagement for Learning Craft</h3>
<p>Authors: Carsten Röcker, Gustavo Rovelo Ruiz, Hitesh Dhiman, Danny Leen, Raf Ramakers</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147763">Link</a></p>
<h3>Learning from Hybrid Craft: Investigating and Reflecting on Innovating and Enlivening Traditional Craft through Literature Review</h3>
<p>Authors: Li Huang, Guanhong Liu, Yuting Diao, Qingyuan Shi, Tianyu Yu, Zhijun Ma, Yuan Yao, Beituo Liu, Yuan-Ling Feng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147895">Link</a></p>
<h3>SharedNeRF: Leveraging Photorealistic and View-dependent Rendering for Real-time and Remote Collaboration</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Bala Kumaravel, Andrew Wilson, Mose Sakashita, Nicolai Marquardt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147720">Link</a></p>
<h3>Lessons Learnt from a Multimodal Learning Analytics Deployment In-the-wild</h3>
<p>Authors: Simon Buckingham Shum, Roberto Martinez-Maldonado, Lixiang Yan, Vanessa Echeverria, Dragan Gasevic, Samantha Dix, Gloria Fernandez-Nieto, Hollie Jaggard, Rosie Wotherspoon, Linxuan Zhao, Riordan Alfredo, Abra Osborne, Xinyu Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150775">Link</a></p>
<h2>Better Future Worlds and AI</h2>
<h3>How Culture Shapes What People Want From AI</h3>
<p>Authors: Hazel Rose Markus, Daigo Misaki, Chunchen Xu, Xiao Ge, Jeanne L. Tsai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148201">Link</a></p>
<p>Abstract: There is an urgent need to incorporate the perspectives of culturally diverse groups into AI developments. We present a novel conceptual framework for research that aims to expand, reimagine, and reground mainstream visions of AI using independent and interdependent cultural models of the self and the environment. Two survey studies support this framework and provide preliminary evidence that people apply their cultural models when imagining their ideal AI. Compared with European American respondents, Chinese respondents viewed it as less important to control AI and more important to connect with AI, and were more likely to prefer AI with capacities to influence. Reflecting both cultural models, findings from African American respondents resembled both European American and Chinese respondents. We discuss study limitations and future directions and highlight the need to develop culturally responsive and relevant AI to serve a broader segment of the world population.</p>
<h3>Charting the Future of AI in Project-Based Learning: A Co-Design Exploration with Students</h3>
<p>Authors: Kangyu Yuan, Shuai Ma, Reza Hadi Mogavi, Zhenhui Peng, Chengbo Zheng, Xiaojuan Ma, Bingcan Guo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147096">Link</a></p>
<p>Abstract: Students' increasing use of Artificial Intelligence (AI) presents new challenges for assessing their mastery of knowledge and skills in project-based learning (PBL). This paper introduces a co-design study to explore the potential of students' AI usage data as a novel material for PBL assessment. We conducted workshops with 18 college students, encouraging them to speculate an alternative world where they could freely employ AI in PBL while needing to report this process to assess their skills and contributions. Our workshops yielded various scenarios of students' use of AI in PBL and ways of analyzing such usage grounded by students' vision of how educational goals may transform. We also found that students with different attitudes toward AI exhibited distinct preferences in how to analyze and understand their use of AI. Based on these findings, we discuss future research opportunities on student-AI interactions and understanding AI-enhanced learning.</p>
<h3>Socio-technical Imaginaries: Envisioning and Understanding AI Parenting Supports through Design Fiction</h3>
<p>Authors: Petr Slovak, Melina Petsolari, Seray Ibrahim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147338">Link</a></p>
<p>Abstract: How might emerging modalities (e.g., NLP) be leveraged to transform the provision of parenting support? To explore the role of AI technologies in supporting parenting behaviour—and child-well-being—we surveyed 92 parents to gather their perspectives on nine future-oriented scenarios. We used Design Fiction and Speed Dating to understand parents needs and preferences around the design of agent-based supports. We explore the perceived benefits of AI assistants (i.e., receiving objective feedback, managing emotions and personalised guidance) and the most voiced concerns (i.e., AI undermining parental authority, replacing human interactions, and promoting lazy parenting). Finally, we highlight a number of plausible design directions based on the scenarios that parents were positive about.</p>
<h3>MindTalker: Navigating the Complexities of AI-Enhanced Social Engagement for People with Early-Stage Dementia</h3>
<p>Authors: Anna Xygkou, Chee Siang Ang, Alexandra Covaci, Jonasz Kopecki, Wan-Jou She, Eiman Kanjo, Panote Siriaraya</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146659">Link</a></p>
<p>Abstract: People living with dementia are at risk of social isolation, and conversational AI agents can potentially support such individuals by reducing their loneliness. In our study, a conversational AI agent, called MindTalker, co-designed with therapists and utilizing the GPT-4 Large Language Model (LLM), was developed to support people with early-stage dementia, allowing them to experience a new type of “social relationship” that could be extended to real life. Eight PwD engaged with MindTalker for one month or even longer, and data was collected from interviews. Our findings emphasized that participants valued the novelty of AI, but sought more consistent, deeper interactions. They desired a personal touch from AI, while stressing the irreplaceable value of human interactions. The findings underscore the complexities of AI engagement dynamics, where participants commented on the artificial nature of AI, highlighting important insights into the future design of conversational AI for this population.</p>
<h2>Microoganism and Fossil Interactions</h2>
<h3>Microbial Revolt: Redefining biolab tools and practices for more-than-human care ecologies</h3>
<p>Authors: Yuning Chen, Larissa Pschetz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147452">Link</a></p>
<h3>PaleoScan: Low-Cost Easy-to-Use High-Volume Fossil Scanning</h3>
<p>Authors: Yurii Piadyk, Akinobu Watanabe, Renan Alfredo Machado Bantim, Naiara Cipriano Oliveira, Otavio Gomes, Antonio Alamo Feitosa Saraiva, Maria Beatriz Silva, João Rulff, Flaviana Jorge de Lima, Daniele Panozzo, Claudio Silva</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147092">Link</a></p>
<h3>Go-Go Biome: Evaluation of a Casual Game for Gut Health Engagement and Reflection</h3>
<p>Authors: Elise van den Hoven, Jessica Danaher, Nandini Pasumarthy, Shreyas Nisal, Rohit Ashok Khot</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147393">Link</a></p>
<h3>(Re)activate, (Re)direct, (Re)arrange: Exploring the Design Space of Direct Interactions with Flavobacteria</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Holly McQuillan, Elvin Karana, Joana Martins, Clarice Risseeuw</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148167">Link</a></p>
<h2>Wellbeing and Mental Health A</h2>
<h3>On Stress: Combining Human Factors and Biosignals to Inform the Placement and Design of a Skin-like Stress Sensor</h3>
<p>Authors: Yasser Khan, Megan Chesnut, Jinxing Li, Pablo Paredes Castro, Zhenan Bao, Akshara Motani, Dalton Duvio, Leanne Williams, James Landay, Amir Foudeh, Jayoung Kim, Keith D. Sudheimer, Matthew Mauriello, Parsa Nowruzi, Jan Liphardt, Boris Murmann, Nicholas Vitale, Erika Shols, Grace Hon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147821">Link</a></p>
<h3>Reading Between the Lines: Identifying the Linguistic Markers of Anhedonia for the Stratification of Depression</h3>
<p>Authors: Bridianne O'Dea, Mark E Larsen, Taylor Braund, Philip J Batterham, Nick Glozier, Alexis E Whitton</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147595">Link</a></p>
<h3>"Waves Push Me to Slumberland": Reducing Pre-Sleep Stress through Spatio-Temporal Tactile Displaying of Music.</h3>
<p>Authors: Jianwei Zhang, Wanyi Wei, Huafeng Shan, Ruixiao Zheng, Shirao Yang, Hui Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146869">Link</a></p>
<h3>MoodCapture: Depression Detection using In-the-Wild Smartphone Images</h3>
<p>Authors: Shayan Mirjafari, Amanda Collins, Weichen Wang, Matthew Nemesure, Nicholas Jacobson, Michael Heinz, Damien Lekkas, Andrew Campbell, Tess Griffin, George Price, Subigya Nepal, Arvind Pillai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148165">Link</a></p>
<h3>Patient Acceptance of Self-Monitoring on a Smartwatch in a Routine Digital Therapy: A Mixed-Methods Study</h3>
<p>Authors: Gavin Doherty, Corina Sas, Derek Richards, Caroline Earley, Camille Nadal, Angel Enrique</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150631">Link</a></p>
<h2>Algorithmic Trust and Censorship</h2>
<h3>Dealing with Uncertainty: Understanding the Impact of Prognostic Versus Diagnostic Tasks on Trust and Reliance in Human-AI Decision Making</h3>
<p>Authors: Gaole He, Ujwal Gadiraju, Sara Salimzadeh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147300">Link</a></p>
<h3>Impact of Model Interpretability and Outcome Feedback on Trust in AI</h3>
<p>Authors: Daehwan Ahn, Abdullah Almaatouq, Kartik Hosanagar, Monisha Gulabani</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147213">Link</a></p>
<h3>Exposed or Erased: Algorithmic Censorship of Nudity in Art</h3>
<p>Authors: Thomas Hofmann, Nuria Oliver, Piera Riccio</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148324">Link</a></p>
<h3>Trust in AI-assisted Decision Making: Perspectives from Those Behind the System and Those for Whom the Decision is Made</h3>
<p>Authors: Oleksandra Vereschak, Gilles Bailly, Baptiste Caramiaux, Fatemeh Alizadeh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147306">Link</a></p>
<h3>Understanding Public Perceptions of AI Conversational Agents: A Cross-Cultural Analysis</h3>
<p>Authors: Anfan Chen, Zihan Liu, Renwen Zhang, Han Li, YI-CHIEH LEE</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148182">Link</a></p>
<h2>Chronic Conditions B</h2>
<h3>Charting the COVID Long Haul Experience - A Longitudinal Exploration of Symptoms, Activity, and Clinical Adherence</h3>
<p>Authors: Fen Lei Chang, Shaan Chopra, Fayika Farhat Nova, Shion Guha, Taha Liaqat, Jeanne Carroll, Tammy Toscos, Jessica Pater, Juliette Zaccour</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147234">Link</a></p>
<h3>Designing online peer support for parents of adolescents at risk of mental health challenges</h3>
<p>Authors: Marie B H Yap, Jue Xie, Dharshani Chandrasekara, Patrick Olivier, Roisin McNaney, Joshua Paolo Seguin, Ling Wu, Mairead Cardamone-Breen, Tom Bartindale</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147515">Link</a></p>
<h3>Co-designing Customizable Clinical Dashboards with Multidisciplinary Teams: Bridging the Gap in Chronic Disease Care</h3>
<p>Authors: Daniela Guerreiro, Diana Miranda, Tiago Reis, Margarida Móteiro, Alexandra Braz, Tiago Guerreiro, Filipa Pona-Ferreira, Rita Miranda, Rita Cardoso, Joana Ramalho, Mariana Leitão, Élia Decoroso, Diogo Branco, Joaquim J Ferreira, Verónica Caniça, Raquel Bouça-Machado, Joana Malheiro, Filipa Rato</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147322">Link</a></p>
<h3>Platforming PCOS Treatment Online: FemTech Logics of Care</h3>
<p>Authors: Preeti Mudliar, Taru Jain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146795">Link</a></p>
<h3>“Is it Even Giving the Correct Reading or Not?”: How Trust and Relationships Mediate Blood Pressure Management in India</h3>
<p>Authors: Mohit Jain, Indrani Medhi Thies, Nimisha Karnatak, Odeline Mateu-Silvernail, William Thies, Brooke Loughrin, Tiffany Kuo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150874">Link</a></p>
<h2>Conversational Agents</h2>
<h3>Apple’s Knowledge Navigator: Why Doesn’t that Conversational Agent Exist Yet?</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Stephen Gilbert, Maddie Sells, Arthur Perron, Mohammadamin Sanaei, Hila Sabouni, Amanda Newendorp, Katherine Nelson, Michael Dorneich, Nikoo Javadpour</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147981">Link</a></p>
<h3>Towards Designing a Question-Answering Chatbot for Online News: Understanding Questions and Perspectives</h3>
<p>Authors: Ayman Mahfuz, Md Naimul Hoque, Mayukha Kindi, Naeemul Hassan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147565">Link</a></p>
<h3>Cooking With Agents: Designing Context-aware Voice Interaction</h3>
<p>BEST_PAPER</p>
<p>Authors: Sabrina Zhong, Iona Gessinger, Duncan Brumby, Donald McMillan, Benjamin Cowan, Razan Jaber, Aida Hosseini, Sanna Kuoppamäki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147273">Link</a></p>
<h3>"It's a Fair Game", or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents</h3>
<p>Authors: Bingsheng Yao, Michelle Jia, Zhiping Zhang, Tianshi Li, Hao-Ping (Hank) Lee, Sauvik Das, Ada Lerner, Dakuo Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147902">Link</a></p>
<h3>Metaphors in Voice User Interfaces: A Slippery Fish</h3>
<p>Authors: Michael Twidale, Smit Desai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150773">Link</a></p>
<h2>Flavor and Food Interactions</h2>
<h3>FoodSkin: Fabricating Edible Gold Leaf Circuits on Food Surfaces</h3>
<p>Authors: Hiromi Nakamura, Kaori Ikematsu, Yuki Igarashi, Kunihiro Kato, Hinako Suzaki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148251">Link</a></p>
<h3>From Plating to Tasting: Towards Understanding the Choreography of Computational Food</h3>
<p>Authors: Florian Mueller, Patrick Olivier, Nathalie Overdevest, Jialin Deng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147646">Link</a></p>
<h3>Füpop: "Real Food" Flavor Delivery via Focused Ultrasound</h3>
<p>Authors: Alexis Kim, Szu Ting Tung, Katherine Song, Eric Paulos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147226">Link</a></p>
<h2>Haptics: Electrical Stimulation</h2>
<h3>Understanding User Acceptance of Electrical Muscle Stimulation in Human-Computer Interaction</h3>
<p>Authors: Stefan Schneegass, Sarah Faltaous, Julie Williamson, Jonas Keppel, Max Pfeiffer, Marion Koelle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147978">Link</a></p>
<h3>Designing Unobtrusive Modulated Electrotactile Feedback on Fingertip Edge to Assist Blind and Low Vision (BLV) People in Comprehending Charts</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Emily Kuang, Mingming Fan, Kaihao Zhang, Chutian Jiang, Junan Xie, Yinan FAN</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147036">Link</a></p>
<h3>TacTex: A Textile Interface with Seamlessly-Integrated Electrodes for High-Resolution electrotactile Stimulation</h3>
<p>Authors: Teng Han, Qi Wang, Hongnan Lin, Guanyun Wang, Feng Tian, Shengsheng Jiang, Wei Sun, Xuanyou Liu, Ye Tao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146969">Link</a></p>
<h3>Paired-EMS: Enhancing Electrical Muscle Stimulation (EMS)-based Force Feedback Experience by Stimulating Both Muscles in Antagonistic Pairs</h3>
<p>Authors: Chia-Yu Cheng, Sitaresmi Handani, Mike Chen, Avijit Balabantaray, Yu Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146902">Link</a></p>
<h2>Mental Health B</h2>
<h3>Exploring Context-Aware Mental Health Self-Tracking Using Multimodal Smart Speakers in Home Environments</h3>
<p>Authors: Uichin Lee, Youngji Koh, Jieun Lim, Auk Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147776">Link</a></p>
<h3>Co-designing the Collaborative Digital Musical Instruments for Group Music Therapy</h3>
<p>Authors: Yuting Diao, Yuan Yao, Haipeng Mi, Zhaoguo Wang, Yu Peng, Hanxuan Li, Yuan-Ling Feng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147511">Link</a></p>
<h3>Approaches for tailoring between-session mental health therapy activities</h3>
<p>Authors: Patricia Arean, Bruna Oewel, Elena Agapie</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147860">Link</a></p>
<h3>Challenges and Opportunities for the Design of Inclusive Digital Mental Health Tools: Understanding Culturally Diverse Young People's Experiences</h3>
<p>Authors: Chengcheng Qu, Ewan Soubutts, Paul Marshall, Pranita Shrestha, Roisin McNaney, Brittany Davidson, Aaron Sefi, Charlotte Mindel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146990">Link</a></p>
<h3>Feeling Stressed and Unproductive? A Field Evaluation of a Therapy-Inspired Digital Intervention for Knowledge Workers</h3>
<p>Authors: Liisa Holsti, Thomas Fritz, Joanna McGrenere, Skye Barbic, Kevin Chow</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150820">Link</a></p>
<h2>Reproductive Rights and Privacy</h2>
<h3>Unpacking the Lived Experience of Collaborative Pregnancy Tracking</h3>
<p>Authors: Yunan Chen, Elena Agapie, Xi Lu, Jacquelyn Powell, Daniel Epstein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148254">Link</a></p>
<h3>“Our Users' Privacy is Paramount to Us”: A Discourse Analysis of How Period and Fertility Tracking App Companies Address the Roe v Wade Overturn</h3>
<p>Authors: Rie Helene (Lindy) Hernandez, Qiurong Song, Xinning Gui, Yubo Kou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146889">Link</a></p>
<h3>"I Deleted It After the Overturn of Roe v. Wade": Understanding Women's Privacy Concerns Toward Period-Tracking Apps in the Post Roe v. Wade Era</h3>
<p>Authors: Pardis Emami-Naeini, Hiba Laabadli, Jiaxun Cao, Chase Mathis, Rebecca Stern</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147370">Link</a></p>
<h3>Teen Reproductive Health Information Seeking and Sharing Post-Roe</h3>
<p>Authors: Nora McDonald, Umama Dewan, Cora Sula</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146968">Link</a></p>
<h3>“I Did Watch ‘The Handmaid’s Tale’”: Threat Modeling Privacy Post-Roe in the United States</h3>
<p>Authors: Nora McDonald, Nazanin Andalibi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150756">Link</a></p>
<h2>Universal Accessibility B</h2>
<h3>RASSAR: Room Accessibility and Safety Scanning in Augmented Reality</h3>
<p>Authors: Kaiming Cheng, Xia Su, Jon Froehlich, Qiaochu LIU, Jaewook Lee, Han Zhang, Wyatt Olson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148045">Link</a></p>
<h3>A Design Space for Vision Augmentations and Augmented Human Perception using Digital Eyewear</h3>
<p>Authors: Jonathan Sutton, Tobias Langlotz, Holger Regenbrecht</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147983">Link</a></p>
<h3>“I never realized sidewalks were a big deal”: A Case Study of a Community-Driven Sidewalk Accessibility Assessment using Project Sidewalk</h3>
<p>Authors: Michael Saugstad, Judy Shanley, Yochai Eisenberg, Jon Froehlich, Katrina Ma, Devon Snyder, Molly Delaney, Delphine Labbé, Kie Fujii, Chu Li, Florian P Thomas</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147783">Link</a></p>
<h3>A Virtual Reality Scene Taxonomy: Identifying and Designing Accessible Scene-Viewing Techniques</h3>
<p>Authors: Martez Mott, Sasa Junuzovic, Rachel Franz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150645">Link</a></p>
<h2>Learning Programming with AI</h2>
<h3>How Beginning Programmers and Code LLMs (Mis)read Each Other</h3>
<p>Authors: Molly Feldman, Hannah McLean Babe, Carolyn Anderson, Sydney Nguyen, Arjun Guha, Yangtian Zi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146777">Link</a></p>
<p>Abstract: Generative AI models, specifically large language models (LLMs), have made strides towards the long-standing goal of text-to-code generation. This progress has invited numerous studies of user interaction. However, less is known about the struggles and strategies of non-experts, for whom each step of the text-to-code problem presents challenges: describing their intent in natural language, evaluating the correctness of generated code, and editing prompts when the generated code is incorrect. This paper presents a large-scale controlled study of how 120 beginning coders across three academic institutions approach writing and editing prompts. A novel experimental design allows us to target specific steps in the text-to-code process and reveals that beginners struggle with writing and editing prompts, even for problems at their skill level and when correctness is automatically determined. Our mixed-methods evaluation provides insight into student processes and perceptions with key implications for non-expert Code LLM use within and outside of education.</p>
<h3>Teach AI How to Code: Using Large Language Models as Teachable Agents for Programming Education</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Seonghee Lee, Hyungyu Shin, Hyoungwook Jin, Juho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148146">Link</a></p>
<p>Abstract: This work investigates large language models (LLMs) as teachable agents for learning by teaching (LBT). LBT with teachable agents helps learners identify knowledge gaps and discover new knowledge. However, teachable agents require expensive programming of subject-specific knowledge. While LLMs as teachable agents can reduce the cost, LLMs' expansive knowledge as tutees discourages learners from teaching. We propose a prompting pipeline that restrains LLMs' knowledge and makes them initiate "why" and "how" questions for effective knowledge-building. We combined these techniques into TeachYou, an LBT environment for algorithm learning, and AlgoBo, an LLM-based tutee chatbot that can simulate misconceptions and unawareness prescribed in its knowledge state. Our technical evaluation confirmed that our prompting pipeline can effectively configure AlgoBo's problem-solving performance. Through a between-subject study with 40 algorithm novices, we also observed that AlgoBo's questions led to knowledge-dense conversations (effect size=0.71). Lastly, we discuss design implications, cost-efficiency, and personalization of LLM-based teachable agents.</p>
<h3>ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12</h3>
<p>Authors: Liuqing Chen, Yaxuan Song, Yunnong Chen, Shuhong Xiao, Lingyun Sun, Ruoyu Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147770">Link</a></p>
<p>Abstract: As Computational Thinking (CT) continues to permeate younger age groups in K-12 education, established CT platforms such as Scratch face challenges in catering to these younger learners, particularly those in the elementary school (ages 6-12). Through formative investigation with Scratch experts, we uncover three key obstacles to children's autonomous Scratch learning: artist's block in project planning, bounded creativity in asset creation, and inadequate coding guidance during implementation. To address these barriers, we introduce ChatScratch, an AI-augmented system to facilitate autonomous programming learning for young children. ChatScratch employs structured interactive storyboards and visual cues to overcome artist's block, integrates digital drawing and advanced image generation technologies to elevate creativity, and leverages Scratch-specialized Large Language Models (LLMs) for professional coding guidance. Our study shows that, compared to Scratch, ChatScratch efficiently fosters autonomous programming learning, and contributes to the creation of high-quality, personally meaningful Scratch projects for children.</p>
<h3>“It’s Weird That it Knows What I Want”: Usability and Interactions with Copilot for Novice Programmers</h3>
<p>Authors: Paul Denny, Garrett Powell, James Prather, Brent Reeves, Brett Becker, Juho Leinonen, Andrew Luxton-Reilly, James Finnie-Ansley, Eddie Antonio Santos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150774">Link</a></p>
<p>Abstract: Recent developments in deep learning have resulted in code-generation models that produce source code from natural language and code-based prompts with high accuracy. This is likely to have profound effects in the classroom, where novices learning to code can now use free tools to automatically suggest solutions to programming exercises and assignments. However, little is currently known about how novices interact with these tools in practice. We present the first study that observes students at the introductory level using one such code auto-generating tool, Github Copilot, on a typical introductory programming (CS1) assignment. Through observations and interviews we explore student perceptions of the benefits and pitfalls of this technology for learning, present new observed interaction patterns, and discuss cognitive and metacognitive difficulties faced by students. We consider design implications of these findings, specifically in terms of how tools like Copilot can better support and scaffold the novice programming experience.</p>
<h2>Research Methods and Tools A</h2>
<h3>Designing a Card-Based Design Tool to Bridge Academic Research &amp; Design Practice For Societal Resilience</h3>
<p>BEST_PAPER</p>
<p>Authors: Chia-Fang Chung, Kay Connelly, Clara Caldeira, Novia Nurain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147574">Link</a></p>
<h3>Playing with Perspectives and Unveiling the Autoethnographic Kaleidoscope in HCI – A Literature Review of Autoethnographies</h3>
<p>Authors: Johannes Schöning, Annika Kaltenhauser, Evropi Stefanidi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148280">Link</a></p>
<h3>The Future of HCI-Policy Collaboration</h3>
<p>Authors: Steven Jackson, Thomas Gilbert, Qian Yang, Sabine Junginger, John Zimmerman, Richmond Wong, Margaret Hagan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147277">Link</a></p>
<h3>DiaryHelper: Exploring the Use of an Automatic Contextual Information Recording Agent for Elicitation Diary Study</h3>
<p>Authors: Junze Li, Changyang He, Xiaojuan Ma, Alon Halevy, Jiaxiong Hu, Boyang Jia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147624">Link</a></p>
<h3>CoAIcoder: Examining the Effectiveness of AI-assisted Human-to-Human Collaboration in Qualitative Analysis</h3>
<p>Authors: Simon Perrault, Jie Gao, Roy Ka-Wei Lee, Kenny Tsu Wei Choo, Junming Cao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150647">Link</a></p>
<h2>AI for Researchers and Educators</h2>
<h3>PaperWeaver: Enriching Topical Paper Alerts by Contextualizing Recommended Papers with User-collected Papers</h3>
<p>Authors: Pao Siangliulue, Matt Latzke, Hyeonsu Kang, Joseph Chee Chang, Jonathan Bragg, Juho Kim, Yoonjoo Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147172">Link</a></p>
<p>Abstract: With the rapid growth of scholarly archives, researchers subscribe to "paper alert" systems that periodically provide them with recommendations of recently published papers that are similar to previously collected papers. However, researchers sometimes struggle to make sense of nuanced connections between recommended papers and their own research context, as existing systems only present paper titles and abstracts. To help researchers spot these connections, we present PaperWeaver, an enriched paper alerts system that provides contextualized text descriptions of recommended papers based on user-collected papers. PaperWeaver employs a computational method based on Large Language Models (LLMs) to infer users’ research interests from their collected papers, extract context-specific aspects of papers, and compare recommended and collected papers on these aspects. Our user study (N=15) showed that participants using PaperWeaver were able to better understand the relevance of recommended papers and triage them more confidently when compared to a baseline that presented the related work sections from recommended papers.</p>
<h3>Integrating measures of replicability into scholarly search: Challenges and opportunities</h3>
<p>Authors: Sarah Rajtmajer, Tatiana Chakravorti, John Carroll, Chuhao Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146636">Link</a></p>
<p>Abstract: Challenges to reproducibility and replicability have gained widespread attention, driven by large replication projects with lukewarm success rates. A nascent work has emerged developing algorithms to estimate the replicability of published findings. The current study explores ways in which AI-enabled signals of confidence in research might be integrated into the literature search. We interview 17 PhD researchers about their current processes for literature search and ask them to provide feedback on a replicability estimation tool. Our findings suggest that participants tend to confuse replicability with generalizability and related concepts. Information about replicability can support researchers throughout the research design processes. However, the use of AI estimation is debatable due to the lack of explainability and transparency. The ethical implications of AI-enabled confidence assessment must be further studied before such tools could be widely accepted. We discuss implications for the design of technological tools to support scholarly activities and advance replicability.</p>
<h3>How AI Processing Delays Foster Creativity: Exploring Research Question Co-Creation with an LLM-based Agent</h3>
<p>Authors: Andrew Mo, Yun Huang, Yiren Liu, Xiao Ran, Mengxia Yu, Haocong Cheng, Si Chen, Yiliu Tang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146979">Link</a></p>
<p>Abstract: Developing novel research questions (RQs) often requires extensive literature reviews, especially in interdisciplinary fields. To support RQ development through human-AI co-creation, we leveraged Large Language Models (LLMs) to build an LLM-based agent system named CoQuest. We conducted an experiment with 20 HCI researchers to examine the impact of two interaction designs: breadth-first and depth-first RQ generation. The findings revealed that participants perceived the breadth-first approach as more creative and trustworthy upon task completion. Conversely, during the task, participants considered the depth-first generated RQs as more creative. Additionally, we discovered that AI processing delays allowed users to reflect on multiple RQs simultaneously, leading to a higher quantity of generated RQs and an enhanced sense of control. Our work makes both theoretical and practical contributions by proposing and evaluating a mental model for human-AI co-creation of RQs. We also address potential ethical issues, such as biases and over-reliance on AI, advocating for using the system to improve human research creativity rather than automating scientific inquiry. The system’s source is available at: https://github.com/yiren-liu/coquest.</p>
<h3>"This is not a data problem": Algorithms and Power in Public Higher Education in Canada</h3>
<p>Authors: Kelly McConvey, Shion Guha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147823">Link</a></p>
<p>Abstract: Algorithmic decision-making is increasingly being adopted across public higher education. The expansion of data-driven practices by post-secondary institutions has occurred in parallel with the adoption of New Public Management approaches by neoliberal administrations. In this study, we conduct a qualitative analysis of an in-depth ethnographic case study of data and algorithms in use at a public college in Ontario, Canada. We identify the data, algorithms, and outcomes in use at the college. We assess how the college's processes and relationships support those outcomes and the different stakeholders' perceptions of the college's data-driven systems. In addition, we find that the growing reliance on algorithmic decisions leads to increased student surveillance, exacerbation of existing inequities, and the automation of the faculty-student relationship. Finally, we identify a cycle of increased institutional power perpetuated by algorithmic decision-making, and driven by a push towards financial sustainability.</p>
<h3>PaperPlain: Making Medical Research Papers Approachable to Healthcare Consumers with Natural Language Processing</h3>
<p>Authors: Tal August, Jonathan Bragg, Kyle Lo, Andrew Head, Marti Hearst, Lucy Lu Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150900">Link</a></p>
<p>Abstract: When seeking information not covered in patient-friendly documents, healthcare consumers may turn to the research literature. Reading medical papers, however, can be a challenging experience. To improve access to medical papers, we introduce a novel interactive interface---Paper Plain---with four features enabled by natural language processing: definitions of unfamiliar terms, in-situ plain language section summaries, a collection of key questions that guides readers to answering passages, and plain language summaries of those passages. We evaluate Paper Plain, finding that participants who used Paper Plain had an easier time reading research papers without a loss in paper comprehension compared to those who used a typical PDF reader. Altogether, the study results suggest that guiding readers to relevant passages and providing plain language summaries alongside the original paper content can make reading medical papers easier and give readers more confidence to approach these papers.</p>
<h2>Crisis Informatics</h2>
<h3>Choosing the Right Reality: A Comparative Analysis of Tangibility in Immersive Trauma Simulations</h3>
<p>Authors: Benjamin Schuster, Rodrigo Gutierrez, Helmut Schrom-Feiertag, Georg Regal, Manfred Tscheligi, Jakob Uhl</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147464">Link</a></p>
<h3>Comparison of Spatial Visualization Techniques for Radiation in Augmented Reality</h3>
<p>Authors: Joan Baixauli, Roderick McCall, Fintan McGee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146651">Link</a></p>
<h3>Exploring the Design Space of Optical See-through AR Head-Mounted Displays to Support First Responders in the Field</h3>
<p>Authors: Lance Hartung, Kexin Zhang, Ruijia Chen, Kevin Ponto, Yuhang Zhao, Bryce Sprecher, Brianna Cochran, Ross Tredinnick, Suman Banerjee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146943">Link</a></p>
<h3>Transitioning Cognitive Aids into Decision Support Platforms: Requirements and Design Guidelines</h3>
<p>Authors: Aleksandra Sarcevic, Angela Mastrianni, Randall Burd, Allison Hu, Sarah Gao, Lynn Almengor, Peyton Tempel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150760">Link</a></p>
<h2>Curating Online Content B</h2>
<h3>Bystanders of Online Moderation: Examining the Effects of Witnessing Post-Removal Explanations</h3>
<p>Authors: Himanshu Rathi, Koustuv Saha, Shagun Jhaver</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148129">Link</a></p>
<h3>Community Begins Where Moderation Ends: Peer Support and Its Implications for Community-Based Rehabilitation</h3>
<p>Authors: Zinan Zhang, Yingfan Zhou, Renkai Ma, Xinning Gui, Yubo Kou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146823">Link</a></p>
<h3>Agency Aspirations: Understanding Users’ Preferences And Perceptions Of Their Role In Personalised News Curation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ewa Luger, John Vines, Michael Evans, Anna Rezk, Auste Simkute, Chris Elsden, Rhianne Jones</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147968">Link</a></p>
<h3>Wikibench: Community-Driven Data Curation for AI Evaluation on Wikipedia</h3>
<p>Authors: Kenneth Holstein, Haiyi Zhu, Zirui Cheng, Aaron Halfaker, Jiwoo Kim, Tongshuang Wu, Tzu-Sheng Kuo, Meng-Hsin Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146778">Link</a></p>
<h3>Empirical Investigation of Accessibility Bug Reports in Mobile Platforms: A Chromium Case Study</h3>
<p>Authors: Wajdi Aljedaani, Mohamed Wiem Mkaouer, Marouane Kessentini, Marcelo Eler</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147552">Link</a></p>
<h2>Body and Wellbeing</h2>
<h3>Critiquing Menstrual Pain Technologies through the Lens of Feminist Disability Studies</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Marianela Ciolfi Felice, Joo Young Park, Madeline Balaam, Nadia Campo Woytuk, Stacy Hsueh, Xuni Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147659">Link</a></p>
<h3>Enhancing Auto-Generated Baseball Highlights via Win Probability and Bias Injection Method</h3>
<p>Authors: Bongwon Suh, Kieun Park, Hajin Lim, Joonhwan Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146747">Link</a></p>
<h3>Understanding the Effect of Reflective Iteration on Individuals’ Physical Activity Planning</h3>
<p>Authors: Kefan Xu, Mark Newman, Xinghui (Erica) Yan, Myeonghan Ryu, Rosa Arriaga</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148178">Link</a></p>
<h3>Sensible and Sensitive AI for Worker Wellbeing: Factors that Inform Adoption and Resistance for Information Workers</h3>
<p>BEST_PAPER</p>
<p>Authors: Munmun De Choudhury, Lan Gao, Gregory Abowd, Vedant Das Swain, Abhirup Mondal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146807">Link</a></p>
<h3>Thrown from Normative Ground: Exploring the Potential of Disorientation as a Critical Methodological Strategy in HCI</h3>
<p>Authors: Heidi Biggs, Shaowen Bardzell</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147235">Link</a></p>
<h2>Fabrication and Dynamic Structures</h2>
<h3>Reconfigurable Interfaces by Shape Change and Embedded Magnets</h3>
<p>Authors: Andrea Bianchi, Clement Zheng, Kongpyung (Justin) Moon, Jeeeun Kim, Himani Deshpande, Bo Han</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147224">Link</a></p>
<h3>ConeAct: A Multistable Actuator for Dynamic Materials</h3>
<p>Authors: Yash Rajeev Banka, Yuyu Lin, Jesse Gonzalez, Alexandra Ion, Zhitong Cui</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147261">Link</a></p>
<h3>TensionFab: Fabrication of Room-scale Surface Structures From the Tension-Active Form of Planar Modules</h3>
<p>Authors: Ziyuan Jiang, Yahui Lyu, Alessandro Garzanti, Carlos Garcia Fernandez, Taiga Urata, Yasuaki Kakehi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146649">Link</a></p>
<h3>Robotic Metamaterials: A Modular System for Hands-On Configuration of Ad-Hoc Dynamic Applications</h3>
<p>Authors: Violet Yinuo Han, Alan Zhu, Shuhong Wang, Willa Yunqi Yang, Tucker Rae-Grant, Alexandra Ion, Scott Hudson, Zhitong Cui</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147544">Link</a></p>
<h3>Nothing Like Compilation: How Professional Digital Fabrication Workflows Go Beyond Extruding, Milling, and Machines</h3>
<p>Authors: Nadya Peek, Gabrielle Benabdallah, Jennifer Jacobs, Mare Hirsch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/156318">Link</a></p>
<h2>Indigeonus Communities and Cutural Heritage A</h2>
<h3>Griot-Style Methodology: Longitudinal Study of Navigating Design With Unwritten Stories</h3>
<p>Authors: Lindah Kotut, Morva Saaty, Derek Haqq, Taha Hassan, Neelma Bhatti</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147144">Link</a></p>
<h3>Where Generalized Equitable Design Practice Meet Specific Indigenous Communities</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Kari Noe, Nurit Kirshenbaum</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148185">Link</a></p>
<h3>Critical Heritage Studies as a Lens to Understand Short Video Sharing of Intangible Cultural Heritage on Douyin</h3>
<p>Authors: Minzhu Zhao, Wanyang Hu, Huanchen Wang, Zhicong Lu, Yuxin Ma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147828">Link</a></p>
<h3>Cultivating Spoken Language Technologies for Unwritten Languages</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ondrej Klejch, Simon Robinson, Jennifer Pearson, Dani Kalarikalayil Raju, Peter Bell, Electra Wallington, Thomas Reitmaier, Matt Jones, Nina Markl</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147443">Link</a></p>
<h2>Indigeonus Communities and Cutural Heritage B</h2>
<h3>Partiality and Misconception: Investigating Cultural Representativeness in Text-to-Image Models</h3>
<p>Authors: Lili Zhang, Zaijia Yang, Qiuling Yang, Deshun Li, Chunjie Wang, Baihang Gao, Xi Liao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148011">Link</a></p>
<h3>Examining the "Local" in ICT4D: A Postcolonial Perspective on Participation</h3>
<p>Authors: Pedro Ferreira</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146929">Link</a></p>
<h3>On the Role of Materials Experience for Novel Interactions with Digital Representations of Historical Pop-up and Movable Books</h3>
<p>Authors: Stefano Parisi, Jeff Love, Elvin Karana, Willemijn Elkhuizen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147645">Link</a></p>
<h3>Cosmovision Of Data: An Indigenous Approach to Technologies for Self-Determination</h3>
<p>BEST_PAPER</p>
<p>Authors: Larissa Pschetz, Carlos Guerrero Millan, Bettina Nissen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148200">Link</a></p>
<h2>Learning and Teaching Technologies C</h2>
<h3>Enhancing ESL Learners' Experience and Performance through Gradual Adjustment of Video Speed during Extensive Viewing</h3>
<p>Authors: Fu-Yin Cherng, Yu-Jung Chung, Chen-Wei Hsu, Meng-Hsun Chan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147456">Link</a></p>
<h3>A Piece of Theatre: Investigating How Teachers Design LLM Chatbots to Assist Adolescent Cyberbullying Education</h3>
<p>Authors: Xinda Ma, Qian Yang, Natalie Bazarova, Ryun Shim, Michael Hedderich, Wenting Zou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147517">Link</a></p>
<h3>Morphing Matter for Teens: Research Processes as a Template for Cross-Disciplinary Activities</h3>
<p>Authors: Sunniva Liu, Alisha Collins, Harshika Jain, Melinda Chen, Lining Yao, Lea Albaugh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147219">Link</a></p>
<h3>Toward Supporting Adaptation: Exploring Affect’s Role in Cognitive Load when Using a Literacy Game</h3>
<p>Authors: Gisele Arevalo, Carrie Demmans Epp, Sin Sze Tang, Genaro Rebolledo Mendez, Yalmaz Abdullah, Minghao Cai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147807">Link</a></p>
<h3>Time-Turner: A Bichronous Learning Environment to Support Positive In-class Multitasking of Online Learners</h3>
<p>BEST_PAPER</p>
<p>Authors: Sahar Mavali, Sidney Fels, Dongwook Yoon, Luanne Sinnamon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147103">Link</a></p>
<h2>Movement and Motor Learning A</h2>
<h3>Real-time 3D Target Inference via Biomechanical Simulation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Chenyu Li, Yi-Chi Liao, Hee-Seung Moon, Byungjoo Lee, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147400">Link</a></p>
<h3>WAVE: Anticipatory Movement Visualization for VR Dancing</h3>
<p>Authors: Monica Tamariz, Nadia Ady, Perttu Hämäläinen, Markus Laattala, Roosa Piitulainen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147795">Link</a></p>
<h3>Designing for Human Operations on the Moon: Challenges and Opportunities of Navigational HUD Interfaces</h3>
<p>Authors: Paul Demedeiros, Aidan Cowley, Andreas Gerndt, Michael Preutenborbeck, Tommy Nilsson, Georgia Albuquerque, Nicolas Herzberger, Frank Flemisch, Jan Wulkop, Florian Dufresne, Leonie Bensch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148215">Link</a></p>
<h3>Watch This! Observational Learning in VR Promotes Better Far Transfer than Active Learning for a Fine Psychomotor Task</h3>
<p>Authors: Michael Proulx, Manoela Milena Oliveira da Silva, Christopher Clarke, Christof Lutteroth, Elizabeth Dark, Isabel Fitton, Jeremy Dalton</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146854">Link</a></p>
<h2>Movement and Motor Learning B</h2>
<h3>Metrics of Motor Learning for Analyzing Movement Mapping in Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Difeng Yu, Mark Schram Christensen, Joanna Bergström, Mantas Cibulskis, Erik Mortensen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147038">Link</a></p>
<h3>WieldingCanvas: Interactive Sketch Canvases for Freehand Drawing in VR</h3>
<p>Authors: Teng Han, Can Liu, Mingming Fan, Feng Tian, Tianren Luo, Zitao Liu, Mi Tian, Zhenxuan He, Xiaohui Tan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147341">Link</a></p>
<h3>Better Definition and Calculation of Throughput and Effective Parameters for Steering to Account for Subjective Speed-accuracy Tradeoffs</h3>
<p>Authors: Yosuke Oba, Homei Miyashita, Nobuhito Kasahara, Wolfgang Stuerzlinger, Anil Ufuk Batmaz, Shota Yamanaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147190">Link</a></p>
<h3>Design Space of Visual Feedforward And Corrective Feedback in XR-Based Motion Guidance Systems</h3>
<p>Authors: Michael Sedlmair, Benjamin Lee, Xingyao Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147637">Link</a></p>
<h2>Privacy in Real Contexts</h2>
<h3>An Investigation of US Universities' Implementation of FERPA Student Directory Policies and Student Privacy Preferences</h3>
<p>Authors: Katherine Quintanilla, Sarah Radway, Cordelia Ludden, Daniel Votipka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146893">Link</a></p>
<h3>Out-of-Device Privacy Unveiled: Designing and Validating the Out-of-Device Privacy Scale (ODPS)</h3>
<p>Authors: Habiba Farzand, Karola Marky, Mohamed Khamis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147478">Link</a></p>
<h3>"We Have No Security Concerns": Understanding the Privacy-Security Nexus in Telehealth for Audiologists and Speech-Language Pathologists</h3>
<p>Authors: Josiah Dykstra, Prashanth Rajivan, Faiza Tazi, Sanchari Das</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147706">Link</a></p>
<h3>On the Feasibility of Predicting Users' Privacy Concerns using Contextual Labels and Personal Preferences</h3>
<p>Authors: yaqing YANG, Tony Li, Haojian Jin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147126">Link</a></p>
<h2>Designing for Privacy</h2>
<h3>Encoding Privacy: Sociotechnical Dynamics of Data Protection Compliance Work</h3>
<p>Authors: Rohan Grover</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147127">Link</a></p>
<h3>Redesigning Privacy with User Feedback: The Case of Zoom Attendee Attention Tracking</h3>
<p>Authors: Tony Li, Arshia Arya, Haojian Jin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148211">Link</a></p>
<h3>Designing Accessible Obfuscation Support for Blind Individuals’ Visual Privacy Management</h3>
<p>Authors: Lotus Zhang, Tanusree Sharma, Inan Xu, Leah Findlater, Yang Wang, Yu-Yun Tseng, Abigale Stangl, Danna Gurari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147347">Link</a></p>
<h3>An Empathy-Based Sandbox Approach to Bridge the Privacy Gap among Attitudes, Goals, Knowledge, and Behaviors</h3>
<p>Authors: Weijun Li, Toby Li, Chaoran Chen, Wenxin Song, Yaxing Yao, Yanfang Ye</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146765">Link</a></p>
<h2>Social Activism A</h2>
<h3>"We happen to be different and different is not bad": Designing for Intersectional Fat-Positive Information-Seeking</h3>
<p>Authors: Kelley Cotter, Ankolika De, Rebecca Jonas</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147459">Link</a></p>
<h3>Negotiating Sociotechnical Boundaries: Moderation Work to Counter Racist Attacks in Online Communities</h3>
<p>Authors: Tayara Romero, Bryan Semaan, Qunfang Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146991">Link</a></p>
<h3>Examining the Unique Online Risk Experiences and Mental Health Outcomes of LGBTQ+ versus Heterosexual Youth</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Joshua Anderson, Mamtaj Akter, Mary Jean Amon, Tangila Islam Tanni, Pamela Wisniewski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146887">Link</a></p>
<h3>“Some Hope, Many Despair”: Experiences of the Normalization within Online Dating among Queer Women in a Closeted Society</h3>
<p>Authors: Seora Park, Hajin Lim, Joonhwan Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147298">Link</a></p>
<h3>See Widely, Think Wisely: Toward Designing a Generative Multi-agent System to Burst Filter Bubbles</h3>
<p>Authors: Mingming Fan, Liuxin Zhang, Qianying Wang, Cen Yao, Xin Geng, Yu Zhang, Yong Rui, Jingwei Sun, Li Feng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148309">Link</a></p>
<h2>Social Activism B</h2>
<h3>Socioeconomic Class in Physical Activity Wearables Research and Design</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Whitney-Jocelyn Kouaho, Daniel Epstein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147491">Link</a></p>
<h3>Engaging recently incarcerated and gang affiliated Black and Latino/a young adults in designing social collocated applications for mixed reality smart glasses through community-based participatory design workshops.</h3>
<p>BEST_PAPER</p>
<p>Authors: kurt squire, Richard Martinez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146915">Link</a></p>
<h3>Evaluating the Experience of LGBTQ+ People Using Large Language Model Based Chatbots for Mental Health Support</h3>
<p>Authors: Zhaoyuan Su, Yinru Long, Zilin Ma, Krzysztof Gajos, Yiyang Mei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146739">Link</a></p>
<h2>Sound Interaction</h2>
<h3>Show, Not Tell: A Human-AI Collaborative Approach for Designing Sound Awareness Systems</h3>
<p>Authors: Jeremy Huang, Dhruv Jain, Hriday Chhabria, Reyna Wood</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147942">Link</a></p>
<h3>Interactive Shape Sonification for Tumor Localization in Breast Cancer Surgery</h3>
<p>Authors: Christoph Leuze, Anh Thien Doan, Nassir Navab, Bruce Daniel, Jacqueline Tsai, Laura Schütz, Trishia El Chemaly, Emmanuelle Weber</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147377">Link</a></p>
<h3>Using Low-frequency Sound to Create Non-contact Sensations On and In the Body</h3>
<p>Authors: Kasper Hornbæk, Asier Marzo, Waseem Hassan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147059">Link</a></p>
<h3>Remembering through Sound: Co-creating Sound-based Mementos together with People with Blindness</h3>
<p>Authors: MinYoung Yoo, Samien Shamsher, Samuel Barnett, Arne Berger, Gillian Russell, Priscilla Lo, William Odom, Lauren Knight, Sadhbh Kenny</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147012">Link</a></p>
<h2>Working with Data B</h2>
<h3>Automatic Macro Mining from Interaction Traces at Scale</h3>
<p>Authors: Forrest Huang, Tao Li, Yang Li, Gang Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147479">Link</a></p>
<h3>Bridging the Gulf of Envisioning: Cognitive Challenges in Prompt Based Interactions with LLMs</h3>
<p>Authors: Roy Pea, Maneesh Agrawala, Hariharan Subramonyam, Colleen Seifert, Christopher Pondoc</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147633">Link</a></p>
<h3>If in a Crowdsourced Data Annotation Pipeline, a GPT-4</h3>
<p>Authors: Zeyu He, Ting-Hao Huang, Chien-Kuang Ding, Chieh-Yang Huang, Shaurya Rohatgi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148078">Link</a></p>
<h3>SEAM-EZ: Simplifying Stateful Analytics through Visual Programming</h3>
<p>Authors: Joel Goldfoot, Vyas Sekar, Henry Milner, Zhengyan Yu, Yang Wang, Jiang Guo, Hun Namkung</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146955">Link</a></p>
<h3>Spreadsheets on Interactive Surfaces: Breaking through the Grid with the Pen</h3>
<p>Authors: Caroline Appert, Emmanuel Pietriga, Vincent Cavez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150829">Link</a></p>
<h2>Working Practices and Tools A</h2>
<h3>Lessons From Working in the Metaverse: Challenges, Choices, and Implications from a Case Study</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Daehwan Ahn, Hyanghee Park, Joonhwan Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148220">Link</a></p>
<h3>ChunkyEdit: Text-first video interview editing via chunking</h3>
<p>Authors: Wilmot Li, Mackenzie Leake</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148086">Link</a></p>
<h3>The Hidden Toll of Instant Messaging Use in Remote Work: Interaction Dynamics Between Subordinates and Supervisors</h3>
<p>Authors: Chien Wen (Tina) Yuan, Chia Hsin Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147176">Link</a></p>
<h3>"If the Machine Is As Good As Me, Then What Use Am I?" – How the Use of ChatGPT Changes Young Professionals' Perception of Productivity and Accomplishment</h3>
<p>Authors: Fiona Draxler, Charlotte Kobiella, Yarhy Flores López, Albrecht Schmidt, Franz Waltenberger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148304">Link</a></p>
<h3>Analysis and Implementation of Nanotargeting on LinkedIn Based on Publicly Available Non-PII</h3>
<p>Authors: Rubén Cuevas, Ángel Cuevas, Angel Merino, José González-Cabañas</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147940">Link</a></p>
<h2>Assistive Technologies for Learning and Information with Neurodiversity</h2>
<h3>Discovering Accessible Data Visualizations for People with ADHD</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Hae-Na Lee, Ji Hwan Park, Tien Tran</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147522">Link</a></p>
<h3>Collaborative School Mental Health System: Leveraging a Conversational Agent for Enhancing Children's Executive Function</h3>
<p>Authors: Yee-Jin Shin, Minseo Cho, Myounglee Choo, Doeun Park, Jinwoo Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146654">Link</a></p>
<h3>Examining the Use of VR as a Study Aid for University Students with ADHD</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Juliana Goncalves de Souza, Joshua Langberg, Thomas Fritz, Isabelle Cuber, David Shepherd, Caroline Lowman, Irene Jacobs</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148326">Link</a></p>
<h3>Narrating Routines through Game Dynamics: Impact of a Gamified Routine Management App for Autistic Individuals</h3>
<p>Authors: Hwajung Hong, Kyungsik Han, Bogoan Kim, Dayoung Jeong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147891">Link</a></p>
<h3>StarRescue: the Design and Evaluation of A Turn-Taking Collaborative Game for Facilitating Autistic Children's Social Skills</h3>
<p>Authors: Ming Li, Yuhang Zhao, Xin Tong, Yihe Wang, Yajie Liu, Yuxuan Huang, Rongqi Bei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147262">Link</a></p>
<h2>Smart Homes and Cities</h2>
<h3>Better to Ask Than Assume: Proactive Voice Assistants’ Communication Strategies That Respect User Agency in a Smart Home Environment</h3>
<p>Authors: Wooseok Kim, Sangsu Lee, Hyeonjeong Im, Jeesun Oh, Sungbae Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147244">Link</a></p>
<h3>Signs of the Smart City: Exploring the Limits and Opportunities of Transparency</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Graham Dove, Eric Corbett</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147824">Link</a></p>
<h3>More than just informed: The importance of consent facets in smart homes</h3>
<p>Authors: Yi-Shyuan Chiang, Adam Bates, Camille Cobb, Omar Khan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148007">Link</a></p>
<h3>Connecting Home: Human-Centric Setup Automation in the Augmented Smart Home</h3>
<p>Authors: Christof Weinhardt, Marius Schenkluhn, Michael Knierim, Francisco Kiss</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147010">Link</a></p>
<h3>FLUID-IoT : Flexible and Fine-Grained Access Control in Shared IoT Environments via Multi-user UI Distribution</h3>
<p>Authors: Minwoo Jeong, Sunjae Lee, Jean Song, Junyoung Choi, Insik Shin, Daye Song, Seoyun Son</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147714">Link</a></p>
<h2>Online Communities: Engagement B</h2>
<h3>Not What it Used to Be: Characterizing Content and User-base Changes in Newly Created Online Communities</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Karrie Karahalios, Vinay Koshy, Alex Atcheson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147485">Link</a></p>
<h3>Observer Effect in Social Media Use</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Munmun De Choudhury, Emre Kiciman, Koustuv Saha, Gloria Mark, Pranshu Gupta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148032">Link</a></p>
<h3>Choosing What You Want Versus Getting What You Want: An Experiment with Choice in Video Ad Placement</h3>
<p>Authors: Karrie Karahalios, Silas Hsu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147760">Link</a></p>
<h3>Recordkeeping in Voice-based Remote Community Engagement</h3>
<p>Authors: Delvin Varghese, Patrick Olivier, Dan Richardson, Md Adnanul Islam, Pratyasha Saha, Muhamad Risqi U. Saputra, Tom Bartindale, Manika Saha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148203">Link</a></p>
<h3>Behind the Pup-ularity Curtain: Understanding the Motivations, Challenges, and Work Performed in Creating and Managing Pet Influencer Accounts</h3>
<p>Authors: Khai Truong, Kevin Pu, Suhyeon Yoo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147143">Link</a></p>
<h2>Exercising and Sports</h2>
<h3>Exploring Opportunities for Augmenting Homes to Support Exercising</h3>
<p>Authors: Hanna Suominen, Michelle Adiwangsa, Mingze Xi, Penny Sweetser, Duncan Stevenson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148103">Link</a></p>
<h3>Grand Challenges in SportsHCI</h3>
<p>Authors: Elise van den Hoven, Lars Elbæk, Florian Mueller, Armağan Karahanoğlu, Vincent van Rheden, Maria Montoya, Don Samitha Elvitigala, Paolo Buono, Fabio Zambetta, Florian Daiber, Regina Bernhaupt, Robby van Delden, Xipei Ren, Dees Postma, Carine Lallemand, Perttu Hämäläinen, Laia Turmo Vidal, Lisa Burr, Dennis Reidsma, Daniel Harrison, Andrii Matviienko, Michael Jones, Rakesh Patibanda</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146749">Link</a></p>
<h3>Enhancing Home Exercise Experiences with Video Motion-Tracking for Automatic Display Height Adjustment</h3>
<p>Authors: Yuqi Li, Jintao Chen, Xinyu Chen, Jiabao Li, Pinyan Tang, Chong Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147402">Link</a></p>
<h3>Born to Run, Programmed to Play: Mapping the Extended Reality Exergames Landscape</h3>
<p>Authors: Lennart Nacke, Sukran Karaosmanoglu, Frank Steinicke, Sebastian Cmentowski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148327">Link</a></p>
<h3>Is it just a score? Understanding Training Load Management Practices Beyond Sports Tracking</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Aykut Coşkun, Armağan Karahanoğlu, Jasper Reenalda, Dees Postma, Ruben Gouveia, Bouke Scheltinga, Dennis Reidsma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147430">Link</a></p>
<h2>Autonomous Vehicles</h2>
<h3>Exploring the Impact of Interconnected External Interfaces in Autonomous Vehicles on Pedestrian Safety and Experience</h3>
<p>Authors: Martin Tomitsch, Yiyuan Wang, Marius Hoggenmüller, Tram Tran, Callum Parker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148231">Link</a></p>
<h3>"It Must Be Gesturing Towards Me": Gesture-Based Interaction between Autonomous Vehicles and Pedestrians</h3>
<p>Authors: Yuxin Cai, Haolin Cai, Jiangtao Gong, Tingmin Yan, Xiaoyan Dong, Guyue Zhou, Zihe Chen, Xiang Chang, Zherui Zhou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147022">Link</a></p>
<h3>Multi-Modal eHMIs: The Relative Impact of Light and Sound in AV-Pedestrian Interaction</h3>
<p>Authors: Mark Colley, Debargha Dey, Wendy Ju, Azra Habibovic, Toros Senan, Bart Hengeveld</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148159">Link</a></p>
<h3>Light it Up: Evaluating Versatile Autonomous Vehicle-Cyclist External Human-Machine Interfaces</h3>
<p>Authors: Ammar Al-Taie, Euan Freeman, Frank Pollick, Graham Wilson, Stephen Brewster</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148184">Link</a></p>
<h3>One Size Does Not Fit All: Designing and Evaluating Criticality-Adaptive Displays in Highly Automated Vehicles</h3>
<p>Authors: Yaohan Ding, Na Du, Lesong Jia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147703">Link</a></p>
<h2>Locomotion in Virtual Environments</h2>
<h3>Doorways Do Not Always Cause Forgetting: Studying the Effect of Locomotion Technique and Doorway Visualization in Virtual Reality</h3>
<p>Authors: Yiannis Kalaitzoglou, Joanna Bergström, Sean Chew, Thomas van Gemert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148003">Link</a></p>
<p>Abstract: The “doorway effect” predicts that crossing an environmental boundary affects memory negatively. In virtual reality (VR), we can design the crossing and the appearance of such boundaries in non-realistic ways. However, it is unclear whether locomotion techniques like teleportation, which avoid crossing the boundary altogether, still induce the effect. Furthermore, it is unclear how different appearances of a doorway act as a boundary and thus induce the effect. To address these questions, we conducted two lab studies. First, we conceptually replicated prior doorway effect studies in VR using natural walking and teleportation. Second, we investigated the effect of five doorway visualizations, ranging from doors to portals. The results show no difference in object recognition performance due to the presence of a doorway, locomotion technique, or doorway visualization. We discuss the implications of these findings on the role of boundaries in event-based memory and the design of boundary interactions in VR.</p>
<h3>Exploring Experience Gaps Between Active and Passive Users During Multi-user Locomotion in VR</h3>
<p>Authors: Teng Han, Fangzhi Yan, Jin Huang, Jiafu Lv, Feng Tian, Fenglin Lu, Tianren Luo, Chun Yu, Chang Liu, Xiaohui Tan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146669">Link</a></p>
<p>Abstract: Multi-user locomotion in VR has grown increasingly common, posing numerous challenges. A key factor contributing to these challenges is the gaps in experience between active and passive users during co-locomotion. Yet, there remains a limited understanding of how and to what extent these experiential gaps manifest in diverse multi-user co-locomotion scenarios. This paper systematically explores the gaps in physiological and psychological experience indicators between active and passive users across various locomotion situations. Such situations include when active users walk, fly by joystick, or teleport, and passive users stand still or look around. We also assess the impact of factors such as sub-locomotion type, speed/teleport-interval, motion sickness susceptibility, etc. Accordingly, we delineate acceptability disparities between active and passive users, offering insights into leveraging notable experimental findings to mitigate discomfort during co-locomotion through avoidance or intervention.</p>
<h3>Investigating Virtual Reality Locomotion Techniques with Blind People</h3>
<p>Authors: André Rodrigues, Renato Ribeiro, Carlos Duarte, Manuel Piçarra, Letícia Seixas Pereira, João Guerreiro, Inês Gonçalves</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147547">Link</a></p>
<p>Abstract: Many Virtual Reality (VR) locomotion techniques have been proposed, but those explored for and with blind people are often custom-made or require specialized equipment. Consequently, it is unclear how popular techniques can support blind people's VR locomotion, blocking access to most VR experiences. We implemented three popular techniques -- Arm Swinging, Linear Movement (joystick-based steering), and Point &amp; Teleport -- with minor adaptations for accessibility. We conducted a study with 14 blind participants consisting of navigation tasks with these techniques and a semi-structured interview. We found no differences in overall performance (e.g., completion time), but contrasting preferences. Findings highlight the challenges and advantages of each technique and participants’ strategies. We discuss, among others, how augmenting the techniques enabled blind people to navigate in VR, the greater control of movement of Arm Swinging, the simplicity and familiarity of Linear Movement, and the potential for efficiency and for scanning the environment of Point &amp; Teleport. </p>
<h3>The Effect of Spatial Audio on Curvature Gains in VR Redirected Walking</h3>
<p>Authors: Christof van Nimwegen, Julian Frommel, Michael Rietzler, Maarten Gerritse</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146928">Link</a></p>
<p>Abstract: Redirected walking (RDW) is a technique that allows users to navigate larger physical spaces in virtual reality (VR) environments by manipulating the users' view of the virtual world. In this study, we investigate the effect of adding spatial audio elements to curvature gains in RDW aiming to increase the perceptual threshold for the manipulation and allowing for higher levels of unnoticed redirection. We conducted a user study (n = 18), evaluating perceptual thresholds across conditions with and without spatial audio elements across different curvature gains. We found that spatial audio can significantly increase thresholds with a large effect size. This finding indicates the value of spatial audio for RDW. It could facilitate higher levels of redirection, while maintaining a convincing experience, leading to more freedom to navigate virtual environments in even smaller physical spaces.</p>
<h3>Stacked Retargeting: Combining Redirected Walking and Hand Redirection to Expand Haptic Retargeting's Coverage</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Aldrich Clarence, Michael Wybrow, Jarrod Knibbe, Maxime Cordeil</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148329">Link</a></p>
<p>Abstract: We present Stacked Retargeting—combining haptic retargeting and redirected walking—to maximise the use of passive proxy objects for VR haptics. Haptic retargeting work to date has considered stationary reaching and grasping interactions, and this inherently limits a proxy object’s scope. We consider exactly where this reaching and grasping occurs from, to increase the potential of each proxy. We present (a) a staged approach to implementing Stacked Retargeting, (b) five redirected walking approaches that enable users to arrive anywhere at the site of interaction, and (c) a usability magnitude estimation evaluation of these techniques. We demonstrate how Stacked Retargeting can meaningfully increase the practical use of proxy objects for VR haptics without degrading the user experience.</p>
<h2>Supporting Communication and Intimacy</h2>
<h3>Rehearsal: Simulating Conflict to Teach Conflict Resolution</h3>
<p>Authors: Omar Shaikh, Diyi Yang, Michele Gelfand, Michael Bernstein, Valentino Chai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147513">Link</a></p>
<p>Abstract: Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill -- one that can be learned through deliberate practice -- but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual "what if?" scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own setting. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations. In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training. Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67%, while doubling their use of cooperative strategies. Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills.</p>
<h3>Seeking Soulmate via Voice: Understanding Promises and Challenges of Online Synchronized Voice-Based Mobile Dating</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yan Xu, Chenxinran Shen, Zhicong Lu, RAY LC</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147442">Link</a></p>
<p>Abstract: Online dating has become a popular way for individuals to connect with potential romantic partners. Many dating apps use personal profiles that include a headshot and self-description, allowing users to present themselves and search for compatible matches. However, this traditional model often has limitations. In this study, we explore a non-traditional voice-based dating app called “Soul”. Unlike traditional platforms that rely heavily on profile information, Soul facilitates user interactions through voice-based communication. We conducted semi-structured interviews with 18 dedicated Soul users to investigate how they engage with the platform and perceive themselves and others in this unique dating environment. Our findings indicate that the role of voice as a moderator influences impression management and shapes perceptions between the sender and the receiver of the voice. Additionally, the synchronous voice-based and community-based dating model offers benefits to users in the Chinese cultural context. Our study contributes to understanding the affordances introduced by voice-based interactions in online dating in China.</p>
<h3>A Change of Scenery: Transformative Insights from Retrospective VR Embodied Perspective-Taking of Conflict With a Close Other</h3>
<p>Authors: Leo Cui, Seraphina Yong, Svetlana Yarosh, Evan Suma Rosenberg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147966">Link</a></p>
<p>Abstract: Close relationships are irreplaceable social resources, yet prone to high-risk conflict. Building on findings from the fields of HCI, virtual reality, and behavioral therapy, we evaluate the unexplored potential of retrospective VR-embodied perspective-taking to fundamentally influence conflict resolution in close others. We develop a biographically-accurate Retrospective Embodied Perspective-Taking system (REPT) and conduct a mixed-methods evaluation of its influence on close others’ reflection and communication, compared to video-based reflection methods currently used in therapy (treatment as usual, or TAU). Our key findings provide evidence that REPT was able to significantly improve communication skills and positive sentiment of both partners during conflict, over TAU. The qualitative data also indicated that REPT surpassed basic perspective-taking by exclusively stimulating users to embody and reflect on both their own and their partner’s experiences at the same level. In light of these findings, we provide implications and an agenda for social embodiment in HCI design: conceptualizing the use of ‘embodied social cognition,’ and envisioning socially-embodied experiences as an interactive context.</p>
<h3>"Delete it and Move On": Digital Management of Shared Sexual Content after a Breakup</h3>
<p>Authors: Allison McDonald, Kathryn Coduto</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147003">Link</a></p>
<p>Abstract: Sexting is a common and healthy behavior in romantic and sexual relationships. However, not every relationship lasts. When a relationship ends, the fate of sexual content that was previously shared can be a source of discomfort, anxiety, or fear for individuals who may no longer trust their former partners. In extreme cases, intimate content may be leaked or misused by its recipient. To investigate opportunities for building safer sexting tools with breakups in mind, we conducted a survey with 310 U.S. adults who have sexted in the last year. We asked about their sexting practices, communication practices within their relationship about sexting, and preferences for their own sexting content after a breakup. We find that most people save sexts in some form, either actively (e.g., via screenshots) or passively (e.g., in chat history). There is no consensus around what one should do with an ex's content: although most (55%) want their content to be deleted at the end of a relationship, many others don't care (25%) or even hope their ex keeps the material (11%). However, most have never spoken to their partner about this preference. We end with design recommendations that support sexting while keeping the entire relationship lifecycle in mind.</p>
<h3>Sharing Frissons among Online Video Viewers: Exploring the Design of Affective Communication for Aesthetic Chills</h3>
<p>Authors: Xinyi Cao, Zeyu Huang, Xiaojuan Ma, Yuanhao Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147357">Link</a></p>
<p>Abstract: On online video platforms, viewers often lack a channel to sense others’ and express their affective state on the fly compared to co-located group-viewing. This study explored the design of complementary affective communication specifically for effortless, spontaneous sharing of frissons during video watching. Also known as aesthetic chills, frissons are instant psycho-physiological reactions like goosebumps and shivers to arousing stimuli. We proposed an approach that unobtrusively detects viewers’ frissons using skin electrodermal activity sensors and presents the aggregated data alongside online videos. Following a design process of brainstorming, focus group interview (N=7), and design iterations, we proposed three different designs to encode viewers’ frisson experiences, namely, ambient light, icon, and vibration. A mixed-methods within-subject study (N=48) suggested that our approach offers a non-intrusive and efficient way to share viewers’ frisson moments, increases the social presence of others as if watching together, and can create affective contagion among viewers.</p>
<h2>Arts and Creative AI</h2>
<h3>Art or Artifice? Large Language Models and the False Promise of Creativity</h3>
<p>Authors: Tuhin Chakrabarty, Philippe Laban, Divyansh Agarwal, Smaranda Muresan, Chien-Sheng Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147597">Link</a></p>
<p>Abstract: Researchers have argued that large language models (LLMs) exhibit high-quality writing capabilities from blogs to stories. However, evaluating objectively the creativity of a piece of writing is challenging. Inspired by the Torrance Test of Creative Thinking (TTCT), which measures creativity as a process, we use the Consensual Assessment Technique and propose Torrance Test of Creative Writing (TTCW) to evaluate creativity as product. TTCW consists of 14 binary tests organized into the original dimensions of Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative writers and implement a human assessment of 48 stories written either by professional authors or LLMs using TTCW. Our analysis shows that LLM-generated stories pass 3-10X less TTCW tests than stories written by professionals. In addition, we explore the use of LLMs as assessors to automate the TTCW evaluation, revealing that none of the LLMs positively correlate with the expert assessments.</p>
<h3>Authors' Values and Attitudes Towards AI-bridged Scalable Personalization of Creative Language Arts</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Matthew Kay, John Chung, Hyomin Han, Eytan Adar, Taewook Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147512">Link</a></p>
<p>Abstract: Generative AI has the potential to create a new form of interactive media: AI-bridged creative language arts (CLA), which bridge the author and audience by personalizing the author's vision to the audience's context and taste at scale. However, it is unclear what the authors' values and attitudes would be regarding AI-bridged CLA. To identify these values and attitudes, we conducted an interview study with 18 authors across eight genres (e.g., poetry, comics) by presenting speculative but realistic AI-bridged CLA scenarios. We identified three benefits derived from the dynamics between author, artifact, and audience: those that 1) authors get from the process, 2) audiences get from the artifact, and 3) authors get from the audience. We found how AI-bridged CLA would either promote or reduce these benefits, along with authors' concerns. We hope our investigation hints at how AI can provide intriguing experiences to CLA audiences while promoting authors' values.</p>
<h3>Generative AI in Creative Practice: ML-Artist Folk Theories of T2I Use, Harm, and Harm-Reduction</h3>
<p>Authors: Negar Rostamzadeh, Renee Shelby, Shalaleh Rismani</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148258">Link</a></p>
<p>Abstract: Understanding how communities experience algorithms is necessary to mitigate potential harmful impacts. This paper presents folk theories of text-to-image (T2I) models to enrich understanding of how artist communities experience creative machine learning systems. This research draws on data collected from a workshop with 15 artists from 10 countries who incorporate T2I models in their creative practice. Through reflexive thematic analysis of workshop data, we highlight artist folk theories of T2I use, harm, and harm reduction. Folk theories of use envision T2I models as an artistic medium, a mundane tool, and locate true creativity as rising above model affordances. Theories of harm articulate T2I models as harmed by engineering efforts to eliminate glitches and product policy efforts to limit functionality. Theories of harm-reduction orient towards protecting T2I models for creative practice through transparency and distributed governance. We examine how these theories relate, and conclude by discussing how folk theorization informs responsible AI efforts.</p>
<h3>Jess+: AI and robotics with inclusive music-making</h3>
<p>Authors: Craig Vear, Adrian Hazzard, Johann Benerradi, Solomiya Moroz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147296">Link</a></p>
<p>Abstract: This paper discusses the findings from a cross-sector research project investigating how a digital score created using AI and robot-ics might stimulate new creative opportunities and relationships within the practices of an inclusive music ensemble. Through the concept of a digital score [65], AI and a robotic arm were introduced into an ensemble’s musical practice to evaluate the impact and ben-efits of using autonomous systems to challenge barriers around a disabled musician's access to creative music-making. Throughout the development process we placed an emphasis on involvement and togetherness of not only the AI and robots' contribution to shared creativity amongst the ensemble, but also to the social as-pects of the creative process across the team of musicians, develop-ers, researchers and supporting organisations. The findings were surprising with many aspects of the project exceeding the expecta-tions of the original aims. In short, all the musicians benefited from the introduction of these unfamiliar technologies with practices enhanced and relationships transformed. </p>
<h2>Assistive Interactions: Navigation and Visualisation for Users Who are Blind or Low Vision</h2>
<h3>Navigating Real-World Challenges: A Quadruped Robot Guiding System for Visually Impaired People in Diverse Environments</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mohd Alqama Shaikh, SHAOJUN CAI, Shengdong Zhao, Kotaro Hara, Zhengtai Gou, Yingjia Wan, Yu-An Chen, David Hsu, Ashwin Ram</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147169">Link</a></p>
<h3>TADA: Making Node-link Diagrams Accessible to Blind and Low-Vision People</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yichun Zhao, Mahadeo Sukhai, Miguel Nacenta, Sowmya Somanath</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147533">Link</a></p>
<h3>Umwelt: Accessible Structured Editing of Multi-Modal Data Representations</h3>
<p>Authors: Daniel Hajas, Jonathan Zong, Arvind Satyanarayan, Isabella Pedraza Pineros, Mengzhu (Katie) Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146952">Link</a></p>
<h3>How Do Low-Vision Individuals Experience Information Visualization?</h3>
<p>Authors: Yuhang Zhao, Yanan Wang, Yea-Seul Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147037">Link</a></p>
<h3>“Customization is Key”: Reconfigurable Textual Tokens for Accessible Data Visualizations</h3>
<p>Authors: Daniel Hajas, Jonathan Zong, Arvind Satyanarayan, Isabella Pedraza Pineros, Shuli Jones</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146771">Link</a></p>
<h2>Attention: multitasking and Interruptions</h2>
<h3>Supporting Task Switching with Reinforcement Learning</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Alexander Lingler, Jussi Jokinen, Philipp Wintersberger, Dinara Talypova, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147418">Link</a></p>
<h3>Augmented Reality Cues Facilitate Task Resumption after Interruptions in Computer-Based and Physical Tasks</h3>
<p>Authors: Lucas Plabst, Tobias Grundgeiger, Lucas Tiemann, Kilian Bahnsen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147918">Link</a></p>
<h3>Heads-Up Multitasker: Simulating Attention Switching On Optical Head-Mounted Displays</h3>
<p>Authors: Aleksi Ikkala, Shengdong Zhao, Lucia Wang, Yunpeng Bai, Pengzhi Yang, Peisen Xu, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147957">Link</a></p>
<h3>SplitBody: Reducing Mental Workload while Multitasking via Muscle Stimulation</h3>
<p>BEST_PAPER</p>
<p>Authors: Yun Ho, Pedro Lopes, Romain Nith</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146989">Link</a></p>
<h3>Improving Attention Using Wearables via Haptic and Multimodal Rhythmic Stimuli</h3>
<p>Authors: Sam Chin, Patrick Chwalek, Samantha Chan, Pattie Maes, Jingru Zhang, Nathan Whitmore</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147209">Link</a></p>
<h2>Creative Media and AI</h2>
<h3>ContextCam: Bridging Context Awareness with Creative Human-AI Image Co-Creation</h3>
<p>Authors: Fenggui Rao, Zihan Wu, Teng Tu, Xianzhe Fan, Weinan Shi, Chun Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148054">Link</a></p>
<p>Abstract: The rapid advancement of AI-generated content (AIGC) promises to transform various aspects of human life significantly. This work particularly focuses on the potential of AIGC to revolutionize image creation, such as photography and self-expression. We introduce ContextCam, a novel human-AI image co-creation system that integrates context awareness with mainstream AIGC technologies like Stable Diffusion. ContextCam provides user's image creation process with inspiration by extracting relevant contextual data, and leverages Large Language Model-based (LLM) multi-agents to co-create images with the user. A study with 16 participants and 136 scenarios revealed that ContextCam was well-received, showcasing personalized and diverse outputs as well as interesting user behavior patterns. Participants provided positive feedback on their engagement and enjoyment when using ContextCam, and acknowledged its ability to inspire creativity.</p>
<h3>InkBrush: A Sketching Tool for 3D Ink Painting</h3>
<p>Authors: Xing-Dong Yang, Zhihao Yao, Haipeng Mi, Guanhong Liu, Yao Lu, Qirui Sun, Beituo Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147709">Link</a></p>
<p>Abstract: InkBrush is a new sketch-based 3D drawing tool for creating 3D ink paintings using free-form 3D ink strokes. It offers a digital calligraphy brush and various editing tools to generate realistic ink-like brush strokes with attributes like hairy edges, ink drips, and scattered dots. Users can adjust parameters such as moisture, color, darkness, dryness, and stroke style to customize the appearance of the brush strokes. The development of InkBrush was guided by a design study involving artists and designers. It was developed as a plugin for Blender, a popular 3D modeling tool, and its effectiveness and usability were evaluated through a user study involving 75 participants. Preliminary feedback from the participants was overwhelmingly positive, indicating that InkBrush was intuitive and easy to use. Following this, we also sought in-depth assessments from experts in ink painting and 3D design. Their evaluations further demonstrated the effectiveness of InkBrush.</p>
<h3>TutoAI: a cross-domain framework for AI-assisted mixed-media tutorial creation on physical tasks</h3>
<p>Authors: Yuexi Chen, Anh Truong, Zhicheng Liu, Vlad Morariu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147303">Link</a></p>
<p>Abstract: Mixed-media tutorials, which integrate videos, images, text, and diagrams to teach procedural skills, offer more browsable alternatives than timeline-based videos. However, manually creating such tutorials is tedious, and existing automated solutions are often restricted to a particular domain. While AI models hold promise, it is unclear how to effectively harness their powers, given the multi-modal data involved and the vast landscape of models. We present TutoAI, a cross-domain framework for AI-assisted mixed-media tutorial creation on physical tasks. First, we distill common tutorial components by surveying existing work; then, we present an approach to identify, assemble, and evaluate AI models for component extraction; finally, we propose guidelines for designing user interfaces (UI) that support tutorial creation based on AI-generated components. We show that TutoAI has achieved higher or similar quality compared to a baseline model in preliminary user studies. </p>
<h3>OutlineSpark: Igniting AI-powered Presentation Slides Creation from Computational Notebooks through Outlines</h3>
<p>Authors: Haotian Li, Yanna Lin, Fengjie Wang, Min Zhu, Huamin Qu, Mingyang Gu, Leni Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147593">Link</a></p>
<p>Abstract: Computational notebooks are widely utilized for exploration and analysis. However, creating slides to communicate analysis results from these notebooks is quite tedious and time-consuming. Researchers have proposed automatic systems for generating slides from notebooks, which, however, often do not consider the process of users conceiving and organizing their messages from massive code cells. Those systems ask users to go directly into the slide creation process, which causes potentially ill-structured slides and burdens in further refinement. Inspired by the common and widely recommended slide creation practice: drafting outlines first and then adding concrete content, we introduce OutlineSpark, an AI-powered slide creation tool that generates slides from a slide outline written by the user. The tool automatically retrieves relevant notebook cells based on the outlines and converts them into slide content. We evaluated OutlineSpark with 12 users. Both the quantitative and qualitative feedback from the participants verify its effectiveness and usability.</p>
<h3>Prompting for Discovery: Flexible Sense-Making for AI Art-Making with Dreamsheets</h3>
<p>Authors: Shm Almeda, J.D. Zamfirescu-Pereira, Bjoern Hartmann, Kyu Won Kim, Pradeep Mani Rathnam</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147361">Link</a></p>
<p>Abstract: Design space exploration (DSE) for Text-to-Image (TTI) models entails navigating a vast, opaque space of possible image outputs, through a commensurately vast input space of hyperparameters and prompt text. Perceptually small movements in prompt-space can surface unexpectedly disparate images. How can interfaces support end-users in reliably steering prompt-space explorations towards interesting results?</p>
<p>Our design probe, DreamSheets, supports user-composed exploration strategies with LLM-assisted prompt construction and large-scale simultaneous display of generated results, hosted in a spreadsheet interface. </p>
<p>Two studies, a preliminary lab study and an extended two-week study where five expert artists developed custom TTI sheet-systems, reveal various strategies for targeted TTI design space exploration---such as using templated text generation to define and layer semantic <code>axes'' for exploration. We identified patterns in exploratory structures across our participants' sheet-systems: configurable exploration</code>units'' that we distill into a UI mockup, and generalizable UI components to guide future interfaces.</p>
<h2>Digital Healthcare and Communication</h2>
<h3>A case for "little English" in Nurse Notes from the Telehealth Intervention Program for Seniors: Implications for Future Design and Research</h3>
<p>Authors: Veena Calambur, DongWhan Jun, Melody Schiaffino, Zhan Zhang, Jina Huh-Yoo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146808">Link</a></p>
<p>Abstract: Community telehealth programs (CTPs) enable low-income older adults to receive telehealth services in community settings (e.g., retirement homes). The Telehealth Intervention Program for Seniors (TIPS) is a CTP that provides vital sign monitoring services managed by remote nurses. TIPS has successfully recruited and retained Limited English Proficient (LEP) participants, but lack of language services might hinder LEP participants' equitable access to care. We conducted a two-part mixed-methods study. We first qualitatively analyzed 40 nurse notes to identify challenges nurses encounter gathering information due to language barriers and the workarounds they employed to address these. We then tested our qualitative findings on 23,975 nurse notes to quantify and compare how these challenges and workarounds scale between LEP and English-proficient TIPS participants. We present future research implications beyond low-hanging solutions, such as automated translation services, and discuss how novel technological solutions can support and ameliorate nurse workarounds and caregiver burden.</p>
<h3>Leveraging Implementation Science in Human-Centred Design for Digital Health</h3>
<p>Authors: Joe Wherton, Christopher Prawira, Patrick Olivier, Peta Stragalinos, Joshua Paolo Seguin, Victoria Manning, Ling Wu, Jessica Watterson, Dan Lubman, Alex Waddell, Jasmin Grigg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146775">Link</a></p>
<p>Abstract: There are increasing concerns that digital interventions in healthcare settings could be better designed for scalable and sustained use. Implementation science is the scientific study of how to embed evidence-based interventions in practice. Calls to integrate implementation science and Human-Centred Design methods have focused on integrating design methods within implementation science processes. By contrast, we present a novel approach to integrating implementation science within Human-Centred Design for digital health interventions. Our approach leverages the socio-technical Nonadoption, abandonment, scale-up, spread, and sustainability (NASSS) framework within the distinct phases of the Double Diamond process. To illustrate our proposal we demonstrate its application in the redesign of a brief health promotion intervention to reduce the risk of alcohol-attributable breast cancer in women attending routine mammography. We discuss reflections on the approach and implications for future research that targets implementation within design. </p>
<h3>Promoting Engagement in Remote Patient Monitoring Using Asynchronous Messaging</h3>
<p>Authors: Eyal de Lara, Alex Mariakakis, Tiago Falk, Robert Wu, Salaar Liaqat, Nisha Patel, Andrea Gershon, Tatiana Son, Daniyal Liaqat</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148308">Link</a></p>
<p>Abstract: Remote patient monitoring is becoming increasingly instrumental to healthcare delivery but can substantially hamper the interpersonal communication that underlies standard clinical practice. In this work, we explore the benefits imparted to patients, clinicians, and researchers by an asynchronous messaging feature within a platform called COVIDFree@Home. We created COVIDFree@Home to assist the healthcare system in a large metropolitan city in North America during the COVID-19 pandemic. Clinicians used COVIDFree@Home to monitor the self-reported symptoms and vital signs of over 350 COVID-19 patients post-infection. Using thematic analysis of user-initiated messages, we found the messaging feature helped maintain protocol adherence while allowing patients to ask questions about their health and clinicians to convey empathetic care. This feedback cycle also led to higher quality data for hospitalization prediction, as the revisions significantly improved the AUROC of a machine learning model trained on demographic variables, vital signs data, and self-reported symptoms from 0.53 to 0.59. </p>
<h3>To Reach the Unreachable: Exploring the Potential of VR Hand Redirection for Upper Limb Rehabilitation</h3>
<p>Authors: Xin Li, Yukai Zhang, Mingming Fan, Jinni ZHOU, Xiquan Hu, Shihan Fu, Peixuan Xiong, Nandi Zhang, Yadan Zheng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147545">Link</a></p>
<p>Abstract: Rehabilitation therapies are widely employed to assist people with motor impairments in regaining control over their affected body parts. Nevertheless, factors such as fatigue and low self-efficacy can hinder patient compliance during extensive rehabilitation processes. Utilizing hand redirection in virtual reality (VR) enables patients to accomplish seemingly more challenging tasks, thereby bolstering their motivation and confidence. While previous research has investigated user experience and hand redirection among able-bodied people, its effects on motor-impaired people remain unexplored. In this paper, we present a VR rehabilitation application that harnesses hand redirection. Through a user study and semi-structured interviews, we examine the impact of hand redirection on the rehabilitation experiences of people with motor impairments and its potential to enhance their motivation for upper limb rehabilitation. Our findings suggest that patients are not sensitive to hand movement inconsistency, and the majority express interest in incorporating hand redirection into future long-term VR rehabilitation programs.</p>
<h3>Investigating the Mechanisms by which Prevalent Online Community Behaviors Influence Responses to Misinformation: Do Perceived Norms Really Act as a Mediator?</h3>
<p>Authors: Eric Baumer, Zhila Aghajari, Nabarun Dasgupta, Dominic DiFranzo, Allison Lazard</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148042">Link</a></p>
<p>Abstract: This study addresses two currently open questions about  how behaviors of online community members influence others' responses to misinformation. First, in contrast to prior work, it directly measures norm perception to address whether (1) norm perception actually acts as a mediator, (2) others' behaviors directly influence individuals' responses to misinformation, (3) both direct and mediated effects occur. Second, it investigates norm perceptions about a behavior that is not readily observable in online communities, but is prone to misinformation, specifically, vaccination. To do so, it experimentally manipulates the prevalence of communicating about vaccination (an unobservable behavior) within an online community. The results demonstrate no evidence of a direct effect---the causal relationship between prevalence of communicating a behavior and intentions to respond to misinformation only occurs via norm perception as a mediator. The paper highlights implications of these findings for designing community-centered interventions to influence perceived norms, thereby mitigating misinformation spread and impacts.</p>
<h2>Ethics of AI</h2>
<h3>Fair Machine Guidance to Enhance Fair Decision Making in Biased People</h3>
<p>Authors: Mingzhe Yang, Hiromi Arai, Naomi Yamashita, Yukino Baba</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147109">Link</a></p>
<p>Abstract: Teaching unbiased decision-making is crucial for addressing biased decision-making in daily life. Although both raising awareness of personal biases and providing guidance on unbiased decision-making are essential, the latter topics remains under-researched. In this study, we developed and evaluated an AI system aimed at educating individuals on making unbiased decisions using fairness-aware machine learning. In a between-subjects experimental design, 99 participants who were prone to bias performed personal assessment tasks. They were divided into two groups: a) those who received AI guidance for fair decision-making before the task and b) those who received no such guidance but were informed of their biases. The results suggest that although several participants doubted the fairness of the AI system, fair machine guidance prompted them to reassess their views regarding fairness, reflect on their biases, and modify their decision-making criteria. Our findings provide insights into the design of AI systems for guiding fair decision-making in humans.</p>
<h3>Exploring the Association between Moral Foundations and Judgements of AI Behaviour</h3>
<p>Authors: Joe Brailsford, Frank Vetere, Eduardo Velloso</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147538">Link</a></p>
<p>Abstract: How do individual differences in personal morality affect perceptions and judgments of morally contentious behaviours from AI systems? By applying Moral Foundations Theory (MFT) to the context of AI, this study sought to develop a predictive Bayesian model for assessing moral judgements based on individual differences in moral constitution. Participants (N=240) were asked to assess six different scenarios, carefully designed to elicit reflection on the behaviour of AI systems. Together, with results from the Moral Foundations Questionnaire, we performed both Bayesian modelling and reflexive thematic analysis to investigate the associations between individual differences in moral foundations and judgements of the AI systems. Results revealed a mild association between individual MFT scores and judgments of AI behaviours. Qualitative responses suggested a participant’s technical understanding of AI systems, rather than intrinsic moral values, predominantly influenced their judgments, with those who judged the behaviour as wrong tending to anthropomorphise the AI systems behaviour.</p>
<h3>Which Artificial Intelligences Do People Care About Most? A Conjoint Experiment on Moral Consideration</h3>
<p>Authors: Jamie Harris, Ali Ladak, Jacy Anthis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147255">Link</a></p>
<p>Abstract: Many studies have identified particular features of artificial intelligences (AI), such as their autonomy and emotion expression, that affect the extent to which they are treated as subjects of moral consideration. However, there has not yet been a comparison of the relative importance of features as is necessary to design and understand increasingly capable, multi-faceted AI systems. We conducted an online conjoint experiment in which 1,163 participants evaluated descriptions of AIs that varied on these features. All 11 features increased how morally wrong participants considered it to harm the AIs. The largest effects were from human-like physical bodies and prosociality (i.e., emotion expression, emotion recognition, cooperation, and moral judgment). For human-computer interaction designers, the importance of prosociality suggests that, because AIs are often seen as threatening, the highest levels of moral consideration may only be granted if the AI has positive intentions.</p>
<h3>The Illusion of Artificial Inclusion</h3>
<p>Authors: Stevie Bergman, Mark Diaz, Seliem El-Sayed, William Agnew, Shakir Mohamed, Jennifer Chien, Jaylen Pittman, Kevin McKee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147179">Link</a></p>
<p>Abstract: Human participants play a central role in the development of modern artificial intelligence (AI) technology, in psychological science, and in user research. Recent advances in generative AI have attracted growing interest to the possibility of replacing human participants in these domains with AI surrogates. We survey several such "substitution proposals" to better understand the arguments for and against substituting human participants with modern generative AI. Our scoping review indicates that the recent wave of these proposals is motivated by goals such as reducing the costs of research and development work and increasing the diversity of collected data. However, these proposals ignore and ultimately conflict with foundational values of work with human participants: representation, inclusion, and understanding. This paper critically examines the principles and goals underlying human participation to help chart out paths for future work that truly centers and empowers participants.</p>
<h3>“They only care to show us the wheelchair”: disability representation in text-to-image AI models</h3>
<p>Authors: Shaun Kane, Rida Qadri, Remi Denton, Cynthia Bennett, Kelly Avery Mack</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147662">Link</a></p>
<p>Abstract: This paper reports on disability representation in images output from text-to-image (T2I) generative AI systems. Through eight focus groups with 25 people with disabilities, we found that models repeatedly presented reductive archetypes for different disabilities. Often these representations reflected broader societal stereotypes and biases, which our participants were concerned to see reproduced through T2I. Our participants discussed further challenges with using these models including the current reliance on prompt engineering to reach satisfactorily diverse results. Finally, they offered suggestions for how to improve disability representation with solutions like showing multiple, heterogeneous images for a single prompt and including the prompt with images generated. Our discussion reflects on tensions and tradeoffs we found among the diverse perspectives shared to inform future research on representation-oriented generative AI system evaluation metrics and development processes.</p>
<h2>Explainable AI</h2>
<h3>User Characteristics in Explainable AI: The Rabbit Hole of Personalization?</h3>
<p>Authors: Marios Constantinides, Ke Zhou, Daniele Quercia, Simone Stumpf, Robert Nimmo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148017">Link</a></p>
<p>Abstract: As Artificial Intelligence (AI) becomes ubiquitous, the need for Explainable AI (XAI) has become critical for transparency and trust among users. A significant challenge in XAI is catering to diverse users, such as data scientists, domain experts, and end-users. Recent research has started to investigate how users' characteristics impact interactions with and user experience of explanations, with a view to personalizing XAI. However, are we heading down a rabbit hole by focusing on unimportant details? Our research aimed to investigate how user characteristics are related to using, understanding, and trusting an AI system that provides explanations. Our empirical study with 149 participants who interacted with an XAI system that flagged inappropriate comments showed that very few user characteristics mattered; only age and the personality trait openness influenced actual understanding. Our work provides evidence to reorient user-focused XAI research and question the pursuit of personalized XAI based on fine-grained user characteristics.</p>
<h3>Incremental XAI: Memorable Understanding of AI with Incremental Explanations</h3>
<p>Authors: Pan Hao, Jessica Bo, Brian Lim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147050">Link</a></p>
<p>Abstract: Many explainable AI (XAI) techniques strive for interpretability by providing concise salient information, such as sparse linear factors. However, users either only see inaccurate global explanations, or highly-varying local explanations. We propose to provide more detailed explanations by leveraging the human cognitive capacity to accumulate knowledge by incrementally receiving more details. Focusing on linear factor explanations (factors × values = outcome), we introduce Incremental XAI to automatically partition explanations for general and atypical instances by providing Base + Incremental factors to help users read and remember more faithful explanations. Memorability is improved by reusing base factors and reducing the number of factors shown in atypical cases. In modeling, formative, and summative user studies, we evaluated the faithfulness, memorability and understandability of Incremental XAI against baseline explanation methods. This work contributes towards more usable explanation that users can better ingrain to facilitate intuitive engagement with AI.</p>
<h3>Why the Fine, AI? The Effect of Explanation Level on Citizens' Fairness Perception of AI-based Discretion in Public Administrations</h3>
<p>Authors: Saja Aljuneidi, Susanne Boll, Larbi Abdenebaoui, Maria Wolters, Wilko Heuten</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147920">Link</a></p>
<p>Abstract: The integration of Artificial Intelligence into decision-making processes within public administration extends to AI-systems that exercise administrative discretion. This raises fairness concerns among citizens, possibly leading to AI-systems abandonment. Uncertainty persists regarding explanation elements impacting citizens' perception of fairness and technology adoption level. In a video-vignette online-survey (N=847), we investigated the impact of explanation levels on citizens' perceptions of informational fairness, distributive fairness, and system adoption level. We enhanced explanations in three stages: none, factor explanations, culminating in factor importance explanations. We found that more detailed explanations improved informational and distributive fairness perceptions, but did not affect citizens' willingness to reuse the system. Interestingly, citizens with higher AI-literacy expressed greater willingness to adopt the system, regardless of the explanation levels. Qualitative findings revealed that greater human involvement and appeal mechanisms could positively influence citizens' perceptions. Our findings highlight the importance of citizen-centered design of AI-based decision-making in public administration.</p>
<h3>EXMOS: Explanatory Model Steering through Multifaceted Explanations and Data Configurations</h3>
<p>Authors: Aditya Bhattacharya, Gregor Stiglic, Lucija Gosak, Katrien Verbert, Simone Stumpf</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146863">Link</a></p>
<p>Abstract: Explanations in interactive machine-learning systems facilitate debugging and improving prediction models. However, the effectiveness of various global model-centric and data-centric explanations in aiding domain experts to detect and resolve potential data issues for model improvement remains unexplored. This research investigates the influence of data-centric and model-centric global explanations in systems that support healthcare experts in optimising models through automated and manual data configurations. We conducted quantitative (n=70) and qualitative (n=30) studies with healthcare experts to explore the impact of different explanations on trust, understandability and model improvement. Our results reveal the insufficiency of global model-centric explanations for guiding users during data configuration. Although data-centric explanations enhanced understanding of post-configuration system changes, a hybrid fusion of both explanation types demonstrated the highest effectiveness. Based on our study results, we also present design implications for effective explanation-driven interactive machine-learning systems.</p>
<h3>The Who in XAI: How AI Background Shapes Perceptions of AI Explanations</h3>
<p>Authors: I-Hsiang Lee, Mark Riedl, Larry Chan, Upol Ehsan, Michael Muller, Q. Vera Liao, Samir Passi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147327">Link</a></p>
<p>Abstract: Explainability of AI systems is critical for users to take informed actions. Understanding who opens the black-box of AI is just as important as opening it. We conduct a mixed-methods study of how two different groups—people with and without AI background—perceive different types of AI explanations. Quantitatively, we share user perceptions along five dimensions. Qualitatively, we describe how AI background can influence interpretations, elucidating the differences through lenses of appropriation and cognitive heuristics. We find that (1) both groups showed unwarranted faith in numbers for different reasons and (2) each group found value in different explanations beyond their intended design. Carrying critical implications for the field of XAI, our findings showcase how AI generated explanations can have negative consequences despite best intentions and how that could lead to harmful manipulation of trust. We propose design interventions to mitigate them. </p>
<h2>Fabrication, Circuits and Tangibles</h2>
<h3>E-Acrylic: Electronic-Acrylic Composites for Making Interactive Artifacts</h3>
<p>Authors: Clement Zheng, Bo Han, Ching Chiuan Yen, Xin Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147806">Link</a></p>
<h3>Painting Inferno: Novel Heat and Stiffness Control Methods with Carbon Nanomaterial Conductive Heating Paint</h3>
<p>Authors: Tatsuya Kobayashi, Yutaka Tokuda</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147168">Link</a></p>
<h3>SnapInflatables: Designing Inflatables with Snap-through Instability for Responsive Interaction</h3>
<p>Authors: Jiang WU, Zhuoyi Zhang, Kuangqi Zhu, Yue Yang, Yongbo Ni, Qi Wang, Xinyan Li, Lei Ren, Guanyun Wang, Chuang Chen, Bin Hu, Lingyun Sun, Jiayi Wu, Junzhe Ji, Yanchen Shen, Ye Tao, Yuyang Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148172">Link</a></p>
<h3>LaCir: A multilayered laser-cuttable material to co-fabricate circuitry and structural components.</h3>
<p>Authors: Niels Buch, Valkyrie Savage, Daniel Ashbrook, Carlos Tejada</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148299">Link</a></p>
<h3>Design Space Exploration for Board-level Circuits: Exploring Alternatives in Component-based Design</h3>
<p>Authors: Ankur Mehta, Parth Pandhare, Bjoern Hartmann, Rohit Ramesh, Prabal Dutta, Richard Lin, Kai Jun Tay</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147466">Link</a></p>
<h2>Fabrication: 3D Printing B</h2>
<h3>CeraMetal: A New Approach to Low-Cost Metal 3D Printing with Bronze Clay</h3>
<p>Authors: Fiona Bell, Jaime Gould, Leah Buechley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147951">Link</a></p>
<h3>Palette-PrintAR: augmented reality design and simulation for multicolor resin 3D printing</h3>
<p>Authors: Joseph DeSimone, Gabriel Lipkowitz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147395">Link</a></p>
<h3>Understanding the Challenges of OpenSCAD Users for 3D Printing</h3>
<p>Authors: Audrey Girouard, Thomas Pietrzak, Géry Casiez, J Gonzalez Avila</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146848">Link</a></p>
<h3>Touch-n-Go: Designing and Fabricating Touch Fastening Structures by FDM 3D Printing</h3>
<p>Authors: Ye Tao, Deying Pan, Boyi Lian, Yue Tao, Hongyi Hu, Guanyun Wang, Shanghua Lou, Lingyun Sun, Junzhe Ji, Yitao Fan, Yuyang Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147487">Link</a></p>
<h3>WeaveSlicer: Expanding the Range of Printable Geometries in Clay</h3>
<p>Authors: Deanna Gelosi, Fiona Bell, Leah Buechley, Camila Friedman-Gerlicz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147620">Link</a></p>
<h2>Gaze Interaction in Immersive Environments</h2>
<h3>Towards an Eye-Brain-Computer Interface: Combining Gaze with the Stimulus-Preceding Negativity for Target Selections in XR</h3>
<p>Authors: Michael Proulx, Leanne Hirshfield, Anthony Ries, G S Rajshekar Reddy</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146977">Link</a></p>
<p>Abstract: Gaze-assisted interaction techniques enable intuitive selections without requiring manual pointing but can result in unintended selections, known as Midas touch. A confirmation trigger eliminates this issue but requires additional physical and conscious user effort. Brain-computer interfaces (BCIs), particularly passive BCIs harnessing anticipatory potentials such as the Stimulus-Preceding Negativity (SPN) - evoked when users anticipate a forthcoming stimulus - present an effortless implicit solution for selection confirmation. Within a VR context, our research uniquely demonstrates that SPN has the potential to decode intent towards the visually focused target. We reinforce the scientific understanding of its mechanism by addressing a confounding factor - we demonstrate that the SPN is driven by the user's intent to select the target, not by the stimulus feedback itself. Furthermore, we examine the effect of familiarly placed targets, finding that SPN may be evoked quicker as users acclimatize to target locations; a key insight for everyday BCIs.</p>
<h3>Gaze on the Go: Effect of Spatial Reference Frame on Visual Target Acquisition During Physical Locomotion in Extended Reality</h3>
<p>Authors: Hans Gellersen, Pavel Manakhov, Ken Pfeuffer, Ludwig Sidenmark</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146967">Link</a></p>
<p>Abstract: Spatial interaction relies on fast and accurate visual acquisition. In this work, we analyse how visual acquisition and tracking of targets presented in a head-mounted display is affected by the user moving linearly at walking and jogging paces. We study four reference frames in which targets can be presented: Head and World where targets are affixed relative to the head and environment, respectively; HeadDelay where targets are presented in the head coordinate system but follow head movement with a delay, and novel Path where targets remain at fixed distance in front of the user, in the direction of their movement. Results of our study in virtual reality demonstrate that the more stable the target is relative to the environment, the faster and more precise it can be fixated. The results have practical significance as head-mounted displays enable interaction during mobility, and in particular when eye tracking is considered as input.</p>
<h3>MOSion: Gaze Guidance with Motion-triggered Visual Cues by Mosaic Patterns</h3>
<p>Authors: Arisa Kohtani, Hidetaka Katsuyama, Hideki Koike, Shio Miyafuji, Keishiro Uragaki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148121">Link</a></p>
<p>Abstract: We propose a gaze-guiding method called MOSion to adjust the guiding strength reacted to observers’ motion based on a high-speed projector and the afterimage effect in the human vision system. Our method decomposes the target area into mosaic patterns to</p>
<p>embed visual cues in the perceived images. The patterns can only direct the attention of the moving observers to the target area. The stopping observer can see the original image with little distortion because of light integration in the visual perception. The pre computation of the patterns provides the adaptive guiding effect without tracking devices and computational costs depending on the movements. The evaluation and the user study show that the mosaic decomposition enhances the perceived saliency with a few visual artifacts, especially in moving conditions. Our method embedded in white lights works in various situations such as planar posters, advertisements, and curved objects.</p>
<h3>FocusFlow: 3D Gaze-Depth Interaction in Virtual Reality Leveraging Active Visual Depth Manipulation</h3>
<p>Authors: Elahe Soltanaghai, Eric Shaffer, Chenyang Zhang, Tiansu Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146886">Link</a></p>
<p>Abstract: Gaze interaction presents a promising avenue in Virtual Reality (VR) due to its intuitive and efficient user experience. Yet, the depth control inherent in our visual system remains underutilized in current methods. In this study, we introduce FocusFlow, a hands-free interaction method that capitalizes on human visual depth perception within the 3D scenes of Virtual Reality. We first develop a binocular visual depth detection algorithm to understand eye input characteristics. We then propose a layer-based user interface and introduce the concept of "Virtual Window" that offers an intuitive and robust gaze-depth VR interaction, despite the constraints of visual depth accuracy and precision spatially at further distances. Finally, to help novice users actively manipulate their visual depth, we propose two learning strategies that use different visual cues to help users master visual depth control. Our user studies on 24 participants demonstrate the usability of our proposed virtual window concept as a gaze-depth interaction method. In addition, our findings reveal that the user experience can be enhanced through an effective learning process with adaptive visual cues, helping users to develop muscle memory for this brand-new input mechanism. We conclude the paper by discussing potential future research topics of gaze-depth interaction.</p>
<h3>Snap, Pursuit and Gain: Virtual Reality Viewport Control by Gaze</h3>
<p>Authors: Hans Gellersen, Hock Siang Lee, Ludwig Sidenmark, Florian Weidner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147889">Link</a></p>
<p>Abstract: Head-mounted displays let users explore virtual environments through a viewport that is coupled with head movement. In this work, we investigate gaze as an alternative modality for viewport control, enabling exploration of virtual worlds with less head movement.</p>
<p>We designed three techniques that leverage gaze based on different eye movements: Dwell Snap for viewport rotation in discrete steps, Gaze Gain for amplified viewport rotation based on gaze angle, and Gaze Pursuit for central viewport alignment of gaze targets. All three techniques enable 360-degree viewport control through naturally coordinated eye and head movement.</p>
<p>We evaluated the techniques in comparison with controller snap and head amplification baselines, for both coarse and precise viewport control, and found them to be as fast and accurate. We observed a high variance in performance which may be attributable to the different degrees to which humans tend to support gaze shifts with head movement.</p>
<h2>Gig Workers</h2>
<h3>"At the end of the day, I am accountable": Gig Workers' Self-Tracking for Multi-Dimensional Accountability Management</h3>
<p>Authors: Rie Helene (Lindy) Hernandez, Qiurong Song, Xinning Gui, Yubo Kou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147575">Link</a></p>
<h3>Silent Delivery: Practices and Challenges of Delivering Among Deaf or Hard of Hearing Couriers</h3>
<p>Authors: Shi Chen, Weijun Li, Xiaodong Wang, Jiaqi Teng, Zhihan Zeng, Jingao Zhang, Yuge Qi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147217">Link</a></p>
<h3>Bodywork at Work: Attending to Bodily Needs in Gig, Shift, and Knowledge Work</h3>
<p>Authors: Kasper Karlgren, Barry Brown, Donald McMillan, Airi Lampinen, Deepika Yadav, Riyaj Shaikh, Karey Helms</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148300">Link</a></p>
<h3>GigSousveillance: Designing Gig Worker Centric Sousveillance Tools</h3>
<p>Authors: Saiph Savage, Michael Muller, Kimberly Do, Maya De Los Santos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147008">Link</a></p>
<h3>Not Just A Dot on The Map: Food Delivery Workers as Infrastructure</h3>
<p>Authors: Anubha Singh, Barry Brown, Airi Lampinen, Riyaj Shaikh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147254">Link</a></p>
<h2>Haptics and Immersive Interactions</h2>
<h3>Augmenting Perceived Length of Handheld Controllers: Effects of Object Handle Properties</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Seungmoon Choi, Chaeyong Park</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147414">Link</a></p>
<p>Abstract: In the realm of virtual reality (VR), shape-changing controllers have emerged as a means to enhance visuo-haptic congruence during user interactions. The major emphasis has been placed on manipulating the inertia tensor of a shape-changing controller to control the perceived shape. This paper delves deeper by exploring how the material properties of the controller's handle, distinct from the inertial information, affect the perceived shape, focusing on the perceived length. We conducted three perceptual experiments to examine the effects of the handle's softness, thermal conductivity, and texture, respectively.  Results demonstrated that a softer handle increases the perceived length, whereas a handle with higher thermal conductivity reduces it. Texture, in the form of varying bumps, also alters the length perception. These results provide more comprehensive knowledge of the intricate relationship between perceived length and controller handle properties, expanding the design alternatives for shape-changing controllers for immersive VR experiences.</p>
<h3>VeeR: Exploring the Feasibility of Deliberately Designing VR Motion that Diverges from Mundane, Everyday Physical Motion to Create More Entertaining VR Experiences</h3>
<p>Authors: Pin Chun Lu, Alvaro Lopez, Wei Tian Mireille Tan, LI-CHUN LU, Chiao-Ju Chang, Ching-Yi Tsai, Mike Chen, Yu Lun Hsu, Che Wei Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148319">Link</a></p>
<p>Abstract: This paper explores the feasibility of deliberately designing VR motion that diverges from users’ physical movements to turn mundane, everyday transportation motion (e.g., metros, trains, and cars) into more entertaining VR motion experiences, in contrast to prior car-based VR approaches that synchronize VR motion to physical car movement exactly. To gain insight into users’ preferences for veering rate and veering direction for turning (left/right) and pitching (up/down) during the three phases of acceleration (accelerating, cruising, and decelerating), we conducted a formative, perceptual study (n=24) followed by a VR experience evaluation (n=18), all conducted on metro trains moving in a mundane, straight-line motion. Results showed that participants preferred relatively high veering rates, and preferred pitching upward during acceleration and downward during deceleration. Furthermore, while veering decreased comfort as expected, it significantly enhanced immersion (p&lt;.01) and entertainment (p&lt;.001) and the overall experience, with comfort being considered, was preferred by 89% of participants.</p>
<h3>InflatableBots: Inflatable Shape-Changing Mobile Robots for Large-Scale Encountered-Type Haptics in VR</h3>
<p>Authors: Ryo Suzuki, Kazuki Takashima, Ryota Gomi, Kazuyuki Fujita, Yoshifumi Kitamura</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147815">Link</a></p>
<p>Abstract: We introduce InflatableBots, shape-changing inflatable robots for large-scale encountered-type haptics in VR. Unlike traditional inflatable shape displays, which are immobile and limited in interaction areas, our approach combines mobile robots with fan-based inflatable structures. This enables safe, scalable, and deployable haptic interactions on a large scale. We developed three coordinated inflatable mobile robots, each of which consists of an omni-directional mobile base and a reel-based inflatable structure. The robot can simultaneously change its height and position rapidly (horizontal: 58.5 cm/sec, vertical: 10.4 cm/sec, from 40 cm to 200 cm), which allows for quick and dynamic haptic rendering of multiple touch points to simulate various body-scale objects and surfaces in real-time across large spaces (3.5 m x 2.5 m). We evaluated our system with a user study (N = 12), which confirms the unique advantages in safety, deployability, and large-scale interactability to significantly improve realism in VR experiences. </p>
<h3>Experiencing Dynamic Weight Changes in Virtual Reality Through Pseudo-Haptics and Vibrotactile Feedback</h3>
<p>Authors: Jan-Niklas Voigt-Antons, Tanja Kojic, Johannes Schöning, Carolin Stellmacher, Feri Pujianto</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147460">Link</a></p>
<p>Abstract: Virtual reality (VR) objects react dynamically to users' touch interactions in real-time. However, experiencing changes in weight through the haptic sense remains challenging with consumer VR controllers due to their limited vibrotactile feedback. While prior works successfully applied pseudo-haptics to perceive absolute weight by manipulating the control-display (C/D) ratio, we continuously adjusted the C/D ratio to mimic weight changes. Vibrotactile feedback additionally emphasises the modulation in the virtual object's physicality. In a study (N=18), we compared our multimodal technique with pseudo-haptics alone and a baseline condition to assess participants' experiences of weight changes. Our findings demonstrate that participants perceived varying degrees of weight change when the C/D ratio was adjusted, validating its effectiveness for simulating dynamic weight in VR. However, the additional vibrotactile feedback did not improve weight change perception. This work extends the understanding of designing haptic experiences for lightweight VR systems by leveraging perceptual mechanisms.</p>
<h3>Exploring Mobile Devices as Haptic Interfaces for Mixed Reality</h3>
<p>Authors: Yannick Weiss, Florian Mathis, Johannes Schöning, Carolin Stellmacher, Nadine Wagener, Meagan Loerakker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148298">Link</a></p>
<p>Abstract: Dedicated handheld controllers facilitate haptic experiences of virtual objects in mixed reality (MR). However, as mobile MR becomes more prevalent, we observe the emergence of controller-free MR interactions. To retain immersive haptic experiences, we explore the use of mobile devices as a substitute for specialised MR controller. In an exploratory gesture elicitation study (n = 18), we examined users' (1) intuitive hand gestures performed with prospective mobile devices and (2) preferences for real-time haptic feedback when exploring haptic object properties. Our results reveal three haptic exploration modes for the mobile device, as an object, hand substitute, or as an additional tool, and emphasise the benefits of incorporating the device's unique physical features into the object interaction. This work expands the design possibilities using mobile devices for tangible object interaction, guiding the future design of mobile devices for haptic MR experiences.</p>
<h2>Haptics: Force, Thermal and Tactile Feedback</h2>
<h3>Stick&amp;Slip: Altering Fingerpad Friction via Liquid Coatings</h3>
<p>Authors: Jacob Serfaty, Pedro Lopes, Alex Mazursky</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148219">Link</a></p>
<h3>HIFU Embossment of Acrylic Sheets</h3>
<p>Authors: Ryosei Kojima, Kengo Tanaka, Takahito Murakami, Ayaka Tsutsui, Tatsuki Fushimi, Yoichi Ochiai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147095">Link</a></p>
<h3>Shaping Compliance: Inducing Haptic Illusion of Compliance in Different Shapes with Electrotactile Grains</h3>
<p>Authors: Jürgen Steimle, Arata Jingu, Nihar Sabnis, Paul Strohmeier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147156">Link</a></p>
<h3>AirPush: A Pneumatic Wearable Haptic Device Providing Multi-Dimensional Force Feedback on a Fingertip</h3>
<p>Authors: Hwan Kim, Yuxin Ma, Tianze Xie, Peng Zhang, Seungwoo Je</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148229">Link</a></p>
<h3>ALCool: Utilizing Alcohol's Evaporative Cooling for Ubiquitous Cold Sensation Feedback</h3>
<p>Authors: Hiroyuki Kajimoto, Izumi Mizoguchi, Keigo Ushiyama, Taiki Takami, Takumi Hamazaki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148230">Link</a></p>
<h2>Health and AI C</h2>
<h3>Memoro: Using Large Language Models to Realize a Concise Interface for Real-Time Memory Augmentation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Samantha Chan, Wazeer Zulfikar, Pattie Maes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147083">Link</a></p>
<p>Abstract: People have to remember an ever-expanding volume of information. Wearables that use information capture and retrieval for memory augmentation can help but can be disruptive and cumbersome in real-world tasks, such as in social settings. To address this, we developed Memoro, a wearable audio-based memory assistant with a concise user interface. Memoro uses a large language model (LLM) to infer the user’s memory needs in a conversational context, semantically search memories, and present minimal suggestions. The assistant has two interaction modes: Query Mode for voicing queries and Queryless Mode for on-demand predictive assistance, without explicit query. Our study of (N=20) participants engaged in a real-time conversation, demonstrated that using Memoro reduced device interaction time and increased recall confidence while preserving conversational quality. We report quantitative results and discuss the preferences and experiences of users. This work contributes towards utilizing LLMs to design wearable memory augmentation systems that are minimally disruptive.</p>
<h3>Artful Path to Healing: Using Machine Learning for Visual Art Recommendation to Prevent and Reduce Post-Intensive Care Syndrome (PICS)</h3>
<p>Authors: Chan Mi Kim, Bereket YILMA, Luis Leiva, Gerald C. Cupchik</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147432">Link</a></p>
<p>Abstract: Staying in the intensive care unit (ICU) is often traumatic, leading to post-intensive care syndrome (PICS), which encompasses physical, psychological, and cognitive impairments. Currently, there are limited interventions available for PICS. Studies indicate that exposure to visual art may help address the psychological aspects of PICS and be more effective if it is personalized. We develop Machine Learning-based Visual Art Recommendation Systems (VA RecSys) to enable personalized therapeutic visual art experiences for post-ICU patients. We investigate four state-of-the-art VA RecSys engines, evaluating the relevance of their recommendations for therapeutic purposes compared to expert-curated recommendations. We conduct an expert pilot test and a large-scale user study (n=150) to assess the appropriateness and effectiveness of these recommendations. Our results suggest all recommendations enhance temporal affective states. Visual and multimodal VA RecSys engines compare favourably with expert-curated recommendations, indicating their potential to support the delivery of personalized art therapy for PICS prevention and treatment.</p>
<h3>Explainable Notes: Examining How to Unlock Meaning in Medical Notes with Interactivity and Artificial Intelligence</h3>
<p>Authors: Hita Kambhamettu, Kevin Johnson, Danaë Metaxa, Andrew Head</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147476">Link</a></p>
<p>Abstract: Medical progress notes have recently become available to patients at an unprecedented scale. Progress notes offer patients insight into their care that they cannot find elsewhere. That said, reading a note requires patients to contend with the language, unspoken assumptions, and clutter common to clinical documentation. As the health system reinvents many of its interfaces to incorporate AI assistance, this paper examines what intelligent interfaces could do to help patients read their progress notes. In a qualitative study, we examine the needs of patients as they read a progress note. We then formulate a vision for the explainable note, an augmented progress note that provides support for directing attention, phrase-level understanding, and tracing lines of reasoning. This vision manifests in a set of patient-inspired opportunities for advancing intelligent interfaces for writing and reading progress notes.</p>
<h3>ConverSense: An Automated Approach to Assess Patient-Provider Interactions using Social Signals</h3>
<p>Authors: Reggie Casanova-Perez, Janice Sabin, Sarah Borsotto, Deepansha Singh, Anuujin Tsedenbal, Nadir Weibel, Manas Satish Bedmutha, Wanda Pratt, Andrea Hartzler, Brian Wood, Emily Bascom, Kelly Tobar, Kimberly Sladek</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148138">Link</a></p>
<p>Abstract: Patient-provider communication influences patient health outcomes, and analyzing such communication could help  providers identify opportunities for improvement, leading to better care. Interpersonal communication can be assessed through “social-signals” expressed in non-verbal, vocal behaviors like interruptions, turn-taking, and pitch. To automate this assessment, we introduce a machine-learning pipeline that ingests audiostreams of conversations and tracks the magnitude of four social-signals:  dominance, interactivity, engagement, and warmth. This pipeline is embedded into ConverSense, a web-application for providers to visualize their communication patterns, both within and across visits. Our user study with 5 clinicians and 10 patient visits demonstrates ConverSense's potential to provide feedback on communication challenges, as well as the need for this feedback to be contextualized within the specific underlying visit and patient interaction. Through this novel approach that uses data-driven self-reflection, ConverSense can help providers improve their communication with patients to deliver improved quality of care.</p>
<h3>Sketching AI Concepts with Capabilities and Examples: AI Innovation in the Intensive Care Unit</h3>
<p>Authors: Sher Shah Amin, Adam Perer, John Minturn, Jeremy Kahn, Billie Davis, Sarah M. Preum, Susanna Zlotnikov, Venkatesh Sivaraman, Leigh Bukowski, Andrew J King, James McCann, John Zimmerman, Dan Ricketts, Kathryn Riman, Nur Yildirim, Deniz Sayar, Lu Tang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146925">Link</a></p>
<p>Abstract: Advances in artificial intelligence (AI) have enabled unprecedented capabilities, yet innovation teams struggle when envisioning AI concepts. Data science teams think of innovations users do not want, while domain experts think of innovations that cannot be built. A lack of effective ideation seems to be a breakdown point. How might multidisciplinary teams identify buildable and desirable use cases? This paper presents a first hand account of ideating AI concepts to improve critical care medicine. As a team of data scientists, clinicians, and HCI researchers, we conducted a series of design workshops to explore more effective approaches to AI concept ideation and problem formulation. We detail our process, the challenges we encountered, and practices and artifacts that proved effective. We discuss the research implications for improved collaboration and stakeholder engagement, and discuss the role HCI might play in reducing the high failure rate experienced in AI innovation.</p>
<h2>Input, Interaction and Time</h2>
<h3>User Performance in Consecutive Temporal Pointing: An Exploratory Study</h3>
<p>Authors: Dawon Lee, Sunjun Kim, Byungjoo Lee, Junyong Noh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147090">Link</a></p>
<h3>Waiting Time Perceptions for Faster Count-downs/ups Are More Sensitive Than Slower Ones: Experimental Investigation and Its Application</h3>
<p>Authors: Chenxi Xie, Takanori Komatsu, Seiji Yamada</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146709">Link</a></p>
<h3>Mouse2Vec: Learning Reusable Semantic Representations of Mouse Behaviour</h3>
<p>Authors: Zhiming Hu, Andreas Bulling, Guanhua Zhang, Mihai Bâce</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147945">Link</a></p>
<h3>The Effect of Latency on Movement Time in Path-steering</h3>
<p>Authors: Wolfgang Stuerzlinger, Shota Yamanaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147611">Link</a></p>
<h2>Interaction and Perception in Immersive Environments</h2>
<h3>MAF: Exploring Mobile Acoustic Field for Hand-to-Face Gesture Interactions</h3>
<p>Authors: Longfei Shangguan, Yujing Huang, Yongjie Yang, Xiuzhen Guo, Tao Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147716">Link</a></p>
<p>Abstract: We present MAF, a novel acoustic sensing approach that leverages the commodity hardware in bone conduction earphones for hand-to-face gesture interactions. Briefly, by shining audio signals with bone conduction earphones, we observe that these signals not only propagate along the surface of the human face but also dissipate into the air, creating an acoustic field that envelops the individual’s head. We conduct benchmark studies to understand how various hand-to-face gestures and human factors influence this acoustic field. Building on the insights gained from these initial studies, we then propose a deep neural network combined with signal preprocessing techniques. This combination empowers MAF to effectively detect, segment, and subsequently recognize a variety of hand-to-face gestures, whether in close contact with the face or above it. Our comprehensive evaluation based on 22 participants demonstrates that MAF achieves an average gesture recognition accuracy of 92% across ten different gestures tailored to users' preferences.</p>
<h3>PhoneInVR: An Evaluation of Spatial Anchoring and Interaction Techniques for Smartphone Usage in Virtual Reality</h3>
<p>Authors: Tovi Grossman, Fengyuan Zhu, Mauricio Sousa, Ludwig Sidenmark</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147762">Link</a></p>
<p>Abstract: When users wear a virtual reality (VR) headset, they lose access to their smartphone and accompanying apps. Past work has proposed smartphones as enhanced VR controllers, but little work has explored using existing smartphone apps and performing traditional smartphone interactions while in VR. In this paper, we consider three potential spatial anchorings for rendering smartphones in VR: On top of a tracked physical smartphone which the user holds (Phone-locked), on top of the user’s empty hand, as if holding a virtual smartphone (Hand-locked), or in a static position in front of the user (World-locked). </p>
<p>We conducted a comparative study of target acquisition, swiping, and scrolling tasks across these anchorings using direct Touch or above-the-surface Pinch. Our findings indicate that physically holding a smartphone with Touch improves accuracy and speed for all tasks, and Pinch performed better with virtual smartphones. These findings provide a valuable foundation to enable smartphones in VR. </p>
<h3>Exploring Visualizations for Precisely Guiding Bare Hand Gestures in Virtual Reality</h3>
<p>Authors: Xizi Wang, Ben Lafreniere, Jian Zhao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147775">Link</a></p>
<p>Abstract: Bare hand interaction in augmented or virtual reality (AR/VR) systems, while intuitive, often results in errors and frustration. However, existing methods, such as a static icon or a dynamic tutorial, can only inform simple and coarse hand gestures and lack corrective feedback. This paper explores various visualizations for enhancing precise hand interaction in VR. Through a comprehensive two-part formative study with 11 participants, we identified four types of essential information for visual guidance and designed different visualizations that manifest these information types. We further distilled four visual designs and conducted a controlled lab study with 15 participants to assess their effectiveness for various single- and double-handed gestures. Our results demonstrate that visual guidance significantly improved users' gesture performance, reducing time and workload while increasing confidence. Moreover, we found that the visualization did not disrupt most users' immersive VR experience or their perceptions of hand tracking and gesture recognition reliability.</p>
<h3>Assessing the Influence of Visual Cues in Virtual Reality on the Spatial Perception of Physical Thermal Stimuli</h3>
<p>Authors: Max Mühlhäuser, Robin Buhlmann, Alexandra Skogseide, Sebastian Günther</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148210">Link</a></p>
<p>Abstract: Advancements in haptics for Virtual Reality (VR) increased the quality of immersive content. Particularly, recent efforts to provide realistic temperature sensations have gained traction, but most often require very specialized or large complex devices to create precise thermal actuations. However, being largely detached from the real world, such a precise correspondence between the physical location of thermal stimuli and the shown visuals in VR might not be necessary for an authentic experience. In this work, we contribute the findings of a controlled experiment with 20 participants, investigating the spatial localization accuracy of thermal stimuli while having matching and non-matching visual cues of a virtual heat source in VR. Although participants were highly confident in their localization decisions, their ability to accurately pinpoint thermal stimuli was notably deficient.</p>
<h3>Improving Electromyographic Muscle Response Times through Visual and Tactile Prior Stimulation in Virtual Reality</h3>
<p>Authors: Valentin Schwind, Karsten Weyers, Leonardo Leite Ferreira, Amir Mahmood, Jessica Sehrt, Thomas Kosch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148137">Link</a></p>
<p>Abstract: Electromyography (EMG) enables hands-free interactions by detecting muscle activity at different human body locations. Previous studies have demonstrated that input performance based on isometric contractions is muscle-dependent and can benefit from synchronous biofeedback. However, it remains unknown whether stimulation before interaction can help to localize and tense a muscle faster. In a response-based VR experiment (N=21), we investigated whether prior stimulation using visual or tactile cues at four different target muscles (biceps, triceps, upper leg, calf) can help reduce the time to perform isometric muscle contractions. The results show that prior stimulation decreases EMG reaction times with visual, vibrotactile, and electrotactile cues. Our experiment also revealed important findings regarding learning and fatigue at the different body locations. We provide qualitative insights into the participants' perceptions and discuss potential reasons for the improved interaction. We contribute with implications and use cases for prior stimulated muscle activation.</p>
<h2>Politics of Data</h2>
<h3>Products of Positionality: How Tech Workers Shape Identity Concepts in Computer Vision</h3>
<p>BEST_PAPER</p>
<p>Authors: Jed Brubaker, Morgan Scheuerman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147182">Link</a></p>
<h3>SalChartQA: Question-driven Saliency on Information Visualisations</h3>
<p>Authors: Yao Wang, Mayar Elfares, Weitian Wang, Zhiming Hu, Abdullah Abdelhafez, Andreas Bulling, Mihai Bâce</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147419">Link</a></p>
<h3>"Things on the Ground are Different": Utility, Survival and Ethics in Multi-Device Ownership and Smartphone Sharing</h3>
<p>Authors: Lindah Kotut, Hummd Alikhan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148190">Link</a></p>
<h3>A Canary in the AI Coal Mine: American Jews May Be Disproportionately Harmed by Intellectual Property Dispossession in Large Language Model Training</h3>
<p>Authors: Brent Hecht, Allison McDonald, Heila Precel, Nicholas Vincent</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148186">Link</a></p>
<h3>When the Body Became Data: Historical Data Cultures and Anatomical Illustration</h3>
<p>Authors: Laura Garrison, Michael Correll</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146916">Link</a></p>
<h2>Reality-Virtuality Continuum: Interaction and Collaboration</h2>
<h3>From Real to Virtual: Exploring Replica-Enhanced Environment Transitions along the Reality-Virtuality Continuum</h3>
<p>Authors: Hans-Christian Jetter, Fabian Pointecker, Judith Friedl-Knirsch, Christoph Anthes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146699">Link</a></p>
<p>Abstract: Recent Head-Mounted Displays enable users to perceive the real environment using a video-based see-through mode and the fully virtual environment within a single display. Leveraging these advancements, we present a generic concept to seamlessly transition between the real and virtual environment, with the goal of supporting users in engaging with and disengaging from any real environment into Virtual Reality. This transition process uses a digital replica of the real environment and incorporates various stages of Milgram’s Reality-Virtuality Continuum, along with visual transitions that facilitate gradual navigation between them. We implemented the overall transition concept and four object-based transition techniques. The overall transition concept and four techniques were evaluated in a qualitative user study, focusing on user experience, the use of the replica and visual coherence. </p>
<p>The results of the user study show, that most participants stated that the replica facilitates the cognitive processing of the transition and supports spatial orientation.</p>
<h3>Blended Whiteboard: Physicality and Reconfigurability in Remote Mixed Reality Collaboration</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Hans Gellersen, Jens Emil Grønbæk, Germán Leiva, Ken Pfeuffer, Eduardo Velloso, Juan Sánchez Esquivel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147453">Link</a></p>
<p>Abstract: The whiteboard is essential for collaborative work. To preserve its physicality in remote collaboration, Mixed Reality (MR) can blend real whiteboards across distributed spaces.</p>
<p>Going beyond reality, MR can further enable interactions like panning and zooming in a virtually reconfigurable infinite whiteboard. However, this reconfigurability conflicts with the sense of physicality. To address this tension, we introduce Blended Whiteboard, a remote collaborative MR system enabling reconfigurable surface blending across distributed physical whiteboards. Blended Whiteboard supports a unique collaboration style, where users can sketch on their local whiteboards but also reconfigure the blended space to facilitate transitions between loosely and tightly coupled work. We describe design principles inspired by proxemics; supporting users in changing between facing each other and being side-by-side, and switching between navigating the whiteboard synchronously and independently. Our work shows exciting benefits and challenges of combining physicality and reconfigurability in the design of distributed MR whiteboards.</p>
<h3>SwitchSpace: Understanding Context-Aware Peeking Between VR and Desktop Interfaces</h3>
<p>Authors: Tovi Grossman, George Fitzmaurice, Johann Wentzel, Fraser Anderson, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147514">Link</a></p>
<p>Abstract: Cross-reality tasks, like creating or consuming virtual reality (VR) content, often involve inconvenient or distracting switches between desktop and VR. An initial formative study explores cross-reality switching habits, finding most switches are momentary "peeks" between interfaces, with specific habits determined by current context. The results inform a design space for context-aware "peeking" techniques that allow users to view or interact with desktop from VR, and vice versa, without fully switching. We implemented a set of peeking techniques and evaluated them in two levels of a cross-reality task: one requiring only viewing, and another requiring input and viewing. Peeking techniques made task completion faster, with increased input accuracy and reduced perceived workload.</p>
<h3>Seated-WIP: Enabling Walking-in-Place Locomotion for Stationary Chairs in Confined Spaces</h3>
<p>BEST_PAPER</p>
<p>Authors: Ming Yun Hsu, Liwei Chan, Tzu-Wei Mi, Yi-Ci Huang, ZHUNG HAO HSUEH</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147661">Link</a></p>
<p>Abstract: We introduce Seated-WIP, a footstep-based locomotion technique tailored for users seated in confined spaces such as on an airplane. It emulates real-world walking using forefoot or rearfoot in-place stepping, enhancing embodiment while reducing fatigue for pro- longed interactions. Our footstep-locomotion maps users’ footstep motions to four locomotion actions: walking forward, turning-in- place, walking backward, and sidestepping. Our first study examined embodiment and fatigue levels across various sitting positions using forefoot, rearfoot, and fullfoot stepping methods. While all these methods effectively replicated walking, users favored the forefoot and rearfoot methods due to reduced fatigue. In our sec- ond study, we compared the footstep-locomotion to leaning- and controller-locomotion on a multitasking navigation task. Results indicate that footstep locomotion offers the best embodied sense of walking and has comparable fatigue levels to controller-locomotion, albeit with slightly reduced efficiency than controller-locomotion. In seated VR environments, footstep locomotion offers a harmonious blend of embodiment, fatigue mitigation, and efficiency.</p>
<h3>Volumetric Hybrid Workspaces: Interactions with Objects in Remote and Co-located Telepresence</h3>
<p>Authors: Mesut Latifoglu, Brandon Syiem, Thuong Hoang, Frank Vetere, Andrew Irlitti</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147499">Link</a></p>
<p>Abstract: Volumetric telepresence aims to create a shared space, allowing people in local and remote settings to collaborate seamlessly. Prior telepresence examples typically have asymmetrical designs, with volumetric capture in one location and objects in one format. In this paper, we present a volumetric telepresence mixed reality system that supports real-time, symmetrical, multi-user, partially distributed interactions, using objects in multiple formats, across multiple locations. We align two volumetric environments around a common spatial feature to create a shared workspace for remote and co-located people using objects in three formats: physical, virtual, and volumetric. We conducted a study with 18 participants over 6 sessions, evaluating how telepresence workspaces support spatial coordination and hybrid communication for co-located and remote users undertaking collaborative tasks. Our findings demonstrate the successful integration of remote spaces, effective use of proxemics and deixis to support negotiation, and strategies to manage interactivity in hybrid workspaces.</p>
<h2>Smart Textiles</h2>
<h3>Ecothreads: Prototyping Biodegradable E-textiles Through Thread-based Fabrication</h3>
<p>Authors: Jingwen Zhu, Lily Winagle, Cindy Hsin-Liu Kao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147320">Link</a></p>
<h3>KnitScape: Computational Design and Yarn-Level Simulation of Slip and Tuck Colorwork Knitting Patterns</h3>
<p>Authors: Emily Whiting, Nadya Peek, Hannah Twigg-Smith</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147407">Link</a></p>
<h3>Expressive Clothing: Understanding Hobbyist-Sewers' Visions for Self-Expression Through Clothing</h3>
<p>Authors: Charles Perin, Sabrina Lakhdhir, Sowmya Somanath</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147610">Link</a></p>
<h3>Desktop Biofibers Spinning: An Open-Source Machine for Exploring Biobased Fibers and their Application Towards Sustainable Smart Textile Design</h3>
<p>Authors: Laura Devendorf, Mirela Alistar, Eldy Lazaro Vasquez, Michael Rivera</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147405">Link</a></p>
<h3>IntelliTex: Fabricating Low-cost and Washable Functional Textiles using A Double-coating Process</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yue Yang, Yuecheng Peng, Danchang Yan, Weitao Song, Guanyun Wang, Lingyun Sun, Ye Tao, Haotian Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146867">Link</a></p>
<h2>Education and AI B</h2>
<h3>Scientific and Fantastical: Creating Immersive, Culturally Relevant Learning Experiences with Augmented Reality and Large Language Models</h3>
<p>Authors: Arjun Sharma, David Wright, Melissa Ran, Roy Pea, Bala Vinaithirthan, Anthony Xie, Meng Guo, Shihe (Tracy) Luan, Andrea Cuadra, Khuyen Le, James Landay, Alan Cheng, Arpit Ranasaria</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147314">Link</a></p>
<p>Abstract: Motivating children to learn is a major challenge in education. One way to inspire motivation to learn is through immersion. We combine the immersive potential of augmented reality (AR), narrative, and large language models (LLMs) to bridge fantasy with reality in a mobile application, Moon Story, that teaches elementary schoolers astronomy and environmental science. Our system also builds upon learning theories such as culturally-relevant pedagogy. Using our application, a child embarks on a journey inspired by Chinese mythology, engages in real-world AR activities, and converses with a fictional character powered by a LLM. We conducted a controlled experiment (N=50) with two conditions: one using an LLM and one that was hard-coded. Both conditions resulted in learning gains, high engagement levels, and increased science learning motivation. Participants in the LLM condition also wrote more relevant answers. Finally, participants of both Chinese and non-Chinese heritage found the culturally-based narrative compelling.</p>
<h3>VIVID: Human-AI Collaborative Authoring of Vicarious Dialogues from Lecture Videos</h3>
<p>Authors: Hyewon Lee, Juho Kim, Seulgi Choi, Yoonjoo Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148330">Link</a></p>
<p>Abstract: The lengthy monologue-style online lectures cause learners to lose engagement easily. Designing lectures in a “vicarious dialogue” format can foster learners’ cognitive activities more than monologue-style. However, designing online lectures in a dialogue style catered to the diverse needs of learners is laborious for instructors. We conducted a design workshop with eight educational experts and seven instructors to present key guidelines and the potential use of large language models (LLM) to transform a monologue lecture script into pedagogically meaningful dialogue. Applying these design guidelines, we created VIVID which allows instructors to collaborate with LLMs to design, evaluate, and modify pedagogical dialogues. In a within-subjects study with instructors (N=12), we show that VIVID helped instructors select and revise dialogues efficiently, thereby supporting the authoring of quality dialogues. Our findings demonstrate the potential of LLMs to assist instructors with creating high-quality educational dialogues across various learning stages.</p>
<h3>Exploring AI Problem Formulation with Children via Teachable Machines</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Salma Elsayed-Ali, Elizabeth Bonsignore, Hernisa Kacorri, Utkarsh Dwivedi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147040">Link</a></p>
<p>Abstract: Emphasizing problem formulation in AI literacy activities with children is vital, yet we lack empirical studies on their structure and affordances. We propose that participatory design involving teachable machines facilitates problem formulation activities. To test this, we integrated problem reduction heuristics into storyboarding and invited a university-based intergenerational design team of 10 children (ages 8-13) and 9 adults to co-design a teachable machine. We find that children draw from personal experiences when formulating AI problems; they assume voice and video capabilities, explore diverse machine learning approaches, and plan for error handling. Their ideas promote human involvement in AI, though some are drawn to more autonomous systems. Their designs prioritize values like capability, logic, helpfulness, responsibility, and obedience, and a preference for a comfortable life, family security, inner harmony, and excitement as end-states. We conclude by discussing how these results can inform the design of future participatory AI activities. </p>
<h3>Mathemyths: Leveraging Large Language Models to Teach Mathematical Language through Child-AI Co-Creative Storytelling</h3>
<p>Authors: Chi-Lin Yu, Ying Xu, Soobin Jeon, Xuechen Liu, Katherine Ziska, Chao Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148341">Link</a></p>
<p>Abstract: Mathematical language is a cornerstone of a child's mathematical development, and children can effectively acquire this language through storytelling with a knowledgeable and engaging partner. In this study, we leverage the recent advances in large language models to conduct free-form, creative conversations with children. Consequently, we developed Mathemyths, a joint storytelling agent that takes turns co-creating stories with children while integrating mathematical terms into the evolving narrative. This paper details our development process, illustrating how prompt-engineering can optimize LLMs for educational contexts. Through a user study involving 35 children aged 4-8 years, our results suggest that when children interacted with Mathemyths, their learning of mathematical language was comparable to those who co-created stories with a human partner. However, we observed differences in how children engaged with co-creation partners of different natures. Overall, we believe that LLM applications, like Mathemyths, offer children a unique conversational experience pertaining to focused learning objectives.</p>
<h3>Testing, Socializing, Exploring: Characterizing Middle Schoolers’ Approaches to and Conceptions of ChatGPT</h3>
<p>Authors: Atefeh Mahdavi Goloujeh, Yasmine Belghith, Brian Magerko, Jessica Roberts, Tom McKlin, Duri Long</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148187">Link</a></p>
<p>Abstract: As generative AI rapidly enters everyday life, educational interventions for teaching about AI need to cater to how young people, in particular middle schoolers who are at a critical age for reasoning skills and identity formation, conceptualize and interact with AI. We conducted nine focus groups with 24 middle school students to elicit their interests, conceptions of, and approaches to a popular generative AI tool, ChatGPT. We highlight a) personally and culturally-relevant topics to this population, b) three distinct approaches in students' open-ended interactions with ChatGPT: AI testing-oriented, AI socializing-oriented, and content exploring-oriented, and 3) an improved understanding of youths' conceptions and misconceptions of generative AI. While misconceptions highlight gaps in understanding what generative AI is and how it works, most learners show interest in learning about what AI is and what it can do. We discuss the implications of these conceptions for designing AI literacy interventions in museums.</p>
<h2>Users Privacy Needs</h2>
<h3>Personalizing Privacy Protection With Individuals' Regulatory Focus: Would You Preserve or Enhance Your Information Privacy?</h3>
<p>Authors: Reza Ghaiumy Anaraky, Danny Yuxing Huang, Hichang Cho, Oded Nov, Kaileigh Angela Byrne, Yao Li, Bart Knijnenburg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146995">Link</a></p>
<h3>Towards Understanding Family Privacy and Security Literacy Conversations at Home: Design Implications for Privacy Literacy Interfaces</h3>
<p>Authors: Adel Hrncic, Nikita Soni, Karthik Singh, Sumanth Kunisetty, Yaxing Yao, Kenan Alghythee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147976">Link</a></p>
<h3>Do You Need to Touch? Exploring Correlations between Personal Attributes and Preferences for Tangible Privacy Mechanisms</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Anh Dao Phuong, Karola Marky, Sarah Delgado Rodriguez, Florian Alt, Priyasha Chatterjee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147786">Link</a></p>
<h3>"I know what you did last semester": Understanding Privacy Expectations and Preferences in the Smart Campus</h3>
<p>Authors: Injung Kim, Adam Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148155">Link</a></p>
<h3>“It doesn’t tell me anything about how my data is used”: User Perceptions of Data Collection Purposes</h3>
<p>Authors: Abraham Mhaidli, Asia Biega, Lin Kyi, Franziska Roesner, Cristiana Teixeira Santos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148272">Link</a></p>
<h2>Wellbeing and Mental Health C</h2>
<h3>The Role of AI in Peer Support for Young People: A Study of Preferences for Human- and AI-Generated Responses</h3>
<p>Authors: Laala M Jawara, Brian Daly, Diep Nguyen, Jina Huh-Yoo, Afsaneh Razi, Jordyn Young</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148227">Link</a></p>
<h3>The Social Journal: Investigating Technology to Support and Reflect on Social Interactions</h3>
<p>Authors: Tabea Blenk, Sophia Sakel, Luke Haliburton, Albrecht Schmidt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147877">Link</a></p>
<h3>S-ADL: Exploring Smartphone-based Activities of Daily Living to Detect Blood Alcohol Concentration in a Controlled Environment</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Uichin Lee, Sang Won Bae, Hansoo Lee, Auk Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146856">Link</a></p>
<h3>Exploring an Extended Reality Floatation Tank Experience to Reduce the Fear of Being in Water</h3>
<p>Authors: Florian Mueller, Sarah Jane Pell, Hannah Qiao, Maria Montoya, Don Samitha Elvitigala, Prasanth Sasikumar, Suranga Nanayakkara</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148060">Link</a></p>
<h2>Accessibility and Aging</h2>
<h3>Designing a Multisensory VR Game Prototype for Older Adults - the Acceptability and Design Implications</h3>
<p>Authors: Yasuyuki Gondo, Xin Suzuki, Kin Wa Fung, Xiaoxuan Li, Xiangshi Ren, Naoaki Yamaji</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146682">Link</a></p>
<h3>Exploring the Opportunity of Augmented Reality (AR) in Supporting Older Adults to Explore and Learn Smartphone Applications</h3>
<p>Authors: Xiaofu Jin, Emily Kuang, Xian Wang, Mingming Fan, Xiaoying Wei, Huamin Qu, Xiaoyu Mo, Wai Tong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146706">Link</a></p>
<h3>Reducing Search Space on Demand Helps Older Adults Find Mobile UI Features Quickly, on Par With Younger Adults</h3>
<p>Authors: Debaleena Chattopadhyay, Ja Eun Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147297">Link</a></p>
<h3>Toward Making Virtual Reality (VR) More Inclusive for Older Adults: Investigating Aging Effect on Target Selection and Manipulation Tasks in VR</h3>
<p>Authors: Duotun Wang, Zeyu Wang, Mingming Fan, Yuru Huang, Zhiqing Wu, Shumeng Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147356">Link</a></p>
<h3>HelpCall: Designing Informal Technology Assistance for Older Adults via Videoconferencing</h3>
<p>Authors: Jiamin Dai, Teerapaun Tanprasert, Joanna McGrenere</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147212">Link</a></p>
<h2>User Security Needs</h2>
<h3>A First Look into Targeted Clickbait and its Countermeasures: The Power of Storytelling</h3>
<p>Authors: Matthew Wright, Mahdi Nasrullah Al-Ameen, Saniat Sohrawardi, Audrey Flood, Ankit Shrestha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146835">Link</a></p>
<h3>Not as easy as just update: Survey of System Administrators and Patching Behaviours</h3>
<p>Authors: Kami Vaniea, Maria Wolters, Adam Jenkins, Linsen Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147837">Link</a></p>
<h3>Understanding User-Perceived Security Risks and Mitigation Strategies in the Web3 Ecosystem</h3>
<p>Authors: Janice Jianing SI, Kanye Ye WANG, Tanusree Sharma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146662">Link</a></p>
<h3>Self-Efficacy and Security Behavior: Results from a Systematic Review of Research Methods</h3>
<p>Authors: Imke Böse, Malte Elson, Angela Sasse, Nele Borgert, Jennifer Friedauer, Luisa Jansen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147732">Link</a></p>
<h3>A Comparative Long-Term Study of Fallback Authentication Schemes</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Markus Dürmuth, Leona Lassak, Elizabeth Stobert, Maximilian Golla, Philipp Markert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148199">Link</a></p>
<h2>Assistive Interactions: Solutions for d/Deaf and Hard of Hearing Users</h2>
<h3>Towards Inclusive Video Commenting: Introducing Signmaku for the Deaf and Hard-of-Hearing</h3>
<p>Authors: Lawrence Angrave, Yun Huang, Desirée Kirst, Qi Wang, Saumya Malhotra, Haocong Cheng, Suzy Su, Jason Situ, Si Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146831">Link</a></p>
<h3>How Users Experience Closed Captions on Live Television: Quality Metrics Remain a Challenge</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Matthew Seita, Molly Feanny, Bernard Thompson, Christian Vogler, Mariana Arroyo Chavez, Abraham Glasser, Skyler Officer, Raja Kushalnagar, Keith Delk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146961">Link</a></p>
<h3>Assessment of Sign Language-Based versus Touch-Based Input for Deaf Users Interacting with Intelligent Personal Assistants</h3>
<p>Authors: Matthew Seita, Christian Vogler, Abraham Glasser, Raja Kushalnagar, Nina Tran, Paige DeVries</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147208">Link</a></p>
<h3>Unspoken Sound: Identifying Trends in Non-Speech Audio Captioning on YouTube</h3>
<p>Authors: Sooyeon Lee, Jhanvi Pai, Lloyd May, Magdalena Fuentes, Khang Dang, Mark Cartwright, Sripathi Sridhar, Keita Ohshiro</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146864">Link</a></p>
<h3>Towards Co-Creating Access and Inclusion: A Group Autoethnography on a Hearing Individual's Journey Towards Effective Communication in Mixed-Hearing Ability Higher Education Settings</h3>
<p>Authors: Matthew Seita, Christian Vogler, Qi Wang, James Waller, Raja Kushalnagar, Si Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147946">Link</a></p>
<h2>Assistive Interactions: Everyday Interactions for Users Who are Blind or Low Vision</h2>
<h3>Help Supporters: Exploring the Design Space of Assistive Technologies to Support Face-to-Face Help Between Blind and Sighted Strangers</h3>
<p>Authors: Connor Courtien, Maryam Aziz, Rajan Vaish, Yves Tseng, Brian Smith, Avery Reyna, Jacqueline Gibson, David Rios, Yuanyang Teng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147252">Link</a></p>
<h3>Visual Cues for Data Analysis Features Amplify Challenges for Blind Spreadsheet Users</h3>
<p>Authors: Bongshin Lee, Minoli Perera, Eun Kyoung Choe, Kim Marriott</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146687">Link</a></p>
<h3>A Contextual Inquiry of People with Vision Impairments in Cooking</h3>
<p>Authors: Shaun Kane, Patrick Carrington, Michael Xieyang Liu, Franklin Mingzhe Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147075">Link</a></p>
<h3>Towards Inclusive Source Code Readability Based on the Preferences of Programmers with Visual Impairments</h3>
<p>Authors: Maulishree Pandey, Andrew Begel, Steve Oney</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146818">Link</a></p>
<h3>FetchAid: Making Parcel Lockers More Accessible to Blind and Low Vision People With Deep-learning Enhanced Touchscreen Guidance, Error-Recovery Mechanism, and AR-based Search Support</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zeyu Xiong, Mingming Fan, Zhitong Guan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147721">Link</a></p>
<h2>Assistive Interactions: Social and Collaborative Interactions for Users Who or Blind or Low Vision</h2>
<h3>"I Don't Really Get Involved In That Way": Investigating Blind and Visually Impaired Individuals’ Experiences of Joint Attention with Sighted People</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Katherine Jones, Ute Leonards, Oussama Metatla</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147896">Link</a></p>
<h3>BubbleCam: Engaging Privacy in Remote Sighted Assistance</h3>
<p>Authors: Sooyeon Lee, He Zhang, Rui Yu, John Carroll, Jingyi Xie, Syed Masum Billah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147457">Link</a></p>
<h3>Conveying Emotions through Shape-changing to Children with and without Visual Impairment</h3>
<p>Authors: Isabel Neto, Filipa Correia, Filipa Rocha, Hugo Nicolau, Ana Paiva, Yuhan Hu, Guy Hoffman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147053">Link</a></p>
<h3>Unblind Text Inputs: Predicting Hint-text of Text Input in Mobile Apps via LLM</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mengzhuo Chen, Yuekai Huang, Chunyang Chen, Jun Hu, Zhe Liu, Boyu Wu, Junjie Wang, Qing Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147794">Link</a></p>
<h3>Designing to Support Blind and Visually Impaired Older Adults in Managing the Invisible Labor of Social Participation: Opportunities and Challenges</h3>
<p>Authors: Aqueasha Martin-Hammond, Pranali Shinde</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148126">Link</a></p>
<h2>Assistive Technologies</h2>
<h3>Designing Gaze-Assisted Upper-Body Gesture Interaction with and for People with Spinal Muscular Atrophy in VR</h3>
<p>Authors: Mingming Fan, Junan Xie, Jingze Tian, Franklin Mingzhe Li, yafeng niu, Liyi Xu, Keye Yu, Yingna Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147764">Link</a></p>
<h3>Beyond Repairing with Electronic Speech: Towards Embodied Communication and Assistive Technology</h3>
<p>Authors: Humphrey Curtis, Timothy Neate</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147301">Link</a></p>
<h3>People with Disabilities Redefining Identity through Robotic and Virtual Avatars: A Case Study in Avatar Robot Cafe</h3>
<p>Authors: Hiroaki Kato, Giulia Barbareschi, Yuji Hatada, Kentaro Yoshifuji, Takuji Narumi, Kazuaki Takeuchi, Kouta Minamizawa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148080">Link</a></p>
<h3>“Can It Be Customized According to My Motor Abilities?”: Toward Designing User-Defined Head Gestures for People with Dystonia</h3>
<p>Authors: Mingming Fan, Su-Jing Wang, Jingting Li, Qin Sun, Yunqi Hu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148234">Link</a></p>
<h3>Barriers to Photosensitive Accessibility in Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Caglar Yildirim, Amy Pavel, Laura South, Michelle Borkin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147690">Link</a></p>
<h2>Assistive Technologies: Work  Independent Living with Neurodiversity</h2>
<h3>Designing for Strengths: Opportunities to Support Neurodiversity in the Workplace</h3>
<p>Authors: Rachel Lowy, Kaely Hall, Parth Arora, Jennifer Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148212">Link</a></p>
<h3>Collaborative Job Seeking for People with Autism: Challenges and Design Opportunities</h3>
<p>Authors: Vivian Genaro Motti, Zinat Ara, Slobodan Vucetic, Amrita Ganguly, Donna Peppard, Dongjun Chung, Sungsoo Ray Hong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148323">Link</a></p>
<h3>“It’s the only thing I can trust”: Envisioning Large Language Model Use by Autistic Workers for Communication Assistance</h3>
<p>Authors: Patrick Carrington, Sanika Moharana, JiWoong Jang, Andrew Begel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147834">Link</a></p>
<h3>Understanding Online Job and Housing Search Practices of Neurodiverse Young Adults to Support Their Independence</h3>
<p>Authors: Ha-Kyung Kong, Saloni Yadav, Daniella Ruzinov, Rachel Lowy, Jennifer Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146962">Link</a></p>
<h3>Towards Digital Independence: Identifying the Tensions between Autistic Young Adults and Their Support Network When Mediating Social Media</h3>
<p>Authors: Xinru Page, Elizabeth Johnson, Spring Cullen, Pamela Wisniewski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146625">Link</a></p>
<h2>Augmented Stories</h2>
<h3>Comfortable Mobility vs. Attractive Scenery: The Key to Augmenting Narrative Worlds in Outdoor Locative Augmented Reality Storytelling</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ikbeom Jeon, Hyunjin Lee, Woontack Woo, Aram Min, Maryam Shakeri, HYERIM PARK</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147164">Link</a></p>
<h3>Investigating the Design of Augmented Narrative Spaces Through Virtual-Real Connections: A Systematic Literature Review</h3>
<p>Authors: Hayun Kim, Woontack Woo, HYERIM PARK, Jae-eun Shin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147128">Link</a></p>
<h3>AudioXtend: Assisted Reality Visual Accompaniments for Audiobook Storytelling During Everyday Routine Tasks</h3>
<p>Authors: Wei Zhen Suen, Yun Huang, Shengdong Zhao, Christophe Hurter, Felicia Tan, Ashwin Ram, Peisen Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148039">Link</a></p>
<h3>Jigsaw: Authoring Immersive Storytelling Experiences with Augmented Reality and Internet of Things</h3>
<p>Authors: Rajan Vaish, Andrés Monroy-Hernández, Ava Robinson, Lei Zhang, Daekun Kim, Youjean Cho, Yu Jiang Tham</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147993">Link</a></p>
<h3>Augmented Reality at Zoo Exhibits: A Design Framework for Enhancing the Zoo Experience</h3>
<p>Authors: Ryan Kelly, Sarah Webber, Jorge Goncalves, Brandon Syiem, Eduardo Velloso, Qiushi Zhou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148105">Link</a></p>
<h2>Chronic Conditions A</h2>
<h3>Good Days, Bad Days: Understanding the Trajectories of Technology Use During Chronic Fatigue Syndrome</h3>
<p>Authors: Sarah Homewood, Léa Paymal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147030">Link</a></p>
<h3>MigraineTracker: Examining Patient Experiences with Goal-Directed Self-Tracking for a Chronic Health Condition</h3>
<p>BEST_PAPER</p>
<p>Authors: Jessica Schroeder, Liwei Jiang, Carla Castillo, Shaan Chopra, James Fogarty, Allison Cole, Anant Mittal, Yasaman Sefidgar, Natalia Murinova, Sean Munson, Hyeyoung Ryu, Tae Jones</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147528">Link</a></p>
<h3>PD-Insighter: A Visual Analytics System to Monitor Daily Actions for Parkinson's Disease Treatment</h3>
<p>Authors: Danielle Szafir, Daniel Szafir, Qian Zhang, Henry Fuchs, Howard Jiang, Michael Lewek, Pranav Wagh, Angelos Angelopoulos, Chelsea Duppen, Jade Kandel, Ashley Neall</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148175">Link</a></p>
<h3>Creating Safe Places: Understanding the Lived Experiences of Families Managing Cystic Fibrosis in Young Children</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yunan Chen, Zhaoyuan Su, Pornchai Tirakitsoontorn, Sunil P. Kamath</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147391">Link</a></p>
<h3>GlucoMaker: Enabling Collaborative Customization of Glucose Monitors</h3>
<p>Authors: Charles Perin, Sabrina Lakhdhir, Liisa Holsti, Irina Kondratova, Helene Fournier, Fraser Anderson, Sowmya Somanath, Chehak Nayar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147409">Link</a></p>
<h2>Chronic Conditions C</h2>
<h3>“I think it saved me. I think it saved my heart”: The Complex Journey From Self-Tracking With Wearables To Diagnosis</h3>
<p>Authors: Rachel Keys, Aisling Ann O'Kane, Paul Marshall, Graham Stuart</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148252">Link</a></p>
<h3>"It's like a glimpse into the future": Exploring the Role of Blood Glucose Prediction Technologies for Type 1 Diabetes Self-Management</h3>
<p>Authors: Jürgen Bernard, Clara-Maria Barth, Elaine M. Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148048">Link</a></p>
<h3>HIV Client Perspectives on Digital Health in Malawi</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Evelyn Viola, Odala Sande, Richard Anderson, Jacqueline Huwa, Hannock Tweya, Agness Thawani, Lisa Orii, Christine Kiruthu-Kamamia, Caryl Feldacker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147847">Link</a></p>
<h3>“Obviously, Nothing's Gonna Happen in Five Minutes”: How Adolescents and Young Adults Infrastructure Resources to Learn Type 1 Diabetes Management</h3>
<p>Authors: Tian Xu, Casey Fiesler, Laurel H. Messer, Gregory Forlenza, Paul Cook, Stephen Voida, Sriram Sankaranarayanan, Emily Jost</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148225">Link</a></p>
<h2>Coding with AI</h2>
<h3>Validating AI-Generated Code with Live Programming</h3>
<p>Authors: Sorin Lerner, Michael James, Nadia Polikarpova, Ruanqianqian (Lisa) Huang, Kasra Ferdowsi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146703">Link</a></p>
<p>Abstract: AI-powered programming assistants are increasingly gaining popularity, with GitHub Copilot alone used by over a million developers worldwide. These tools are far from perfect, however, producing code suggestions that may be incorrect in subtle ways. As a result, developers face a new challenge: validating AI's suggestions. This paper explores whether Live Programming (LP), a continuous display of a program's runtime values, can help address this challenge. To answer this question, we built a Python editor that combines an AI-powered programming assistant with an existing LP environment. Using this environment in a between-subjects study (N=17), we found that by lowering the cost of validation by execution, LP can mitigate over- and under-reliance on AI-generated programs and reduce the cognitive load of validation for certain types of tasks.</p>
<h3>Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT &amp; NetLogo Chat</h3>
<p>Authors: Yuzhou Du, Uri Wilensky, Mike Horn, John Chen, Xi Lu, Ruth Bagley, Michael Rejtig</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148257">Link</a></p>
<p>Abstract: Large Language Models (LLMs) have the potential to fundamentally change the way people engage in computer programming. Agent-based modeling (ABM) has become ubiquitous in natural and social sciences and education, yet no prior studies have explored the potential of LLMs to assist it. We designed NetLogo Chat to support the learning and practice of NetLogo, a programming language for ABM. To understand how users perceive, use, and need LLM-based interfaces, we interviewed 30 participants from global academia, industry, and graduate schools. Experts reported more perceived benefits than novices and were more inclined to adopt LLMs in their workflow. We found significant differences between experts and novices in their perceptions, behaviors, and needs for human-AI collaboration. We surfaced a knowledge gap between experts and novices as a possible reason for the benefit gap. We identified guidance, personalization, and integration as major needs for LLM-based interfaces to support the programming of ABM.</p>
<h3>Ivie: Lightweight Anchored Explanations of Just-Generated Code</h3>
<p>Authors: Zhiyuan Wu, Alyssa Hwang, Andrew Head, Litao Yan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147626">Link</a></p>
<p>Abstract: Programming assistants have reshaped the experience of programming into one where programmers spend less time writing and more time critically examining code. In this paper, we explore how programming assistants can be extended to accelerate the inspection of generated code. We introduce an extension to the programming assistant called Ivie, or instantly visible in-situ explanations. When using Ivie, a programmer's generated code is instantly accompanied by explanations positioned just adjacent to the code. Our design was optimized for extremely low-cost invocation and dismissal. Explanations are compact and informative. They describe meaningful expressions, from individual variables to entire blocks of code. We present an implementation of Ivie that forks VS Code, applying a modern LLM for timely segmentation and explanation of generated code. In a lab study, we compared Ivie to a contemporary baseline tool for code understanding. Ivie improved understanding of generated code, and was received by programmers as a highly useful, low distraction, desirable complement to the programming assistant.</p>
<h3>Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Eric Horvitz, Hussein Mozannar, Gagan Bansal, Adam Fourney</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146797">Link</a></p>
<p>Abstract: Code-recommendation systems, such as Copilot and CodeWhisperer, have the potential to improve programmer productivity by suggesting and auto-completing code. However, to fully realize their potential, we must understand how programmers interact with these systems and identify ways to improve that interaction. To seek insights about human-AI collaboration with code recommendations systems, we studied GitHub Copilot, a code-recommendation system used by millions of programmers daily. </p>
<p>We developed CUPS, a taxonomy of common programmer activities when interacting with Copilot. Our study of 21 programmers, who completed coding tasks and retrospectively labeled their sessions with CUPS, showed that CUPS can help us understand how programmers interact with code-recommendation systems, revealing inefficiencies and time costs. Our insights reveal how programmers interact with Copilot and motivate new interface designs and metrics. </p>
<h3>CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs</h3>
<p>Authors: Paul Denny, Tovi Grossman, Michelle Craig, Austin Henley, Runlong Ye, Xiaoning Wang, Majeed Kazemitabaar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147379">Link</a></p>
<p>Abstract: Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student's incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI's unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.</p>
<h2>Colors</h2>
<h3>Exploring Interactive Color Palettes for Abstraction-Driven Exploratory Image Colorization</h3>
<p>Authors: Ryan Rossi, Mingyu Liu, Xinyu Shi, Jian Zhao, Ali Neshati, Ziqi Zhou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147505">Link</a></p>
<h3>Cieran: Designing Sequential Colormaps via In-Situ Active Preference Learning</h3>
<p>Authors: Danielle Szafir, Zachary Sunberg, Matt-Heun Hong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147642">Link</a></p>
<h3>Palette, Purpose, Prototype: The Three Ps of Color Design and How Designers Navigate Them</h3>
<p>Authors: Lena Hegemann, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147335">Link</a></p>
<h3>Color Maker: a Mixed-Initiative Approach to Creating Accessible Color Maps</h3>
<p>Authors: Amey Salvi, Khairi Reda, Kecheng Lu, Yunhai Wang, Michael Papka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147098">Link</a></p>
<h3>Piet: Facilitating Color Authoring for Motion Graphics Video</h3>
<p>BEST_PAPER</p>
<p>Authors: Yinghou Wang, Xinyu Shi, Jian Zhao, Yun Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147118">Link</a></p>
<h2>Creative Professionals and AI A</h2>
<h3>Unlocking Creator-AI Synergy: Challenges, Requirements, and Design Opportunities in AI-Powered Short-Form Video Production</h3>
<p>Authors: Hajun Kim, Jini Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147507">Link</a></p>
<p>Abstract: The emergence of AI-Powered Short-Form Video Generators (ASVG) has showcased the potential to streamline production time and foster creative ideas. Despite their widespread adoption, research has underexplored ASVG, especially from creators’ perspectives. To evaluate the role of ASVG as creator-centered collaborators, we conducted mixed-method research: (1) interviews (N = 17) and (2) a participatory design workshop (N = 12) with short-form video creators. In our interviews, we investigated creators’ production process and challenges in creating short-form videos. In participatory workshops, short-form video creators envisioned AI-powered video tools, addressing their requirements and AI collaboration perceptions. Our findings indicate ASVGs can provide various advantages including inspiration, swift access to video sources, and automated highlight generation. To put things in perspective, we also underscore concerns arising from AI collaboration, including potential creator identity dilution, reduced creative output, and information bubble. We also discuss design considerations when designing ASVG to retain their creative values.</p>
<h3>ReelFramer: Human-AI Co-Creation for News-to-Video Translation</h3>
<p>Authors: Kevin Crowston, Mark Hansen, Sitong Wang, Lydia Chilton, Jeffrey Nickerson, Samia Menon, Dingzeyu Li, Keren Henderson, Tao Long</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147933">Link</a></p>
<p>Abstract: Short videos on social media are the dominant way young people consume content. News outlets aim to reach audiences through news reels---short videos conveying news---but struggle to translate traditional journalistic formats into short, entertaining videos. To translate news into social media reels, we support journalists in reframing the narrative. In literature, narrative framing is a high-level structure that shapes the overall presentation of a story. We identified three narrative framings for reels that adapt social media norms but preserve news value, each with a different balance of information and entertainment. We introduce ReelFramer, a human-AI co-creative system that helps journalists translate print articles into scripts and storyboards. ReelFramer supports exploring multiple narrative framings to find one appropriate to the story. AI suggests foundational narrative details, including characters, plot, setting, and key information. ReelFramer also supports visual framing; AI suggests character and visual detail designs before generating a full storyboard. Our studies show that narrative framing introduces the necessary diversity to translate various articles into reels, and establishing foundational details helps generate scripts that are more relevant and coherent. We also discuss the benefits of using narrative framing and foundational details in content retargeting.</p>
<h3>Understanding Nonlinear Collaboration between Human and AI Agents: A Co-design Framework for Creative Design</h3>
<p>Authors: Haotian Li, Weiwei Cui, Junxiu Tang, Tan Tang, Renzhong Li, Jiayi Zhou, Yingcai Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148154">Link</a></p>
<p>Abstract: Creative design is a nonlinear process where designers generate diverse ideas in the pursuit of an open-ended goal and converge towards consensus through iterative remixing.</p>
<p>In contrast, AI-powered design tools often employ a linear sequence of incremental and precise instructions to approximate design objectives.</p>
<p>Such operations violate customary creative design practices and thus hinder AI agents' ability to complete creative design tasks.</p>
<p>To explore better human-AI co-design tools, we first summarize human designers’ practices through a formative study with 12 design experts.</p>
<p>Taking graphic design as a representative scenario, we formulate a nonlinear human-AI co-design framework and develop a proof-of-concept prototype, OptiMuse. </p>
<p>We evaluate OptiMuse and validate the nonlinear framework through a comparative study.</p>
<p>We notice a subconscious change in people's attitudes towards AI agents, shifting from perceiving them as mere executors to regarding them as opinionated colleagues. </p>
<p>This shift effectively fostered the exploration and reflection processes of individual designers.</p>
<h3>PlantoGraphy: Incorporating Iterative Design Process into Generative Artificial Intelligence for Landscape Rendering</h3>
<p>Authors: Haichuan Lin, Wei Zeng, Chuanzhang Chen, Rong Huang, Kang Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147560">Link</a></p>
<p>Abstract: Landscape renderings are realistic images of landscape sites, allowing stakeholders to perceive better and evaluate design ideas. While recent advances in Generative Artificial Intelligence (GAI) enable automated generation of landscape renderings, the end-to-end methods are not compatible with common design processes, leading to insufficient alignment with design idealizations and limited cohesion of iterative landscape design. Informed by a formative study for comprehending design requirements, we present PlantoGraphy, an iterative design system that allows for interactive configuration of GAI models to accommodate human-centered design practice. A two-stage pipeline is incorporated: first, the concretization module transforms conceptual ideas into concrete scene layouts with a domain-oriented large language model; and second, the illustration</p>
<p>module converts scene layouts into realistic landscape renderings with a layout-guided diffusion model fine-tuned through Low-Rank Adaptation. PlantoGraphy has undergone a series of performance evaluations and user studies, demonstrating its effectiveness in landscape rendering generation and the high recognition of its interactive functionality.</p>
<h3>Fashioning Creative Expertise with Generative AI:  Graphical Interfaces for Design Space Exploration Better Support Ideation Than Text Prompts</h3>
<p>Authors: Thiemo Wambsganss, Richard Davis, Tanja Käser, Kevin Gonyop Kim, Wei Jiang, Pierre Dillenbourg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147024">Link</a></p>
<p>Abstract: This paper investigates the potential impact of deep generative models on the work of creative professionals. We argue that current generative modeling tools lack critical features that would make them useful creativity support tools, and introduce our own tool, generative.fashion, which was designed with theoretical principles of design space exploration in mind. Through qualitative studies with fashion design apprentices, we demonstrate how generative.fashion supported both divergent and convergent thinking, and compare it with a state-of-the-art text-based interface using Stable Diffusion. In general, the apprentices preferred generative.fashion, citing the features explicitly designed to support ideation. In two follow-up studies, we provide quantitative results that support and expand on these insights. We conclude that text-only prompts in existing models restrict creative exploration, especially for novices. Our work demonstrates that interfaces which are theoretically aligned with principles of design space exploration are essential for unlocking the full creative potential of generative AI.</p>
<h2>Creative Professionals and AI B</h2>
<h3>LumiMood: A Creativity Support Tool for Designing the Mood of a 3D Scene</h3>
<p>Authors: SeungJun Kim, Seungju Kim, Jeongseok Oh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148271">Link</a></p>
<p>Abstract: The aesthetic design of 3D scenes in game content enhances players' experience by inducing desired emotions. Creating emotionally engaging scenes involves designing low-level features, such as color distribution, contrast, and brightness. This study presents LumiMood, an AI-driven creativity support tool (CST) that automatically adjusts lighting and post-processing to create moods for 3D scenes. LumiMood supports designers by synthesizing reference images, creating mood templates, and providing intermediate design steps. Our formative study with 10 designers identified distinct challenges in mood design based on the participants' experience levels. A user study involving 40 designers revealed that using LumiMood benefits the designers by streamlining workflow, improving precision, and increasing mood intention accuracy. Results indicate that LumiMood supports clarifying mood concepts and improves interpretation of lighting and post-processing, thus resolving the challenges. We observe the effect of template based designing and discuss considerable factors for AI-driven CSTs for users with varying levels of experiences.</p>
<h3>C2Ideas: Supporting Creative Interior Color Design Ideation with a Large Language Model</h3>
<p>Authors: Hao Cui, Yihan Hou, Wei Zeng, Lei WANG, Manling YANG, Jie Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147389">Link</a></p>
<p>Abstract: Interior color design is a creative process that endeavors to allocate colors to furniture and other elements within an interior space. While much research focuses on generating realistic interior designs, these automated approaches often misalign with user intention and disregard design rationales. Informed by a need-finding preliminary study, we develop C2Ideas, an innovative system for designers to creatively ideate color schemes enabled by an intent-aligned and domain-oriented large language model. C2Ideas integrates a three-stage process: Idea Prompting stage distills user intentions into color linguistic prompts; Word-Color Association stage transforms the prompts into semantically and stylistically coherent color schemes; and Interior Coloring stage assigns colors to interior elements complying with design principles. We also develop an interactive interface that enables flexible user refinement and interpretable reasoning. C2Ideas has undergone a series of indoor cases and user studies, demonstrating its effectiveness and high recognition of interactive functionality by designers.</p>
<h3>TypeDance: Creating Semantic Typographic Logos from Image through Personalized Generation</h3>
<p>Authors: Wei Zeng, Liangwei Wang, Xiaojuan Ma, Shishi Xiao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146619">Link</a></p>
<p>Abstract: Semantic typographic logos harmoniously blend typeface and imagery to represent semantic concepts while maintaining legibility. Conventional methods using spatial composition and shape substitution are hindered by the conflicting requirement for achieving seamless spatial fusion between geometrically dissimilar typefaces and semantics. While recent advances made AI generation of semantic typography possible, the end-to-end approaches exclude designer involvement and disregard personalized design. This paper presents TypeDance, an AI-assisted tool incorporating design rationales with the generative model for personalized semantic typographic logo design. It leverages combinable design priors extracted from uploaded image exemplars and supports type-imagery mapping at various structural granularity, achieving diverse aesthetic designs with flexible control. Additionally, we instantiate a comprehensive design workflow in TypeDance, including ideation, selection, generation, evaluation, and iteration. A two-task user evaluation, including imitation and creation, confirmed the usability of TypeDance in design across different usage scenarios.</p>
<h3>When Teams Embrace AI: Human Collaboration Strategies in Generative Prompting in a Creative Design Task</h3>
<p>Authors: Ziyi Qiu, Yuanning Han, JIALE CHENG, RAY LC</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147669">Link</a></p>
<p>Abstract: Studies of Generative AI (GenAI)-assisted creative workflows have focused on individuals overcoming challenges of prompting to produce what they envisioned. When designers work in teams, how do collaboration and prompting influence each other, and how do users perceive generative AI and their collaborators during the co-prompting process? We engaged students with design or performance backgrounds, and little exposure to GenAI, to work in pairs with GenAI to create stage designs based on a creative theme. We found two patterns of collaborative prompting focused on generating story descriptions first, or visual imagery first. GenAI tools helped participants build consensus in the task, and allowed for discussion of the prompting strategies. Participants perceived GenAI as efficient tools rather than true collaborators, suggesting that human partners reduced the reliance on their use. This work highlights the importance of human-human collaboration when working with GenAI tools, suggesting systems that take advantage of shared human expertise in the prompting process.</p>
<h3>Is Resistance Futile?: Early Career Game Developers, Generative AI, and Ethical Skepticism</h3>
<p>Authors: Josiah Boucher, Yunus Telliel, Gillian Smith</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146874">Link</a></p>
<p>Abstract: This paper presents a study that examines developer perceptions and usage of generative AI (GAI) in a summer professional development program for game development interns focused on mobile game design. GAI applications are in common usage worldwide, yet the impacts of this technology in game development remain relatively underexplored. Through a qualitative study using ethnographic interviews and participatory observation, this paper explores how GAI impacted the workflows, creative processes, and professional identities of early career game developers. We present a case of GAI integration that was not a straightforward adoption. Focusing on the interns' resistance, negotiation, and reimagining, we show that the interns were actively developing a new professional culture both with and against generative AI. For the interns, their ethical commitments to fellow game developers and the future of their profession were as important as their practical concerns about usability, utility, and efficacy of GAI tools.</p>
<h2>Data Visualization: Charts</h2>
<h3>Do You See What I See? A Qualitative Study Eliciting High-Level Visualization Comprehension</h3>
<p>Authors: Danielle Szafir, Zhehao Wang, Arran Zeyu Wang, Paul Rosen, Jennifer Adorno, Ghulam Jilani Quadri</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146696">Link</a></p>
<h3>Effects of Point Size and Opacity Adjustments in Scatterplots</h3>
<p>Authors: Gabriel Strain, Caroline Jay, Andrew J. Stewart, Paul Warren</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147175">Link</a></p>
<h3>Spatial Audio-Enhanced Multimodal Graph Rendering for Efficient Data Trend Learning on Touchscreen Devices</h3>
<p>Authors: Jennifer Tennison, Nicholas Giudice, Medhani Kalal, Wilfredo Robinson Moore, Jenna Gorlewicz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146668">Link</a></p>
<h3>VisTorch: Interacting with Situated Visualizations using Handheld Projectors</h3>
<p>Authors: Huaishu Peng, Biswaksen Patnaik, Niklas Elmqvist</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147315">Link</a></p>
<h3>To Cut or Not To Cut? A Systematic Exploration of Y-Axis Truncation</h3>
<p>Authors: Matthew Kay, Sheng Long</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147733">Link</a></p>
<h2>Data Visualization: Geospatial and Multimodal</h2>
<h3>DeepSee: Multidimensional Visualizations of Seabed Ecosystems</h3>
<p>Authors: Eric Martin, Rebecca Wipfler, Hillary Mushkin, Maggie Hendrie, Noah Deutsch, John Magyar, Victoria Orphan, Sergio Parra, Scott Davidoff, Alex Endert, Jennifer Paduan, David W. Caress, Haley Sapers, Daniel Utter, Malika Khurana, Adam Coscia, Santiago Lombeyda</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146725">Link</a></p>
<h3>SalienTime: User-driven Selection of Salient Time Steps for Large-Scale Geospatial Data Visualization</h3>
<p>Authors: Huayuan Ye, Changbo Wang, Chenhui Li, Haiwen Huang, Juntong Chen, Zhong Peng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147827">Link</a></p>
<h3>Data Cubes in Hand: A Design Space of Tangible Cubes for Visualizing 3D Spatio-Temporal Data in Mixed Reality</h3>
<p>Authors: Luyan Jiang, Haonan Yao, Hai-Ning Liang, Nan Xiang, Shuqi He, Yue Li, Kaiwen Li, Lingyun Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146834">Link</a></p>
<h3>Understanding Reader Takeaways in Thematic Maps Under Varying Text, Detail, and Spatial Autocorrelation</h3>
<p>Authors: Fan Lei, Ross Maciejewski, Michelle Mancenido, Arlen Fan, Alan MacEachren</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148161">Link</a></p>
<h3>MAIDR: Making Statistical Visualizations Accessible with Multimodal Data Representation</h3>
<p>Authors: Yilin Xia, Bongshin Lee, JooYoung Seo, Sean McCurry, Yu Jun Yam</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146802">Link</a></p>
<h2>Dementia Care</h2>
<h3>Evolving Presentation of Self: The Influence of Dementia Communication Challenges on Everyday Interactions</h3>
<p>Authors: Yvon Ruitenburg, Panos Markopoulos, Wijnand IJsselsteijn, Minha Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147523">Link</a></p>
<h3>Mnemosyne - Supporting Reminiscence for Individuals with Dementia in Residential Care Settings</h3>
<p>Authors: Peter Shaw, Andrea Baumann, Ludwig Trotter, Nigel Davies, Sarah Clinch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147516">Link</a></p>
<h3>Technology-Mediated Non-pharmacological Interventions for Dementia: Needs for and Challenges in Professional, Personalized and Multi-Stakeholder Collaborative Interventions</h3>
<p>BEST_PAPER</p>
<p>Authors: JUNYAN MAO, Yuling Sun, Xiaojuan Ma, Xin Tong, Zhennan Yi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146988">Link</a></p>
<h3>Family Caregiver Experiences of Using a Mobile App for Music-based Training to Support Dementia Care</h3>
<p>Authors: Tanara Vieira Sousa, Ryan Kelly, Nicola T. Lautenschlager, Zara Thompson, Amit Lampit, Jeanette Tamplin, Felicity Baker, Dianna Vidas, Jenny Waycott, Lars Kulik</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147009">Link</a></p>
<h3>Design Opportunities for Care Transitions in Dementia: Understanding Informal Caregivers' Experiences Through a Practice-Informed Approach</h3>
<p>Authors: Maudy Gosen, Wijnand IJsselsteijn, Maarten Houben, Rens Brankaert, Veerle Van Overloop</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147643">Link</a></p>
<h2>Digital Wellbeing A</h2>
<h3>Real-World Winds: Micro Challenges to Promote Balance Post Smartphone Overload</h3>
<p>Authors: Sven Mayer, Nađa Terzimehić, Sarah Aragon-Hahner, Julia Huber</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146849">Link</a></p>
<h3>StayFocused: Examining the Effects of Reflective Prompts and Chatbot Support on Compulsive Smartphone Use</h3>
<p>Authors: Yuhan Luo, Minhui Liang, Zhuoyang LI, RAY LC</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148192">Link</a></p>
<h3>Attention Receipts: Utilizing the Materiality of Receipts to Improve Screen-time Reflection on YouTube</h3>
<p>Authors: Anup Sathya, Ken Nakagaki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147812">Link</a></p>
<h3>A Longitudinal In-the-Wild Investigation of Design Frictions to Prevent Smartphone Overuse</h3>
<p>Authors: Luke Haliburton, Frederik Riedel, Nađa Terzimehić, Albrecht Schmidt, David Grüning</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147365">Link</a></p>
<h3>InteractOut: Leveraging Interaction Proxies as Input Manipulation Strategies for Reducing Smartphone Overuse</h3>
<p>Authors: Tao Lu, Anhong Guo, Tianying Zhang, Hongxiao Zheng, Xuhai "Orson" Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147313">Link</a></p>
<h2>Digital Wellbeing B</h2>
<h3>Time2Stop: Adaptive and Explainable Human-AI Loop for Smartphone Overuse Intervention</h3>
<p>Authors: Yukang Yan, Yuntao Wang, Anind Dey, Marzyeh Ghassemi, Han Xiao, Yuanchun Shi, Adiba Orzikulova, Zhipeng Li, Xuhai "Orson" Xu, Sung-Ju Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146643">Link</a></p>
<h3>“I finally felt I had the tools to control these urges”: Empowering Students to Achieve Their Device Use Goals With the Reduce Digital Distraction Workshop</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Kasper Hornbæk, Petr Slovak, Maureen Freed, Nigel Shadbolt, Lize Alberts, Kai Lukoff, Max Van Kleek, Hannah Andrews, Michael Inzlicht, Guido Makransky, Laura Csuka, Ulrik Lyngs, Victoria Oldemburgo de Mello, Claudine Tinsman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147658">Link</a></p>
<h3>MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention</h3>
<p>Authors: Ruolan Wu, Xiaole Pan, Ningning Zhang, Yuanchun Shi, Li Chen, Yue Fu, Qiaolei Jiang, Yujia Liu, Yuhan Wang, Chun Yu, Xuhai "Orson" Xu, Zhi Zheng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146884">Link</a></p>
<h3>“You Can Find a Part of my Life in Every Single App”: An Interview Study of What Makes Smartphone Applications Special to Their Users</h3>
<p>Authors: Kasper Hornbæk, Mikael B. Skov, Olga Iarygina, Ulrik Lyngs</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148169">Link</a></p>
<h3>Navigating User-System Gaps: Understanding User-Interactions in User-Centric Context-Aware Systems for Digital Well-being Intervention</h3>
<p>Authors: Uichin Lee, Inyeop Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147725">Link</a></p>
<h2>Education and AI A</h2>
<h3>From Primary Education to Premium Workforce: Drawing on K-12 Approaches for Developing AI Literacy</h3>
<p>Authors: Ole Sejer Iversen, Magnus Høholt Kaspersen, Christian Dindler, Karl-Emil Bilstrup, Peter Dalsgaard, Marianne Graves Petersen, Line Musaeus</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147388">Link</a></p>
<p>Abstract: Advances in artificial intelligence present a need for fostering AI literacy in workplaces. While there is a lack of research on how this can be achieved, there are documented successful approaches in child-computer interaction (CCI), albeit aimed at K-12 education. We present an in-vivo explorative case study of how CCI approaches can be adopted for adult professionals via a full-day workshop developed in collaboration with a trade union to upskill workers. Analyzing data from pre- and post-surveys, a follow-up survey, and materials produced by participants (n=53), we demonstrate how this increased participants’ knowledge of AI while their self-efficacy and empowerment did not improve. This is similar to findings from K-12 education, pointing to self-efficacy and empowerment as major challenges for AI literacy across sectors. We discuss the role of ambassadorships and professional organizations in addressing these issues, and indicate research directions for the CHI community.</p>
<h3>More than Model Documentation: Uncovering Teachers' Bespoke Information Needs for Informed Classroom Integration of ChatGPT</h3>
<p>Authors: Hariharan Subramonyam, Mei Tan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147621">Link</a></p>
<p>Abstract: ChatGPT has entered classrooms, circumventing typical training and vetting procedures. Unlike other educational technologies, it placed teachers in direct contact with the versatility of generative AI. Consequently, teachers are urgently tasked to assess its capabilities to inform their use of ChatGPT. However, it is unclear what support teachers have and need and whether existing documentation, such as model cards, provides adequate direction for educators in this new paradigm. By interviewing 22 middle- and high-school ELA and Social Studies teachers, we connect the discourse on AI transparency and documentation with educational technology integration, highlighting the information needs of teachers. Our findings reveal that teachers confront significant information gaps, lacking clarity on exploring ChatGPT's capabilities for bespoke learning tasks and ensuring its fit with the needs of diverse learners. As a solution, we propose a framework for interactive model documentation that empowers teachers to navigate the interplay between pedagogical and technical knowledge. </p>
<h3>The Promise and Peril of ChatGPT in Higher Education: Opportunities, Challenges, and Design Implications</h3>
<p>Authors: Daehwan Ahn, Hyanghee Park</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147256">Link</a></p>
<p>Abstract: A growing number of students in higher education are using ChatGPT for various educational purposes, ranging from seeking information to writing essays. Although many universities have officially banned the use of ChatGPT because of its potential harm and unintended consequences, it is still important to uncover how students leverage ChatGPT for learning, what challenges emerge, and how we can make better use of ChatGPT in higher education. Thus, we conducted focus group workshops and a series of participatory design sessions with thirty students who have actively interacted with ChatGPT for one semester in university and with other five stakeholders (e.g., professors, AI experts). Based on these, this paper identifies real opportunities and challenges of utilizing and designing ChatGPT for higher education.</p>
<h3>Teaching artificial intelligence in extracurricular contexts through narrative-based learnersourcing</h3>
<p>Authors: Bansharee Ireen, Sophia Moore, Elizabeth Murnane, Grigory Artazyan, Winston Iskandar, Dylan Moore</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147257">Link</a></p>
<p>Abstract: Collaborative technology provides powerful opportunities to engage young people in active learning experiences that are inclusive, immersive, and personally meaningful. In particular, interactive narratives have proven to be effective scaffolds for learning, and learnersourcing has emerged as a promising student-driven approach to enable personalized education and quality control at-scale. We introduce the first synthesis of these ideas in the context of teaching artificial intelligence (AI), which is now seen as a critical component of 21st-century education. Specifically, we explore the design of a narrative-based learnersourcing platform where engagement is centered around a learner-made choose-your-own-adventure story. In grounding our approach, we draw from pedagogical literature, digital storytelling, and recent work on learnersourcing. We report on our iterative, learner-centered design process as well as our study findings that demonstrate the platform’s positive effects on knowledge gains, interest in AI concepts, and the overall user experience of narrative-based learnersourcing technology.</p>
<h3>ml-machine.org: Infrastructuring a Research Product to Disseminate AI Literacy in Education</h3>
<p>Authors: Niels Olof Bouvin, Magnus Høholt Kaspersen, Karl-Emil Bilstrup, Marianne Graves Petersen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148135">Link</a></p>
<p>Abstract: ml-machine.org is a web- and micro:bit-based educational tool for building machine learning models designed to enable more widespread teaching of AI literacy in secondary education. It has been designed as a research product in collaboration with partners from the educational sector, including the Danish Broadcasting Corporation and the Micro:bit Educational Foundation. ml-machine.org currently has more than 5000 unique users and is used in schools and teacher training. It is publicly available and promoted on the broadcasting corporation's platforms. We describe the two-year process of developing and disseminating ml-machine.org. Based on interviews with partners and educators, we report on how ml-machine.org supports inquiry into the adoption and appropriation of such educational tools. We also provide insights on working with formal education infrastructures in order to scale and integrate a research product into teacher practices. Based on these experiences, we propose infrastructure as a novel quality of research products.</p>
<h2>Ethics of Digital Technologies A</h2>
<h3>BLIP: Facilitating the Exploration of Undesirable Consequences of Digital Technologies</h3>
<p>Authors: Katharina Reinecke, Rock Pang, Sebastin Santy, Rene Just</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146666">Link</a></p>
<h3>Perceptions of Fairness in Technology-Mediated Marketplaces</h3>
<p>Authors: Coye Cheshire, Andrew Chong, Ji Su Yoo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147651">Link</a></p>
<h3>STILE: Exploring and Debugging Social Biases in Pre-trained Text Representations</h3>
<p>Authors: Samia Kabir, Lixiang Li, Tianyi Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147326">Link</a></p>
<h3>An Ontology of Dark Patterns Knowledge: Foundations, Definitions, and a Pathway for Shared Knowledge-Building</h3>
<p>Authors: Thomas Mildner, Nataliia Bielova, Colin Gray, Cristiana Teixeira Santos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147221">Link</a></p>
<h3>Beyond Dark Patterns: A Concept-Based Framework for Ethical Software Design</h3>
<p>Authors: Jonathan Zong, Daniel Jackson, Evan Caragay, Katherine Xiong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147293">Link</a></p>
<h2>Evaluating AI Technologies A</h2>
<h3>Are We Asking the Right Questions?: Designing for Community Stakeholders’ Interactions with AI in Policing</h3>
<p>Authors: Devansh Saxena, Joseph Chudzik, Md Romael Haque, Katy Weathington, Shion Guha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147789">Link</a></p>
<p>Abstract: Research into recidivism risk prediction in the criminal justice system has garnered significant attention from HCI, critical algorithm studies, and the emerging field of human-AI decision-making. This study focuses on algorithmic crime mapping, a prevalent yet underexplored form of algorithmic decision support (ADS) in this context. We conducted experiments and follow-up interviews with 60 participants, including community members, technical experts, and law enforcement agents (LEAs), to explore how lived experiences, technical knowledge, and domain expertise shape interactions with the ADS, impacting human-AI decision-making. Surprisingly, we found that domain experts (LEAs) often exhibited anchoring bias, readily accepting and engaging with the first crime map presented to them. Conversely, community members and technical experts were more inclined to engage with the tool, adjust controls, and generate different maps. Our findings highlight that all three stakeholders were able to provide critical feedback regarding AI design and use - community members questioned the core motivation of the tool, technical experts drew attention to the elastic nature of data science practice, and LEAs suggested redesign pathways such that the tool could complement their domain expertise.</p>
<h3>Human-LLM Collaborative Annotation Through Effective Verification of LLM Labels</h3>
<p>Authors: Sajjadur Rahman, Hannah Kim, Kushan Mitra, Xinru Wang, Zhengjie Miao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147019">Link</a></p>
<p>Abstract: Large language models (LLMs) have shown remarkable performance across various natural language processing (NLP) tasks, indicating their significant potential as data annotators. Although LLM-generated annotations are more cost-effective and efficient to obtain, they are often erroneous for complex or domain-specific tasks and may introduce bias when compared to human annotations. Therefore, instead of completely replacing human annotators with LLMs, we need to leverage the strengths of both LLMs and humans to ensure the accuracy and reliability of annotations. This paper presents a multi-step human-LLM collaborative approach where (1) LLMs generate labels and provide explanations, (2) a verifier assesses the quality of LLM-generated labels, and (3) human annotators re-annotate a subset of labels with lower verification scores. To facilitate human-LLM collaboration, we make use of LLM's ability to rationalize its decisions. LLM-generated explanations can provide additional information to the verifier model as well as help humans better understand LLM labels. We demonstrate that our verifier is able to identify potentially incorrect LLM labels for human re-annotation. Furthermore, we investigate the impact of presenting LLM labels and explanations on human re-annotation through crowdsourced studies.</p>
<h3>"AI enhances our performance, I have no doubt this one will do the same": The Placebo effect is robust to negative descriptions of AI</h3>
<p>Authors: Agnes Kloft, Steeven Villa, Robin Welsch, Thomas Kosch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148294">Link</a></p>
<p>Abstract: Heightened AI expectations facilitate performance in human-AI interactions through placebo effects. While lowering expectations to control for placebo effects is advisable, overly negative expectations could induce nocebo effects. In a letter discrimination task, we informed participants that an AI would either increase or decrease their performance by adapting the interface, when in reality, no AI was present in any condition. A Bayesian analysis showed that participants had high expectations and performed descriptively better irrespective of the AI description when a sham-AI was present. Using cognitive modeling, we could trace this advantage back to participants gathering more information. A replication study verified that negative AI descriptions do not alter expectations, suggesting that performance expectations with AI are biased and robust to negative verbal descriptions. We discuss the impact of user expectations on AI interactions and evaluation.</p>
<h3>An Evaluation of Situational Autonomy for Human-AI Collaboration in a Shared Workspace Setting</h3>
<p>Authors: Frank Jäkel, Dirk Balfanz, Dorothea Koert, Janik Schöpper, Vildan Salikutluk, Katrin Scheuermann, Eric Frodl, Franziska Herbert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147227">Link</a></p>
<p>Abstract: Designing interactions for human-AI teams (HATs) can be challenging due to an AI agent's potential autonomy. Previous work suggests that higher autonomy does not always improve team performance, and situation-dependent autonomy adaptation might be beneficial. However, there is a lack of systematic empirical evaluations of such autonomy adaptation in human-AI interaction. Therefore, we propose a cooperative task in a simulated shared workspace to investigate effects of fixed levels of AI autonomy and situation-dependent autonomy adaptation on team performance and user satisfaction. We derive adaptation rules for AI autonomy from previous work and a pilot study. We implement these rule for our main experiment and find that team performance was best when humans collaborated with an agent adjusting its autonomy based on the situation. Additionally, users rated this agent highest in terms of perceived intelligence. From these results, we discuss the influence of varying autonomy degrees on HATs in shared workspaces.</p>
<h3>Evaluating the Utility of Conformal Prediction Sets for AI-Advised Image Labeling</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Negar Kamali, Jessica Hullman, Angelos Chatzimparmpas, Dongping Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146876">Link</a></p>
<p>Abstract: As deep neural networks are more commonly deployed in high-stakes domains, their black-box nature makes uncertainty quantification challenging. We investigate the effects of presenting conformal prediction sets---a distribution-free class of methods for generating prediction sets with specified coverage---to express uncertainty in AI-advised decision-making. Through a large online experiment, we compare the utility of conformal prediction sets to displays of Top-$1$ and Top-$k$ predictions for AI-advised image labeling. In a pre-registered analysis, we find that the utility of prediction sets for accuracy varies with the difficulty of the task: while they result in accuracy on par with or less than Top-$1$ and Top-$k$ displays for easy images, prediction sets excel at assisting humans in labeling out-of-distribution (OOD) images, especially when the set size is small. Our results empirically pinpoint practical challenges of conformal prediction sets and provide implications on how to incorporate them for real-world decision-making.</p>
<h2>Eye and Face</h2>
<h3>EyeEcho: Continuous and Low-power Facial Expression Tracking on Glasses</h3>
<p>Authors: Francois Guimbretiere, Ke Li, Boao Chen, Mose Sakashita, Cheng Zhang, Ruidong Zhang, Siyuan Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146746">Link</a></p>
<h3>Uncovering and Addressing Blink-Related Challenges in Using Eye Tracking for Interactive Systems</h3>
<p>Authors: Henrike Weingärtner, Sven Mayer, Jesse Grootjen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147069">Link</a></p>
<h3>MELDER: The Design and Evaluation of a Real-time Silent Speech Recognizer for Mobile Devices</h3>
<p>Authors: Laxmi Pandey, Ahmed Arif</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146951">Link</a></p>
<h3>ReHEarSSE: Recognizing Hidden-in-the-Ear Silently Spelled Expressions</h3>
<p>Authors: Yuntao Wang, Ken Christofferson, Yifei Chen, Alex Mariakakis, Kaoru Sezaki, Xuefu Dong, Yuuki Nishiyama</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147342">Link</a></p>
<h3>Watch Your Mouth: Silent Speech Recognition with Depth Sensing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yang Zhang, Jun Rekimoto, Zixiong Su, Xue Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147350">Link</a></p>
<h2>Fabrication: 3D Printing A</h2>
<h3>SolderlessPCB: Reusing Electronic Components in PCB Prototyping through Detachable 3D Printed Housings</h3>
<p>Authors: Huaishu Peng, Jiasheng Li, Zining Zhang, Zeyu Yan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146974">Link</a></p>
<h3>The Effect of Orientation on the Readability and Comfort of 3D-Printed Braille</h3>
<p>Authors: Tarik Crnovrsanin, Laura South, Eduardo Puerta, Cody Dunne</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147955">Link</a></p>
<h3>SketchPath: Using Digital Drawing to Integrate the Gestural Qualities of Craft in CAM-Based Clay 3D Printing</h3>
<p>BEST_PAPER</p>
<p>Authors: Devon Frost, Eun-Ha Paek, Jennifer Jacobs, Raina Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148134">Link</a></p>
<h3>Throwing Out Conventions: Reimagining Craft-Centered CNC Tool Design through the Digital Pottery Wheel</h3>
<p>BEST_PAPER</p>
<p>Authors: Ilan Moyer, Devon Frost, Sam Bourgault, Jennifer Jacobs</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147769">Link</a></p>
<h3>3D Printing Locally Activated Visual-Displays Embedded in 3D Objects via Electrically Conductive and Thermochromic Materials</h3>
<p>Authors: Ryo Suzuki, Andrea Bianchi, Kongpyung (Justin) Moon, Zofia Marciniak</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147413">Link</a></p>
<h2>Finance and Money</h2>
<h3>Shortchanged: Uncovering and Analyzing Intimate Partner Financial Abuse in Consumer Complaints</h3>
<p>Authors: Vineeth Ravi, Rosanna Bellini, Kevin Lee, Jessica Staddon, Arkaprabha Bhattacharya</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148177">Link</a></p>
<h3>Stranger Danger? Investor Behavior and Incentives on Cryptocurrency Copy-Trading Platforms</h3>
<p>Authors: Daisuke Kawai, Kyle Soska, Nicolas Christin, Bryan Routledge, Ariel Zetlin-Jones</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148232">Link</a></p>
<h3>Supportive Fintech for Individuals with Bipolar Disorder: Financial Data Sharing Preferences for Longitudinal Care Management</h3>
<p>Authors: Mark Matthews, Johnna Blair, Erika F. H. Saunders, Jeff Brozena, Saeed Abdullah, Dahlia Mukherjee, Thomas Richardson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147609">Link</a></p>
<h3>Trading as Gambling: Social Investing and Financial Risks on the r/WallStreetBets subreddit</h3>
<p>Authors: Sam Moradzadeh, Xinning Gui, Yubo Kou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147259">Link</a></p>
<h3>"Don't put all your eggs in one basket": How Cryptocurrency Users Choose and Secure Their Wallets</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Tanusree Sharma, Sauvik Das, Yang Wang, Yaman Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148179">Link</a></p>
<h2>Hand Interaction</h2>
<h3>EITPose: Wearable and Practical Electrical Impedance Tomography for Continuous Hand Pose Estimation</h3>
<p>Authors: Alexander Kyu, Mayank Goel, Hongyu Mao, Karan Ahuja, Junyi Zhu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147181">Link</a></p>
<h3>EchoWrist: Continuous Hand Pose Tracking and Hand-Object Interaction Recognition Using Low-Power Active Acoustic Sensing On a Wristband</h3>
<p>Authors: Chi-Jung Lee, Sicheng Yin, Francois Guimbretiere, Ke Li, Tianhong Yu, Oliver Lopez, Vipin Gunda, Devansh Agarwal, Mose Sakashita, Cheng Zhang, James Kim, Ruidong Zhang, Boao Dong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147046">Link</a></p>
<h3>Single-handed Folding Interactions with a Modified Clamshell Flip Phone</h3>
<p>Authors: Antony Albert Raj Irudayaraj, Yen-Ting Yeh, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147358">Link</a></p>
<h3>Emotion Embodied: Unveiling the Expressive Potential of Single-Hand Gestures</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Kening Zhu, Shannon Santosa, Junnan Yu, Yuhan Luo, Yichen Wan, Minhui Liang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146626">Link</a></p>
<h3>Hand Gesture Recognition for Blind Users by Tracking 3D Gesture Trajectory</h3>
<p>Authors: Aruna Balasubramanian, IV Ramakrishnan, Xiaojun Bi, Prerna Khanna, Shubham Jain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148204">Link</a></p>
<h2>Health and AI A</h2>
<h3>``It Is a Moving Process'': Understanding the Evolution of Explainability Needs of Clinicians in Pulmonary Medicine</h3>
<p>Authors: Agathe Balayn, Jiwon Jung, Rembrandt Oltmans, Jie Yang, Lorenzo Corti, Marlies Wijsenbeek</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147566">Link</a></p>
<p>Abstract: Clinicians increasingly pay attention to Artificial Intelligence (AI) to improve the quality and timeliness of their services. There are converging opinions on the need for Explainable AI (XAI) in healthcare. However, prior work considers explanations as stationary entities with no account for the temporal dynamics of patient care. In this work, we involve 16 Idiopathic Pulmonary Fibrosis (IPF) clinicians from a European university medical centre and investigate their evolving uses and purposes for explainability throughout patient care. By applying a patient journey map for IPF, we elucidate clinicians' informational needs, how human agency and patient-specific conditions can influence the interaction with XAI systems, and the content, delivery, and relevance of explanations over time. We discuss implications for integrating XAI in clinical contexts and more broadly how explainability is defined and evaluated. Furthermore, we reflect on the role of medical education in addressing epistemic challenges related to AI literacy.</p>
<h3>Understanding the Impact of Long-Term Memory on Self-Disclosure with Large Language Model-Driven Chatbots for Public Health Intervention</h3>
<p>Authors: Yuin Jeong, Eunkyung Jo, SoHyun Park, Young-Ho Kim, Daniel Epstein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148244">Link</a></p>
<p>Abstract: Recent large language models (LLMs) offer the potential to support public health monitoring by facilitating health disclosure through open-ended conversations but rarely preserve the knowledge gained about individuals across repeated interactions. Augmenting LLMs with long-term memory (LTM) presents an opportunity to improve engagement and self-disclosure, but we lack an understanding of how LTM impacts people's interaction with LLM-driven chatbots in public health interventions. We examine the case of CareCall—an LLM-driven voice chatbot with LTM—through the analysis of 1,252 call logs and interviews with nine users. We found that LTM enhanced health disclosure and fostered positive perceptions of the chatbot by offering familiarity. However, we also observed challenges in promoting self-disclosure through LTM, particularly around addressing chronic health conditions and privacy concerns. We discuss considerations for LTM integration in LLM-driven chatbots for public health monitoring, including carefully deciding what topics need to be remembered in light of public health goals.  </p>
<h3>Advancing Patient-Centered Shared Decision-Making with AI Systems for Older Adult Cancer Patients</h3>
<p>Authors: Robert Riter, Yuexing Hao, Zeyu Liu, Saleh Kalantari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148222">Link</a></p>
<p>Abstract: Shared decision making (SDM) plays a vital role in clinical practice guidelines, fostering enduring therapeutic communication and patient-clinician relationships. Previous research indicates that active patient participation in decision-making improves satisfaction and treatment outcomes. However, medical decision-making can be intricate and multifaceted. To help make SDM more accessible, we designed a patient-centered Artificial Intelligence (AI) SDM system for older adult cancer patients who lack high health literacy to become more involved in the clinical decision-making process and to improve comprehension toward treatment outcomes. We conducted a pilot feasibility study through 12 preliminary interviews followed by 25 usability testing interviews after the system development, with older adult cancer survivors and clinicians. Results indicated promise in the AI system's ability to enhance SDM, providing personalized healthcare experiences and education for cancer patients. Clinician responses also provided useful suggestions for SDM’s new design and research opportunities in mitigating medical errors and improving clinical efficiency.</p>
<h3>Beyond the Waiting Room: Patient's Perspectives on the Conversational Nuances of Pre-Consultation Chatbots</h3>
<p>Authors: Khai Truong, Brenna Li, Noah Crampton, Alex Mariakakis, Ofek Gross, Saba Tauseef, Mamta Kapoor, Mohit Jain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147742">Link</a></p>
<p>Abstract: Pre-consultation serves as a critical information exchange between healthcare providers and patients, streamlining visits and supporting patient-centered care. Human-led pre-consultations offer many benefits, yet they require significant time and energy from clinical staff. In this work, we identify design goals for pre-consultation chatbots given their potential to carry out human-like conversations and autonomously adapt their line of questioning. We conducted a study with 33 walk-in clinic patients to elicit design considerations for pre-consultation chatbots. Participants were exposed to one of two study conditions: an LLM-powered AI agent and a Wizard-of-Oz agent simulated by medical professionals. Our study found that both conditions were equally well-received and demonstrated comparable conversational capabilities. However, the extent of the follow-up questions and the amount of empathy impacted the chatbot's perceived thoroughness and sincerity. Patients also highlighted the importance of setting expectations for the chatbot before and after the pre-consultation experience.</p>
<h3>How Much Decision Power Should (A)I Have?: Investigating Patients’ Preferences Towards AI Autonomy in Healthcare Decision Making</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Niko Vegt, Marina Bos-de Vos, Valentijn Visch, Dajung Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146903">Link</a></p>
<p>Abstract: Despite the growing potential of artificial intelligence (AI) in improving clinical decision making, patients' perspectives on the use of AI for their care decision making are underexplored. In this paper, we investigate patients’ preferences towards the autonomy of AI in assisting healthcare decision making. We conducted interviews and an online survey using an interactive narrative and speculative AI prototypes to elicit participants’ preferred choices of using AI in a pregnancy care context. The analysis of the interviews and in-story responses reveals that patients’ preferences for AI autonomy vary per person and context, and may change over time. This finding suggests the need for involving patients in defining and reassessing the appropriate level of AI assistance for healthcare decision making. Departing from these varied preferences for AI autonomy, we discuss implications for incorporating patient-centeredness in designing AI-powered healthcare decision making.</p>
<h2>Health and AI B</h2>
<h3>The Illusion of Empathy? Notes on Displays of Emotion in Human-Computer Interaction</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Malte Jung, Andrea Cuadra, James Landay, Nicola Dell, Deborah Estrin, Lynn Stein, Maria Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147950">Link</a></p>
<p>Abstract: From ELIZA to Alexa, Conversational Agents (CAs) have been deliberately designed to elicit or project empathy. Although empathy can help technology better serve human needs, it can also be deceptive and potentially exploitative. In this work, we characterize empathy in interactions with CAs, highlighting the importance of distinguishing evocations of empathy between two humans from ones between a human and a CA. To this end, we systematically prompt CAs backed by large language models (LLMs) to display empathy while conversing with, or about, 65 distinct human identities, and also compare how different LLMs display or model empathy. We find that CAs make value judgments about certain identities, and can be encouraging of identities related to harmful ideologies (e.g., Nazism and xenophobia). Moreover, a computational approach to understanding empathy reveals that despite their ability to display empathy, CAs do poorly when interpreting and exploring a user's experience, contrasting with their human counterparts.</p>
<h3>Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis</h3>
<p>Authors: Bingsheng Yao, Jeffrey Caterino, Shao Zhang, Jianing Yu, Lace Padilla, Ping Zhang, Yuxuan Lu, Dakuo Wang, Changchang Yin, Xuhai "Orson" Xu, Melanie Tory</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147992">Link</a></p>
<p>Abstract: Today's AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that \system enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.</p>
<h3>Leveraging Prompt-Based Large Language Models: Predicting Pandemic Health Decisions and Outcomes Through Social Media Language</h3>
<p>Authors: Eugenia Rho, Valerie Reyna, Uma Sushmitha Gunturi, Xiaohan Ding, Buse Carik</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147157">Link</a></p>
<p>Abstract: We introduce a multi-step reasoning framework using prompt-based LLMs to examine the relationship between social media language patterns and trends in national health outcomes. Grounded in fuzzy-trace theory, which emphasizes the importance of “gists” of causal coherence in effective health communication, we introduce Role-Based Incremental Coaching (RBIC), a prompt-based LLM framework, to identify gists at-scale. Using RBIC, we systematically extract gists from subreddit discussions opposing COVID-19 health measures (Study 1). We then track how these gists evolve across key events (Study 2) and assess their influence on online engagement (Study 3). Finally, we investigate how the volume of gists is associated with national health trends like vaccine uptake and hospitalizations (Study 4). Our work is the first to empirically link social media linguistic patterns to real-world public health trends, highlighting the potential of prompt-based LLMs in identifying critical online discussion patterns that can form the basis of public health communication strategies.</p>
<h3>Multimodal Healthcare AI: Identifying and Designing Clinically Relevant Vision-Language Applications for Radiology</h3>
<p>Authors: Shruthi Bannur, Daniel Coelho de Castro, Fernando Pérez-García, Stephen Harris, Matthew Lungren, Hannah Richardson, Stephanie Hyland, Kenza Bouzid, Anja Thieme, Joseph Jacob, Aditya Nori, Mercy Ranjit, Maria Teodora Wetscherek, Pratik Ghosh, Junaid Bajwa, Javier Alvarez-Valle, Ozan Oktay, Anton Schwaighofer, Nur Yildirim, Harshita Sharma, Mark Pinnock</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146624">Link</a></p>
<p>Abstract: Recent advances in AI combine large language models (LLMs) with vision encoders that bring forward unprecedented technical capabilities to leverage for a wide range of healthcare applications. Focusing on the domain of radiology, vision-language models (VLMs) achieve good performance results for tasks such as generating radiology findings based on a patient's medical image, or answering visual questions (e.g., ``Where are the nodules in this chest X-ray?''). However, the clinical utility of potential applications of these capabilities is currently underexplored. We engaged in an iterative, multidisciplinary design process to envision clinically relevant VLM interactions, and co-designed four VLM use concepts: Draft Report Generation, Augmented Report Review, Visual Search and Querying, and Patient Imaging History Highlights. We studied these concepts with 13 radiologists and clinicians who assessed the VLM concepts as valuable, yet articulated many design considerations. Reflecting on our findings, we discuss implications for integrating VLM capabilities in radiology, and for healthcare AI more generally.</p>
<h3>Human-Algorithmic Interaction Using a Large Language Model-Augmented Artificial Intelligence Clinical Decision Support System</h3>
<p>Authors: Ambrose Wong, Dennis Shung, Jasjeet Sekhon, Yuan Pu, Allen Hsiao, Loren Laine, Leigh Evans, Terika McCall, Kisung You, Rene Kizilcec, Mauro Giuffre, Niroop Rajashekar, Sunny Chung, Yeo Eun Shin, Colleen Chan, Theo Saarinen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147431">Link</a></p>
<p>Abstract: Integration of artificial intelligence (AI) into clinical decision support systems (CDSS) poses a socio-technological challenge that is impacted by usability, trust, and human-computer interaction (HCI). AI-CDSS interventions have shown limited benefit in clinical outcomes, which may be due to insufficient understanding of how health-care providers interact with AI systems. Large language models (LLMs) have the potential to enhance AI-CDSS, but haven't been studied in either simulated or real-world clinical scenarios. We present findings from a randomized controlled trial deploying AI-CDSS for the management of upper gastrointestinal bleeding (UGIB) with and without an LLM interface within realistic clinical simulations for physician and medical student participants. We find evidence that LLM augmentation improves ease-of-use, that LLM-generated responses with citations improve trust, and HCI varies based on clinical expertise. Qualitative themes from interviews suggest the perception of LLM-augmented AI-CDSS as a team-member used to confirm initial clinical intuitions and help evaluate borderline decisions. </p>
<h2>Health and Care Practices</h2>
<h3>Designing Communication Feedback Systems To Reduce Healthcare Providers’ Implicit Biases In Patient Encounters</h3>
<p>Authors: Reggie Casanova-Perez, Janice Sabin, Nadir Weibel, Manas Satish Bedmutha, Harshini Ramaswamy, Wanda Pratt, Andrea Hartzler, Brian Wood, Emily Bascom, Kelly Tobar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147797">Link</a></p>
<h3>Perceived Empathy of Technology Scale (PETS): Measuring Empathy of Systems Toward the User</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jonathan Rupp, Sven Mayer, Matthias Schmidmaier, Darina Cvetanova</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146760">Link</a></p>
<h3>Designing for Caregiver-facing Values Elicitation Tools</h3>
<p>BEST_PAPER</p>
<p>Authors: Charisse Foo, Gerald Huat Choon Koh, Sajeban Antonyrex, Pin Sym Foong, Natasha Ureyang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146676">Link</a></p>
<h3>Hospital Employee Experiences Caring for Patients in Smart Patient Rooms</h3>
<p>Authors: Jason Wiese, Joshua Dawson, Eden Fisher</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147343">Link</a></p>
<h3>Investigating Why Clinicians Deviate from Standards of Care: Liberating Patients from Mechanical Ventilation in the ICU</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Gursimran Chawla, Jeremy Kahn, Susanna Zlotnikov, Leigh Bukowski, James McCann, John Zimmerman, Aradhana Venkat, Jennifer Kim, Nur Yildirim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147846">Link</a></p>
<h2>Healthcare Training</h2>
<h3>Looking Together ≠ Seeing the Same Thing: Understanding Surgeons' Visual Needs During Intra-operative Coordination and Instruction</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Natalie Mateju, Michael Kemp, Xu Wang, Xinyue Chen, Jingying Wang, Vitaliy Popov, Gurjit Sandhu, Taylor Kantor</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146738">Link</a></p>
<h3>Surgment: Segmentation-enabled Semantic Search and Creation of Visual Question and Feedback to Support Video-Based Surgery Learning</h3>
<p>Authors: Tandis Soltani, Xu Wang, Haoran Tang, Jingying Wang, Vitaliy Popov, Taylor Kantor</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147894">Link</a></p>
<h3>MR Microsurgical Suture Training System with Level-Appropriate Support</h3>
<p>Authors: Hideki Koike, Shio Miyafuji, Yusuke Kojima, Taichi Kin, Yuka Tashiro, Takeo Igarashi, Satoshi Kiyofuji</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147989">Link</a></p>
<h3>Facilitating Virtual Reality Integration in Medical Education: A Case Study of Acceptability and Learning Impact in Childbirth Delivery Training</h3>
<p>Authors: Shengdong Zhao, Abhiram Kanneganti, Gosavi Arundhati Tushar, Eng Tat Khoo, Chang Liu, Felicia Tan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147754">Link</a></p>
<h3>"I'd be watching him contour till 10 o'clock at night'': Understanding Tensions between Teaching Methods and Learning Needs in Healthcare Apprenticeship</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Nadir Weibel, James D. Murphy, Kexin Cheng, Chen Chen, Matin Yarmand</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147449">Link</a></p>
<h2>Human-Robot Interaction A</h2>
<h3>A Robot Jumping the Queue: Expectations About Politeness and Power During Conflicts in Everyday Human-Robot Encounters</h3>
<p>Authors: Sam Thellman, Philipp Hock, Tom Ziemke, Linda Miller, Franziska Babel, Robin Welsch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147417">Link</a></p>
<h3>I feel being there, they feel being together: Exploring How Telepresence Robots Facilitate Long-Distance Family Communication</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Bongwon Suh, Hajin Lim, Joonhwan Lee, Jiyeon Seo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147312">Link</a></p>
<h3>PepperPose: Full-Body Pose Estimation with a Companion Robot</h3>
<p>Authors: Siqi Zheng, Yuntao Wang, Chongyang Wang, Tin Lun Lam, Yuanchun Shi, Lingxiao Zhong, Yuan Gao, Chen Liang, Chun Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146730">Link</a></p>
<h3>Giving Robots a Voice: Human-in-the-Loop Voice Creation and open-ended Labeling</h3>
<p>Authors: Pol van Rijn, Nori Jacoby, Kathrin Janowski, Katharina Weitz, Silvan Mertes, Elisabeth André</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147115">Link</a></p>
<h2>Human-Robot Interaction B</h2>
<h3>Robot-Assisted Decision-Making: Unveiling the Role of Uncertainty Visualisation and Embodiment</h3>
<p>Authors: Saumya Pareek, Wafa Johal, Jorge Goncalves, Sarah Schömbs</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146811">Link</a></p>
<h3>Trash in Motion: Emergent Interactions with a Robotic Trashcan</h3>
<p>Authors: Barry Brown, Wendy Ju, Ilan Mandel, Fanjun Bu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146631">Link</a></p>
<h3>Investigating Effect of Altered Auditory Feedback on Self-Representation, Subjective Operator Experience, and Task Performance in Teleoperation of a Social Robot</h3>
<p>Authors: Nami Ogawa, Jun Baba, Junya Nakanishi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147866">Link</a></p>
<h3>The Adaptive Architectural Layout: How the Control of a Semi-Autonomous Mobile Robotic Partition was Shared to Mediate the Environmental Demands and Resources of an Open-Plan Office</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Andrew Vande Moere, Alex Binh Vinh Duc Nguyen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146791">Link</a></p>
<h3>From Agent Autonomy to Casual Collaboration: A Design Investigation on Help-Seeking Urban Robots</h3>
<p>Authors: Martin Tomitsch, Marius Hoggenmüller, Xinyan Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148163">Link</a></p>
<h2>Human-Robot Interaction C</h2>
<h3>Impact of Multi-Robot Presence and Anthropomorphism on Human Cognition and Emotion</h3>
<p>Authors: Jiadi Luo, Lawrence Kim, Veronika Domova</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147559">Link</a></p>
<h3>Join Me Here if You Will: Investigating Embodiment and Politeness Behaviors When Joining Small Groups of Humans, Robots, and Virtual Characters</h3>
<p>Authors: Iolanda Leite, Sahba Zojaji, Christopher Peters, Andrii Matviienko</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147171">Link</a></p>
<h3>Designing Multispecies Worlds for Robots, Cats, and Humans</h3>
<p>BEST_PAPER</p>
<p>Authors: Eike Schneiders, Matt Adams, Nick Tandavanitj, Victor Ngo, Clara Mancini, Alan Chamberlain, Steven Benford, Simon Castle-Green, Joel Fischer, Ju Row Farr</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147577">Link</a></p>
<h3>Towards Robotic Companions: Understanding Handler-Guide Dog Interactions for Informed Guide Dog Robot Design</h3>
<p>BEST_PAPER</p>
<p>Authors: Sunghoon Lee, Hochul Hwang, Nicholas Giudice, Donghyun Kim, Joydeep Biswas, Hee-Tae Jung</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147890">Link</a></p>
<h2>Inter- and Cross-Species Interactions</h2>
<h3>No More Angry Birds: Investigating Touchscreen Ergonomics to Improve Tablet-Based Enrichment for Parrots</h3>
<p>Authors: Rebecca Kleinberger, Ilyena Hirskyj-Douglas, Jennifer Cunha, Megan McMahon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148084">Link</a></p>
<h3>Ellie Talks About the Weather: Toward Evaluating the Expressive and Enrichment Potential of a Tablet-Based Speech Board in a single Goffin’s Cockatoo</h3>
<p>Authors: Rebecca Kleinberger, Jennifer Cunha, Nikhil Singh, Megan McMahon, Lily Stella, Hao Jin, Corinne Renguette</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147963">Link</a></p>
<h3>Call of the Wild Web: Comparing Parrot Engagement in Live vs. Pre-Recorded Video Calls</h3>
<p>Authors: Rebecca Kleinberger, Ilyena Hirskyj-Douglas, Jennifer Cunha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147943">Link</a></p>
<h3>Uncovering Lemur Cross-Species Usage of an Interactive Audio Device In Zoos</h3>
<p>Authors: Ilyena Hirskyj-Douglas, Vilma Kankaanpää, Fay Clark</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147810">Link</a></p>
<h3>Charting Ethical Tensions in Multispecies Technology Research through Beneficiary-Epistemology Space</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Pepita Barnard Stringer, Ayse Kucukyilmaz, Eike Schneiders, Matt Adams, Guido Salimbeni, Nick Tandavanitj, Victor Ngo, Clara Mancini, Alan Chamberlain, Steven Benford, Simon Castle-Green, Joel Fischer, Ju Row Farr</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147025">Link</a></p>
<h2>Perception and Input in Immersive Environments</h2>
<h3>Big or Small, It’s All in Your Head: Visuo-Haptic Illusion of Size-Change Using Finger-Repositioning</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Andrea Bianchi, Mike Sinclair, Eyal Ofek, Myung Jin Kim, Michel Pahud</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147073">Link</a></p>
<p>Abstract: Haptic perception of physical sizes increases the realism and immersion in Virtual Reality (VR). Prior work rendered sizes by exerting pressure on the user’s fingertips or employing tangible, shape-changing devices. These interfaces are constrained by the physical shapes they can assume, making it challenging to simulate objects growing larger or smaller than the perceived size of the interface. Motivated by literature on pseudo-haptics describing the strong influence of visuals over haptic perception, this work investigates modulating the perception of size beyond this range. We developed a fixed-sized VR controller leveraging finger-repositioning to create a visuo-haptic illusion of dynamic size-change of handheld virtual objects. Through two user studies, we found that with an accompanying size-changing visual context, users can perceive virtual object sizes up to 44.2% smaller to 160.4%larger than the perceived size of the device. Without the accompanying visuals, a constant size (141.4% of device size) was perceived.</p>
<h3>STMG: A Machine Learning Microgesture Recognition System for Supporting Thumb-Based VR/AR Input</h3>
<p>Authors: Moshe Ben-Zacharia, Necati Cihan Camgöz, Shugao Ma, Eric Sauser, Andrei Marin, Yubo Zhang, Ayush Bhargava, Robert Wang, Chengde Wan, Yujun Cai, Fedor Kovalev, Ken Koh, Shannon Hoople, Mariel Sanchez-Rodriguez, Marcos Nunes-Ueno, Kenrick Kin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146737">Link</a></p>
<p>Abstract: AR/VR devices have started to adopt hand tracking, in lieu of controllers, to support user interaction. However, today's hand input rely primarily on one gesture: pinch. Moreover, current mappings of hand motion to use cases like VR locomotion and content scrolling involve more complex and larger arm motions than joystick or trackpad usage. STMG increases the gesture space by recognizing additional small thumb-based microgestures from skeletal tracking running on a headset. We take a machine learning approach and achieve a 95.1% recognition accuracy across seven thumb gestures performed on the index finger surface: four directional thumb swipes (left, right, forward, backward), thumb tap, and fingertip pinch start and pinch end. We detail the components to our machine learning pipeline and highlight our design decisions and lessons learned in producing a well generalized model. We then demonstrate how these microgestures simplify and reduce arm motions for hand-based locomotion and scrolling interactions.</p>
<h3>Beyond the Blink: Investigating Combined Saccadic &amp; Blink-Suppressed Hand Redirection in Virtual Reality</h3>
<p>Authors: Oscar Ariza, André Zenner, Chiara Karr, Antonio Krüger, Martin Feick</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147392">Link</a></p>
<p>Abstract: In pursuit of hand redirection techniques that are ever more tailored to human perception, we propose the first algorithm for hand redirection in virtual reality that makes use of saccades, i.e., fast ballistic eye movements that are accompanied by the perceptual phenomenon of change blindness. Our technique combines the previously proposed approaches of gradual hand warping and blink-suppressed hand redirection with the novel approach of saccadic redirection in one unified yet simple algorithm. We compare three variants of the proposed Saccadic &amp; Blink-Suppressed Hand Redirection (SBHR) technique with the conventional approach to redirection in a psychophysical study (N=25). Our results highlight the great potential of our proposed technique for comfortable redirection by showing that SBHR allows for significantly greater magnitudes of unnoticeable redirection while being perceived as significantly less intrusive and less noticeable than commonly employed techniques that only use gradual hand warping.</p>
<h3>TriPad: Touch Input in AR on Ordinary Surfaces with Hand Tracking Only</h3>
<p>Authors: Caroline Appert, Stéphanie Rey, Camille Dupré, Emmanuel Pietriga, Houssem Saidi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147490">Link</a></p>
<p>Abstract: TriPad enables opportunistic touch interaction in Augmented Reality using hand tracking only. Users declare the surface they want to appropriate with a simple hand tap gesture. They can then use this surface at will for direct and indirect touch input. TriPad only involves analyzing hand movements and postures, without the need for additional instrumentation, scene understanding or machine learning. TriPad thus works on a variety of flat surfaces, including glass. It also ensures low computational overhead on devices that typically have a limited power budget. We describe the approach, and report on two user studies. The first study demonstrates the robustness of TriPad's hand movement interpreter on different surface materials. The second study compares TriPad against direct mid-air AR input techniques on both discrete and continuous tasks and with different surface orientations. TriPad achieves a better speed-accuracy trade-off overall, improves comfort and minimizes fatigue.</p>
<h3>Flicker Augmentations: Rapid Brightness Modulation for Real-World Visual Guidance using Augmented Reality</h3>
<p>Authors: Kasper Hornbæk, Jonathan Sutton, Tobias Langlotz, Alexander Plopski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147292">Link</a></p>
<p>Abstract: Providing attention guidance, such as assisting in search tasks, is a prominent use for Augmented Reality.  Typically, this is achieved by graphically overlaying geometrical shapes such as arrows. However, providing visual guidance can cause side effects such as attention tunnelling or scene occlusions, and introduce additional visual clutter. Alternatively, visual guidance can adjust saliency but this comes with different challenges such as hardware requirements and environment dependent parameters. In this work we advocate for using flicker as an alternative for real-world guidance using Augmented Reality. We provide evidence for the effectiveness of flicker from two user studies. The first compared flicker against alternative approaches in a highly controlled setting, demonstrating efficacy (N = 28). The second investigated flicker in a practical task, demonstrating feasibility with higher ecological validity (N = 20). Finally, our discussion highlights the opportunities and challenges when using flicker to provide real-world visual guidance using Augmented Reality.</p>
<h2>Learning with AI</h2>
<h3>The Metacognitive Demands and Opportunities of Generative AI</h3>
<p>BEST_PAPER</p>
<p>Authors: Lev Tankelevitch, Auste Simkute, Ava Scott, Advait Sarkar, Viktor Kewenig, Abigail Sellen, Sean Rintel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147504">Link</a></p>
<p>Abstract: Generative AI (GenAI) systems offer unprecedented opportunities for transforming professional and personal work, yet present challenges around prompting, evaluating and relying on outputs, and optimizing workflows. We argue that metacognition—the psychological ability to monitor and control one’s thoughts and behavior—offers a valuable lens to understand and design for these usability challenges. Drawing on research in psychology and cognitive science, and recent GenAI user studies, we illustrate how GenAI systems impose metacognitive demands on users, requiring a high degree of metacognitive monitoring and control. We propose these demands could be addressed by integrating metacognitive support strategies into GenAI systems, and by designing GenAI systems to reduce their metacognitive demand by targeting explainability and customizability. Metacognition offers a coherent framework for understanding the usability challenges posed by GenAI, and provides novel research and design directions to advance human-AI interaction.</p>
<h3>BIDTrainer: An LLMs-driven Education Tool for Enhancing the Understanding and Reasoning in Bio-inspired Design</h3>
<p>Authors: Peter Childs, Zebin Cai, Liuqing Chen, Zhaojun Jiang, Lingyun Sun, Haoyu Zuo, Duowei Xia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147876">Link</a></p>
<p>Abstract: Bio-inspired design (BID) fosters innovative solutions in engineering by drawing inspiration from biology. Learning BID is crucial for developing multidisciplinary innovation skills of designers and engineers. While current BID education has attempted to enhance learners' understanding and analogical reasoning skills in BID, it often relies much on teachers' expertise. When learners turn to learn independently through some educational tools, there are challenges in understanding and reasoning practice in such complex multidisciplinary environment, as well as evaluating learning outcomes comprehensively. Addressing these challenges, we introduce a Large Language Models (LLMs)-driven BID education method based on a structured ontology, as well as three strategies: enhancing understanding through LLMs-enpowered "learning by asking", assisting reasoning by providing hints and feedback, and assessing learning outcomes through benchmarking against existing BID knowledge. Implementing the method, we developed BIDTrainer, an interactive BID education tool. User studies indicate that learners using BIDTrainer understood BID cases better, reason faster with higher interactivity than the baseline, and BIDTrainer assessed the learning outcomes consistent with experts.</p>
<h3>Teachers, Parents, and Students' perspectives on Integrating Generative AI into Elementary Literacy Education</h3>
<p>Authors: Xiaofei Zhou, Kylie Peppler, Shenshen Han, Zhenyao Cai, Richard Ko, Seth Corrigan, Ariel Han</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147607">Link</a></p>
<p>Abstract: The viral launch of new generative AI (GAI) systems, such as ChatGPT and Text-to-Image (TTL) generators, sparked questions about how they can be effectively incorporated into writing education. However, it is still unclear how teachers, parents, and students perceive and suspect GAI systems in elementary school settings. We conducted a workshop with twelve families (parent-child dyads) with children ages 8-12 and interviewed sixteen teachers in order to understand each stakeholder's perspectives and opinions on GAI systems for learning and teaching writing. We found that the GAI systems could be beneficial in generating adaptable teaching materials for teachers, enhancing ideation, and providing students with personalized, timely feedback. However, there are concerns over authorship, students’ agency in learning, and uncertainty concerning bias and misinformation. In this article, we discuss design strategies to mitigate these constraints by implementing an adults-oversight system, balancing AI-role allocation, and facilitating customization to enhance students’ agency over writing projects.</p>
<h3>Teaching Middle Schoolers about the Privacy Threats of Tracking and Pervasive Personalization: A Classroom Intervention Using Design-Based Research</h3>
<p>Authors: Philip Nelson, Kyra Derrick, Khushbu Singh, Nicole Bannister, Mehtab Iqbal, Sushmita Khan, Oluwafemi Osho, Kelly Caine, Bart Knijnenburg, Emily Sidnam-Mauch, Lingyuan Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146762">Link</a></p>
<p>Abstract: With the pervasive and evolving use of tracking and AI to make inferences about online platform users, it has become imperative for adolescents---a key demographic using such platforms---to develop a deep understanding of these practices to protect their privacy. Traditionally, K-12 cybersecurity education has largely been confined to extracurricular activities, limiting underrepresented students' access. To resolve this shortcoming, we partnered with a rural-identifying middle school to deliver AI-related privacy education in classrooms. Using Design-Based Research methodology, we identified students' AI-related privacy learning needs and developed six education modules. This paper focuses on the design, classroom implementation, and evaluation of module #2, covering the privacy threats of Tracking and Pervasive Personalization (TaPP). Student assessment outcomes show they developed transferable foundational knowledge of the privacy implications of tracking and personalization after participating in the TaPP module. Our findings demonstrate the benefits of integrating AI-related privacy education into existing K-12 curricula.</p>
<h3>Putting Things into Context: Generative AI-Enabled Context Personalization for Vocabulary Learning Improves Learning Motivation</h3>
<p>Authors: Pat Pataranutaporn, Yaoli Mao, Pattie Maes, Valdemar Danry, Joanne Leong, Florian Perteneder</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147682">Link</a></p>
<p>Abstract: Fostering students' interests in learning is considered to have many positive downstream effects. Large language models have opened up new horizons for generating content tuned to one's interests, yet it is unclear in what ways and to what extent this customization could have positive effects on learning. To explore this novel dimension, we conducted a between-subjects online study (n=272) featuring different variations of a generative AI vocabulary learning app that enables users to personalize their learning examples. Participants were randomly assigned to control (sentence sourced from pre-existing text) or experimental conditions (generated sentence or short story based on users’ text input). While we did not observe a difference in learning performance between the conditions, the analysis revealed that generative AI-driven context personalization positively affected learning motivation. We discuss how these results relate to previous findings and underscore their significance for the emerging field of using generative AI for personalized learning.  </p>
<h2>Menstrual Tracking and Health</h2>
<h3>Understanding Cultural and Religious Values Relating to Awareness of Women’s Intimate Health among Arab Muslims</h3>
<p>Authors: Latifa Al Naimi, Mirela Alistar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147619">Link</a></p>
<h3>"Islamically, I am not on my period": A Study of Menstrual Tracking in Muslim Women in the US</h3>
<p>Authors: James Clawson, Pallavi Panchpor, Zaidat Ibrahim, Novia Nurain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147294">Link</a></p>
<h3>Tracking During Ramadan: Examining the Intersection of Menstrual and Religious Tracking Practices Among Muslim Women in the United States</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: James Clawson, Zaidat Ibrahim, Novia Nurain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147054">Link</a></p>
<h3>Functional Design Requirements to Facilitate Menstrual Health Data Exploration</h3>
<p>Authors: Khai Truong, Brenna Li, Alex Mariakakis, Georgianna Lin, Minh Le, Pierre-William Lessard, Fanny Chevalier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147625">Link</a></p>
<h3>My Data, My Choice, My Insights: Women's Requirements when Collecting, Interpreting and Sharing their Personal Health Data</h3>
<p>Authors: Susanna Spoerl, Susanne Boll, Sophie Grimme, Marion Koelle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148283">Link</a></p>
<h2>Mental Health A</h2>
<h3>Supporting Cognitive Reappraisal With Digital Technology: A Content Analysis and Scoping Review of Challenges, Interventions, and Future Directions</h3>
<p>Authors: Alissa Antle, Petr Slovak, Alexandra Kitson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148296">Link</a></p>
<h3>Multi-stakeholder Perspectives on Mental Health Screening Tools for Children</h3>
<p>Authors: Tauhidur Rahman, Deepak Ganesan, Adam Grabell, Lynnea Mayorga, Adrelys Mateo Santana, Manasa Kalanadhabhatta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147792">Link</a></p>
<h3>HCI Contributions in Mental Health: A Modular Framework to Guide Psychosocial Intervention Design</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Petr Slovak, Sean Munson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148036">Link</a></p>
<h3>“Can you be with that feeling?”: Extending Design Strategies for Interoceptive Awareness for the Context of Mental Health</h3>
<p>Authors: A. Jess Williams, Petr Slovak, MacKenzie D. A. Robertson, Phoebe Staab</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146761">Link</a></p>
<h3>''I Call Upon a Friend'': Virtual Reality-Based Supports for Cognitive Reappraisal Identified through Co-designing with Adolescents</h3>
<p>Authors: Artun Cimensel, Alissa Antle, Ashu Adhikari, Alexandra Kitson, Kenneth Karthik, Sadhbh Kenny, Melissa Chan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147702">Link</a></p>
<h2>Mental Health and AI</h2>
<h3>Patient Perspectives on AI-Driven Predictions of Schizophrenia Relapses: Understanding Concerns and Opportunities for Self-Care and Treatment</h3>
<p>Authors: Viet Cuong Nguyen, Munmun De Choudhury, Dong Whi Yoo, Hayoung Woo, Kaylee Kruzan, Gregory Abowd, Michael L. Birnbaum, Jennifer Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147243">Link</a></p>
<p>Abstract: Early detection and intervention for relapse is important in the treatment of schizophrenia spectrum disorders. Researchers have developed AI models to predict relapse from patient-contributed data like social media. However, these models face challenges, including misalignment with practice and ethical issues related to transparency, accountability, and potential harm. Furthermore, how patients who have recovered from schizophrenia view these AI models has been underexplored. To address this gap, we first conducted semi-structured interviews with 28 patients and reflexive thematic analysis, which revealed a disconnect between AI predictions and patient experience, and the importance of the social aspect of relapse detection. In response, we developed a prototype that used patients' Facebook data to predict relapse. Feedback from seven patients highlighted the potential for AI to foster collaboration between patients and their support systems, and to encourage self-reflection. Our work provides insights into human-AI interaction and suggests ways to empower people with schizophrenia.</p>
<h3>Understanding Human-AI Collaboration in Music Therapy Through Co-Design with Therapists</h3>
<p>Authors: Jingjing Sun, Jingyi Yang, Jiangtao Gong, Guyue Zhou, Yucheng Jin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146901">Link</a></p>
<p>Abstract: The rapid development of musical AI technologies has expanded the creative potential of various musical activities, ranging from music style transformation to music generation. However, little research has investigated how musical AIs can support music therapists, who urgently need new technology support. This study used a mixed method, including semi-structured interviews and a participatory design approach. By collaborating with music therapists, we explored design opportunities for musical AIs in music therapy. We presented the co-design outcomes involving the integration of musical AIs into a music therapy process, which was developed from a theoretical framework rooted in emotion-focused therapy. After that, we concluded the benefits and concerns surrounding music AIs from the perspective of music therapists. Based on our findings, we discussed the opportunities and design implications for applying musical AIs to music therapy. Our work offers valuable insights for developing human-AI collaborative music systems in therapy involving complex procedures and specific requirements.</p>
<h3>Simulating Emotions With an Integrated Computational Model of Appraisal and Reinforcement Learning</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jussi Jokinen, Bernhard Hilpert, Jiayi Zhang, Joost Broekens</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147014">Link</a></p>
<p>Abstract: Predicting users' emotional states during interaction is a long-standing goal of affective computing. However, traditional methods based on sensory data alone fall short due to the interplay between users' latent cognitive states and emotional responses. To address this, we introduce a computational cognitive model that simulates emotion as a continuous process, rather than a static state, during interactive episodes. This model integrates cognitive-emotional appraisal mechanisms with computational rationality, utilizing value predictions from reinforcement learning. Experiments with human participants demonstrate the model's ability to predict and explain the emergence of emotions such as happiness, boredom, and irritation during interactions. Our approach opens the possibility of designing interactive systems that adapt to users' emotional states, thereby improving user experience and engagement. This work also deepens our understanding of the potential of modeling the relationship between reward processing, reinforcement learning, goal-directed behavior, and appraisal.</p>
<h3>Facilitating Self-Guided Mental Health Interventions Through Human-Language Model Interaction: A Case Study of Cognitive Restructuring</h3>
<p>Authors: Tim Althoff, Kevin Rushton, Theresa Nguyen, Inna Lin, Ashish Sharma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147699">Link</a></p>
<p>Abstract: Self-guided mental health interventions, such as "do-it-yourself" tools to learn and practice coping strategies, show great promise to improve access to mental health care. However, these interventions are often cognitively demanding and emotionally triggering, creating accessibility barriers that limit their wide-scale implementation and adoption. In this paper, we study how human-language model interaction can support self-guided mental health interventions. We take cognitive restructuring, an evidence-based therapeutic technique to overcome negative thinking, as a case study. In an IRB-approved randomized field study on a large mental health website with 15,531 participants, we design and evaluate a system that uses language models to support people through various steps of cognitive restructuring. Our findings reveal that our system positively impacts emotional intensity for 67% of participants and helps 65% overcome negative thoughts. Although adolescents report relatively worse outcomes, we find that tailored interventions that simplify language model generations improve overall effectiveness and equity.</p>
<h3>Seeking in Cycles: How Users Leverage Personal Information Ecosystems to Find Mental Health Information</h3>
<p>Authors: Abhishek Roy, Ashlee Milton, Rebecca Umbach, Stevie Chancellor, Juan Maestre</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146836">Link</a></p>
<p>Abstract: Information is crucial to how people understand their mental health and well-being, and many turn to online sources found through search engines and social media. We present an interview study (n = 17) of participants who use online platforms to seek information about their mental illnesses. Participants use their personal information ecosystems in a cyclical process to find information. This cycle is driven by the adoption of new information and questioning the credibility of information. Privacy concerns fueled by perceptions of stigma and platform design also influence their information-seeking decisions. Our work proposes theoretical implications for social computing and information retrieval on information seeking in users' personal information ecosystems. We offer design implications to support users in navigating personal information ecosystems to find mental health information.</p>
<h2>Mindfulness and Goals</h2>
<h3>Fragmented Moments, Balanced Choices: How Do People Make Use of Their Waiting Time?</h3>
<p>Authors: Jian Zheng, Ge Gao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147136">Link</a></p>
<h3>Mindful Scroll: An Infinite Scroll Abstract Colouring App for Mindfulness</h3>
<p>Authors: Craig Kaplan, Saralin Zassman, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147867">Link</a></p>
<h3>My Voice as a Daily Reminder: Self-Voice Alarm for Daily Goal Achievement</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jieun Kim, Hayeon Song</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146620">Link</a></p>
<h3>Leveraging Idle Games to Incentivize Intermittent and Frequent Practice of Deep Breathing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Book Sadprasid, Scott Bateman, Anne Mei, Alex Mariakakis, Fanny Chevalier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147724">Link</a></p>
<h3>Stairway to Heaven: A Gamified VR Journey for Breath Awareness</h3>
<p>Authors: Giovanni Troiano, Joseph Schwab, Hamid Ghaednia, Caleb Myers, Amir Abdollahi, Nathan Miner, Casper Harteveld, Mehmet Kosa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147670">Link</a></p>
<h2>Participatory AI</h2>
<h3>How Do Analysts Understand and Verify AI-Assisted Data Analyses?</h3>
<p>Authors: Ruoxi Shang, Steven Drucker, Tim Althoff, Ken Gu, Chenglong Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148040">Link</a></p>
<p>Abstract: Data analysis is challenging as it requires synthesizing domain knowledge, statistical expertise, and programming skills. Assistants powered by large language models (LLMs), such as ChatGPT, can assist analysts by translating natural language instructions into code. However, AI-assistant responses and analysis code can be misaligned with the analyst's intent or be seemingly correct but lead to incorrect conclusions. Therefore, validating AI assistance is crucial and challenging. Here, we explore how analysts understand and verify the correctness of AI-generated analyses. To observe analysts in diverse verification approaches, we develop a design probe equipped with natural language explanations, code, visualizations, and interactive data tables with common data operations. Through a qualitative user study (n=22) using this probe, we uncover common behaviors within verification workflows and how analysts' programming, analysis, and tool backgrounds reflect these behaviors. Additionally, we provide recommendations for analysts and highlight opportunities for designers to improve future AI-assistant experiences.</p>
<h3>From Fitting Participation to Forging Relationships: The Art of Participatory ML</h3>
<p>Authors: Alexandra Zafiroglu, Ned Cooper</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148266">Link</a></p>
<p>Abstract: Participatory machine learning (ML) encourages the inclusion of end users and people affected by ML systems in design and development processes. We interviewed 18 participation brokers—individuals who facilitate such inclusion and transform the products of participants' labour into inputs for an ML artefact or system—across a range of organisational settings and project locations. Our findings demonstrate the inherent challenges of integrating messy contextual information generated through participation with the structured data formats required by ML workflows and the uneven power dynamics in project contexts. We advocate for evolution in the role of brokers to more equitably balance value generated in Participatory ML projects for design and development teams with value created for participants. To move beyond 'fitting' participation to existing processes and empower participants to envision alternative futures through ML, brokers must become educators and advocates for end users, while attending to frustration and dissent from indirect stakeholders.</p>
<h3>Explaining It Your Way - Findings from a Co-Creative Design Workshop on Designing XAI Applications with AI End-Users from the Public Sector</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ceenu George, Maris Männiste, Katharina Weitz, Ruben Schlagowski, Elisabeth André</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148130">Link</a></p>
<p>Abstract: Human-Centered AI prioritizes end-users' needs like transparency and usability. This is vital for applications that affect people's everyday lives, such as social assessment tasks in the public sector. This paper discusses our pioneering effort to involve public sector AI users in XAI application design through a co-creative workshop with unemployment consultants from Estonia. The workshop's objectives were identifying user needs and creating novel XAI interfaces for the used AI system. As a result of our user-centered design approach, consultants were able to develop AI interface prototypes that would support them in creating success stories for their clients by getting detailed feedback and suggestions. We present a discussion on the value of co-creative design methods with end-users working in the public sector to improve AI application design and provide a summary of recommendations for practitioners and researchers working on AI systems in the public sector. </p>
<h3>Generative AI in the Wild: Prospects, Challenges, and Strategies</h3>
<p>Authors: Ting Wang, Yuan Sun, Eunchae Jang, Fenglong Ma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146627">Link</a></p>
<p>Abstract: Propelled by their remarkable capabilities to generate novel and engaging content, Generative Artificial Intelligence (GenAI) technologies are disrupting traditional workflows in many industries. While prior research has examined GenAI from a techno-centric perspective, there is still a lack of understanding about how users perceive and utilize GenAI in real-world scenarios. To bridge this gap, we conducted semi-structured interviews with (N = 18) GenAI users in creative industries, investigating the human-GenAI co-creation process within a holistic LUA (Learning, Using and Assessing) framework. Our study uncovered an intriguingly complex landscape: Prospects -- GenAI greatly fosters the co-creation between human expertise and GenAI capabilities, profoundly transforming creative workflows; Challenges -- Meanwhile, users face substantial uncertainties and complexities arising from resource availability, tool usability, and regulatory compliance; Strategies -- In response, users actively devise various strategies to overcome many of such challenges. Our study reveals key implications for the design of future GenAI tools. </p>
<h3>The Situate AI Guidebook: Co-Designing a Toolkit to Support Multi-Stakeholder, Early-stage Deliberations Around Public Sector AI Proposals</h3>
<p>Authors: Kenneth Holstein, Anna Kawakami, Haiyi Zhu, Amanda Coston, Hoda Heidari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147906">Link</a></p>
<p>Abstract: Public sector agencies are rapidly deploying AI systems to augment or automate critical decisions in real-world contexts like child welfare, criminal justice, and public health. </p>
<p>A growing body of work documents how these AI systems often fail to improve services in practice. These failures can often be traced to decisions made during the early stages of AI ideation and design, such as problem formulation. However, today, we lack systematic processes to support effective, early-stage decision-making about whether and under what conditions to move forward with a proposed AI project. To understand how to scaffold such processes in real-world settings, we worked with public sector agency leaders, AI developers, frontline workers, and community advocates across four public sector agencies and three community advocacy groups in the United States. Through an iterative co-design process, we created the Situate AI Guidebook: a structured process centered around a set of deliberation questions to scaffold conversations around (1) goals and intended use or a proposed AI system, (2) societal and legal considerations, (3) data and modeling constraints, and (4) organizational governance factors. We discuss how the guidebook's design is informed by participants’ challenges, needs, and desires for improved deliberation processes. We further elaborate on implications for designing responsible AI toolkits in collaboration with public sector agency stakeholders and opportunities for future work to expand upon the guidebook. This design approach can be more broadly adopted to support the co-creation of responsible AI toolkits that scaffold key decision-making processes surrounding the use of AI in the public sector and beyond.</p>
<h2>Privacy &amp; Boundaries</h2>
<h3>Under the (neighbor)hood: Hyperlocal Surveillance on Nextdoor</h3>
<p>Authors: Madiha Zahrah Choksi, Travis Lloyd, Marianne Aubin Le Quere, James Grimmelmann, Ruojia Tao, Mor Naaman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147901">Link</a></p>
<h3>What You Experience is What We Collect: User Experience Based Fine-Grained Permissions for Everyday Augmented Reality</h3>
<p>Authors: Melvin Abraham, Mohamed Khamis, Mark McGill</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146684">Link</a></p>
<h3>“I Don’t Want to Become a Number’’: Examining Different Stakeholder Perspectives on a Video-Based Monitoring System for Senior Care with Inherent Privacy Protection (by Design).</h3>
<p>Authors: Tamara Mujirishvili, Kooshan Hashemifard, Francisco Florez-Revuelta, Pau Climent-Pérez, Anton Fedosov</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146872">Link</a></p>
<h3>Bring Privacy To The Table: Interactive Negotiation for Privacy Settings of Shared Sensing Devices</h3>
<p>Authors: Haozhe Zhou, Mayank Goel, Yuvraj Agarwal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147351">Link</a></p>
<h3>What to the Muslim is Internet search: Digital Borders as Barriers to Information</h3>
<p>Authors: Sucheta Ghoshal, Lubna Razaq</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147363">Link</a></p>
<h2>Privacy for Safer Web and Apps</h2>
<h3>“That’s Kind of Sus(picious)”: The Comprehensiveness of Mental Health Application Users’ Privacy and Security Concerns</h3>
<p>Authors: Rachael Kang, Helena M. Mentis, Yi Xuan Khoo, Tera L. Reynolds</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146698">Link</a></p>
<h3>Websites Need Your Permission Too -- User Sentiment and Decision-Making on Web Permission Prompts in Desktop Chrome</h3>
<p>Authors: Marian Harbach</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147321">Link</a></p>
<h3>PriviAware: Exploring Data Visualization and Dynamic Privacy Control Support for Data Collection in Mobile Sensing Research</h3>
<p>Authors: Yugyeong Jung, Uichin Lee, Hei Yiu Law, Seolyeong Bae, Hyunsoo Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148313">Link</a></p>
<h3>Privacy of Default Apps in Apple’s Mobile Ecosystem</h3>
<p>Authors: Janne Lindqvist, Amel Bourdoucen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147013">Link</a></p>
<h3>Measuring Compliance with the California Consumer Privacy Act Over Space and Time</h3>
<p>Authors: Van Tran, Aarushi Mehrotra, Lior Strahilevitz, Marshini Chetty, Nick Feamster, Jens Frankenreiter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147035">Link</a></p>
<h2>Privacy and Deepfake</h2>
<h3>Non-Consensual Synthetic Intimate Imagery: Prevalence, Attitudes, and Knowledge in 10 Countries</h3>
<p>Authors: Nicola Henry, Rebecca Umbach, Colleen Berryessa, Gemma Beard</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148314">Link</a></p>
<h3>It's Trying Too Hard To Look Real: Deepfake Moderation Mistakes and Identity-Based Bias</h3>
<p>Authors: Collins Munyendo, Gang Wang, Jaron Mink, Kurt Hugenberg, Tadayoshi Kohno, Elissa Redmiles, Miranda Wei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147959">Link</a></p>
<h3>Examining Human Perception of Generative Content Replacement in Image Privacy Protection</h3>
<p>Authors: Koji Yatani, Shitao Fang, Anran Xu, Simo Hosio, Huan Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148241">Link</a></p>
<h3>Dungeons &amp; Deepfakes: Using scenario-based role-play to study journalists' behavior towards using AI-based verification tools for video content</h3>
<p>Authors: Matthew Wright, Yijing Kelly Wu, Andrea Hickerson, Saniat Sohrawardi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146663">Link</a></p>
<h3>Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks</h3>
<p>BEST_PAPER</p>
<p>Authors: Hao-Ping (Hank) Lee, Sauvik Das, Thomas Serban von Davier, Jodi Forlizzi, Yu-Ju Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146930">Link</a></p>
<h2>Reflection and Regulation for Wellbeing</h2>
<h3>“I feel like he’s looking in the computer world to be social, but I can’t trust his judgement”: Reimagining Parental Control for Children with ASD</h3>
<p>Authors: Prakriti Dumaru, Mahdi Nasrullah Al-Ameen, Audrey Flood, Bryson Hackler</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147979">Link</a></p>
<h3>Supporting Experiential Learning in People with Gestational Diabetes Mellitus</h3>
<p>Authors: Chia-Fang Chung, Clara Caldeira, Zaidat Ibrahim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147011">Link</a></p>
<h3>Momentary Stressor Logging and Reflective Visualizations: Implications for Stress Management with Wearables</h3>
<p>Authors: Mithun Saha, Nasir Ali, David M. Almeida, Santosh Kumar, Anandatirtha Nandugudi, Shahin Samiei, Timothy Hnat, Sameer Neupane</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148091">Link</a></p>
<h3>From Disorientation to Harmony: Autoethnographic Insights into Transformative Videogame Experiences</h3>
<p>BEST_PAPER</p>
<p>Authors: Jaakko Väkevä, Elisa Mekler, Janne Lindqvist</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147641">Link</a></p>
<h3>New Understandings of Loss: Examining the Role of Reflective Technology Within Bereavement and Meaning-Making</h3>
<p>Authors: Chia-Fang Chung, Colin LeFevre</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147535">Link</a></p>
<h2>Research Methods and Tools B</h2>
<h3>"To Click or not to Click": Back to Basic for Experience Sampling for Office Well-being in Shared Office Spaces</h3>
<p>Authors: Steven Houben, Hans Brombacher, Steven Vos, Dimitra Dritsa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147147">Link</a></p>
<h3>Who is "I"?: Subjectivity and  Ethnography in HCI</h3>
<p>Authors: Heidi Biggs, Tejaswini Joshi, Jeffrey Bardzell, Shaowen Bardzell</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147561">Link</a></p>
<h3>Understanding fraudulence in online qualitative studies: From the researcher's perspective</h3>
<p>Authors: Chia-Fang Chung, Chun-Han Ariel Wang, Seung Wan Ha, Kay Connelly, Aswati Panicker, Yuxing Wu, Katie Siek, Zaidat Ibrahim, Novia Nurain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147323">Link</a></p>
<h3>Did You Misclick? Reversing 5-Point Satisfaction Scales Causes Unintended Responses</h3>
<p>Authors: Martin Pielot</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147691">Link</a></p>
<h3>Towards Estimating Missing Emotion Self-reports Leveraging User Similarity: A Multi-task Learning Approach</h3>
<p>Authors: Surjya Ghosh, Sougata Sen, Salma Mandi, Bivas Mitra, Pradipta De</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148276">Link</a></p>
<h2>Security Systems</h2>
<h3>Is a Trustmark and QR Code Enough? The Effect of IoT Security and Privacy Label Information Complexity on Consumer Comprehension and Behavior</h3>
<p>Authors: Xinran Li, Lorrie Cranor, Dillon Shu, Hamsini Ravishankar, Yuvraj Agarwal, Claire Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146756">Link</a></p>
<h3>I see an IC: A Mixed-Methods Approach to Study Human Problem-Solving Processes in Hardware Reverse Engineering</h3>
<p>Authors: Markus Weber, René Walendy, Steffen Becker, Carina Wiesen, Christof Paar, Nikol Rummel, Malte Elson, Jingjie Li, Younghyun Kim, Kassem Fawaz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146998">Link</a></p>
<h3>Mental Models, Expectations and Implications of Client-Side Scanning: An Interview Study with Experts</h3>
<p>Authors: Sascha Fahl, Adrian Dabrowski, Divyanshu Bhardwaj, Katharina Krombholz, Carolyn Guthoff</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147543">Link</a></p>
<h3>VeriSMS: A Message Verification System for Inclusive Patient Outreach against Phishing Attacks</h3>
<p>Authors: Chenkai Wang, Jonathan Handler, Gang Wang, Cody Zevnik, Hadjer Benkraouda, Zhuofan Jia, Roopa Foulger, Nicholas Heuermann</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148268">Link</a></p>
<h3>SkullID: Through-Skull Sound Conduction based Authentication for Smartglasses</h3>
<p>Authors: HongMin Kim, Iljoo Kim, Ian Oakley, Eunyong Cheon, Bum Jun Kwon, Hyejin Shin, Jun Ho Huh, Choong-Hoon Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146810">Link</a></p>
<h2>Social Support for Wellbeing</h2>
<h3>Saharaline: A Collective Social Support Intervention for Teachers in Low-Income Indian Schools</h3>
<p>Authors: Rama Adithya Varanasi, Nicola Dell, Aditya Vashistha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147521">Link</a></p>
<h3>Machine and Human Understanding of Empathy in Online Peer Support: A Cognitive Behavioral Approach</h3>
<p>Authors: Zainab Iftikhar, Sara Syed, Jeff Huang, Amy Xiao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146964">Link</a></p>
<h3>"Butt call me once you get a chance to chat &#128578;" : Designing Persuasive Reminders for Veterans to Facilitate Peer-Mentor Support</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: SHEIKH AHAMED, Robert Curry, Md Romael Haque, Praveen Madiraju, Sabirat Rubya, Natalie Baker, Zeno Franco, OTIS WINSTEAD</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146845">Link</a></p>
<h3>Transitioning Towards a Proactive Practice: A Longitudinal Field Study on the Implementation of a ML System in Adult Social Care</h3>
<p>Authors: Marina Jirotka, Lars Kunze, Tyler Reinmund</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147484">Link</a></p>
<h3>The Sound of Support: Gendered Voice Agent as Support to Minority Teammates in Gender-Imbalanced Team</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Angel Hsing-Chi Hwang, Andrea Stevenson Won</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148275">Link</a></p>
<h2>Universal Accessibility A</h2>
<h3>Exploring Mobile Device Accessibility: Challenges, Insights, and Recommendations for Evaluation Methodologies</h3>
<p>Authors: Carlos Duarte, Letícia Seixas Pereira, Maria Matos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146754">Link</a></p>
<h3>Human I/O: Towards a Unified Approach to Detecting Situational Impairments</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jiahao Li, Ruofei Du, Xiang 'Anthony' Chen, David Kim, Xingyu Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148270">Link</a></p>
<h3>AXNav: Replaying Accessibility Tests from Natural Language</h3>
<p>Authors: Ruijia Cheng, Amanda Swearngin, Yue Jiang, Maryam Taeb, Eldon Schoop, Jeffrey Nichols</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147260">Link</a></p>
<h3>AccessLens: Auto-detecting Inaccessibility of Everyday Objects</h3>
<p>Authors: Qian Lu, Nahyun Kwon, Muhammad Hasham Qazi, Jeeeun Kim, Joanne Liu, Changhoon Oh, Shu Kong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147903">Link</a></p>
<h3>A Systematic Review of Ability-diverse Collaboration through Ability-based Lens in HCI</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Lan Xiao, Tigmanshu Bhatnagar, Maryam Bandukda, Michael Sedlmair, Katrin Angerbauer, Weiyue Lin, Catherine Holloway</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147798">Link</a></p>
<h2>User Studies on Large Language Models</h2>
<h3>The Effects of Perceived AI Use On Content Perceptions</h3>
<p>Authors: Irene Rae</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147441">Link</a></p>
<p>Abstract: There is a potential future where the content created by a human and an AI are indistinguishable. In this future, if you can't tell the difference, does it matter?  We conducted a 3 (Assigned creator: human, human with AI assistance, AI) by 4 (Context: news, travel, health, and jokes) mixed-design experiment where participants evaluated human-written content that was presented as created by a human, a human with AI assistance, or an AI.  We found that participants felt more negatively about the content creator and were less satisfied when they thought AI was used, but assigned creator had no effect on content judgments.  We also identified five interpretations for how participants thought AI use affected the content creation process.  Our work suggests that informing users about AI use may not have the intended effect of helping consumers make content judgments and may instead damage the relationship between creators and followers.</p>
<h3>DirectGPT: A Direct Manipulation Interface to Interact with Large Language Models</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Sylvain Malacria, Géry Casiez, Damien Masson, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146635">Link</a></p>
<p>Abstract: We characterize and demonstrate how the principles of direct manipulation can improve interaction with large language models. This includes: continuous representation of generated objects of interest; reuse of prompt syntax in a toolbar of commands; manipulable outputs to compose or control the effect of prompts; and undo mechanisms. This idea is exemplified in DirectGPT, a user interface layer on top of ChatGPT that works by transforming direct manipulation actions to engineered prompts. A study shows participants were 50% faster and relied on 50% fewer and 72% shorter prompts to edit text, code, and vector images compared to baseline ChatGPT. Our work contributes a validated approach to integrate LLMs into traditional software using direct manipulation. Data, code, and demo available at https://osf.io/3wt6s.</p>
<h3>From Text to Self: Users’ Perception of AIMC Tools on Interpersonal Communication and Self</h3>
<p>BEST_PAPER</p>
<p>Authors: Sami Foell, Alexis Hiniker, Yue Fu, Xuhai "Orson" Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146970">Link</a></p>
<p>Abstract: In the rapidly evolving landscape of AI-mediated communication (AIMC), tools powered by Large Language Models (LLMs) are becoming integral to interpersonal communication. Employing a mixed-methods approach, we conducted a one-week diary and interview study to explore users’ perceptions of these tools’ ability to: 1) support interpersonal communication in the short-term, and 2) lead to potential long-term effects. Our findings indicate that participants view AIMC support favorably, citing benefits such as increased communication confidence, finding precise language to express their thoughts, and navigating linguistic and cultural barriers. However, our findings also show current limitations of AIMC tools, including verbosity, unnatural responses, and excessive emotional intensity. These shortcomings are further exacerbated by user concerns about inauthenticity and potential overreliance on the technology. We identify four key communication spaces delineated by communication stakes (high or low) and relationship dynamics (formal or informal) that differentially predict users’ attitudes toward AIMC tools. Specifically, participants report that these tools are more suitable for communicating in formal relationships than informal ones and more beneficial in high-stakes than low-stakes communication.</p>
<h3>Farsight: Fostering Responsible AI Awareness During AI Application Prototyping</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Michael Terry, Michael Madaio, Zijie Wang, Lauren Wilcox, Chinmay Kulkarni</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146993">Link</a></p>
<p>Abstract: Prompt-based interfaces for Large Language Models (LLMs) have made prototyping and building AI-powered applications easier than ever before. However, identifying potential harms that may arise from AI applications remains a challenge, particularly during prompt-based prototyping. To address this, we present Farsight, a novel in situ interactive tool that helps people identify potential harms from the AI applications they are prototyping. Based on a user's prompt, Farsight highlights news articles about relevant AI incidents and allows users to explore and edit LLM-generated use cases, stakeholders, and harms. We report design insights from a co-design study with 10 AI prototypers and findings from a user study with 42 AI prototypers. After using Farsight, AI prototypers in our user study are better able to independently identify potential harms associated with a prompt and find our tool more useful and usable than existing resources. Their qualitative feedback also highlights that Farsight encourages them to focus on end-users and think beyond immediate harms. We discuss these findings and reflect on their implications for designing AI prototyping experiences that meaningfully engage with AI harms. Farsight is publicly accessible at: https://pair-code.github.io/farsight.</p>
<h3>“As an AI language model, I cannot”: Investigating LLM Denials of User Requests</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Niels van Berkel, Joel Wester, Henning Pohl, Tim Schrills</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148063">Link</a></p>
<p>Abstract: Users ask large language models (LLMs) to help with their homework, for lifestyle advice, or for support in making challenging decisions. Yet LLMs are often unable to fulfil these requests, either as a result of their technical inabilities or policies restricting their responses. To investigate the effect of LLMs denying user requests, we evaluate participants' perceptions of different denial styles. We compare specific denial styles (baseline, factual, diverting, and opinionated) across two studies, respectively focusing on LLM's technical limitations and their social policy restrictions. Our results indicate significant differences in users' perceptions of the denials between the denial styles. The baseline denial, which provided participants with brief denials without any motivation, was rated significantly higher on frustration and significantly lower on usefulness, appropriateness, and relevance. In contrast, we found that participants generally appreciated the diverting denial style. We provide design recommendations for LLM denials that better meet peoples' denial expectations.</p>
<h2>Visualization and Sonification</h2>
<h3>Glanceable Data Visualizations for Older Adults: Establishing Thresholds and Examining Disparities Between Age Groups</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yujie Gong, Petra Isenberg, Ali Sarvghad, Tanja Blascheck, Zack While</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148143">Link</a></p>
<h3>DynaVis: Dynamically Synthesized UI Widgets for Visualization Editing</h3>
<p>BEST_PAPER</p>
<p>Authors: Priyan Vaithilingam, Jeevana Priya Inala, Elena Glassman, Chenglong Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148267">Link</a></p>
<h3>Graph4GUI: Graph Neural Networks for Representing Graphical User Interfaces</h3>
<p>Authors: Yue Jiang, Vikas Garg, Changkong Zhou, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146736">Link</a></p>
<h3>Erie: A Declarative Grammar for Data Sonification</h3>
<p>Authors: Yea-Seul Kim, Jessica Hullman, Hyeok Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148059">Link</a></p>
<h3>“It is hard to remove from my eye”: Design Makeup Residue Visualization System for Chinese Traditional Opera (Xiqu) Performers</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zeyu Xiong, Mingming Fan, Chenqing Zhu, Shihan Fu, Xiaojuan Ma, Yanying Zhu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146861">Link</a></p>
<h2>Wellbeing and Eating: Nutrition and Weight</h2>
<h3>FoodCensor: Promoting Mindful Digital Food Content Consumption for People with Eating Disorders</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Subin Park, Sujin Han, Ryuhaerang Choi, Sung-Ju Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146779">Link</a></p>
<h3>Integrating Expertise in LLMs: Crafting a Customized Nutrition Assistant with Refined Template Instructions</h3>
<p>Authors: Ronald Metoyer, Heather Eicher-Miller, Brianna Wimer, Annalisa Szymanski, Oghenemaro Anuyah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147537">Link</a></p>
<h3>Beyond Static Labels: Unpacking Nutrition Comprehension in the Digital Age</h3>
<p>Authors: Ronald Metoyer, Brianna Wimer, Annalisa Szymanski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148140">Link</a></p>
<h3>Investigating Contextual Notifications to Drive Self-Monitoring in mHealth Apps for Weight Maintenance</h3>
<p>Authors: Meena Shankar, Jaime Ruiz, Xuanpu Zhang, Oluwatomisin Obajemu, Yu-Peng Chen, Lisa Anthony, Kathryn Ross, Julia Woodward, Dinank Bista, Ishvina Singh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148173">Link</a></p>
<h3>Predicting early user churn in a public digital weight loss intervention</h3>
<p>Authors: Elgar Fleisch, Robert Jakob, Tobias Kowatsch, Nils Lepper</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148260">Link</a></p>
<h2>Wellbeing and Mental Health B</h2>
<h3>DeepStress: Supporting Stressful Context Sensemaking in Personal Informatics Systems Using a Quasi-experimental Approach</h3>
<p>Authors: Uichin Lee, Sangjun Park, Gyuwon Jung</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147710">Link</a></p>
<h3>Maintaining Continuing Bonds in Bereavement: A Participatory Design Process of Be.side</h3>
<p>Authors: Jieun Kim, Giulia Barbareschi, Daisuke Uriu, Youichi Kamiyama, Kouta Minamizawa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146846">Link</a></p>
<h3>"I'm gonna KMS": From Imminent Risk to Youth Joking about Suicide and Self-Harm via Social Media</h3>
<p>Authors: Munmun De Choudhury, Sarvech Qadir, Ashwaq Alsoubai, Naima Samreen Ali, Pamela Wisniewski, Afsaneh Razi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147067">Link</a></p>
<h3>EmoEden: Applying Generative Artificial Intelligence to Emotional Learning for Children with High-Function Autism</h3>
<p>Authors: Wenkai Chen, Yu Cai, Yao Du, Liuqing Chen, Yilin Tang, Lingyun Sun, Ziyu Chen, Fan Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146914">Link</a></p>
<h3>“This app said I had severe depression, and now I don’t know what to do”: the unintentional harms of mental health applications</h3>
<p>BEST_PAPER</p>
<p>Authors: Rachael Kang, Tera L. Reynolds</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147719">Link</a></p>
<h2>Writing and AI A</h2>
<h3>MindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients' Journaling</h3>
<p>Authors: Hwajung Hong, Chanmo Yang, Hyun AH Kim, Su-woo Lee, Seolyeong Bae, Taewan Kim, Young-Ho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147830">Link</a></p>
<p>Abstract: Large Language Models (LLMs) offer promising opportunities in mental health domains, although their inherent complexity and low controllability elicit concern regarding their applicability in clinical settings. We present MindfulDiary, an LLM-driven journaling app that helps psychiatric patients document daily experiences through conversation. Designed in collaboration with mental health professionals, MindfulDiary takes a state-based approach to safely comply with the experts' guidelines while carrying on free-form conversations. Through a four-week field study involving 28 patients with major depressive disorder and five psychiatrists, we examined how MindfulDiary facilitates patients' journaling practice and clinical care. The study revealed that MindfulDiary supported patients in consistently enriching their daily records and helped clinicians better empathize with their patients through an understanding of their thoughts and daily contexts. Drawing on these findings, we discuss the implications of leveraging LLMs in the mental health domain, bridging the technical feasibility and their integration into clinical settings.</p>
<h3>Shaping Human-AI Collaboration: Varied Scaffolding Levels in Co-writing with Language Models</h3>
<p>Authors: Shaochun Zheng, Somayeh Molaei, Lionel Robert, Paramveer Dhillon, Maximilian Golub, Jiaqi Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147385">Link</a></p>
<p>Abstract: Advances in language modeling have paved the way for novel human-AI co-writing experiences. This paper explores how varying levels of scaffolding from large language models (LLMs) shape the co-writing process. Employing a within-subjects field experiment with a Latin square design, we asked participants (N=131) to respond to argumentative writing prompts under three randomly sequenced conditions: no AI assistance (control), next-sentence suggestions (low scaffolding), and next-paragraph suggestions (high scaffolding). Our findings reveal a U-shaped impact of scaffolding on writing quality and productivity (words/time). While low scaffolding did not significantly improve writing quality or productivity, high scaffolding led to significant improvements, especially benefiting non-regular writers and less tech-savvy users. No significant cognitive burden was observed while using the scaffolded writing tools, but a moderate decrease in text ownership and satisfaction was noted. Our results have broad implications for the design of AI-powered writing tools, including the need for personalized scaffolding mechanisms.</p>
<h3>The HaLLMark Effect: Supporting Provenance and Transparent Use of Large Language Models in Writing with Interactive Visualization</h3>
<p>Authors: Cecilia Shelton, Md Naimul Hoque, Kari Kraus, Bhavya Ghai, Tasfia Mashiat, Fanny Chevalier, Niklas Elmqvist</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147129">Link</a></p>
<p>Abstract: The use of Large Language Models (LLMs) for writing has sparked controversy both among readers and writers. On one hand, writers are concerned that LLMs will deprive them of agency and ownership, and readers are concerned about spending their time on text generated by soulless machines. On the other hand, AI-assistance can improve writing as long as writers can conform to publisher policies, and as long as readers can be assured that a text has been verified by a human. We argue that a system that captures the provenance of interaction with an LLM can help writers retain their agency, conform to policies, and communicate their use of AI to publishers and readers transparently. Thus we propose HaLLMark, a tool for visualizing the writer's interaction with the LLM. We evaluated HaLLMark with 13 creative writers, and found that it helped them retain a sense of control and ownership of the text.</p>
<h3>ABScribe: Rapid Exploration &amp; Organization of Multiple Writing Variations in Human-AI Co-Writing Tasks using Large Language Models</h3>
<p>Authors: Kashish Mittal, Joseph Williams, Tovi Grossman, Anastasia Kuzminykh, Peter Dushniku, Ilya Musabirov, Nathan Laundry, Michael Liut, Zhi Yuan "Michael" Yu, Mohi Reza</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148096">Link</a></p>
<p>Abstract: Exploring alternative ideas by rewriting text is integral to the writing process. State-of-the-art Large Language Models (LLMs) can simplify writing variation generation. However, current interfaces pose challenges for simultaneous consideration of multiple variations: creating new variations without overwriting text can be difficult, and pasting them sequentially can clutter documents, increasing workload and disrupting writers' flow. To tackle this, we present ABScribe, an interface that supports rapid, yet visually structured, exploration and organization of writing variations in human-AI co-writing tasks. With ABScribe, users can swiftly modify variations using LLM prompts, which are auto-converted into reusable buttons. Variations are stored adjacently within text fields for rapid in-place comparisons using mouse-over interactions on a popup toolbar. Our user study with 12 writers shows that ABScribe significantly reduces task workload (d = 1.20, p &lt; 0.001), enhances user perceptions of the revision process (d = 2.41, p &lt; 0.001) compared to a popular baseline workflow, and provides insights into how writers explore variations using LLMs.</p>
<h2>Writing and AI B</h2>
<h3>Writer-Defined AI Personas for On-Demand Feedback Generation</h3>
<p>Authors: Hendrik Heuer, Daniel Buschek, Florian Lehmann, Tim Zindulka, Karim Benharrak</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147111">Link</a></p>
<p>Abstract: Compelling writing is tailored to its audience. This is challenging, as writers may struggle to empathize with readers, get feedback in time, or gain access to the target group. We propose a concept that generates on-demand feedback, based on writer-defined AI personas of any target audience. We explore this concept with a prototype (using GPT-3.5) in two user studies (N=5 and N=11): Writers appreciated the concept and strategically used personas for getting different perspectives. The feedback was seen as helpful and inspired revisions of text and personas, although it was often verbose and unspecific. We discuss the impact of on-demand feedback, the limited representativity of contemporary AI systems, and further ideas for defining AI personas. This work contributes to the vision of supporting writers with AI by expanding the socio-technical perspective in AI tool design: To empower creators, we also need to keep in mind their relationship to an audience.</p>
<h3>Intelligent Support Engages Writers Through Relevant Cognitive Processes</h3>
<p>Authors: Thiemo Wambsganss, Andreas Göldi, Seyed Parsa Neshaei, Roman Rietsche</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147114">Link</a></p>
<p>Abstract: Student peer review writing is prevalent and important in education for fostering critical thinking and learning motivation. However, it often entails challenges such as high effort and writer's block. Leaving students unsupported may thus diminish the efficacy of the process. Large Language Models (LLMs) offer a potential remedy, but their utility hinges on user-centered design. Guided by design-determining constructs from the Cognitive Process Theory of Writing, we developed an intelligent writing support tool to alleviate these challenges, aiding 1) ideation and 2) evaluation. A randomized experiment (n=120) confirmed users were less inclined to utilize the tool's intelligent features when offered pre-supplied ideas or evaluations, validating our approach. Moreover, students engaged not less but more with their writing if support was available, indicating an enhanced experience. Our research illuminates design choices for enhancing LLM-based tools' usability and user experience, specifically optimizing intelligent writing support tools to facilitate student peer review.</p>
<h3>The Value, Benefits, and Concerns of Generative AI-Powered Assistance in Writing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jing Peng, Chen Liang, Ming Yin, Zhuoyan Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147288">Link</a></p>
<p>Abstract: Recent advances in generative AI technologies like large language models raise both excitement and concerns about the future of human-AI co-creation in writing. To unpack people’s attitude towards and experience with generative AI-powered writing assistants, in this paper, we conduct an experiment to understand whether and how much value people attach to AI assistance, and how the incorporation of AI assistance in writing workflows changes people’s writing perceptions and performance. Our results suggest that people are willing to forgo financial payments to receive writing assistance from AI, especially if AI can provide direct content generation assistance and the writing task is highly creative. Generative AI-powered assistance is found to offer benefits in increasing people’s productivity and confidence in writing. However, direct content generation assistance offered by AI also comes with risks, including decreasing people’s sense of accountability and diversity in writing. We conclude by discussing the implications of our findings.</p>
<h3>Rambler: Supporting Writing With Speech via LLM-Assisted Gist Manipulation</h3>
<p>Authors: Can Liu, J.D. Zamfirescu-Pereira, Sauhard Jain, Susan Lin, Shumin Zhai, Bjoern Hartmann, Matthew Lee, Michael Xuelin Huang, Jeremy Warner, Shanqing Cai, Piyawat Lertvittayakumjorn</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147240">Link</a></p>
<p>Abstract: Dictation enables efficient text input on mobile devices. However, writing with speech can produce disfluent, wordy, and incoherent text and thus requires heavy post-processing. This paper presents Rambler, an LLM-powered graphical user interface that supports gist-level manipulation of dictated text with two main sets of functions: gist extraction and macro revision. Gist extraction generates keywords and summaries as anchors to support the review and interaction with spoken text. LLM-assisted macro revisions allow users to respeak, split, merge, and transform dictated text without specifying precise editing locations. Together they pave the way for interactive dictation and revision that help close gaps between spontaneously spoken words and well-structured writing. In a comparative study with 12 participants performing verbal composition tasks, \tool outperformed the baseline of a speech-to-text editor + ChatGPT, as it better facilitates iterative revisions with enhanced user control over the content while supporting surprisingly diverse user strategies.</p>
<h2>Writing, Sketching and AI</h2>
<h3>Neural Canvas: Supporting Scenic Design Prototyping by Integrating 3D Sketching and Generative AI</h3>
<p>Authors: Jiawen Cheng, Zeyu Wang, Yifei Shen, Mingming Fan, Chutian Jiang, Yulin Shen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147583">Link</a></p>
<p>Abstract: We propose Neural Canvas, a lightweight 3D platform that integrates sketching and a collection of generative AI models to facilitate scenic design prototyping. Compared with traditional 3D tools, sketching in a 3D environment helps designers quickly express spatial ideas, but it does not facilitate the rapid prototyping of scene appearance or atmosphere. Neural Canvas integrates generative AI models into a 3D sketching interface and incorporates four types of projection operations to facilitate 2D-to-3D content creation. Our user study shows that Neural Canvas is an effective creativity support tool, enabling users to rapidly explore visual ideas and iterate 3D scenic designs. It also expedites the creative process for both novices and artists who wish to leverage generative AI technology, resulting in attractive and detailed 3D designs created more efficiently than using traditional modeling tools or individual generative AI platforms.</p>
<h3>A Design Space for Intelligent and Interactive Writing Assistants</h3>
<p>Authors: Pao Siangliulue, Simon Buckingham Shum, Sherol Chen, Thiemo Wambsganss, Disha Shrivastava, Madiha Zahrah Choksi, Roy Pea, Subhashini Venugopalan, Sitong Wang, Eugenia Rho, Hua Shen, Antoine Bosselut, John Chung, Avinash Bhat, Tal August, Jessi Stark, Joonsuk Park, Joseph Chee Chang, Senjuti Dutta, Max Kreminski, David Zhou, Zejiang Shen, Lila Shroff, Yewon Kim, Daniel Buschek, Agnia Sergeyuk, Katy Gero, Antonette Shibani, Md Naimul Hoque, Vipul Raheja, Seyed Parsa Neshaei, Sarah Sterman, Emad Alghamdi, Jin L.C. Guo, Mina Lee, Simon Knight</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146994">Link</a></p>
<p>Abstract: In our era of rapid technological advancement, the research landscape for writing assistants has become increasingly fragmented across various research communities. We seek to address this challenge by proposing a design space as a structured way to examine and explore the multidimensional space of intelligent and interactive writing assistants. Through community collaboration, we explore five aspects of writing assistants: task, user, technology, interaction, and ecosystem. Within each aspect, we define dimensions and codes by systematically reviewing 115 papers while leveraging the expertise of researchers in various disciplines. Our design space aims to offer researchers and designers a practical tool to navigate, comprehend, and compare the various possibilities of writing assistants, and aid in the design of new writing assistants.</p>
<h3>The Impact of Sketch-guided vs. Prompt-guided 3D Generative AIs on the Design Exploration Process</h3>
<p>Authors: Sergio Bromberg, Tae Hee Jo, Seonghoon Ban, Kyungwon Yun, Kyung Hoon Hyun, Seung Won Lee, Jiin Choi, Semin Jin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148240">Link</a></p>
<p>Abstract: Various modalities have emerged in the field of 3D generative AI (GenAI) to enhance design outcomes.  While some designers find inspiration in prompts to guide their design options, others prefer sketching to embody creative visions. Nonetheless, the impact of the different modalities of 3D GenAI on the design process remains largely unexplored. This study examines the utilization of prompt- and sketch-guided modalities within the design process by conducting linkography and workflow analyses with 12 designers. The results revealed that prompts played a pivotal role in stimulating initial ideation, whereas sketches played a crucial role in embodying design ideas. This investigation highlights the distinct contributions of these modalities at different phases of the design process, suggesting the potential for a more refined and synergistic collaboration between humans and AI. By elucidating the diverse functions of sketches and prompts, we propose prospective directions for the UX framework of the 3D GenAI.</p>
<h3>CreativeConnect: Supporting Reference Recombination for Graphic Design Ideation with Generative AI</h3>
<p>Authors: Jeongeon Park, John Chung, DaEun Choi, Sumin Hong, Juho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147936">Link</a></p>
<p>Abstract: Graphic designers often get inspiration through the recombination of references. Our formative study (N=6) reveals that graphic designers focus on conceptual keywords during this process, and want support for discovering the keywords, expanding them, and exploring diverse recombination options of them, while still having room for designers' creativity. We propose CreativeConnect, a system with generative AI pipelines that helps users discover useful elements from the reference image using keywords, recommends relevant keywords, generates diverse recombination options with user-selected keywords, and shows recombinations as sketches with text descriptions. Our user study (N=16) showed that CreativeConnect helped users discover keywords from the reference and generate multiple ideas based on them, ultimately helping users produce more design ideas with higher self-reported creativity compared to the baseline system without generative pipelines. While CreativeConnect was shown effective in ideation, we discussed how CreativeConnect can be extended to support other types of tasks in creativity support.</p>
<h2>Children and Adults Online Safety</h2>
<h3>"Pikachu would electrocute people who are misbehaving": Expert, Guardian and Child Perspectives on Automated Embodied Moderators for Safeguarding Children in Social Virtual Reality</h3>
<p>Authors: Cristina Fiani, Mohamed Khamis, Shaun Macdonald, Mark McGill, Robin Bretin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147166">Link</a></p>
<h3>Tricky vs. Transparent: Towards an Ecologically Valid and Safe Approach for Evaluating Online Safety Nudges for Teens</h3>
<p>Authors: Zainab Agha, Ruyuan Wan, Jinkyung Park, Yiwei Wang, Dominic DiFranzo, Naima Samreen Ali, Pamela Wisniewski, Karla Badillo-Urquiola</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147274">Link</a></p>
<h3>Systemization of Knowledge (SoK): Creating a Research Agenda for Human-Centered Real-Time Risk Detection on Social Media Platforms</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jinkyung Park, Sarvech Qadir, Ashwaq Alsoubai, Pamela Wisniewski, Afsaneh Razi, Gianluca Stringhini</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147468">Link</a></p>
<h3>"I Know I'm Being Observed:" Video Interventions to Educate Users about Targeted Advertising on Facebook</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Rhea Vengurlekar, Trevor Jones, Xinru Page, Stephanie Morales, Brian Smith, Norman Su, Yun-Chieh Tsai, Garrett Smith, Rachel George, Mainack Mondal, Josh Bedwell, Bart Knijnenburg, Sarah Carson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147986">Link</a></p>
<h3>Sharenting on TikTok: Exploring Parental Sharing Behaviors and the Discourse Around Children's Online Privacy</h3>
<p>Authors: Sophie Stephenson, Christopher Page, Franziska Roesner, Apu Kapadia, Miranda Wei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147746">Link</a></p>
<h2>Creativity Tools</h2>
<h3>EyeGuide &amp; EyeConGuide: Gaze-based Visual Guides to Improve 3D Sketching Systems</h3>
<p>Authors: Wolfgang Stuerzlinger, Zeynep Ecem Gelmez, Rumeysa Turkmen, Mayra Barrera Machuca, Paul Asente, Anil Ufuk Batmaz, Mine Sarac, Ken Pfeuffer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147653">Link</a></p>
<h3>Formulating or Fixating: Effects of Examples on Problem Solving Vary as a Function of Example Presentation Interface Design</h3>
<p>Authors: Mark Fuge, Joel Chan, Zijian Ding, Eesh Kamrah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147454">Link</a></p>
<h3>GenQuery: Supporting Expressive Visual Search with Generative Models</h3>
<p>Authors: DaEun Choi, Tae Soo Kim, Juho Kim, Kihoon Son, Young-Ho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148274">Link</a></p>
<h3>Inkeraction: An Interaction Modality Powered by Ink Recognition and Synthesis</h3>
<p>Authors: Tayeb Karim, Lei Shi, Philippe Gervais, Palash Nandy, Rob Mickle, Mathangi Venkatesan, Mike Cleron, Ashwin Ganti, David Robishaw, Chris Melancon, Rachel Campbell, Maria Cirimele, Pedro Gonnet, Andrii Maksai, Angad Singh, Xiaoyu Iris Qu, Chelsey Fleming, Kirsten Climer, Claudiu Musat, Peggy Chi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147672">Link</a></p>
<h3>Personalizing Products with Stylized Head Portraits for Self-Expression</h3>
<p>Authors: Shengqi Dang, Yang Shi, Nan Cao, Nanxuan Zhao, Yechun Peng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147814">Link</a></p>
<h2>Ethics of Digital Technologies B</h2>
<h3>Fighting Malicious Designs: Towards Visual Countermeasures Against Dark Patterns</h3>
<p>Authors: Jan Borchers, René Röpke, René Schäfer, Sarah Sahabi, Paul Preuschoff</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147553">Link</a></p>
<h3>A Scoping Study of Evaluation Practices for Responsible AI Tools: Steps Towards Effectiveness Evaluations</h3>
<p>Authors: Glen Berman, Michael Madaio, Nitesh Goyal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147656">Link</a></p>
<h3>Searching for the Non-Consequential: Dialectical Activities in HCI and the Limits of Computers</h3>
<p>Authors: Haoqi Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147571">Link</a></p>
<h3>Building an Ethics-Focused Action Plan: Roles, Process Moves, and Trajectories</h3>
<p>Authors: Ziqing Li, Brookley Rigsbee, Matthew Will, Shruthi Sai Chivukula, Aayushi Bharadwaj, Janna Johns, Ambika R Menon, Thomas Carlock, Anne Pivonka, Colin Gray, Ike Obi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147804">Link</a></p>
<h3>Staying at the Roach Motel: Cross-Country Analysis of Manipulative Subscription and Cancellation Flows</h3>
<p>Authors: Ashley Sheil, David Malone, Raphael Gellert, Hanna Schraffenberger, Gunes Acar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147230">Link</a></p>
<h2>Supporting Children and Teens Socialization</h2>
<h3>From Adolescents' Eyes: Assessing an Indicator-Based Intervention to Combat Misinformation on TikTok</h3>
<p>Authors: Franziska Schneider, Tom Biselli, Katrin Hartwig, Christian Reuter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147187">Link</a></p>
<h3>For Me or Not for Me? The Ease With Which Teens Navigate Accurate and Inaccurate Personalized Social Media Content</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Nora McDonald, John Seberger, Afsaneh Razi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146940">Link</a></p>
<h3>Wrist-bound Guanxi, Jiazu, and Kuolie: Unpacking Chinese Adolescent Smartwatch-Mediated Socialization</h3>
<p>Authors: Zhicong Lu, Lanjing Liu, Chao Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148286">Link</a></p>
<h3>ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events</h3>
<p>Authors: Chanmo Yang, Woosuk Seo, Young-Ho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148027">Link</a></p>
<h3>‘A Teaspoon of Authenticity’: Exploring How Young Adults BeReal on Social Media</h3>
<p>Authors: Priya Kumar, Ananya Reddy</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148046">Link</a></p>
<h2>Online Communities: Engagement A</h2>
<h3>Message in a Bottle: Investigating Bioart Installations as a Transdisciplinary Means of Community Engagement</h3>
<p>Authors: Lydia Stamato, Hasan Mahmud Prottoy, Erin Higgins, Lisa Scheifele, Foad Hamidi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147439">Link</a></p>
<h3>Analyzing User Engagement with TikTok's Short Format Video Recommendations using Data Donations</h3>
<p>Authors: Angelica Goetzen, Savvas Zannettou, Oshrat Ayalon, Olivia Nemes-Nemeth, Franziska Roesner, Krishna P. Gummadi, Elissa Redmiles</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147650">Link</a></p>
<h3>Mapping the Design Space of Teachable Social Media Feed Experiences</h3>
<p>Authors: K. J. Kevin Feng, Xander Koo, David McDonald, Amy Zhang, Lawrence Tan, Amy Bruckman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147899">Link</a></p>
<h3>How Founder Motivations, Goals, and Actions Influence Early Trajectories of Online Communities</h3>
<p>Authors: Sanjay Kairam, Jeremy Foote</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147364">Link</a></p>
<h3>“I Prefer Regular Visitors to Answer My Questions”: Users’ Desired Experiential Background of Contributors for Location-based Crowdsourcing Platform</h3>
<p>Authors: Chia-Yi Lee, Fang-Yu Lin, Yi-Ting Ho, Grace Yu-Chun Yen, Yao-Kuang Chen, Pei-Hua Tsai, Yung-Ju Chang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147015">Link</a></p>
<h2>Evaluating AI Technologies B</h2>
<h3>Listening to the Voices: Describing Ethical Caveats of Conversational User Interfaces According to Experts and Frequent Users</h3>
<p>Authors: John Sloan, Gian-Luca Savino, Jasmin Niess, Thomas Mildner, Rainer Malaka, Nina Wenig, Leigh Clark, Anna-Maria Meck, Marion Bartl, Diego Garaialde, Philip Doyle, Orla Cooney</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147969">Link</a></p>
<p>Abstract: Advances in natural language processing and understanding have led to a rapid growth in the popularity of conversational user interfaces (CUIs). While CUIs introduce novel benefits, they also yield risks that may exploit people's trust. Although research looking at unethical design deployed through graphical user interfaces (GUIs) established a thorough taxonomy of so-called dark patterns, there is a need for an equally in-depth understanding in the context of CUIs. Addressing this gap, we interviewed 27 participants from three cohorts: researchers, practitioners, and frequent users of CUIs. Applying thematic analysis, we develop five themes reflecting each cohort's insights about ethical design challenges and introduce the CUI Expectation Cycle, bridging system capabilities and user expectations while respecting each theme's ethical caveats. This research aims to inform future work to consider ethical constraints while adopting a human-centred approach.</p>
<h3>EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria</h3>
<p>Authors: Jamin Shin, Tae Soo Kim, Juho Kim, Young-Ho Kim, Yoonjoo Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147201">Link</a></p>
<p>Abstract: By simply composing prompts, developers can prototype novel generative applications with Large Language Models (LLMs). To refine prototypes into products, however, developers must iteratively revise prompts by evaluating outputs to diagnose weaknesses. Formative interviews (N=8) revealed that developers invest significant effort in manually evaluating outputs as they assess context-specific and subjective criteria. We present EvalLM, an interactive system for iteratively refining prompts by evaluating multiple outputs on user-defined criteria. By describing criteria in natural language, users can employ the system's LLM-based evaluator to get an overview of where prompts excel or fail, and improve these based on the evaluator's feedback. A comparative study (N=12) showed that EvalLM, when compared to manual evaluation, helped participants compose more diverse criteria, examine twice as many outputs, and reach satisfactory prompts with 59% fewer revisions. Beyond prompts, our work can be extended to augment model evaluation and alignment in specific application contexts.</p>
<h3>Understanding Choice Independence and Error Types in Human-AI Collaboration</h3>
<p>Authors: Abhinav Sharma, Ujwal Gadiraju, Alexander Erlei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147055">Link</a></p>
<p>Abstract: The ability to make appropriate delegation decisions is an important prerequisite of effective human-AI collaboration. Recent work, however, has shown that people struggle to evaluate AI systems in the presence of forecasting errors, falling well short of relying on AI systems appropriately. We use a pre-registered crowdsourcing study ($N=611$) to extend this literature by two underexplored crucial features of human AI decision-making: \textit{choice independence} and \textit{error type}. Subjects in our study repeatedly complete two prediction tasks and choose which predictions they want to delegate to an AI system. For one task, subjects receive a decision heuristic that allows them to make informed and relatively accurate predictions. The second task is substantially harder to solve, and subjects must come up with their own decision rule. We systematically vary the AI system's performance such that it either provides the best possible prediction for both tasks or only for one of the two. Our results demonstrate that people systematically violate choice independence by taking the AI's performance in an unrelated second task into account. Humans who delegate predictions to a superior AI in their own expertise domain significantly reduce appropriate reliance when the model makes systematic errors in a complementary expertise domain. In contrast, humans who delegate predictions to a superior AI in a complementary expertise domain significantly increase appropriate reliance when the model systematically errs in the human expertise domain. Furthermore, we show that humans differentiate between error types and that this effect is conditional on the considered expertise domain. This is the first empirical exploration of choice independence and error types in the context of human-AI collaboration. Our results have broad and important implications for the future design, deployment, and appropriate application of AI systems.  </p>
<h3>ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Martin Wattenberg, Priyan Vaithilingam, Chelse Swoopes, Ian Arawjo, Elena Glassman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147701">Link</a></p>
<p>Abstract: Evaluating outputs of large language models (LLMs) is challenging, requiring making—and making sense of—many responses. Yet tools that go beyond basic prompting tend to require knowledge of programming APIs, focus on narrow domains, or are closed-source. We present ChainForge, an open-source visual toolkit for prompt engineering and on-demand hypothesis testing of text generation LLMs. ChainForge provides a graphical interface for comparison of responses across models and prompt variations. Our system was designed to support three tasks: model selection, prompt template design, and hypothesis testing (e.g., auditing). We released ChainForge early in its development and iterated on its design with academics and online users. Through in-lab and interview studies, we find that a range of people could use ChainForge to investigate hypotheses that matter to them, including in real-world settings. We identify three modes of prompt engineering and LLM hypothesis testing: opportunistic exploration, limited evaluation, and iterative refinement.</p>
<h3>CloChat: Understanding How People Customize, Interact, and Experience Personas in Large Language Models</h3>
<p>Authors: DaEun Han, Hyeon Jeon, Jinwook Seo, Changhoon Oh, Juhye Ha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147362">Link</a></p>
<p>Abstract: Large language models (LLMs) have facilitated significant strides in generating conversational agents, enabling seamless, contextually relevant dialogues across diverse topics. However, the existing LLM-driven conversational agents have fixed personalities and functionalities, limiting their adaptability to individual user needs. Creating personalized agent personas with distinct expertise or traits can address this issue. Nonetheless, we lack knowledge of how people customize and interact with agent personas. In this research, we investigated how users customize agent personas and their impact on interaction quality, diversity, and dynamics. To this end, we developed CloChat, an interface supporting easy and accurate customization of agent personas in LLMs. We conducted a study comparing how participants interact with CloChat and ChatGPT. The results indicate that participants formed emotional bonds with the customized agents, engaged in more dynamic dialogues, and showed interest in sustaining interactions. These findings contribute to design implications for future systems with conversational agents using LLMs.</p>
<h2>Politics of Datasets</h2>
<h3>The Cadaver in the Machine: The Social Practices of Measurement and Validation in Motion Capture Technology</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mona Sloane, Hauke Sandhaus, Abigail Jacobs, Emanuel Moss, Emma Harvey</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147039">Link</a></p>
<h3>Aligning Data with the Goals of an Organization and Its Workers: Designing Data Labeling for Social Service Case Notes</h3>
<p>Authors: Whitney Nelson, Apoorva Gondimalla, Kenneth Fleischmann, Govind Joshi, Eunsol Choi, Sherri Greenberg, Varshinee Sreekanth, Stephen Slota, Min Kyung Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148090">Link</a></p>
<h3>The ``Colonial Impulse" of Natural Language Processing: An Audit of Bengali Sentiment Analysis Tools and Their Identity-based Biases</h3>
<p>Authors: Jed Brubaker, Bryan Semaan, Shion Guha, Dipto Das</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146683">Link</a></p>
<h3>Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM</h3>
<p>Authors: Jeffrey Heer, Michael Bernstein, James Landay, Janice Teoh, Michelle Lam</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147161">Link</a></p>
<h3>Situating Datasets: Making Public Eviction Data Actionable for Housing Justice</h3>
<p>Authors: Grace Guo, Katsuki Chan, Jordan Taylor, Carl DiSalvo, Elora Raymond, Anh-Ton Tran</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148020">Link</a></p>
<h2>Touch, Gesture and Posture</h2>
<h3>CRTypist: Simulating Touchscreen Typing Behavior via Computational Rationality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jussi Jokinen, Yujun Zhu, Aditya Acharya, Shumin Zhai, Danqing Shi, Aini Putkonen, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147836">Link</a></p>
<h3>WheelPose: Data Synthesis Techniques to Improve Pose Estimation Performance on Wheelchair Users</h3>
<p>Authors: Yang Zhang, William Huang, Siyou Pei, Sam Ghahremani</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148072">Link</a></p>
<h3>Sitting Posture Recognition and Feedback: A Literature Review</h3>
<p>Authors: Christian Krauter, Michael Sedlmair, Sven Mayer, Alexander Achberger, Katrin Angerbauer, Aimée Sousa Calepso</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147428">Link</a></p>
<h3>iPose: Interactive Human Pose Reconstruction from Video</h3>
<p>Authors: Li-Yi Wei, Jingyuan Liu, Takeo Igarashi, Ariel Shamir</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146911">Link</a></p>
<h2>Governance and Public Policies</h2>
<h3>Data Probes as Boundary Objects for Technology Policy Design: Demystifying Technology for Policymakers and Aligning Stakeholder Objectives in Rideshare Gig Work</h3>
<p>Authors: Alexander Boltz, Angie Zhang, Veena Dubal, Rocita Rana, Min Kyung Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146997">Link</a></p>
<h3>In Dice We Trust: Uncertainty Displays for Maintaining Trust in Election Forecasts Over Time</h3>
<p>BEST_PAPER</p>
<p>Authors: Matthew Kay, Fumeng Yang, Nicholas Diakopoulos, Erik Nisbet, Chloe Mortenson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147247">Link</a></p>
<h3>V-FRAMER: Visualization Framework for Mitigating Reasoning Errors in Public Policy</h3>
<p>Authors: Matthew Kay, Lily Ge, Steven Franconeri, Peter Cheng, Matthew Easterday, Evanthia Dimara</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147167">Link</a></p>
<h3>Affective Design: The Influence of Facebook Reactions on the Emotional Expression of the 114th US Congress</h3>
<p>Authors: Jacob Erickson, Bei Yan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147668">Link</a></p>
<h3>Watching the Election Sausage Get Made: How Data Journalists Visualize the Vote Counting Process in U.S. Elections</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Matthew Kay, Mandi Cai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146972">Link</a></p>
<h2>Supporting Communities</h2>
<h3>Pika: Empowering Non-Programmers to Author Executable Governance Policies in Online Communities</h3>
<p>Authors: Leijie Wang, Julija Rukanskaitė, Amy Zhang, Nicholas Vincent</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146949">Link</a></p>
<h3>Do We Run How We Say We Run? Formalization and Practice of Governance in OSS Communities</h3>
<p>Authors: Curtis Atkisson, Mahasweta Chakraborti, Vladimir Filkov, Ştefan Stănciulescu, Seth Frey</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147289">Link</a></p>
<h3>Third-Party Developers and Tool Development For Community Management on Live Streaming Platform Twitch</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: He Zhang, Jie Cai, John Carroll, Ya-Fang Lin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147232">Link</a></p>
<h3>“I was able to give her the confidence”: Reciprocal Capacity Building in a Community-based Program for Digital Engagement</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jeanette Szomstein, Tawanna Dillahunt, Lutalo Sanifu, Julie Hui, Christie Baer, Kristin Seefeldt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146613">Link</a></p>
<h3>In Between Users and Developers: Serendipitous Connections and Intermediaries in Volunteer-Driven Open-Source Software Development</h3>
<p>Authors: Volker Wulf, Dave Randall, Yannick Bollmann, Lea Katharina Michel, Vasilis Ntouros, Leonie Jahn, Philip Engelbutzeder</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148224">Link</a></p>
<h2>AI and Interaction Design</h2>
<h3>(Un)making AI Magic: A Design Taxonomy</h3>
<p>Authors: Maria Luce Lupetti, Dave Murray-Rust</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147268">Link</a></p>
<p>Abstract: This paper examines the role that enchantment plays in the design of AI things by constructing a taxonomy of design approaches that increase or decrease the perception of magic and enchantment. We start from the design discourse surrounding recent developments in AI technologies, highlighting specific interaction qualities such as algorithmic uncertainties and errors and articulating relations to the rhetoric of magic and supernatural thinking. Through analyzing and reflecting upon 52 students' design projects from two editions of a Master course in design and AI, we identify seven design principles and unpack the effects of each in terms of enchantment and disenchantment. We conclude by articulating ways in which this taxonomy can be approached and appropriated by design/HCI practitioners, especially to support exploration and reflexivity.</p>
<h3>AI-Assisted Causal Pathway Diagram for Human-Centered Design</h3>
<p>Authors: Predrag Klasnja, Rosemary Meza, Donghoon Shin, Gary Hsieh, Lucas Colusso, Ruican Zhong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147483">Link</a></p>
<p>Abstract: This paper explores the integration of causal pathway diagrams (CPD) into human-centered design (HCD), investigating how these diagrams can enhance the early stages of the design process. A dedicated CPD plugin for the online collaborative whiteboard platform Miro was developed to streamline diagram creation and offer real-time AI-driven guidance. Through a user study with designers ($N=20$), we found that CPD's branching and its emphasis on causal connections supported both divergent and convergent processes during design. CPD can also facilitate communication among stakeholders. Additionally, we found our plugin significantly reduces designers' cognitive workload and increases their creativity during brainstorming, highlighting the implications of AI-assisted tools in supporting creative work and evidence-based designs.</p>
<h3>VAL: Interactive Task Learning with GPT Dialog Parsing</h3>
<p>Authors: Christopher MacLellan, Lane Lawley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148061">Link</a></p>
<p>Abstract: Machine learning often requires millions of examples to produce static, black-box models. In contrast, interactive task learning (ITL) emphasizes incremental knowledge acquisition from limited instruction provided by humans in modalities such as natural language. However, ITL systems often suffer from brittle, error-prone language parsing, which limits their usability. Large language models (LLMs) are resistant to brittleness but are not interpretable and cannot learn incrementally. We present VAL, an ITL system with a new philosophy for LLM/symbolic integration. By using LLMs only for specific tasks—such as predicate and argument selection—within an algorithmic framework, VAL reaps the benefits of LLMs to support interactive learning of hierarchical task knowledge from natural language. Acquired knowledge is human interpretable and generalizes to support execution of novel tasks without additional training. We studied users' interactions with VAL in a video game setting, finding that most users could successfully teach VAL using language they felt was natural.</p>
<h3>Jigsaw: Supporting Designers to Prototype Multimodal Applications by Chaining AI Foundation Models</h3>
<p>Authors: David Chuan-En Lin, Nikolas Martelaro</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147352">Link</a></p>
<p>Abstract: Recent advancements in AI foundation models have made it possible for them to be utilized off-the-shelf for creative tasks, including ideating design concepts or generating visual prototypes. However, integrating these models into the creative process can be challenging as they often exist as standalone applications tailored to specific tasks. To address this challenge, we introduce Jigsaw, a prototype system that employs puzzle pieces as metaphors to represent foundation models. Jigsaw allows designers to combine different foundation model capabilities across various modalities by assembling compatible puzzle pieces. To inform the design of Jigsaw, we interviewed ten designers and distilled design goals. In a user study, we showed that Jigsaw enhanced designers' understanding of available foundation model capabilities, provided guidance on combining capabilities across different modalities and tasks, and served as a canvas to support design exploration, prototyping, and documentation.</p>
<h3>Enhancing UX Evaluation Through Collaboration with Conversational AI Assistants: Effects of Proactive Dialogue and Timing</h3>
<p>Authors: Emily Kuang, Minghao Li, Kristen Shinohara, Mingming Fan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147731">Link</a></p>
<p>Abstract: Usability testing is vital for enhancing the user experience (UX) of interactive systems. However, analyzing test videos is complex and resource-intensive. Recent AI advancements have spurred exploration into human-AI collaboration for UX analysis, particularly through natural language. Unlike user-initiated dialogue, our study investigated the potential of proactive conversational assistants to aid UX evaluators through automatic suggestions at three distinct times: before, in sync with, and after potential usability problems. We conducted a hybrid Wizard-of-Oz study involving 24 UX evaluators, using ChatGPT to generate automatic problem suggestions and a human actor to respond to impromptu questions. While timing did not significantly impact analytic performance, suggestions appearing after potential problems were preferred, enhancing trust and efficiency. Participants found the automatic suggestions useful, but they collectively identified more than twice as many problems, underscoring the irreplaceable role of human expertise. Our findings also offer insights into future human-AI collaborative tools for UX evaluation.</p>
<h2>AI and UI Design</h2>
<h3>SimUser: Generating Usability Feedback by Simulating Various Users Interacting with Mobile Applications</h3>
<p>Authors: Shi Chen, Hanfei Zhu, Yuping Jin, Suqi Lou, Zhenghua Pan, Lingyun Sun, Wei Xiang, Xinli Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148321">Link</a></p>
<p>Abstract: The conflict between the rapid iteration demand of prototyping and the time-consuming nature of user tests has led researchers to adopt AI methods to identify usability issues. However, these AI-driven methods concentrate on evaluating the feasibility of a system, while often overlooking the influence of specified user characteristics and usage contexts. Our work proposes a tool named SimUser based on large language models (LLMs) with the Chain-of-Thought structure and user modeling method. It generates usability feedback by simulating the interaction between users and applications, which is influenced by user characteristics and contextual factors. The empirical study (48 human users and 21 designers) validated that in the context of a simple smartwatch interface, SimUser could generate heuristic usability feedback with the similarity varying from 35.7% to 100% according to the user groups and usability category. Our work provides insights into simulating users by LLM to improve future design activities.</p>
<h3>Generating Automatic Feedback on UI Mockups with Large Language Models</h3>
<p>Authors: Peitong Duan, Yang Li, Bjoern Hartmann, Jeremy Warner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146712">Link</a></p>
<p>Abstract: Feedback on user interface (UI) mockups is crucial in design. However, human feedback is not always readily available. We explore the potential of using large language models for automatic feedback. Specifically, we focus on \changes{applying GPT-4 to automate heuristic evaluation}, which currently entails a human expert assessing a UI’s compliance with a set of design guidelines. We implemented a Figma plugin that takes in a UI design and a set of written heuristics, and renders automatically-generated feedback as constructive suggestions. We assessed performance on 51 UIs using three sets of guidelines, compared GPT-4-generated design suggestions with those from human experts, and conducted a study with 12 expert designers to understand fit with existing practice. We found that GPT-4-based feedback is useful for catching subtle errors, improving text, and considering UI semantics, but feedback also decreased in utility over iterations. Participants described several uses for this plugin despite its imperfect suggestions.</p>
<h3>MUD: Towards a Large-Scale and Noise-Filtered UI Dataset for Modern Style UI Modeling</h3>
<p>Authors: Chunyang Chen, Sidong Feng, Suyu Ma, David Kong, Han Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147307">Link</a></p>
<p>Abstract: The importance of computational modeling of mobile user interfaces (UIs) is undeniable. However, these require a high-quality UI dataset. Existing datasets are often outdated, collected years ago, and are frequently noisy with mismatches in their visual representation. This presents challenges in modeling UI understanding in the wild. This paper introduces a novel approach to automatically mine UI data from Android apps, leveraging Large Language Models (LLMs) to mimic human-like exploration. To ensure dataset quality, we employ the best practices in UI noise filtering and incorporate human annotation as a final validation step. Our results demonstrate the effectiveness of LLMs-enhanced app exploration in mining more meaningful UIs, resulting in a large dataset MUD of 18k human-annotated UIs from 3.3k apps. We highlight the usefulness of MUD in two common UI modeling tasks: element detection and UI retrieval, showcasing its potential to establish a foundation for future research into high-quality, modern UIs.</p>
<h3>Surveyor: Facilitating Discovery Within Video Games for Blind and Low Vision Players</h3>
<p>Authors: Peize Song, Hanxiu 'Hazel' Zhu, Jizhong Wang, Brian Smith, Vishnu Nair</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147935">Link</a></p>
<p>Abstract: Video games are increasingly accessible to blind and low vision (BLV) players, yet many aspects remain inaccessible. One aspect is the joy players feel when they explore environments and make new discoveries, which is integral to many games. Sighted players experience discovery by surveying environments and identifying unexplored areas. Current accessibility tools, however, guide BLV players directly to items and places, robbing them of that experience. Thus, a crucial challenge is to develop navigation assistance tools that also foster exploration and discovery. To address this challenge, we propose the concept of exploration assistance in games and design Surveyor, an in-game exploration assistance tool that enhances discovery by tracking where BLV players look and highlighting unexplored areas. We designed Surveyor using insights from a formative study and compared Surveyor's effectiveness to approaches found in existing accessible games. Our findings reveal implications for facilitating richer play experiences for BLV users within games.</p>
<h3>OmniActions: Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs</h3>
<p>Authors: Jiahao Li, Tovi Grossman, Stephanie Santosa, Michelle Li, Yan Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147206">Link</a></p>
<p>Abstract: The progression to "Pervasive Augmented Reality" envisions easy access to multimodal information continuously. However, in many everyday scenarios, users are occupied physically, cognitively or socially. This may increase the friction to act upon the multimodal information that users encounter in the world. To reduce such friction, future interactive interfaces should intelligently provide quick access to digital actions based on users' context. To explore the range of possible digital actions, we conducted a diary study that required participants to capture and share the media that they intended to perform actions on (e.g., images or audio), along with their desired actions and other contextual information. Using this data, we generated a holistic design space of digital follow-up actions that could be performed in response to different types of multimodal sensory inputs. We then designed \codename, a pipeline powered by large language models (LLMs) that processes multimodal sensory inputs and predicts follow-up actions on the target information grounded in the derived design space. Using the empirical data collected in the diary study, we performed quantitative evaluations on three variations of LLM techniques (intent classification, in-context learning and finetuning) and identified the most effective technique for our task. Additionally, as an instantiation of the pipeline, we developed an interactive prototype and reported preliminary user feedback about how people perceive and react to the action predictions and its errors. </p>
<h2>AI for Researchers</h2>
<h3>Know Your Audience: The benefits and pitfalls of generating plain language summaries beyond the "general" audience</h3>
<p>Authors: Noah A. Smith, Tal August, Katharina Reinecke, Kyle Lo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147146">Link</a></p>
<p>Abstract: Language models (LMs) show promise as tools for communicating science to the general public by simplifying and summarizing complex language. Because models can be prompted to generate text for a specific audience (e.g., college-educated adults), LMs might be used to create multiple versions of plain language summaries for people with different familiarities of scientific topics. However, it is not clear what the benefits and pitfalls of adaptive plain language are. When is simplifying necessary, what are the costs in doing so, and do these costs differ for readers with different background knowledge? Through three within-subjects studies in which we surface summaries for different envisioned audiences to participants of different backgrounds, we found that while simpler text led to the best reading experience for readers with little to no familiarity in a topic, high familiarity readers tended to ignore certain details in overly plain summaries (e.g., study limitations). Our work provides methods and guidance on ways of adapting plain language summaries beyond the single "general" audience. </p>
<h3>Evaluating Large Language Models on Academic Literature Understanding and Review: An Empirical Study among Early-stage Scholars</h3>
<p>Authors: Song Yan, Zuyuan Wang, Jiyao Wang, Haolong Hu, Youyu Sheng, Dengbo He</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147471">Link</a></p>
<p>Abstract: The rapid advancement of large language models (LLMs) such as ChatGPT makes LLM-based academic tools possible. However, little research has empirically evaluated how scholars perform different types of academic tasks with LLMs. Through an empirical study followed by a semi-structured interview, we assessed 48 early-stage scholars’ performance in conducting core academic activities (i.e., paper reading and literature reviews) under different levels of time pressure. Before conducting the tasks, participants received different training programs regarding the limitations and capabilities of the LLMs. After completing the tasks, participants completed an interview. Quantitative data regarding the influence of time pressure, task type, and training program on participants' performance in academic tasks was analyzed. Semi-structured interviews provided additional information on the influential factors of task performance, participants' perceptions of LLMs, and concerns about integrating LLMs into academic workflows. The findings can guide more appropriate usage and design of LLM-based tools in assisting academic work.</p>
<h3>Understanding the Role of Large Language Models in Personalizing and Scaffolding Strategies to Combat Academic Procrastination</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Joseph Williams, Alex Mariakakis, Anastasia Kuzminykh, Yuchen Zeng, Minyi Ma, Syed Ishtiaque Ahmed, Michael Liut, Rachel Kornfield, Dana Kulzhabayeva, Sarah Yi Xu, Mary Czerwinski, Ananya Bhattacharjee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148128">Link</a></p>
<p>Abstract: Traditional interventions for academic procrastination often fail to capture the nuanced, individual-specific factors that underlie them. Large language models (LLMs) hold immense potential for addressing this gap by permitting open-ended inputs, including the ability to customize interventions to individuals' unique needs. However, user expectations and potential limitations of LLMs in this context remain underexplored. To address this, we conducted interviews and focus group discussions with 15 university students and 6 experts, during which a technology probe for generating personalized advice for managing procrastination was presented. Our results highlight the necessity for LLMs to provide structured, deadline-oriented steps and enhanced user support mechanisms. Additionally, our results surface the need for an adaptive approach to questioning based on factors like busyness. These findings offer crucial design implications for the development of LLM-based tools for managing procrastination while cautioning the use of LLMs for therapeutic guidance.</p>
<h3>From Paper to Card: Transforming Design Implications with Generative AI</h3>
<p>Authors: Lucy Wang, Donghoon Shin, Gary Hsieh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147713">Link</a></p>
<p>Abstract: Communicating design implications is common within the HCI community when publishing academic papers, yet these papers are rarely read and used by designers. One solution is to use design cards as a form of translational resource that communicates valuable insights from papers in a more digestible and accessible format to assist in design processes. However, creating design cards can be time-consuming, and authors may lack the resources/know-how to produce cards. Through an iterative design process, we built a system that helps create design cards from academic papers using an LLM and text-to-image model. Our evaluation with designers (N=21) and authors of selected papers (N=12) revealed that designers perceived the design implications from our design cards as more inspiring and generative, compared to reading original paper texts, and the authors viewed our system as an effective way of communicating their design implications. We also propose future enhancements for AI-generated design cards.</p>
<h3>CollabCoder: A Lower-barrier, Rigorous Workflow for Inductive Collaborative Qualitative Analysis with Large Language Models</h3>
<p>Authors: Simon Perrault, Toby Li, Yuchen Guo, Tianqin Zhang, Gionnieve Lim, Zheng Zhang, Jie Gao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147401">Link</a></p>
<p>Abstract: Collaborative Qualitative Analysis (CQA) can enhance qualitative analysis rigor and depth by incorporating varied viewpoints. Nevertheless, ensuring a rigorous CQA procedure itself can be both complex and costly. To lower this bar, we take a theoretical perspective to design a one-stop, end-to-end workflow, CollabCoder, that integrates Large Language Models (LLMs) into key inductive CQA stages. In the independent open coding phase, CollabCoder offers AI-generated code suggestions and records decision-making data. During the iterative discussion phase, it promotes mutual understanding by sharing this data within the coding team and using quantitative metrics to identify coding (dis)agreements, aiding in consensus-building. In the codebook development phase, CollabCoder provides primary code group suggestions, lightening the workload of developing a codebook from scratch. A 16-user evaluation confirmed the effectiveness of CollabCoder, demonstrating its advantages over the existing CQA platform. All related materials of CollabCoder, including code and further extensions, will be included in: https://gaojie058.github.io/CollabCoder/.</p>
<h2>Assistive Technologies for Neurodiversity</h2>
<h3>Designing Scaffolding Strategies for Conversational Agents in Dialog Task of Neurocognitive Disorders Screening</h3>
<p>Authors: Dongjie Yang, Danxuan LIANG, Junze Li, Helen Meng, YUHANG ZENG, Xiaojuan Ma, Jiaxiong Hu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147967">Link</a></p>
<h3>Unlock Life with a Chat(GPT): Integrating Conversational AI with Large Language Models into Everyday Lives of Autistic Individuals</h3>
<p>Authors: Hwajung Hong, Sung-In Kim, Dasom Choi, Sunok Lee, Kyungah Lee, Sangsu Lee, Hee Jeong Yoo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146853">Link</a></p>
<h3>An Emotion Translator: Speculative Design By Neurodiverse Dyads</h3>
<p>Authors: Jaime Snyder, Annuska Zolyomi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148281">Link</a></p>
<h3>From Letterboards to Holograms: Advancing Assistive Technology for Nonspeaking Autistic Individuals with the HoloBoard</h3>
<p>Authors: Vikram Jaswal, Lorans Alabood, Travis Dow, Diwakar Krishnamurthy, Kaylyn Feeley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147346">Link</a></p>
<h3>Are Robots Ready to Deliver Autism Inclusion?: A Critical Review</h3>
<p>Authors: Imani Munyaka, Raunak Mondal, Naba Rizvi, Andrew Begel, Mya Bolds, William Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147238">Link</a></p>
<h2>Body, Avatars, and Interaction in Immersive Realities</h2>
<h3>Your Avatar Seems Hesitant to Share About Yourself: How People Perceive Others' Avatars in the Transparent System</h3>
<p>Authors: Huisung Kwon, Ki Joon Kim, Hyemin Park, Yeonju Jang, Taenyun Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146653">Link</a></p>
<p>Abstract: In avatar-mediated communications, users often cannot identify how others' avatars are created, which is one of the important information they need to evaluate others. Thus, we tested a social virtual world that is transparent about others' avatar-creation methods and investigated how knowing about others' avatar-creation methods shapes users' perceptions of others and their self-disclosure. We conducted a 2x2 mixed-design experiment with system design (nontransparent vs. transparent system) as a between-subjects and avatar-creation method (customized vs. personalized avatar) as a within-subjects variable with 60 participants. The results revealed that personalized avatars in the transparent system were viewed less positively than customized avatars in the transparent system or avatars in the nontransparent system. These avatars appeared less comfortable and honest in their self-disclosure and less competent. Interestingly, avatars in the nontransparent system attracted more followers. Our results suggest being cautious when creating a social virtual world that discloses the avatar-creation process.</p>
<h3>CamTroller: An Auxiliary Tool for Controlling Your Avatar in PC Games Using Natural Motion Mapping</h3>
<p>Authors: Yuqian Wang, Junjian CHEN, Yan Luximon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147378">Link</a></p>
<p>Abstract: Natural motion mapping enhances the gaming experience by reducing the cognitive burden and increasing immersion. However, many players still use the keyboard and mouse in recent commercial PC games. To solve the conflict between complex avatar motion and the limited interaction system, we introduced CamTroller, an auxiliary tool for commercial one-to-one avatar mapping PC games following the concept of a natural user interface. To validate this concept, we selected PUBG  as the application scenario and developed a proof-of-concept system to help players achieve a better experience by naturally mapping selected human motions to the avatars in games through an RGB webcam. A within-subject study with 18 non-professional players practiced common operation (Basic), professional player’s operation (Pro), and CamTroller. Results showed that the performance of CamTroller was as good as the Pro and significantly higher than Basic. Also, the subjective evaluation showed that CamTroller achieved significantly higher intuitiveness than Basic and Pro.</p>
<h3>Stretch your reach: Studying Self-Avatar and Controller Misalignment in Virtual Reality Interaction</h3>
<p>Authors: Nuria Pelechano, Jose Luis Ponton, Alejandro Beacco, Reza Keshavarz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147486">Link</a></p>
<p>Abstract: Immersive Virtual Reality typically requires a head-mounted display (HMD) to visualize the environment and hand-held controllers to interact with the virtual objects. Recently, many applications display full-body avatars to represent the user and animate the arms to follow the controllers. Embodiment is higher when the self-avatar movements align correctly with the user. However, having a full-body self-avatar following the user's movements can be challenging due to the disparities between the virtual body and the user's body. This can lead to misalignments in the hand position that can be noticeable when interacting with virtual objects. In this work, we propose five different interaction modes to allow the user to interact with virtual objects despite the self-avatar and controller misalignment and study their influence on embodiment, proprioception, preference, and task performance. We modify aspects such as whether the virtual controllers are rendered, whether controllers are rendered in their real physical location or attached to the user's hand, and whether stretching the avatar arms to always reach the real controllers. We evaluate the interaction modes both quantitatively (performance metrics) and qualitatively (embodiment, proprioception, and user preference questionnaires). Our results show that the stretching arms solution, which provides body continuity and guarantees that the virtual hands or controllers are in the correct location, offers the best results in embodiment, user preference, proprioception, and performance. Also, rendering the controller does not have an effect on either embodiment or user preference. </p>
<h3>Virtual Body Swapping: A VR-Based Approach to Embodied Third-Person Self-Processing in Mind-Body Therapy</h3>
<p>Authors: Nina Döllinger, Carolin Wienrich, Mario Botsch, Erik Wolf, David Mal, Sebastian Keppler, Johann Habakuk Israel, Marc Latoschik</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146675">Link</a></p>
<p>Abstract: Virtual reality (VR) offers various opportunities for innovative therapeutic approaches, especially regarding self-related mind-body interventions.</p>
<p>We introduce a VR body swap system enabling multiple users to swap their perspectives and appearances and evaluate its effects on virtual sense of embodiment (SoE) and perception- and cognition-based self-related processes.</p>
<p>In a self-compassion-framed scenario, twenty participants embodied their personalized, photorealistic avatar, swapped bodies with an unfamiliar peer, and reported their SoE, interoceptive awareness (perception), and self-compassion (cognition). Participants' experiences differed between bottom-up and top-down processes. Regarding SoE, their agency and self-location shifted to the swap avatar, while their top-down self-identification remained with their personalized avatar. Further, the experience positively affected interoceptive awareness but not self-compassion. Our outcomes offer novel insights into the SoE in a multiple-embodiment scenario and highlight the need to differentiate between the different processes in intervention design. They raise concerns and requirements for future research on avatar-based mind-body interventions.</p>
<h3>"I Shot the Interviewer!": The Effects of In-VR Interviews on Participant Feedback and Rapport</h3>
<p>Authors: Nadia Pantidi, Jacob Young, Jennifer Ferreira</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146913">Link</a></p>
<p>Abstract: The integration of questionnaires into virtual reality experiences has recently been proposed as a way to reduce the potential biases introduced through the negative effects of leaving VR, however there has been little attention paid to how qualitative interviews could similarly be integrated into the virtual world for the purposes of user evaluation. In this paper we explore how conducting interviews within the virtual environment may affect the outcome of the evaluation and the relationship between participant and interviewer, and how this may differ with and without visual representation of the interviewer through use of an avatar. We conclude that in-VR interviews are a valid and promising method of data collection for user evaluation with similar data quality to in-person interviews, but that the interviewer should have a visual presence in the environment to maintain their relationship with the participant and the perceived realism of the environment.</p>
<h2>Children and Family A</h2>
<h3>LegacySphere: Facilitating Intergenerational Communication Through Perspective-Taking and Storytelling in Embodied VR</h3>
<p>Authors: Dongwook Yoon, Chenxinran Shen, Joanna McGrenere</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147857">Link</a></p>
<h3>Open Sesame? Open Salami! Personalizing Vocabulary Assessment-Intervention for Children via Pervasive Profiling and Bespoke Storybook Generation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Suwon Yoon, Wonjeong Park, Eunae Jeong, Inseok Hwang, Jungeun Lee, Dongsun Yim, Kyoosik Lee, Jae-Eun Cho</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147041">Link</a></p>
<h3>Parent-Child Joint Media Engagement within HCI: A Scoping Analysis of the Research Landscape</h3>
<p>Authors: Junnan Yu, Siqi Yang, Xiang QI</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147467">Link</a></p>
<h3>"When He Feels Cold, He Goes to the Seahorse"—Blending Generative AI into Multimaterial Storymaking for Family Expressive Arts Therapy</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Di Liu, Pengcheng An, Hanqing Zhou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147056">Link</a></p>
<h3>"I want it to talk like Darth Vader": Helping Children Construct Creative Self-Efficacy with Generative AI</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Matthew Pedraja, Maia B. Song, Kaiwen Sun, Ritesh Kanchi, Ilena Dalla Gasperina, Grace Shin, Jason Yip, Jin Ha Lee, Michele Newman, Rannie Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147049">Link</a></p>
<h2>Creative Practices, Arts and AI</h2>
<h3>CollageVis: Rapid Previsualization Tool for Indie Filmmaking using Video Collages</h3>
<p>Authors: Ryo Suzuki, Hye-Young Jo, Yoonji Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147599">Link</a></p>
<p>Abstract: Previsualization, previs, is essential for film production, allowing cinematographic experiments and effective collaboration. However, traditional previs methods like 2D storyboarding and 3D animation require substantial time, cost, and technical expertise, posing challenges for indie filmmakers. We introduce CollageVis, a rapid previsualization tool using video collages. CollageVis enables filmmakers to create previs through two main user interfaces. First, it automatically segments actors from videos and assigns roles using name tags, color filters, and face swaps. Second, it positions video layers on a virtual stage and allows users to record shots using mobile as a proxy for a virtual camera. These features were developed based on formative interviews by reflecting indie filmmakers’ needs and working methods. We demonstrate the system’s capability by replicating seven film scenes and evaluate the system’s usability with six indie filmmakers. The findings indicate that CollageVis allows more flexible yet expressive previs creation for idea development and collaboration.</p>
<h3>Machine Learning Processes As Sources of Ambiguity: Insights from AI Art</h3>
<p>Authors: Guido Salimbeni, Jichen Zhu, Steven Benford, Christian Sivertsen, Anders Løvlie</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148345">Link</a></p>
<p>Abstract: Ongoing efforts to turn Machine Learning (ML) into a design material have encountered limited success. </p>
<p>This paper examines the burgeoning area of AI art to understand how artists incorporate ML in their creative work. Drawing upon related HCI theories, we investigate how artists create ambiguity by analyzing nine AI artworks that use computer vision and image synthesis.</p>
<p>Our analysis shows that, in addition to the established types of ambiguity, artists worked closely with the ML process (dataset curation, model training, and application) and developed various techniques to evoke the ambiguity of processes. Our finding indicates that the current conceptualization of ML as a design material needs to reframe the ML process as design elements, instead of technical details. Finally, this paper offers reflections on commonly held assumptions in HCI about ML uncertainty, dependability, and explainability, and advocates to supplement the artifact-centered design perspective of ML with a process-centered one.</p>
<h3>Metamorpheus: Interactive, Affective, and Creative Dream Narration Through Metaphorical Visual Storytelling</h3>
<p>Authors: Zhicong Lu, Xin Feng, Zhiqi Gao, Qian Wan, Yining Bei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148065">Link</a></p>
<p>Abstract: Human emotions are essentially molded by lived experiences, from which we construct personalised meaning. The engagement in such meaning-making process has been practiced as an intervention in various psychotherapies to promote wellness. Nevertheless, to support recollecting and recounting lived experiences in everyday life remains under explored in HCI. It also remains unknown how technologies such as generative AI models can facilitate the meaning making process, and ultimately support affective mindfulness. In this paper we present Metamorpheus, an affective interface that engages users in a creative visual storytelling of emotional experiences during dreams. Metamorpheus arranges the storyline based on a dream's emotional arc, and provokes self-reflection through the creation of metaphorical images and text depictions. The system provides metaphor suggestions, and generates visual metaphors and text depictions using generative AI models, while users can apply generations to recolour and re-arrange the interface to be visually affective. Our experience-centred evaluation manifests that, by interacting with Metamorpheus, users can recall their dreams in vivid detail, through which they relive and reflect upon their experiences in a meaningful way.</p>
<h3>An Artists' Perspectives on Natural Interactions for Virtual Reality 3D Sketching</h3>
<p>Authors: Francisco Ortega, Richard Rodriguez, Cyane Tornatzky, Mayra Barrera Machuca, Anil Ufuk Batmaz, Brian Sullivan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147688">Link</a></p>
<p>Abstract: Virtual Reality (VR) applications like OpenBrush offer artists access to 3D sketching tools within the digital 3D virtual space. These 3D sketching tools allow users to ``paint'' using virtual digital strokes that emulate real-world mark-making. Yet, users paint these strokes through (unimodal) VR controllers. Given that sketching in VR is a relatively nascent field, this paper investigates ways to expand our understanding of sketching in virtual space, taking full advantage of what an immersive digital canvas offers. Through a study conducted with the participation of artists, we identify potential methods for natural multimodal and unimodal interaction techniques in 3D sketching. These methods demonstrate ways to incrementally improve existing interaction techniques and incorporate artistic feedback into the design.</p>
<h3>#PoetsOfInstagram: Navigating The Practices And Challenges Of Novice Poets On Instagram</h3>
<p>Authors: Ankolika De, Zhicong Lu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148301">Link</a></p>
<p>Abstract: Commencing as a photo-sharing platform, Instagram has since become multifaceted, accommodating diverse art forms, with poetry emerging as a prominent one. However, the academic understanding of Instagram's poetry community is limited, yet its significance emerges from its distinctive utilization of a primarily visual social media platform guided by recommendation algorithms for disseminating poetry, further characterized by a predominantly novice creative population. We employ qualitative analysis to explore motivations, experiences, and algorithmic influence within Instagram's poetry community. We demonstrate that participants prioritize conforming to algorithmic constraints for visibility, yet maintain their community's values of integrity and originality, illustrating the tension between algorithmic growth and participant authenticity. We introduce the concept of Algorithmically Mediated Creative Labor, a phenomenon specific to non-monetizing creative users who are impacted by the prioritization of professional creators and continually adapt their creative endeavours to align with platform logic, thereby affecting their motivation and creative outputs.</p>
<h2>Creativity: Visualizations and AI</h2>
<h3>IntentTuner: An Interactive Framework for Integrating Human Intentions in Fine-tuning Text-to-Image Generative Models</h3>
<p>Authors: Wei Zeng, Xingchen Zeng, Ziyao Gao, Yilin Ye</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147372">Link</a></p>
<p>Abstract: Fine-tuning facilitates the adaptation of text-to-image generative models to novel concepts (e.g., styles and portraits), empowering users to forge creatively customized content. Recent efforts on fine-tuning focus on reducing training data and lightening computation overload but neglect alignment with user intentions, particularly in manual curation of multi-modal training data and intent-oriented evaluation. Informed by a formative study with fine-tuning practitioners for comprehending user intentions, we propose IntentTuner, an interactive framework that intelligently incorporates human intentions throughout each phase of the fine-tuning workflow. IntentTuner enables users to articulate training intentions with imagery exemplars and textual descriptions, automatically converting them into effective data augmentation strategies. Furthermore, IntentTuner introduces novel metrics to measure user intent alignment, allowing intent-aware monitoring and evaluation of model training. Application exemplars and user studies demonstrate that IntentTuner streamlines fine-tuning, reducing cognitive effort and yielding superior models compared to the common baseline tool.</p>
<h3>Table Illustrator: Puzzle-based interactive authoring of plain tables</h3>
<p>Authors: Di Weng, Yurun Yang, Yanwei Huang, Ran Chen, Yingcai Wu, Xinhuan Shu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147780">Link</a></p>
<p>Abstract: Plain tables excel at displaying data details and are widely used in data presentation, often polished to an elaborate appearance for readability in many scenarios. However, existing authoring tools fail to provide both flexible and efficient support for altering the table layout and styles, motivating us to develop an intuitive and swift tool for table prototyping. To this end, we contribute Table Illustrator, a table authoring system taking a novel visual metaphor, puzzle, as the primary interaction unit. Through combinations and configurations on puzzles, the system enables rapid table construction and supports a diverse range of table layouts and styles. The tool design is informed by practical challenges and requirements from interviews with 10 table practitioners and a structured design space based on an analysis of over 2,500 real-world tables. User studies showed that Table Illustrator achieved comparable performance to Microsoft Excel while reducing users' completion time and perceived workload.</p>
<h3>Is It AI or Is It Me? Understanding Users’ Prompt Journey with Text-to-Image Generative AI Tools</h3>
<p>Authors: Atefeh Mahdavi Goloujeh, Brian Magerko, Anne Sullivan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146973">Link</a></p>
<p>Abstract: Generative Artificial Intelligence (AI) has witnessed unprecedented growth in text-to-image AI tools. Yet, much remains unknown about users' prompt journey with such tools in the wild. In this paper, we posit that designing human-centered text-to-image AI tools requires a clear understanding of how individuals intuitively approach crafting prompts, and what challenges they may encounter. To address this, we conducted semi-structured interviews with 19 existing users of a text-to-image AI tool. Our findings (1) offer insights into users’ prompt journey including structures and processes for writing, evaluating, and refining prompts in text-to-image AI tools and (2) indicate that users must overcome barriers to aligning AI to their intents, and mastering prompt crafting knowledge. From the findings, we discuss the prompt journey as an individual yet a social experience and highlight opportunities for aligning text-to-image AI tools and users’ intents.</p>
<h3>PromptCharm: Text-to-Image Generation through Multi-modal Prompting and Refinement</h3>
<p>Authors: Lei Ma, Yuheng Huang, Zhijie Wang, Da Song, Tianyi Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148288">Link</a></p>
<p>Abstract: The recent advancements in Generative AI have significantly advanced the field of text-to-image generation. The state-of-the-art text-to-image model, Stable Diffusion, is now capable of synthesizing high-quality images with a strong sense of aesthetics. Crafting text prompts that align with the model's interpretation and the user's intent thus becomes crucial. However, prompting remains challenging for novice users due to the complexity of the stable diffusion model and the non-trivial efforts required for iteratively editing and refining the text prompts. To address these challenges, we propose PromptCharm, a mixed-initiative system that facilitates text-to-image creation through multi-modal prompt engineering and refinement. To assist novice users in prompting, PromptCharm first automatically refines and optimizes the user's initial prompt. Furthermore, PromptCharm supports the user in exploring and selecting different image styles within a large database. To assist users in effectively refining their prompts and images, PromptCharm renders model explanations by visualizing the model's attention values. If the user notices any unsatisfactory areas in the generated images, they can further refine the images through model attention adjustment or image inpainting within the rich feedback loop of PromptCharm. To evaluate the effectiveness and usability of PromptCharm, we conducted a controlled user study with 12 participants and an exploratory user study with another 12 participants. These two studies show that participants using PromptCharm were able to create images with higher quality and better aligned with the user's expectations compared with using two variants of PromptCharm that lacked interaction or visualization support.</p>
<h3>An Accessible, Three-Axis Plotter for Enhancing Calligraphy Learning through Generated Motion</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Cathy Mengying Fang, Zach Lieberman, Quincy Kuang, Pattie Maes, Hiroshi Ishii, Lingdong Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147202">Link</a></p>
<p>Abstract: An Accessible, Three-Axis Plotter for Enhancing Calligraphy Learning through Generated Motion</p>
<h2>Data Visualization and Literacy</h2>
<h3>Data Storytelling in Data Visualisation: Does it Enhance the Efficiency and Effectiveness of Information Retrieval and Insights Comprehension?</h3>
<p>Authors: Roberto Martinez-Maldonado, Lixiang Yan, Vanessa Echeverria, Hongbo Shao, Dragan Gasevic</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146892">Link</a></p>
<h3>Make Interaction Situated: Designing User Acceptable Interaction for Situated Visualization in Public Environments</h3>
<p>Authors: Zhuo Wang, Wei Zeng, Xiaojuan Ma, Weiyue Lin, Qian Zhu, Wai Tong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147605">Link</a></p>
<h3>A Human Information Processing Theory of the Interpretation of Visualizations: Demonstrating Its Utility</h3>
<p>Authors: Mateja Jamnik, Peter Cheng, Daniel Raggi, Grecia Garcia Garcia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147576">Link</a></p>
<h3>VAID: Indexing View Designs in Visual Analytics System</h3>
<p>Authors: Zikun Deng, Ji Lan, Haotian Li, Yong Wang, Dazhen Deng, Aoyu Wu, Huamin Qu, Lu Ying, Jiang Wu, Yingcai Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148123">Link</a></p>
<h3>Reading Between the Pixels: Investigating the Barriers to Visualization Literacy</h3>
<p>Authors: Kehang Zhu, Hanspeter Pfister, Carolina Nobre, Johanna Beyer, Eric Mörth</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147374">Link</a></p>
<h2>Data Visualization and Physicalization</h2>
<h3>StableLev: Data-Driven Stability Enhancement for Multi-Particle Acoustic Levitation</h3>
<p>Authors: Sriram Subramanian, Prateek Mittal, Giorgos Christopoulos, Lei Gao, Ryuji Hirayama</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148311">Link</a></p>
<h3>"Yeah, this graph doesn't show that": Analysis of Online Engagement with Misleading Data Visualizations</h3>
<p>Authors: Alexander Lex, Marina Kogan, Maxim Lisnic</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147712">Link</a></p>
<h3>Epigraphics: Message-Driven Infographics Authoring</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Tongyu Zhou, Gromit Yeuk-Yin Chan, Jeff Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148344">Link</a></p>
<h3>From Exploration to End of Life: Unpacking Sustainability in Physicalization Practices</h3>
<p>BEST_PAPER</p>
<p>Authors: Tatiana Losev, Sarah Hayes, Rebecca Noonan, Georgia Panagiotidou, Uta Hinrichs, Luiz Morais</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147627">Link</a></p>
<h3>That's Rough! Encoding Data into Roughness for Physicalization</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Xiaojiao Du, Kadek Ananta Satriadi, Andrew Cunningham, Ross Smith, Adam Drogemuller, Brandon Matthews, James A. Walsh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147680">Link</a></p>
<h2>Design Methods</h2>
<h3>Demystifying Tacit Knowledge in Graphic Design: Characteristics, Instances, Approaches, and Guidelines</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: DaEun Choi, Tae Soo Kim, Juho Kim, Kihoon Son</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147058">Link</a></p>
<h3>A Living Framework for Understanding Cooperative Games</h3>
<p>Authors: Pedro Pais, André Rodrigues, Pedro Trindade, Kathrin Gerling, Dmitry Alexandrovsky, Manuel Piçarra, Daniel Reis, João Guerreiro, David Gonçalves, João Godinho, João Morais</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148293">Link</a></p>
<h3>"I Am So Overwhelmed I Don't Know Where to Begin!" Towards Developing Relationship-Based and Values-Based End-of-Life Data Planning Approaches</h3>
<p>Authors: Jed Brubaker, Dylan Doyle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148141">Link</a></p>
<h3>Embodied Tentacle: Mapping Design to Control of Non-Analogous Body Parts with the Human Body</h3>
<p>Authors: Shuto Takashita, Michiteru Kitazaki, Hiroto Saito, Ken Arai, Masahiko Inami</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147057">Link</a></p>
<h3>Imagining Sustainable Energy Communities: Design Narratives of Future Digital Technologies, Sites, and Participation</h3>
<p>Authors: Rachel Smith, Rikke Hagensby Jensen, Victor Jensen, Kristina Laursen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147766">Link</a></p>
<h2>Design Tools A</h2>
<h3>KOALA Hero Toolkit: A New Approach to Inform Families of Mobile Datafication Risks</h3>
<p>Authors: Blanche Duron, Nigel Shadbolt, Ge Wang, Adrien Zier, Max Van Kleek, Zhilin Zhang, Jun Zhao, Konrad Kollnig</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148198">Link</a></p>
<h3>Rapid Prototyping with VideoClipper: In-camera Storyboarding and Video Capture</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Wendy Mackay, Germán Leiva, Alexandre Battut, Michel Beaudouin-Lafon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147150">Link</a></p>
<h3>Grand challenges in WaterHCI</h3>
<p>Authors: Winslow Burleson, Paul Dietz, Scott Bateman, John Quarles, Florian Mueller, Sarah Jane Pell, Ian Smith, Alexander Bakogeorge, Ali Mazalek, Joe Marshall, Maria Montoya, Steve Mann, Don Samitha Elvitigala, Mathieu Simonnet, Swamy Ananthanarayan, Nathan Semertzidis, Christal Clashing, Leif Oppermann, Kirsten Ellis, Mark Blythe, Chris Hill, Alexander Verni</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147744">Link</a></p>
<h3>A temporal vocabulary of Design Events for Research through Design</h3>
<p>Authors: Audrey Desjardins, Doenja Oogjes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148024">Link</a></p>
<h3>Strategies of Product Managers: Negotiating Social Values in Digital Product Design</h3>
<p>Authors: Eran Toch, Maayan Roichman, Eilat Lev Ari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147477">Link</a></p>
<h2>Design Tools B</h2>
<h3>Griffith: A Storyboarding Tool Designed with Japanese Animation Professionals</h3>
<p>Authors: Kenta Hara, Nao Hirasawa, Jun Kato</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147403">Link</a></p>
<h3>From Concept to Community: Unpacking the Work of Designing Educational and Activist Toolkits</h3>
<p>Authors: Jennifer Turns, Hana Frluckaj, Sreehana Mandava, Ayesha Bhimdiwala, Ahmer Arif, Tamar Wilner, Krishna Akhil Kumar Adavi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147784">Link</a></p>
<h3>AdapTics: A Toolkit for Creative Design and Integration of Real-Time Adaptive Mid-Air Ultrasound Tactons</h3>
<p>Authors: Yinan Li, Kevin John, Hasti Seifi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148147">Link</a></p>
<h3>Bitacora: A Toolkit for Supporting  NonProfits to Critically Reflect on Social Media Data Use</h3>
<p>Authors: Christopher Le Dantec, Marisol Wong-Villacres, Benjamín Hernández, Adriana Alvarado Garcia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146866">Link</a></p>
<h3>Design Patterns for Data-Driven News Articles</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zezhong Wang, Benjamin Bach, Shan Hao, Larissa Pschetz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146944">Link</a></p>
<h2>Drivers and Pedestrians A</h2>
<h3>Inter-regional Lens on the Privacy Preferences of Drivers for ITS and Future VANETs</h3>
<p>Authors: Lejla Islami, Simone Fischer-Hübner, Agnieszka Kitkowska</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146934">Link</a></p>
<h3>AdaptiveVoice: Cognitively Adaptive Voice Interface for Driving Assistance</h3>
<p>Authors: Yukang Yan, Songming Ping, Hai-Ning Liang, Xuhai "Orson" Xu, Shaoyue Wen, Jialin Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147590">Link</a></p>
<h3>Portobello: Extending Driving Simulation from the Lab to the Road</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mark Colley, Wendy Ju, Stacey Li, David Goedicke, Gyanendra Sharma, Fanjun Bu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146873">Link</a></p>
<h3>SYNC-VR: Synchronizing Your Senses to Conquer Motion Sickness for Enriching In-Vehicle Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Aya Ataya, SeungJun Kim, Eunsol An, Ahmed Elsharkawy, Dohyeon Yeo, Seokhyun Hwang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147287">Link</a></p>
<h3>Can You Hazard a Guess?: Evaluating the Effect of Augmented Reality Cues on Driver Hazard Prediction</h3>
<p>Authors: Frank Pollick, Thomas Goodge, Stephen Brewster</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146912">Link</a></p>
<h2>Drivers and Pedestrians B</h2>
<h3>Investigating the Effects of External Communication and Platoon Behavior on Manual Drivers at Highway Access</h3>
<p>Authors: Mark Colley, Omid Rajabi, Enrico Rukzio</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147216">Link</a></p>
<h3>Understanding Human-machine Cooperation in Game-theoretical Driving Scenarios amid Mixed Traffic</h3>
<p>Authors: Morgan Frank, Edmond Awad, Yutong Zhang, Na Du, Peng Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147435">Link</a></p>
<h3>An Eye Gaze Heatmap Analysis of Uncertainty Head-Up Display Designs for Conditional Automated Driving</h3>
<p>Authors: Michael Gerber, Daniel Johnson, Andry Rakotonirainy, Jonny Kuo, Mike Lenné, Christian Janssen, Ronald Schroeter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147765">Link</a></p>
<h3>From Slow-Mo to Ludicrous Speed: Comfortably Manipulating the Perception of Linear In-Car VR Motion Through Vehicular Translational Gain and Attenuation</h3>
<p>Authors: Katharina Pöhlmann, Graham Wilson, Mark McGill, Stephen Brewster, Gang Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148305">Link</a></p>
<h3>Understanding Pedestrians’ Perception of Safety and Safe Mobility Practices</h3>
<p>Authors: Min Zhang, Arosha Bandara</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146652">Link</a></p>
<h2>Drone Interaction</h2>
<h3>Swarm Body: Embodied Swarm Robots</h3>
<p>Authors: Mai Nishimura, So Kuroki, Sosuke Ichihashi, Takefumi Hiraki, Shigeo Yoshida, Kazumi Kasaura, Kazutoshi Tanaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146948">Link</a></p>
<h3>Exploring Intended Functions of Indoor Flying Robots Interacting With Humans in Proximity</h3>
<p>Authors: Xiaowei Chen, Ziming Wang, Shiwei Yang, Morten Fjeld, Yiqian Wu, Björn Rohles</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147793">Link</a></p>
<h3>Firefighters' Perceptions on Collaboration and Interaction with Autonomous Drones: Results of a Field Trial</h3>
<p>Authors: Dzmitry Katsiuba, Moyi Li, Mateusz Dolata, Gerhard Schwabe</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147198">Link</a></p>
<h3>HIFuzz: Human Interaction Fuzzing for Small Unmanned Aerial Vehicles</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Salil Purandare, Theodore Chambers, Ankit Agrawal, Michael Vierhauser, Myra Cohen, Michael Murphy, Jason Matthew Brauer, Jane Cleland-Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147755">Link</a></p>
<h3>Dances with Drones: Spatial Matching and Perceived Agency in Improvised Movements with Drone and Human Partners</h3>
<p>Authors: Pakpong Chirarattananon, Kaixu Dong, Zhiyuan Zhang, Xiaoyu CHANG, RAY LC</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147482">Link</a></p>
<h2>Fabrication and Tangible Interaction A</h2>
<h3>MoiréWidgets: High-Precision, Passive Tangible Interfaces via Moiré Effect</h3>
<p>Authors: Mustafa Doga Dogan, Alexa Siu, Chang Xiao, Eunyee Koh, Daniel Campos Zamora</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147630">Link</a></p>
<h3>DungeonMaker: Embedding Tangible Creation and Destruction in Hybrid Board Games through Personal Fabrication Technology</h3>
<p>Authors: Anja Schikorr, Omid Rajabi, Ali Askari, Julian Frommel, Tobias Wagner, Evgeny Stemasov, Enrico Rukzio, Jessica Janek, Jan Gugenheimer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146888">Link</a></p>
<h3>Squishy, Yet Satisfying: Exploring Deformable Shapes' Cross-Modal Correspondences with Colours and Emotions</h3>
<p>Authors: Michael Proulx, Kim Sauvé, Crescent Jicol, Cameron Steer, Omosunmisola Lawal, Jason Alexander, Anika Jain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148261">Link</a></p>
<h3>PaperTouch: Tangible Interfaces through Paper Craft and Touchscreen Devices</h3>
<p>Authors: Zhen Zhou Yong, Clement Zheng, Bo Han, Ching Chiuan Yen, Qian Ye</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146860">Link</a></p>
<h3>WooDowel: Electrode Isolation for Electromagnetic Shielding in Triboelectric Plywood Sensors</h3>
<p>Authors: Xing-Dong Yang, Yonghao Shi, Te-Yen Wu, Yuning Su, Chenzheng Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147211">Link</a></p>
<h2>Fabrication and Tangible Interaction B</h2>
<h3>Tandem: Reproducible Digital Fabrication Workflows as Multimodal Programs</h3>
<p>Authors: Jasper Tran O'Leary, Nadya Peek, Octi Zhang, Thrisha Ramesh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146800">Link</a></p>
<h3>ecSkin: Low-Cost Fabrication of Epidermal Electrochemical Sensors for Detecting Biomarkers in Sweat</h3>
<p>Authors: Mohammad Janghorban, Aditya Shekhar Nittala, Richa Pandey, Vrahant Nagoria, Chang Lee, Sai Nandan Panigrahy</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147205">Link</a></p>
<h3>VabricBeads : Variable Stiffness Structured Fabric using Artificial Muscle in Woven Beads</h3>
<p>Authors: Hideki Koike, Shio Miyafuji, Nobuhiro Takahashi, Jefferson Pardomuan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147426">Link</a></p>
<h3>DisplayFab: The State of the Art and a Roadmap in the Personal Fabrication of Free-Form Displays Using Active Materials and Additive Manufacturing.</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mike Fraser, Ollie Hanton, Anne Roudaut</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147502">Link</a></p>
<h3>pARam: Leveraging Parametric Design in Extended Reality to Support the Personalization of Artifacts for Personal Fabrication</h3>
<p>Authors: Simon Demharter, Max Rädler, Evgeny Stemasov, Enrico Rukzio, Jan Gugenheimer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147551">Link</a></p>
<h2>Game Design A</h2>
<h3>Not All the Same: Understanding and Informing Similarity Estimation in Tile-Based Video Games</h3>
<p>Authors: Christian Guckelsberger, Vanessa Volz, Laurissa Tokarchuk, Sebastian Berns, Sam Snodgrass</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147878">Link</a></p>
<h3>Find the Bot!: Gamifying Facial Emotion Recognition for Both Human Training and Machine Learning Data Collection</h3>
<p>Authors: John Chung, Jean Song, Ahyeon Shin, Yeonsun Yang, Huidam Woo, Nayoung Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148164">Link</a></p>
<h3>Cheat Codes as External Support for Players Navigating Fear of Failure and Self-Regulation Challenges In Digital Games</h3>
<p>Authors: Susanne Poeller, Nicola Baumann, Martin Dechant, Karla Waldenmeier, Regan Mandryk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147333">Link</a></p>
<h3>How does Juicy Game Feedback Motivate? Testing Curiosity, Competence, and Effectance</h3>
<p>Authors: Kathrin Gerling, Sebastian Deterding, Dominic Kao, Nick Ballou, Heiko Breitsohl</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148171">Link</a></p>
<h3>"Ah! I see'' - Facilitating Process Reflection in Gameplay through a Novel Spatio-Temporal Visualization System</h3>
<p>Authors: Sai Siddartha Maram, Jennifer Villareale, Erica Kleinman, Jichen Zhu, Magy Seif El-Nasr</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147359">Link</a></p>
<h2>Game Design B</h2>
<h3>A Game of Love for Women: Social Support in Otome Game Mr. Love: Queen’s Choice in China</h3>
<p>Authors: Jingyi Guo, Hiu Man Ho, Ran Tang, Qinyuan Lei, Zilu Tang, Han Zhou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147914">Link</a></p>
<h3>Independent Validation of the Player Experience Inventory: Findings from a Large Set of Video Game Players</h3>
<p>Authors: Klaus Opwis, Sebastian Perrig, Lena Aeschbach, Nicolas Scharowski, Florian Brühlmann, Nick von Felten</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147606">Link</a></p>
<h3>Effects of a Gaze-Based 2D Platform Game on User Enjoyment, Perceived Competence, and Digital Eye Strain</h3>
<p>Authors: Mark Colley, Pascal Jansen, Julian Frommel, Max Rädler, Beate Wanner, Teresa Hirzle, Enrico Rukzio, Marcel Rötzer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148322">Link</a></p>
<h3>Damage Optimization in Video Games: A Player-Driven Co-Creative Approach</h3>
<p>Authors: Erica Kleinman, Manik Charan, Johannes Pfau, Magy Seif El-Nasr</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147749">Link</a></p>
<h3>The Trick is to Stay Behind?: Defining and Exploring the Design Space of Player Balancing Mechanics</h3>
<p>Authors: Pedro Pais, André Rodrigues, Daniel Barros, Tiago Guerreiro, João Guerreiro, David Gonçalves</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147203">Link</a></p>
<h2>Generative AI for Design</h2>
<h3>The Effects of Generative AI on Design Fixation and Divergent Thinking</h3>
<p>Authors: Ryan Kelly, Saumya Pareek, Samangi Wadinambiarachchi, Eduardo Velloso, Qiushi Zhou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147562">Link</a></p>
<p>Abstract: Generative AI systems have been heralded as tools for augmenting human creativity and inspiring divergent thinking, though with little empirical evidence for these claims. This paper explores the effects of exposure to AI-generated images on measures of design fixation and divergent thinking in a visual ideation task. Through a between-participants experiment (N=60), we found that support from an AI image generator during ideation leads to higher fixation on an initial example. Participants who used AI produced fewer ideas, with less variety and lower originality compared to a baseline. Our qualitative analysis suggests that the effectiveness of co-ideation with AI rests on participants' chosen approach to prompt creation and on the strategies used by participants to generate ideas in response to the AI's suggestions. We discuss opportunities for designing generative AI systems for ideation support and incorporating these AI tools into ideation workflows.</p>
<h3>Beyond Numbers: Creating Analogies to Enhance Data Comprehension and Communication with Generative AI</h3>
<p>Authors: Zhida Sun, Jiyao Zhang, Wei Shuai, Nan Cao, Qing Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146906">Link</a></p>
<p>Abstract: Unfamiliar measurements usually hinder readers from grasping the scale of the numerical data, understanding the content, and feeling engaged with the context. To enhance data comprehension and communication, we leverage analogies to bridge the gap between abstract data and familiar measurements. In this work, we first conduct semi-structured interviews with design experts to identify design problems and summarize design considerations. Then, we collect an analogy dataset of 138 cases from various online sources. Based on the collected dataset, we characterize a design space for creating data analogies. Next, we build a prototype system, AnalogyMate, that automatically suggests data analogies, their corresponding design solutions, and generated visual representations powered by generative AI. The study results show the usefulness of AnalogyMate in aiding the creation process of data analogies and the effectiveness of data analogy in enhancing data comprehension and communication. </p>
<h3>RoomDreaming: Generative-AI Approach to Facilitating Iterative, Preliminary Interior Design Exploration</h3>
<p>Authors: Alwena Lin, Ching-Yi Tsai, Serena Chen, Mike Chen, Wei-Chung Su, Marta Misztal, Yu Chen, Katherine Cheng, Shun-Yu Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147375">Link</a></p>
<p>Abstract: Interior design aims to create aesthetically pleasing and functional environments within an architectural space. For a simple room, the preliminary design exploration currently takes multiple meetings and days of work for interior designers to incorporate homeowners' personal preferences through layout, furnishings, form, colors, and materials.</p>
<p>We present RoomDreaming, a generative AI-based approach designed to facilitate preliminary interior design exploration. It empowers owners and designers to rapidly and efficiently iterate through a broad range of AI-generated, photo-realistic design alternatives, each uniquely tailored to fit actual space layouts and individual design preferences.</p>
<p>We conducted a series of formative and summative studies with a total of 18 homeowners and 20 interior designers to help design, improve, and evaluate RoomDreaming.</p>
<p>Owners reported that RoomDreaming effectively increased the breadth and depth of design exploration with higher efficiency and satisfaction. Designers reported that one hour of collaborative designing with RoomDreaming yielded results comparable to several days of traditional owner-designer meetings, plus days to weeks worth of designer work to develop and refine designs.</p>
<h3>Design Principles for Generative AI Applications</h3>
<p>Authors: Justin Weisz, Gabriela Hoefer, Michael Muller, Rachel Miles, Werner Geyer, Jessica He</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147832">Link</a></p>
<p>Abstract: Generative AI applications present unique design challenges. As generative AI technologies are increasingly being incorporated into mainstream applications, there is an urgent need for guidance on how to design user experiences that foster effective and safe use. We present six principles for the design of generative AI applications that address unique characteristics of generative AI UX and offer new interpretations and extensions of known issues in the design of AI applications. Each principle is coupled with a set of design strategies for implementing that principle via UX capabilities or through the design process. The principles and strategies were developed through an iterative process involving literature review, feedback from design practitioners, validation against real-world generative AI applications, and incorporation into the design process of two generative AI applications. We anticipate the principles to usefully inform the design of generative AI applications by driving actionable design recommendations.</p>
<h3>User Experience Design Professionals’ Perceptions of Generative Artificial Intelligence</h3>
<p>Authors: Jie Li, Hancheng Cao, Ruihao Zhu, Abdallah El Ali, Youyang Hou, Laura Lin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148101">Link</a></p>
<p>Abstract: Among creative professionals, Generative Artificial Intelligence (GenAI) has sparked excitement over its capabilities and fear over unanticipated consequences. How does GenAI impact User Experience Design (UXD) practice, and are fears warranted? We interviewed 20 UX Designers, with diverse experience and across companies (startups to large enterprises). We probed them to characterize their practices, and sample their attitudes, concerns, and expectations. We found that experienced designers are confident in their originality, creativity, and empathic skills, and find GenAI’s role as assistive. They emphasized the unique human factors of “enjoyment” and “agency”, where humans remain the arbiters of “AI alignment”. However, skill degradation, job replacement, and creativity exhaustion can adversely impact junior designers. We discuss implications for human-GenAI collaboration, specifically copyright and ownership, human creativity and agency, and AI literacy and access. Through the lens of responsible and participatory AI, we contribute a deeper understanding of GenAI fears and opportunities for UXD.</p>
<h2>Haptics and Embodied Interaction A</h2>
<h3>Touching the Moon: Leveraging Passive Haptics, Embodiment and Presence for Operational Assessments in Virtual Reality</h3>
<p>BEST_PAPER</p>
<p>Authors: Nikolai Callus, Aidan Cowley, Olivier Christmann, André Zenner, Tommy Nilsson, Geoffrey Gorisse, Enrico Guerra, Florian Dufresne, Leonie Bensch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147838">Link</a></p>
<h3>A Meta-Bayesian Approach for Rapid Online Parametric Optimization for Wrist-based Interactions</h3>
<p>Authors: Yi-Chi Liao, Alec Pierce, Ruta Desai, Krista Taylor, Tanya Jonker, Aakar Gupta, Hrvoje Benko</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146812">Link</a></p>
<h3>vARitouch: Back of the Finger Device for Adding Variable Compliance to Rigid Objects</h3>
<p>Authors: Audrey Girouard, Valentin Martinez-Missir, Gabriela Vega, Karen Cochrane, Dennis Wittchen, Nihar Sabnis, Paul Strohmeier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147275">Link</a></p>
<h3>Haptic Source-effector: Full-body Haptics via Non-invasive Brain Stimulation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jacob Serfaty, Pedro Lopes, Yudai Tanaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147704">Link</a></p>
<h3>MouseRing: Always-available Touchpad Interaction with IMU Rings</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Xutong Wang, Yuanchun Shi, Xiyuan Shen, Chen Liang, Chun Yu, Haozhan Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148332">Link</a></p>
<h2>Haptics and Embodied Interaction B</h2>
<h3>Thermal Masking: When the Illusion Takes Over the Real</h3>
<p>Authors: Hyunjae Gil, Yatharth Singhal, Jin Ryong Kim, Haokun Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147304">Link</a></p>
<h3>Haptic Permeability: Adding Holes to Tactile Devices Improves Dexterity</h3>
<p>Authors: Shan-Yuan Teng, Pedro Lopes, Aryan Gupta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146851">Link</a></p>
<h3>Don’t Look Now: Audio/Haptic Guidance for 3D Scanning of Landmarks</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Gabriel Brostow, Liv Urwin, Jessica Van Brummelen, Mohamed Sayed, Oliver Johnston</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147615">Link</a></p>
<h3>ErgoPulse: Electrifying Your Lower Body With Biomechanical Simulation-based Electrical Muscle Stimulation Haptic System in Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Minwoo Seong, SeungJun Kim, Seongjun Kang, Jeongseok Oh, Ahmed Elsharkawy, Seokhyun Hwang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147568">Link</a></p>
<h3>Motionless Movement: Towards Vibrotactile Kinesthetic Displays</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yuran Ding, Nihar Sabnis, Paul Strohmeier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147366">Link</a></p>
<h2>HCI for Development A</h2>
<h3>Enhancing Communication Equity: Evaluation of an Automated Speech Recognition Application in Ghana</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Gifty Ayoka, Giulia Barbareschi, Richard Cave, Catherine Holloway</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147191">Link</a></p>
<h3>Hearing Community Voices in HCI4D: Establishing Safe Places to Co-Create Counter-Collective Narratives with Women Farmers in Bangladesh</h3>
<p>Authors: Delvin Varghese, Patrick Olivier, Gillian Oliver, Jessica Watterson, Stephen Lindsay, Syed Ishtiaque Ahmed, Ms Mallika Saha, Tom Bartindale, Manika Saha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147578">Link</a></p>
<h3>Digital Repression in Palestine</h3>
<p>Authors: Ghadeer Awwad, Kentaro Toyama</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146966">Link</a></p>
<h3>"Unrest and trauma stays with you!": Navigating mental health and professional service-seeking in Kashmir</h3>
<p>Authors: Asra Wani, Ishika Joshi, Pushpendra Singh, Nadia Nahvi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147671">Link</a></p>
<h3>“I know I have this till my Last Breath”: Unmasking the Gaps in Chronic Obstructive Pulmonary Disease (COPD) Care in India</h3>
<p>BEST_PAPER</p>
<p>Authors: Gautami Tripathi, Medhavi Sabherwal, Pushpendra Singh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147082">Link</a></p>
<h2>HCI for Development B</h2>
<h3>Challenges to Online Disability Rights Advocacy in India</h3>
<p>Authors: Sukhnidh Kaur, Manohar Swaminathan, Kalika Bali, Aditya Vashistha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147020">Link</a></p>
<h3>Expanding Concepts of Non-Consensual Image-Disclosure Abuse: A Study of NCIDA in Pakistan</h3>
<p>Authors: Mustafa Naseem, Amna Batool, Kentaro Toyama</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146885">Link</a></p>
<h3>Viewer2Explorer: Designing a Map Interface for Spatial Navigation in Linear 360 Museum Exhibition Video</h3>
<p>Authors: HyeonBeom Yi, Chaeeun Lee, Woohun Lee, Jinwook Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147613">Link</a></p>
<h3>Explorable Explainable AI: Improving AI Understanding for Community Health Workers in India</h3>
<p>Authors: Ian Solano-Kamaiko, Dibyendu Mishra, Nicola Dell, Aditya Vashistha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147612">Link</a></p>
<h2>Healthy Aging</h2>
<h3>Redefining Activity Tracking Through Older Adults' Reflections on Meaningful Activities</h3>
<p>Authors: Bongshin Lee, Margaret Danilovich, Eun Kyoung Choe, Mengying Li, David E Conroy, Amanda Lazar, Yiwen Wang, Young-Ho Kim, Hernisa Kacorri</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148041">Link</a></p>
<h3>“X-Ray Vision” as a Compensatory Augmentation for Slowing Cognitive Map Decay in Older Adults</h3>
<p>Authors: Christopher Bennett, Paul Fink, Nicholas Giudice</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147822">Link</a></p>
<h3>Mentorable Interfaces for Automated Vehicles: A New Paradigm for Designing Learnable Technology for Older Adults</h3>
<p>Authors: Togtokhtur Batbold, Alessandro Soro, Ronald Schroeter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147087">Link</a></p>
<h3>Navigating the Maze of Routine Disruption: Exploring How Older Adults Living Alone Navigate Barriers to Establishing and Maintaining Physical Activity Habits</h3>
<p>Authors: Karyn Moffatt, Muhe Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147390">Link</a></p>
<h3>LightSword: A Customized Virtual Reality Exergame for Long-Term Cognitive Inhibition Training in Older Adults</h3>
<p>Authors: Mingming Fan, Xiaoying Wei, Zhen Song, Haiyan Jiang, Qiuxin Du, Dongdong Weng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147594">Link</a></p>
<h2>Interaction and Input in Immersive Environments</h2>
<h3>Spatial Gaze Markers: Supporting Effective Task Switching in Augmented Reality</h3>
<p>Authors: Hans Gellersen, Jens Emil Grønbæk, Tobias Langlotz, Mathias Lystbæk, Ken Pfeuffer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147964">Link</a></p>
<p>Abstract: Task switching can occur frequently in daily routines with physical activity. In this paper, we introduce Spatial Gaze Markers, an augmented reality tool to support users in immediately returning to the last point of interest after an attention shift. The tool is task-agnostic, using only eye-tracking information to infer distinct points of visual attention and to mark the corresponding area in the physical environment. We present a user study that evaluates the effectiveness of Spatial Gaze Markers in simulated physical repair and inspection tasks against a no-marker baseline. The results give insights into how Spatial Gaze Markers affect user performance, task load, and experience of users with varying levels of task type and distractions. Our work is relevant to assist physical workers with simple AR techniques and render task switching faster with less effort.</p>
<h3>The RayHand Navigation: A Virtual Navigation Method with Relative Position between Hand and Gaze-Ray</h3>
<p>Authors: Gun Lee, Sei Kang, Soo-Hyung Kim, Hyung-Jeong Yang, Seungwon Kim, Jaejoon Jeong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148284">Link</a></p>
<p>Abstract: In this paper, we introduce a novel Virtual Reality (VR) navigation method using gaze ray and hand, named RayHand navigation. It supports controlling navigation speed and direction by quickly indicating the initial direction using gaze and then using dexterous hand movement for controlling the speed and direction based on the relative position between the gaze ray and user’s hand. We conducted a user study comparing our approach to the head-hand and torso-leaning-based navigation methods, and also evaluated their learning effect. The results showed that the RayHand and head-hand navigations were less physically demanding than the torso-leaning navigation, and the RayHand supported rich navigation experience with high hedonic quality and solved the issue of the user unintentionally stepping out from the designated interaction area. In addition, our approach showed a significant improvement over time with a learning effect.</p>
<h3>Effects of Device Environment and Information Layout on Spatial Memory and Performance in VR Selection Tasks</h3>
<p>Authors: Kim Kargut, Carl Gutwin, Andy Cockburn</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147581">Link</a></p>
<p>Abstract: Virtual Reality systems are increasingly proposed as a platform for everyday interactive software. Many applications are dependent on actions such as navigation and selection, but it is not clear how well immersive environments support these basic activities. Previous studies have suggested advantages for spatial learning in VR, so we carried out a study that investigated two aspects of immersion on spatial memory and selection: the degree to which the user is immersed in the data, and whether the system uses immersive input and output. The study showed that more-immersive conditions had substantially worse selection performance, and did not improve spatial learning. However, most participants believed that the immersive conditions were better for learning object locations, and most people preferred the immersive layout and the HMD. Our study suggests that designers should be cautious about assuming that everyday software applications will benefit from being deployed in an immersive VR environment.</p>
<h3>Rowing Beyond: Investigating Steering Methods for Rowing-based Locomotion in Virtual Environments</h3>
<p>Authors: Gerrit Meixner, Andrii Matviienko, Martin Hedlund, Cristian Bogdan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147740">Link</a></p>
<p>Abstract: Rowing has great potential in Virtual Reality (VR) exergames as it requires physical effort and uses physical motion to map the locomotion in a virtual space. However, rowing in VR is currently restricted to locomotion along one axis, leaving 2D and 3D locomotion out of the scope. To facilitate rowing-based locomotion, we implemented three steering techniques based on head, hands, and feet movements for 2D and 3D VR environments. To investigate these methods, we conducted a controlled experiment (N = 24) to assess the user performance, experience and VR sickness. We found that head steering leads to fast and precise steering in 2D and 3D, and hand steering is the most realistic. Feet steering had the largest performance difference between 2D and 3D but comparable precision to hands in 2D. Lastly, head steering is the least mentally demanding, and all methods had comparable VR sickness. </p>
<h3>Sicknificant Steps: A Systematic Review and Meta-analysis of VR Sickness in Walking-based Locomotion for Virtual Reality</h3>
<p>Authors: Niels Christian Nilsson, Joanna Bergström, Teresa Hirzle, Thomas van Gemert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147138">Link</a></p>
<p>Abstract: Walking-based locomotion techniques in virtual reality (VR) can use redirection to enable walking in a virtual environment larger than the physical one. This results in a mismatch between the perceived virtual and physical movement, which is known to cause VR sickness. However, it is unclear if different types of walking techniques (e.g., resetting, reorientation, or self-overlapping spaces) affect VR sickness differently. To address this, we conducted a systematic review and meta-analysis of 96 papers published in 2016–2022 that measure VR sickness in walking-based locomotion. We find different VR sickness effects between types of redirection and between normal walking and redirection. However, we also identified several problems with the use and reporting of VR sickness measures. We discuss the challenges in understanding VR sickness differences between walking techniques and present guidelines for measuring VR sickness in locomotion studies.</p>
<h2>Reality and Un-Reality in Immersive Interactions</h2>
<h3>The Effects of False but Stable Heart Rate Feedback on Cybersickness and User Experience in Virtual Reality</h3>
<p>Authors: Hanseob Kim, DongYun Joo, Gerard Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148245">Link</a></p>
<p>Abstract: Virtual reality (VR) offers a compelling and immersive experience; however, cybersickness (or VR sickness) stands as a significant obstacle to its widespread adoption. </p>
<p>When a user experiences cybersickness, one's physical condition deteriorates with various symptoms, often accompanied by an increased and destabilized heart rate and even altered perception of one's state. In this paper, we propose to provide ``False but Stable Heart rate (FSH)'' feedback through auditory and vibrotactile stimulation to reversely induce a stably perceived heart rate and, thereby, alleviate cybersickness while navigating a sickness-inducing VR content. </p>
<p>The validation of the human experiment confirmed the intended effect in a statistically significant way. Furthermore, it was found that the lesser compatible FSH feedback had a more substantial sickness reduction effect but distracted the user with the reduced immersive experience. </p>
<p>The compatible FSH feedback still showed moderate sickness reduction with the maintained sense of presence and immersion. </p>
<h3>Was it Real or Virtual? Confirming the Occurrence and Explaining Causes of Memory Source Confusion between Reality and Virtual Reality</h3>
<p>Authors: Julian Frommel, Elise Bonnail, Eric Lecolinet, Samuel Huron, Jan Gugenheimer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147768">Link</a></p>
<p>Abstract: Source confusion occurs when individuals attribute a memory to the wrong source (e.g., confusing a picture with an experienced event). Virtual Reality (VR) represents a new source of memories particularly prone to being confused with reality. While previous research identified causes of source confusion between reality and other sources (e.g., imagination, pictures), there is currently no understanding of what characteristics specific to VR (e.g., immersion, presence) could influence source confusion. Through a laboratory study (n=29), we 1) confirm the existence of VR source confusion with current technology, and 2) present a quantitative and qualitative exploration of factors influencing VR source confusion. Building on the Source Monitoring Framework, we identify VR characteristics and assumptions about VR capabilities (e.g., poor rendering) that are used to distinguish virtual from real memories. From these insights, we reflect on how the increasing realism of VR could leave users vulnerable to memory errors and perceptual manipulations.</p>
<h3>Socially Late, Virtually Present: The Effects of Transforming Asynchronous Social Interactions in Virtual Reality</h3>
<p>Authors: Jeremy Bailenson, Anna Queiroz, Mark Miller, Portia Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148136">Link</a></p>
<p>Abstract: Social Virtual Reality (VR) typically entails users interacting in real time. However, asynchronous Social VR presents the possibility of combining the convenience of asynchronous communication with the high presence of VR. Because the tools to easily record and replay VR social interactions are fairly new, scholars have not yet examined how users perceive asynchronous VR social interactions, and how nonverbal transformations of recorded interactions influence user behavior. In this work, we study nonverbal transformations of group interactions around proxemics and gaze and present results from an exploratory user study (N=128) investigating their effects. We found that the combination of spatial accommodation and added gaze increases social presence, perceived attention, and mutual gaze. Results also showed an inverse relationship between interpersonal distance and perceived levels of dominance and threat of the recorded group. Finally, we outline implications for educators and virtual meeting organizers to incorporate these transformations into real-world scenarios.</p>
<h3>“I’d rather drink in VRChat”: Understanding Drinking in Social Virtual Reality</h3>
<p>Authors: Qijia Chen, Giulio Jacucci, Andrea Bellucci</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147852">Link</a></p>
<p>Abstract: Drinking in social VR has become popular, yet little is known about how users perceive and experience alcohol consumption while immersed in virtual spaces with others, as well as its potential harm and negative effects on their offline and online lives. To better understand this emerging phenomenon from the perspective of both drinkers and non-drinkers, we analyzed public discussions from the r/VRchat online community on users' perceptions, and experiences with alcohol consumption in social VR. Heavy drinking is prevalent. We find that VR drinkers feel less intoxicated, which makes them drink more without being aware of it. Anti-cybersickness designs may affect users' perception of vertigo, even if the vertigo is not caused by VR. We discuss how affordances that support meaningful activities (i.e., sense of presence, embodiment, and social interactions) exacerbate alcohol abuse. We propose implications for the design of safer social VR experiences for both drinkers and non-drinkers.</p>
<h3>Using Feedforward to Reveal Interaction Possibilities in Virtual Reality</h3>
<p>Authors: Kasper Hornbæk, Andreea Muresan, Jess McIntosh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150634">Link</a></p>
<p>Abstract: In virtual reality (VR), interactions may fail when users encounter new, unknown, or unexpected objects. We propose using feedforward in VR to help users interact with objects by revealing how such objects work. Feedforward lets users know what to do and how to do it by showing the available actions and outcomes before an interaction. In this article, we first chart the design space of feedforward in VR and illustrate how to design feedforward for specific VR interactions. We discuss starting the feedforward, previewing actions and outcomes, and returning the virtual world to its state before the feedforward. Second, we implement three real-world VR applications to show how feedforward can be applied to multistep interactions, perceived interactivity, and discoverability. Third, we conduct an evaluation of the design space with 14 VR experts to understand its usefulness. Finally, we summarize the findings of our work on VR feedforward in 15 guidelines.</p>
<h2>Large Language Models</h2>
<h3>Model Compression in Practice: Lessons Learned from Practitioners Creating On-device Machine Learning Experiences</h3>
<p>Authors: Donghao Ren, Fred Hohman, Dominik Moritz, Mary Beth Kery</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147982">Link</a></p>
<p>Abstract: On-device machine learning (ML) promises to improve the privacy, responsiveness, and proliferation of new, intelligent user experiences by moving ML computation onto everyday personal devices. However, today's large ML models must be drastically compressed to run efficiently on-device, a hurtle that requires deep, yet currently niche expertise. To engage the broader human-centered ML community in on-device ML experiences, we present the results from an interview study with 30 experts at Apple that specialize in producing efficient models. We compile tacit knowledge that experts have developed through practical experience with model compression across different hardware platforms. Our findings offer pragmatic considerations missing from prior work, covering the design process, trade-offs, and technical strategies that go into creating efficient models. Finally, we distill design recommendations for tooling to help ease the difficulty of this work and bring on-device ML into to more widespread practice.</p>
<h3>Talaria: Interactively Optimizing Machine Learning Models for Efficient Inference</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zhile Ren, Cecile Foret, Fred Hohman, Chaoqun Wang, Jeffrey Bigham, Jochen Görtler, Dominik Moritz, Xiaoyi Zhang, Qi Shan, Jinmook Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146741">Link</a></p>
<p>Abstract: On-device machine learning (ML) moves computation from the cloud to personal devices, protecting user privacy and enabling intelligent user experiences. However, fitting models on devices with limited resources presents a major technical challenge: practitioners need to optimize models and balance hardware metrics such as model size, latency, and power. To help practitioners create efficient ML models, we designed and developed Talaria: a model visualization and optimization system. Talaria enables practitioners to compile models to hardware, interactively visualize model statistics, and simulate optimizations to test the impact on inference metrics. Since its internal deployment two years ago, we have evaluated Talaria using three methodologies: (1) a log analysis highlighting its growth of 800+ practitioners submitting 3,600+ models; (2) a usability survey with 26 users assessing the utility of 20 Talaria features; and (3) a qualitative interview with the 7 most active users about their experience using Talaria.</p>
<h3>Luminate: Structured Generation and Exploration of Design Space with Large Language Models for Human-AI Co-Creation</h3>
<p>Authors: Bryan Min, Toby Li, Haijun Xia, Sangho Suh, Meng Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147623">Link</a></p>
<p>Abstract: Thanks to their generative capabilities, large language models (LLMs) have become an invaluable tool for creative processes. These models have the capacity to produce hundreds and thousands of visual and textual outputs, offering abundant inspiration for creative endeavors. But are we harnessing their full potential? We argue that current interaction paradigms fall short, guiding users towards rapid convergence on a limited set of ideas, rather than empowering them to explore the vast latent design space in generative models. To address this limitation, we propose a framework that facilitates the structured generation of design space in which users can seamlessly explore, evaluate, and synthesize a multitude of responses. We demonstrate the feasibility and usefulness of this framework through the design and development of an interactive system, Luminate, and a user study with 14 professional writers. Our work advances how we interact with LLMs for creative tasks, introducing a way to harness the creative potential of LLMs.</p>
<h3>Narrating Fitness: Leveraging Large Language Models for Reflective Fitness Tracker Data Interpretation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Stanislas Henry, Jasmin Niess, Paweł W. Woźniak, Tim Johansson, Konstantin Strömel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147608">Link</a></p>
<p>Abstract: While fitness trackers generate and present quantitative data, past research suggests that users often conceptualise their wellbeing in qualitative terms. This discrepancy between numeric data and personal wellbeing perception may limit the effectiveness of personal informatics tools in encouraging meaningful engagement with one’s wellbeing. In this work, we aim to bridge the gap between raw numeric metrics and users’ qualitative perceptions of wellbeing. In an online survey with $n=273$ participants, we used step data from fitness trackers and compared three presentation formats: standard charts, qualitative descriptions generated by an LLM (Large Language Model), and a combination of both. Our findings reveal that users experienced more reflection, focused attention and reward when presented with the generated qualitative data compared to the standard charts alone. Our work demonstrates how automatically generated data descriptions can effectively complement numeric fitness data, fostering a richer, more reflective engagement with personal wellbeing information.</p>
<h3>RELIC: Investigating Large Language Model Responses using Self-Consistency</h3>
<p>Authors: Mennatallah El-Assady, Hendrik Strobelt, Simran Arora, Vilém Zouhar, Mrinmaya Sachan, Furui Cheng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147472">Link</a></p>
<p>Abstract: Large Language Models (LLMs) are notorious for blending fact with fiction and generating non-factual content, known as hallucinations. To address this challenge, we propose an interactive system that helps users gain insight into the reliability of the generated text. Our approach is based on the idea that the self-consistency of multiple samples generated by the same LLM relates to its confidence in individual claims in the generated texts. Using this idea, we design RELIC, an interactive system that enables users to investigate and verify semantic-level variations in multiple long-form responses. This allows users to recognize potentially inaccurate information in the generated text and make necessary corrections. From a user study with ten participants, we demonstrate that our approach helps users better verify the reliability of the generated text. We further summarize the design implications and lessons learned from this research for future studies of reliable human-LLM interactions.</p>
<h2>Learning and Teaching CS and STEAM</h2>
<h3>EXPLORA: A teacher-apprentice methodology for eliciting natural child-computer interactions</h3>
<p>Authors: Vanessa Figueiredo, Catherine Ann Cameron</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148216">Link</a></p>
<h3>Interactive Murals: New Opportunities for Collaborative STEAM Learning</h3>
<p>Authors: Alyshia Bustos, Fiona Bell, Leah Buechley, Nanibah Chacon, Mia Shaw</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147930">Link</a></p>
<h3>From Prisons to Programming: Fostering Self-Efficacy via Virtual Web Design Curricula in Prisons and Jails</h3>
<p>Authors: Faraz Faruqi, Raechel Soicher, Martin Nisser, Joshua Long, Marisa Gaetz, Andrew Fishberg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147558">Link</a></p>
<h3>Mapping Accessibility Assignments into Core Computer Science Topics: An Empirical Study with Interviews and Surveys of Instructors and Students</h3>
<p>Authors: Emily Kuang, Kristen Shinohara, Catherine Baker, Di Pham, Yasmine Elglaly, Selah Bellscheidt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147853">Link</a></p>
<h3>The Matchmaker Inclusive Design Curriculum: A Faculty-Enabling Curriculum to Teach Inclusive Design Throughout Undergraduate CS</h3>
<p>Authors: Maria Jesus Alzugaray-Orellana, Gail Verdi, Heather Garcia, Spencer Madsen, Patricia Morreale, Elizabeth Li, Geraldine Jimena Noa, Rosalinda Garcia, Margaret Burnett</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147021">Link</a></p>
<h2>Learning and Teaching Technologies A</h2>
<h3>Investigating the Effects of Real-time Student Monitoring Interface on Instructors’ Monitoring Practices in Online Teaching</h3>
<p>Authors: Seora Park, Ha Yeon Lee, Esther Hehsun Kim, Hajin Lim, Joonhwan Lee, Jiyeon Seo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146670">Link</a></p>
<h3>Bridging the Literacy Gap for Adults: Streaming and Engaging in Adult Literacy Education through Livestreaming</h3>
<p>Authors: Emily Kuang, Mingming Fan, Shihan Fu, Jianhao Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148074">Link</a></p>
<h3>ClassMeta: Designing Interactive Virtual Classmate to Promote VR Classroom Participation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Xiyun Hu, Kylie Peppler, Karthik Ramani, Ziyi Liu, Lijun Zhu, Enze Jiang, Zhengzhe Zhu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147941">Link</a></p>
<h3>Simulator-based Mixed Reality eVTOL Pilot Training: The Instructor Operator Station</h3>
<p>Authors: Sharina Kimura, Florian Holzapfel, Michael Zintl, Claudius Hammann</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146971">Link</a></p>
<h3>Privacy Concerns of Student Data Shared with Instructors in an Online Learning Management System</h3>
<p>Authors: Avanya Kohli, Prashanth Rajivan, Monika Kwapisz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146719">Link</a></p>
<h2>Learning and Teaching Technologies B</h2>
<h3>“Oh My God! It’s Recreating Our Room!” Understanding Children’s Experiences with A Room-Scale Augmented Reality Authoring Toolkit</h3>
<p>Authors: Yinmiao Li, Uri Wilensky, Mike Horn, Zhennian Xie, Lexie Zhao, John Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147001">Link</a></p>
<h3>ClassInSight: Designing Conversation Support Tools to Visualize Classroom Discussion for Personalized Teacher Professional Development</h3>
<p>Authors: S Sushil, Angela Stewart, Prasenjit Mitra, Saranya Venkatraman, Neil Thawani, John Zimmerman, Ung-Sang Lee, Amy Ogan, Sherice Clarke, Tricia Ngoon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146615">Link</a></p>
<h3>Virtual Reality, Real Pedagogy: A Contextual Inquiry of Instructor Practices with VR Video</h3>
<p>Authors: Yu Liu, Bo Han, Feng Qian, Qiao Jin, Svetlana Yarosh, Ye Yuan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146868">Link</a></p>
<h3>Investigating Demographics and Motivation in Engineering Education Using Radio and Phone-Based Educational Technologies</h3>
<p>Authors: Darren Butler, Judith Uchidiuno, John Stamper, Christine Kwon, Amy Ogan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147291">Link</a></p>
<h3>Xylocode: A Novel Approach to Fostering Interest in Computer Science via an Embodied Music Simulation</h3>
<p>Authors: Brian Magerko, Jiaxi Yang, Duri Long, Cassandra Naomi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146705">Link</a></p>
<h2>Music</h2>
<h3>A Way for Deaf and Hard of Hearing People to Enjoy Music by Exploring and Customizing Cross-modal Music Concepts</h3>
<p>Authors: Jin-Hyuk Hong, Yeo-Gyeong Noh, ChungHa Lee, Youjin Choi, Junryeol Jeon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147004">Link</a></p>
<h3>Capturing Cancer as Music: Cancer Mechanisms Expressed through Musification</h3>
<p>Authors: Rostyslav Hnatyshyn, Jiayi Hong, Christopher Norby, Carlo C. Maley, Ross Maciejewski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146927">Link</a></p>
<h3>MARingBA: Music-Adaptive Ringtones for Blended Audio Notification Delivery</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Alexander Wang, Yi Fei Cheng, David Lindlbauer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147470">Link</a></p>
<h3>Challenges of Music Score Writing and the Potentials of Interactive Surfaces</h3>
<p>Authors: Caroline Appert, Catherine Letondal, Emmanuel Pietriga, Vincent Cavez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148089">Link</a></p>
<h3>Sound Designer-Generative AI Interactions: Towards Designing Creative Support Tools for Professional Sound Designers</h3>
<p>Authors: Purnima Kamath, Priambudi Lintang Bagaskara, Fabio Morreale, Yize Wei, Suranga Nanayakkara</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148093">Link</a></p>
<h2>Players and Game Experiences</h2>
<h3>Sweating the Details: Emotion Recognition and the Influence of Physical Exertion in Virtual Reality Exergaming</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Tarini Sehgal, Dominic Potts, Zoe Broad, Christopher Clarke, Christof Lutteroth, Eamonn O'Neill, Joseph Hartley, Crescent Jicol</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148111">Link</a></p>
<h3>Exploring the association between engagement with location-based game features and getting inspired about environmental issues and nature</h3>
<p>Authors: Samuli Laato, Bastian Kordyaka, Sebastian Weber, Bjoern Niehaves, Juho Hamari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147451">Link</a></p>
<h3>``Backseat Gaming" A Study of Co-Regulated Learning within a Collegiate Male Esports Community</h3>
<p>Authors: Garrett Powell, Brent Reeves, Erica Kleinman, James Prather, Reza Habibi, Magy Seif El-Nasr</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147778">Link</a></p>
<h3>Quantifying Wrist-Aiming Habits with A Dual-Sensor Mouse: Implications for Player Performance and Workload</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Donghyeon Kang, Namsub Kim, June-Seop Yoon, Sunjun Kim, Byungjoo Lee, Daekaun Kang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146862">Link</a></p>
<h3>Traumatizing or Just Annoying? Unveiling the Spectrum of Gamer Toxicity in the StarCraft II Community</h3>
<p>Authors: Samuli Laato, Bastian Kordyaka, Juho Hamari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148033">Link</a></p>
<h2>Understanding Player Experiences</h2>
<h3>Tunnel Runner: a Proof-of-principle for the Feasibility and Benefits of Facilitating Players' Sense of Control in Cognitive Assessment Games</h3>
<p>Authors: Max Birk, Panos Markopoulos, Benny Markovitch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147125">Link</a></p>
<h3>"I Know What You Mean": Context-Aware Recognition to Enhance Speech-Based Games</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Thomas Muender, Mohamed Lamine Fetni, Nima Zargham, Rainer Malaka, Laura Spillner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147848">Link</a></p>
<h3>Screenless Interactive Tabletop Gaming with Capacitive Surface Sensing</h3>
<p>Authors: Anna Walczak, Julia Dominiak, Krzysztof Adamkiewicz, Paweł W. Woźniak, Andrzej Romanowski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147873">Link</a></p>
<h3>Characterizing and Quantifying Expert Input Behavior in League of Legends</h3>
<p>Authors: Youngjung Uh, Seyeon Lee, Hanbyeol Lee, Byungjoo Lee, Rohan Nallapati</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148156">Link</a></p>
<h3>Toxicity in Online Games: The Prevalence and Efficacy of Coping Strategies</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Julian Frommel, Regan Mandryk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147177">Link</a></p>
<h2>Reflecting on Online Content</h2>
<h3>Help Me Reflect: Leveraging Self-Reflection Interface Nudges to Enhance Deliberativeness on Online Deliberation Platforms</h3>
<p>Authors: Simon Perrault, Weiyu Zhang, Gionnieve Lim, ShunYi Yeo, Jie Gao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147640">Link</a></p>
<h3>Capra: Making Use of Multiple Perspectives for Capturing, Noticing and Revisiting Hiking Experiences Over Time</h3>
<p>Authors: Tal Amram, Henry Lin, MinYoung Yoo, Samuel Barnett, Nico Brand, William Odom, Jordan White</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148073">Link</a></p>
<h3>AI-Driven Mediation Strategies for Audience Depolarisation in Online Debates</h3>
<p>Authors: Jorge Goncalves, Jarod Govers, Vassilis Kostakos, Eduardo Velloso</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147072">Link</a></p>
<h3>Debate Chatbots to Facilitate Critical Thinking on YouTube: Social Identity and Conversational Style Make A Difference</h3>
<p>BEST_PAPER</p>
<p>Authors: Sidney Fels, Dongwook Yoon, Luanne Sinnamon, Thitaree Tanprasert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147628">Link</a></p>
<h3>Viblio: Introducing Credibility Signals and Citations to Video-Sharing Platforms</h3>
<p>Authors: Renee Wang, Tanushree Mitra, Tony Li, Prerna Juneja, Amy Zhang, Emelia Hughes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148085">Link</a></p>
<h2>Security</h2>
<h3>Comparing the Use and Usefulness of Four IoT Security Labels</h3>
<p>Authors: Jacob Abbott, Peter Caven, Zitao Zhang, Xinyao Ma, LJean Camp</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147913">Link</a></p>
<h3>Better Together: The Interplay Between a Phishing Awareness Video and a Link-centric Phishing Support Tool</h3>
<p>Authors: Mattia Mossano, Benjamin Berens, Melanie Volkamer, Florian Schaub</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147585">Link</a></p>
<h3>The Effects of Group Discussion and Role-playing Training on Self-efficacy, Support-seeking, and Reporting Phishing Emails: Evidence from a Mixed-design Experiment</h3>
<p>Authors: Xiaowei Chen, Gabriele Lenzini, Anastasia Sergeeva, Verena Distler, Margault Sacré, Samuel Greiff</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146688">Link</a></p>
<h3>Usable News Authentication: How the Presentation and Location of Cryptographic Information Impacts the Usability of Provenance Information and Perceptions of News Articles</h3>
<p>Authors: Kimberly Brown, Ayana Monroe, Samya Potlapalli, Catherine Barwulor, Julia Jose, Errol Francis II, Kelly Caine, Susan McGregor, Emily Sidnam-Mauch, Kediel Morales</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147602">Link</a></p>
<h3>Interdisciplinary Approaches to Cybervulnerability Impact Assessment for Energy Critical Infrastructure</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Katya Le Blanc, Lorrie Cranor, Lujo Bauer, Robert Erbes, Andrea Gallardo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147155">Link</a></p>
<h2>Sensemaking with AI A</h2>
<h3>Selenite: Scaffolding Online Sensemaking with Comprehensive Overviews Elicited from Large Language Models</h3>
<p>Authors: Aniket Kittur, Brad Myers, Michael Xieyang Liu, Franklin Mingzhe Li, Tongshuang Wu, Tianying Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148071">Link</a></p>
<p>Abstract: Sensemaking in unfamiliar domains can be challenging, demanding considerable user effort to compare different options with respect to various criteria. Prior research and our formative study found that people would benefit from reading an overview of an information space upfront, including the criteria others previously found useful. However, existing sensemaking tools struggle with the "cold-start" problem -- not only requiring significant input from previous users to generate and share these overviews, but also that such overviews may turn out to be biased and incomplete. In this work, we introduce a novel system, Selenite, which leverages Large Language Models (LLMs) as reasoning machines and knowledge retrievers to automatically produce a comprehensive overview of options and criteria to jumpstart users' sensemaking processes. Subsequently, Selenite also adapts as people use it, helping users find, read, and navigate unfamiliar information in a systematic yet personalized manner. Through three studies, we found that Selenite produced accurate and high-quality overviews reliably, significantly accelerated users' information processing, and effectively improved their overall comprehension and sensemaking experience.</p>
<h3>Supporting Sensemaking of Large Language Model Outputs at Scale</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ziwei Gu, Chelse Swoopes, Jonathan Kummerfeld, Katy Gero, Elena Glassman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146937">Link</a></p>
<p>Abstract: Large language models (LLMs) are capable of generating multiple responses to a single prompt, yet little effort has been expended to help end-users or system designers make use of this capability. In this paper, we explore how to present many LLM responses at once. We design five features, which include both pre-existing and novel methods for computing similarities and differences across textual documents, as well as how to render their outputs. We report on a controlled user study (n=24) and eight case studies evaluating these features and how they support users in different tasks. We find that the features support a wide variety of sensemaking tasks and even make tasks tractable that our participants previously considered to be too difficult to attempt. Finally, we present design guidelines to inform future explorations of new LLM interfaces.</p>
<h3>Explanations, Fairness, and Appropriate Reliance in Human-AI Decision-Making</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Maria De-Arteaga, Niklas Kühl, Jakob Schoeffer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147316">Link</a></p>
<p>Abstract: In this work, we study the effects of feature-based explanations on distributive fairness of AI-assisted decisions, specifically focusing on the task of predicting occupations from short textual bios. We also investigate how any effects are mediated by humans' fairness perceptions and their reliance on AI recommendations. Our findings show that explanations influence fairness perceptions, which, in turn, relate to humans' tendency to adhere to AI recommendations. However, we see that such explanations do not enable humans to discern correct and incorrect AI recommendations. Instead, we show that they may affect reliance irrespective of the correctness of AI recommendations. Depending on which features an explanation highlights, this can foster or hinder distributive fairness: when explanations highlight features that are task-irrelevant and evidently associated with the sensitive attribute, this prompts overrides that counter AI recommendations that align with gender stereotypes. Meanwhile, if explanations appear task-relevant, this induces reliance behavior that reinforces stereotype-aligned errors. These results imply that feature-based explanations are not a reliable mechanism to improve distributive fairness.</p>
<h3>Unraveling the Dilemma of AI Errors: Exploring the Effectiveness of Human and Machine Explanations for Large Language Models</h3>
<p>Authors: Mark Hancock, Marvin Pafla, Kate Larson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147603">Link</a></p>
<p>Abstract: The field of eXplainable artificial intelligence (XAI) has produced a plethora of methods (e.g., saliency-maps) to gain insight into artificial intelligence (AI) models, and has exploded with the rise of deep learning (DL). However, human-participant studies question the efficacy of these methods, particularly when the AI output is wrong. In this study, we collected and analyzed 156 human-generated text and saliency-based explanations collected in a question-answering task (N=40) and compared them empirically to state-of-the-art XAI explanations (integrated gradients, conservative LRP, and ChatGPT) in a human-participant study (N=136). Our findings show that participants found human saliency maps to be more helpful in explaining AI answers than machine saliency maps, but performance negatively correlated with trust in the AI model and explanations. This finding hints at the dilemma of AI errors in explanation, where helpful explanations can lead to lower task performance when they support wrong AI predictions. </p>
<h3>"Are You Really Sure?'' Understanding the Effects of Human Self-Confidence Calibration in AI-Assisted Decision Making</h3>
<p>Authors: Shuai Ma, Chuhan Shi, Xinru Wang, Xiaojuan Ma, Ying Lei, Ming Yin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147034">Link</a></p>
<p>Abstract: In AI-assisted decision-making, it is crucial but challenging for humans to achieve appropriate reliance on AI. This paper approaches this problem from a human-centered perspective, "human self-confidence calibration". We begin by proposing an analytical framework to highlight the importance of calibrated human self-confidence. In our first study, we explore the relationship between human self-confidence appropriateness and reliance appropriateness. Then in our second study, We propose three calibration mechanisms and compare their effects on humans' self-confidence and user experience. Subsequently, our third study investigates the effects of self-confidence calibration on AI-assisted decision-making. Results show that calibrating human self-confidence enhances human-AI team performance and encourages more rational reliance on AI (in some aspects) compared to uncalibrated baselines. Finally, we discuss our main findings and provide implications for designing future AI-assisted decision-making interfaces.</p>
<h2>Sensemaking with AI B</h2>
<h3>Towards a Diffractive Analysis of Prompt-Based Generative AI</h3>
<p>Authors: Jon McCormack, Maria Teresa Llano Rodriguez, Nina Rajcic</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148226">Link</a></p>
<p>Abstract: Recent developments in prompt-based generative AI has given rise to discourse surrounding the perceived ethical concerns, economic implications, and consequences for the future of cultural production. As generative imagery becomes pervasive in mainstream society, dominated primarily by emerging industry leaders, we encourage that the role of the CHI community be one of inquiry; to investigate the numerous ways in which generative AI has the potential to, and already is, augmenting human creativity. In this paper, we conducted a diffractive analysis exploring the potential role of prompt-based interfaces in artists' creative practice. Over a two week period, seven visual artists were given access to a personalised instance of Stable Diffusion, fine-tuned on a dataset of their work. In the following diffractive analysis, we identified two dominant modes adopted by participants, AI for ideation, and AI for production. We furthermore present a number of ethical design considerations for the future development of generative AI interfaces.</p>
<h3>Where Are We So Far? Understanding Data Storytelling Tools from the Perspective of Human-AI Collaboration</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Haotian Li, Huamin Qu, Yun Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146630">Link</a></p>
<p>Abstract: Data storytelling is powerful for communicating data insights, but it requires diverse skills and considerable effort from human creators. Recent research has widely explored the potential for artificial intelligence (AI) to support and augment humans in data storytelling. However, there lacks a systematic review to understand data storytelling tools from the perspective of human-AI collaboration, which hinders researchers from reflecting on the existing collaborative tool designs that promote humans' and AI's advantages and mitigate their shortcomings. This paper investigated existing tools with a framework from two perspectives: the stages in the storytelling workflow where a tool serves, including analysis, planning, implementation, and communication, and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers. Through our analysis, we recognize the common collaboration patterns in existing tools, summarize lessons learned from these patterns, and further illustrate research opportunities for human-AI collaboration in data storytelling.</p>
<h3>Dissecting users' needs for search result explanations</h3>
<p>Authors: Alex Jaimes, Wenjuan Zhang, Joel Tetreault, Prerna Juneja, Alison Smith-Renner, Hemank Lamba</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148160">Link</a></p>
<p>Abstract: There is a growing demand for transparency in search engines to understand how search results are curated and to enhance users' trust. Prior research has introduced search result explanations with a focus on "how" to explain, assuming explanations are beneficial. Our study takes a step back to examine "if" search explanations are needed and "when" they are likely to provide benefits. Additionally, we summarize key characteristics of helpful explanations and share users' perspectives on explanation features provided by Google and Bing. Interviews with non-technical individuals reveal that users do not always seek or understand search explanations and mostly desire them for complex and critical tasks. They find Google's search explanations too obvious but appreciate the ability to contest search results. Based on our findings, we offer design recommendations for search engines and explanations to help users better evaluate search results and enhance their search experience.</p>
<h3>Natural Language Dataset Generation Framework for Visualizations Powered by Large Language Models</h3>
<p>Authors: Kwon Ko, Hyeon Jeon, Dae Hyun Kim, Jinwook Seo, Juho Kim, Gwanmo Park, Nam Wook Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147000">Link</a></p>
<p>Abstract: We introduce VL2NL, a Large Language Model (LLM) framework that generates rich and diverse NL datasets using Vega-Lite specifications as input, thereby streamlining the development of Natural Language Interfaces (NLIs) for data visualization. To synthesize relevant chart semantics accurately and enhance syntactic diversity in each NL dataset, we leverage 1) a guided discovery incorporated into prompting so that LLMs can steer themselves to create faithful NL datasets in a self-directed manner; 2) a score-based paraphrasing to augment NL syntax along with four language axes. We also present a new collection of 1,981 real-world Vega-Lite specifications that have increased diversity and complexity than existing chart collections. When tested on our chart collection, VL2NL extracted chart semantics and generated L1/L2 captions with 89.4% and 76.0% accuracy, respectively. It also demonstrated generating and paraphrasing utterances and questions with greater diversity compared to the benchmarks. Last, we discuss how our NL datasets and framework can be utilized in real-world scenarios. The codes and chart collection are available at https://github.com/hyungkwonko/chart-llm.</p>
<h3>Marco: Supporting Business Document Workflows via Collection-Centric Information Foraging with Large Language Models</h3>
<p>Authors: Tong Sun, Alexa Siu, Nedim Lipka, Raymond Fok</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147634">Link</a></p>
<p>Abstract: Knowledge workers often need to extract and analyze information from a collection of documents to solve complex information tasks in the workplace, e.g., hiring managers reviewing resumes or analysts assessing risk in contracts. However, foraging for relevant information can become tedious and repetitive over many documents and criteria of interest. We introduce Marco, a mixed-initiative workspace supporting sensemaking over diverse business document collections. Through collection-centric assistance, Marco reduces the cognitive costs of extracting and structuring information, allowing users to prioritize comparative synthesis and decision making processes. Users interactively communicate their information needs to an AI assistant using natural language and compose schemas that provide an overview of a document collection. Findings from a usability study (n=16) demonstrate that when using Marco, users complete sensemaking tasks 16% more quickly, with less effort, and without diminishing accuracy. A design probe with seven domain experts identifies how Marco can benefit various real-world workflows.</p>
<h2>Smart Homes and Environments</h2>
<h3>Decide Yourself or Delegate - User Preferences Regarding the Autonomy of Personal Privacy Assistants in Private IoT-Equipped Environments</h3>
<p>Authors: Paul Gerber, Alina Stöver, Karola Marky, Max Mühlhäuser, Verena Zimmermann, Sarah Prange, Kira Bleck, Florian Müller, Florian Alt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146932">Link</a></p>
<h3>“You can’t write down the logic”: Bringing smart technology into the water infrastructure control room</h3>
<p>Authors: Jacquelyn Schmidt, Branko Kerkez, Ariel Roy</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147334">Link</a></p>
<h3>Tagnoo: Enabling Smart Room-Scale Environments with RFID-Augmented Plywood</h3>
<p>Authors: Tingyu Zhang, Xing-Dong Yang, Yonghao Shi, Te-Yen Wu, Yuning Su, Jiuen Feng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148075">Link</a></p>
<h3>Who Should Hold Control? Rethinking Empowerment in Home Automation among Cohabitants through the Lens of Co-Design</h3>
<p>Authors: Xinyi Fu, Xiao XUE, Xinyang Li, Jiachen Du, Boyang Jia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147601">Link</a></p>
<h3>Understanding Users' Interaction with Login Notifications</h3>
<p>Authors: Markus Dürmuth, Leona Lassak, Philipp Markert, Maximilian Golla</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147051">Link</a></p>
<h2>Smart Textiles and Changing Displays</h2>
<h3>MagneSwift: Low-Cost, Interactive Shape Display Leveraging Magnetic Materials</h3>
<p>Authors: Kentaro Yasu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146985">Link</a></p>
<h3>Shape-Changing Clay-Dough: Taking a Material-Oriented Approach to 3D Printing Ceramic Forms</h3>
<p>Authors: Fiona Bell, Ruby Ta, Erin McClure, Leah Buechley, Camila Friedman-Gerlicz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146926">Link</a></p>
<h3>Waxpaper Actuator: Sequentially and Conditionally Programmable Wax Paper for Morphing Interfaces</h3>
<p>Authors: Di Wu, Yunjia Zhang, Qiuyu Lu, Lining Yao, Hsuanju Lai, Emily Guan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148150">Link</a></p>
<h3>Loopsense: low-scale, unobtrusive, and minimally invasive knitted force sensors for multi-modal input, enabled by selective loop-meshing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Roland Aigner, Mira Haberfellner, Michael Haller</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147384">Link</a></p>
<h3>Cymatics Cup: Shape-Changing Drinks by Leveraging Cymatics</h3>
<p>Authors: Yun Suen Pai, Yang Yang, Kao-Hua Liu, Junichi Yamaoka, Weijen Chen, Kouta Minamizawa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147592">Link</a></p>
<h2>Social and Political Activism</h2>
<h3>Keyboard Fighters: The Use of ICTs by Activists in Times of Military Coup in Myanmar</h3>
<p>Authors: Laura Guntrum</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147122">Link</a></p>
<h3>Designing for Harm Reduction: Communication Repair for Multicultural Users' Voice Interactions</h3>
<p>BEST_PAPER</p>
<p>Authors: Geoff Kaufman, Kimi Wenzel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147425">Link</a></p>
<h3>Persuasion or Insulting? Unpacking Discursive Strategies of Gender Debate in Everyday Feminism in China</h3>
<p>Authors: Zheng Chen, Bo Li, Changyang He, Zhicong Lu, Yue DENG</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147170">Link</a></p>
<h3>Starting a New Life after Crossing the Tumen River: How North Korean Defectors Use Digital Technology in Transition</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Hayoun Noh, Soohyun Yoon, Hyunah Jo, Max Van Kleek, Younah Kang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147753">Link</a></p>
<h2>Sound, Rhythm, Movement</h2>
<h3>FabSound: Audio-Tactile and Affective Fabric Experiences Through Mid-air Haptics</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Patricia Cornelio, Christopher Dawes, Roberto Montano Murillo, William Frier, Marianna Obrist, Jing Xue</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147299">Link</a></p>
<h3>Exploring Collaborative Movement Improvisation Towards the Design of LuminAI—a Co-Creative AI Dance Partner</h3>
<p>Authors: Andrea Knowlton, Brian Magerko, Milka Trajkova, Manoj Deshpande, Duri Long</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147151">Link</a></p>
<h3>Understanding Feedback in Rhythmic Gymnastics Training: An Ethnographic-Informed Study of a Competition Class</h3>
<p>BEST_PAPER</p>
<p>Authors: Leonor Portugal da Fonseca, Paula Alexandra Silva, Francisco Nunes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148223">Link</a></p>
<h3>Designing and Evaluating an Advanced Dance Video Comprehension Tool with In-situ Move Identification Capabilities</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Garreth Tigwell, Caluã de Lacerda Pataca, Saad Hassan, Laleh Nourian, Will Silver Wagman, Briana Davis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147258">Link</a></p>
<h3>DoodleTunes: Interactive Visual Analysis of Music-Inspired Children Doodles with Automated Feature Annotation</h3>
<p>Authors: Mingtian Tao, Huayuan Ye, Changbo Wang, Jia Bu, Shuqi Liu, Shiqi Jiang, Chenhui Li, Juntong Chen, Liping Guo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147267">Link</a></p>
<h2>Supporting Accessibility of Text, Image and Video A</h2>
<h3>“It’s Kind of Context Dependent”: Understanding Blind and Low Vision People’s Video Accessibility Preferences Across Viewing Scenarios</h3>
<p>Authors: Crescentia Jung, Mahika Phutane, Lucy Jiang, Abigale Stangl, Shiri Azenkot</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146788">Link</a></p>
<h3>GazePrompt: Enhancing Low Vision People's Reading Experience with Gaze-Aware Augmentations</h3>
<p>Authors: Yun Ho, Sanbrita Mondal, Linxiu Zeng, Yuhang Zhao, Ru Wang, Daniel Killough, Zach Potter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147371">Link</a></p>
<h3>Constrained Highlighting in a Document Reader can Improve Reading Comprehension</h3>
<p>BEST_PAPER</p>
<p>Authors: Nikhita Joshi, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147932">Link</a></p>
<h3>Making Short-Form Videos Accessible with Hierarchical Video Summaries</h3>
<p>Authors: Tess Van Daele, Akhil Iyer, Amy Pavel, Yuning Zhang, Mina Huh, Jalyn Derry</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148297">Link</a></p>
<h2>Supporting Accessibility of Text, Image and Video B</h2>
<h3>Caption Royale: Exploring the Design Space of Affective Captions from the Perspective of Deaf and Hard-of-Hearing Individuals</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Caluã de Lacerda Pataca, Roshan Peiris, Saad Hassan, Matt Huenerfauth, Nathan Tinker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148008">Link</a></p>
<h3>SPICA: Interactive Video Content Exploration through Augmented Audio Descriptions for Blind or Low-Vision Viewers</h3>
<p>Authors: Zheng Ning, Kaiwen Jiang, Brianna Wimer, Toby Li, Jerrick Ban, Yuhang Zhao, Keyi Chen, Yapeng Tian</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147481">Link</a></p>
<h3>An AI-Resilient Text Rendering Technique for Reading and Skimming Documents</h3>
<p>Authors: Ziwei Gu, Jonathan Kummerfeld, Ian Arawjo, Elena Glassman, Kenneth Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147987">Link</a></p>
<h3>Investigating Use Cases of AI-Powered Scene Description Applications for Blind and Low Vision People</h3>
<p>Authors: Jazmin Collins, Ricardo Gonzalez Penuela, Shiri Azenkot, Cynthia Bennett</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147196">Link</a></p>
<h3>From Provenance to Aberrations: Image Creator and Screen Reader User Perspectives on Alt Text for AI-Generated Images</h3>
<p>Authors: Shaun Kane, Meredith Morris, Alexander Fiannaca, Maitraye Das, Cynthia Bennett</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148306">Link</a></p>
<h2>Supporting Communication Needs A</h2>
<h3>Lights, Camera, Access: A Closeup on Audiovisual Media Accessibility and Aphasia</h3>
<p>Authors: Elena Simperl, Alexandre Nevsky, Madeline Cruice, Timothy Neate</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147404">Link</a></p>
<p>Abstract: The presence of audiovisual media is a mainstay in the lives of many, increasingly so with technological progress. Accessing video and audio content, however, can be challenging for people with diverse needs. Existing research has explored a wide range of accessibility challenges and worked with disabled communities to design technologies that help bridge the access gap. Despite this work, our understanding of the challenges faced by communities with complex communication needs (CCNs) remains poor. To address this shortcoming, we present the first study that investigates the viewing experience of people with the communication impairment aphasia through an online survey (N=41) and two focus group sessions (N=10), with the aim of understanding their specific access challenges. We find that aphasia significantly impact viewing experience and present a taxonomy of access barriers and facilitators, with suggestions for future research.</p>
<h3>Co-Designing QuickPic: Automated Topic-Specific Communication Boards from Photographs for AAC-Based Language Instruction</h3>
<p>Authors: Karyn Moffatt, Howard C. Shane, Christina Yu, Mauricio Fontana de Vargas</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147269">Link</a></p>
<p>Abstract:  Traditional topic-specific communication boards for Augmentative and Alternative Communication (AAC)  require  manual programming of relevant symbolic vocabulary, which is time-consuming and often impractical even for experienced Speech-Language Pathologists (SLPs). While recent research has demonstrated the potential to automatically generate these boards from photographs using artificial intelligence, there has been no exploration on how to design such tools to support the specific needs of AAC-based language instruction. This paper introduces QuickPic, a mobile AAC application co-designed with SLPs and special educators, aimed at enhancing language learning for non-speaking individuals, such as autistic children. Through a 17-month design process, we uncover the unique design features required to provide timely language support in therapy and special education contexts. We present emerging evidence on the overall satisfaction of SLPs using QuickPic, and on the advantages of large language model-based generation compared to the existing technique for automated vocabulary from photographs for AAC.</p>
<h3>Empowering Independence Through Design: Investigating Standard Digital Design Patterns For Easy-to-Read Users.</h3>
<p>Authors: Ann Bessemans, Sabina Sieghart, Björn Rohles</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148221">Link</a></p>
<p>Abstract: As designers and researchers, it is our duty to ensure information accessibility for all, irrespective of cognitive abilities. Currently, Easy-to-Read (ETR) is commonly used to simplify text for individuals with cognitive impairments. Although design aspects of text</p>
<p>comprehensibility have recently gained attention, digital design patterns remain relatively unexplored. Our understanding of how ETR users interact with digital media, and how to design specifically for their needs, is still limited. Our study involved observing 20 German</p>
<p>ETR users engaging with a digital PDF and a website designed in a participatory process. We collected data on their access to digital media, personal use and workarounds, and their interaction with digital design patterns. Tasks on the smartphone were completed mostly successfully, while only 50% could navigate a digital PDF. In both cases, visual cues played a significant role. Our findings contribute recommendations for beneficial digital design patterns and future research.</p>
<h3>ChatDirector: Enhancing Video Conferencing with Space-Aware Scene Rendering and Speech-Driven Layout Transition</h3>
<p>Authors: Brian Collins, Ruofei Du, Karthik Ramani, Yinda Zhang, David Kim, Feitong Tan, Alex Olwal, Xun Qian</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148295">Link</a></p>
<p>Abstract: Remote video conferencing systems (RVCS) are widely adopted in personal and professional communication. However, they often lack the co-presence experience of in-person meetings. This is largely due to the absence of intuitive visual cues and clear spatial relationships among remote participants, which can lead to speech interruptions and loss of attention. This paper presents ChatDirector, a novel RVCS that overcomes these limitations by incorporating space-aware visual presence and speech-aware attention transition assistance. ChatDirector employs a real-time pipeline that converts participants' RGB video streams into 3D portrait avatars and renders them in a virtual 3D scene. We also contribute a decision tree algorithm that directs the avatar layouts and behaviors based on participants' speech states. We report on results from a user study (N=16) where we evaluated ChatDirector. The satisfactory algorithm performance and complimentary subject user feedback imply that ChatDirector significantly enhances communication efficacy and user engagement.</p>
<h3>COR Themes for Readability from Iterative Feedback</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Bernard Kerr, Zoya Bylinskii, Michael Kraley, Aleena Niklaus, Tianyuan Cai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148158">Link</a></p>
<p>Abstract: Digital reading applications give readers the ability to customize fonts, sizes, and spacings, all of which have been shown to improve the reading experience for readers from different demographics. However, tweaking these text features can be challenging, especially given their interactions on the final look and feel of the text. Our solution is to offer readers preset combinations of font, character, word and line spacing, which we bundle together into reading themes. We identify a recommended set of reading themes through data-driven design iterations with the crowd and experts. We show that after four design iterations, we converge on a set of three COR themes (Compact, Open, and Relaxed) that meet diverse readers' preferences, when evaluating the reading speeds, comprehension scores, and preferences of hundreds of readers with and without dyslexia, using crowdsourced experiments.</p>
<h2>Supporting Communication Needs B</h2>
<h3>COMPA: Using Conversation Context to Achieve Common Ground in AAC</h3>
<p>Authors: Henny Admoni, Yufei Wu, Stephanie Valencia, Zixuan Zheng, Amy Pavel, Jessica Huynh, Jeffrey Bigham, Teresa Wan, Emma Jiang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146686">Link</a></p>
<p>Abstract: Group conversations often shift quickly from topic to topic, leaving a small window of time for participants to contribute. AAC users often miss this window due to the speed asymmetry between using speech and using AAC devices. AAC users may take over a minute longer to contribute, and this speed difference can cause mismatches between the ongoing conversation and the AAC user's response. This results in misunderstandings and missed opportunities to participate. We present COMPA, an add-on tool for online group conversations that seeks to support conversation partners in achieving common ground. COMPA uses a conversation's live transcription to enable AAC users to mark conversation segments they intend to address (Context Marking) and generate contextual starter phrases related to the marked conversation segment (Phrase Assistance) and a selected user intent. We study COMPA in 5 different triadic group conversations, each composed by a researcher, an AAC user and a conversation partner (n=10) and share findings on how conversational context supports conversation partners in achieving common ground.</p>
<h3>Finding My Voice over Zoom: An Autoethnography of Videoconferencing Experience for a Person Who Stutters</h3>
<p>Authors: Shaomei Wu, Jingjin Li, Gilly Leshed</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146953">Link</a></p>
<p>Abstract: Existing videoconferencing (VC) technologies are often optimized for productivity and efficiency, with little support for the "soft side" of VC meetings such as empathy, authenticity, belonging, and emotional connections. This paper presents findings from a 15-month long autoethnographic study of VC experiences by the first author, a person who stutters (PWS). Our research shed light on the hidden costs of VC for PWS, uncovering the substantial emotional and cognitive efforts that other meeting attendants are often unaware of. Recognizing the disproportionate burden on PWS to be heard in VC, we propose a set of design implications for a more inclusive communication environment, advocating for shared responsibility among all, including communication technologies, to ensure the inclusion and respect of every voice.</p>
<h3>Breaking Badge: Augmenting Communication with Wearable AAC Smartbadges and Displays</h3>
<p>Authors: Humphrey Curtis, Duncan Lau, Timothy Neate</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147567">Link</a></p>
<p>Abstract: People living with complex communication needs employ multimodal pathways to communicate including: limited speech, paralinguistics, non-verbal communication and leveraging low-tech devices. However, most augmentative and alternative communication (AAC) interventions undermine end-users' agency by obstructing these intuitive communication pathways. In this paper, we collaborate with 19 people living with the language impairment aphasia exploring contextual communication challenges, before low-fidelity prototyping and wireframing wearable AAC displays. These activities culminated in two low-input wearable AAC prototypes that instead, scaffold users' pre-existing communication abilities. Firstly, the InkTalker is a low-power and affordable eInk AAC smartbadge designed to discreetly reveal invisible disabilities and usable as a communication prop. Secondly, WalkieTalkie is a scalable AAC app that converts smartphones into a feature-rich public display operable via multimodal input/outputs. We offer results from communication interactions with both devices, discussions and feedback responses. Participants used both AAC devices to interdependently socialise with others and augment pre-existing communication abilities.</p>
<h3>"It Is Easy Using My Apps:" Understanding Technology Use and Needs of Adults with Down Syndrome</h3>
<p>Authors: Audra Sterling, Hailey Johnson, Bilge Mutlu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147214">Link</a></p>
<p>Abstract: Assistive technologies for adults with Down syndrome (DS) need designs tailored to their specific technology requirements. While prior research has explored technology design for individuals with intellectual disabilities, little is understood about the needs and expectations of adults with DS. Assistive technologies should leverage the abilities and interests of the population, while incorporating age- and context-considerate content. In this work, we interviewed six adults with DS, seven parents of adults with DS, and three experts in speech-language pathology, special education, and occupational therapy to determine how technology could support adults with DS. In our thematic analysis, four main themes emerged, including (1) community vs. home social involvement; (2) misalignment of skill expectations between adults with DS and parents; (3) family limitations in technology support; and (4) considerations for technology development. Our findings extend prior literature by including the voices of adults with DS in how and when they use technology.</p>
<h3>Voice Assistive Technology for Activities of Daily Living: Developing an Alexa Telehealth Training for Adults with Cognitive-Communication Disorders</h3>
<p>Authors: Yao Du, Ginna Byun, Lauren Kim, Priyal Vora, Siona Amrgousian, Claire O'Connor</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147679">Link</a></p>
<p>Abstract: Individuals with cognitive-communication disorders (CCDs) due to neurological conditions, such as traumatic brain injury and aphasia, experience difficulties in communication and cognition that impact their ability to perform activities of daily living, or ADLs (e.g., self-care, meal preparation, scheduling). Voice assistive technology (VAT) can support the independent performance of ADLs; however, there are limited VAT training programs that teach individuals with CCDs how to properly implement and use VAT for ADLs. The present study examined the implementation of an online training program using Alexa voice commands for five ADL domains (scheduling, entertainment, self-care, news &amp; facts, and meal preparation). Using video analysis with seven adults with CCDs between ages 25 and 82 and interviews with five participants and three caregivers, we synthesized five weeks of training performance, analyzed participants' perceived benefits and challenges, and discussed challenges and opportunities for implementing VAT training for ADLs skills for adults with CCDs. </p>
<h2>Supporting Programmers and Learners A</h2>
<h3>Understanding the Needs of Novice Developers in Creating Self-Powered IoT</h3>
<p>Authors: Tian Min, Chengshuo Xia, Daxing Zhang, Congsi Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147080">Link</a></p>
<h3>AQuA: Automated Question-Answering in Software Tutorial Videos with Visual Anchors</h3>
<p>Authors: Saelyne Yang, George Fitzmaurice, Justin Matejka, Jo Vermeulen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148273">Link</a></p>
<h3>Meta-Manager: A Tool for Collecting and Exploring Meta Information about Code</h3>
<p>Authors: Brad Myers, Amber Horvath, Andrew Macvean</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147791">Link</a></p>
<h3>SQL Puzzles: Evaluating Micro Parsons Problems With Different Feedbacks as Practice for Novices</h3>
<p>Authors: Zihan Wu, Barbara Ericson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148131">Link</a></p>
<h3>Taking ASCII Drawings Seriously: How Programmers Diagram Code</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Brian Hempel, Philip Guo, William Duan, Devamardeep Hayatpur, Haijun Xia, Kathy Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147729">Link</a></p>
<h2>Supporting Programmers and Learners B</h2>
<h3>"Do You Want Me to Participate or Not?": Investigating the Accessibility of Software Development Meetings for Blind and Low Vision Professionals</h3>
<p>Authors: André van der Hoek, Emory Edwards, Stacy Branham, Jessy Ayala, Yoonha Cha, Isabela Figueira, Joshua Garcia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147835">Link</a></p>
<h3>MµSE: Supporting Exploration of Software-Hardware Interactions Through Examples</h3>
<p>Authors: Stefan Ramson, Robert Hirschfeld, Tom Beckmann, Paul Methfessel, Patrick Rein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148162">Link</a></p>
<h3>Is Stack Overflow Obsolete? An Empirical Study of the Characteristics of ChatGPT Answers to Stack Overflow Questions</h3>
<p>Authors: Samia Kabir, Bonan Kou, David N. Udo-Imeh, Tianyi Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146667">Link</a></p>
<h3>CoPrompt: Supporting Prompt Sharing and Referring in Collaborative Natural Language Programming</h3>
<p>Authors: Mingming Fan, Zhicong Lu, Jian Zhao, Ryan Yen, Yuzhe You, Li Feng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147317">Link</a></p>
<h3>Understanding Documentation Use Through Log Analysis: A Case Study of Four Cloud Services</h3>
<p>Authors: Brad Myers, Daye Nam, Andrew Macvean, Bogdan Vasilescu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147074">Link</a></p>
<h2>Trust in Social Media</h2>
<h3>Uncovering Human Traits in Determining Real and Spoofed Audio: Insights from Blind and Sighted Individuals</h3>
<p>Authors: Chaeeun Han, Prasenjit Mitra, Syed Masum Billah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146813">Link</a></p>
<h3>Understanding Underground Incentivized Review Services</h3>
<p>Authors: Rajvardhan Oak, Zubair Shafiq</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147503">Link</a></p>
<h3>Trust, Privacy, and Safety Factors Associated with Decision Making in P2P Markets Based on Social Networks: A Case Study of Facebook Marketplace in USA and Canada</h3>
<p>Authors: Masoud Mehrabi Koushki, Yue Huang, Konstantin (Kosta) Beznosov, Guillaume Humbert, Borke Obada-Obieh, Azadeh Mokhberi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148310">Link</a></p>
<h3>Profiling the Dynamics of Trust &amp; Distrust in Social Media: A Survey Study</h3>
<p>Authors: Jacqueline Griffin, Yimeng Wang, Joseph Gaggiano, Andrea Parker, Yixuan Zhang, Miso Kim, Nurul Suhaimi, Nutchanon Yongsatianchot, Anne Okrah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148331">Link</a></p>
<h3>A Browser Extension for in-place Signaling and Assessment of Misinformation</h3>
<p>Authors: Farnaz Jahanbakhsh, David Karger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148142">Link</a></p>
<h2>Wellbeing in Aging</h2>
<h3>An Iterative Participatory Design Approach to Develop Collaborative Augmented Reality Activities for Older Adults in Long-Term Care Facilities</h3>
<p>Authors: Mahrukh Tauseef, Cathy Maxwell, JUDITH TATE, Nilanjan Sarkar, Lorraine Mion, Akshith Ullal, Alexandra Watkins, Lisa Juckett</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147541">Link</a></p>
<h3>Understanding Socio-technical Opportunities for Enhancing Communication Between Older Adults and their Remote Family</h3>
<p>Authors: Xueliang Li, Baihui Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146735">Link</a></p>
<h3>Designing for Inclusive Experiences: Investigating Opportunities for Supporting Older Adults in Community-based Social Programs</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yushan Xing, Ryan Kelly, Kashifa Aslam, Melissa Rogerson, Jenny Waycott</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147962">Link</a></p>
<h3>Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults</h3>
<p>Authors: Wanling Cai, Yizhe Zhang, Tonglin Jiang, Li Chen, Gavin Doherty, Yucheng Jin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147408">Link</a></p>
<h3>Dancing with the Roles: Towards Designing Technology that Supports the Multifaceted Roles of Caregivers for Older Adults</h3>
<p>Authors: Chia-Fang Chung, Long-Jing Hsu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147745">Link</a></p>
<h2>Working Practices and Tools B</h2>
<h3>The Impact of Social Norms on Hybrid Workers’ Well-Being: A Cross-Cultural Comparison of Japan and the United States</h3>
<p>Authors: Momoko Nakatani, Ryo Hashimoto, Jack Jamieson, Wataru Akahori, Masahiro Watanabe, Naomi Yamashita</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146875">Link</a></p>
<h3>Mental Models of Meeting Goals: Supporting Intentionality in Meeting Technologies</h3>
<p>Authors: Lev Tankelevitch, Ava Scott, Sean Rintel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146999">Link</a></p>
<h3>Circle Back Next Week: The Effect of Meeting-Free Weeks on Distributed Workers’ Unstructured Time and Attention Negotiation</h3>
<p>Authors: Sharon Ferguson, Michael Massimi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147336">Link</a></p>
<h3>Exploring the Diminishing Allure of Paper and Low-Fidelity Prototyping Among Designers in the Software Industry: Impacts of Hybrid Work, Digital Tools, and Corporate Culture</h3>
<p>Authors: Dongwook Yoon, Jonathan Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146922">Link</a></p>
<h3>Reinforcing and Reclaiming The Home: Co-speculating Future Technologies to Support Remote and Hybrid Work</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Dasom Choi, Junnan Yu, Stephen Voida, Janghee Cho</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146980">Link</a></p>
<h2>Working Practices and Tools C</h2>
<h3>Practice-informed Patterns for Organising Large Groups in Distributed Mixed Reality Collaboration</h3>
<p>Authors: Jens Emil Grønbæk, Germán Leiva, Eduardo Velloso, Emily Wong, Juan Sánchez Esquivel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147880">Link</a></p>
<h3>Whispering Through Walls: Towards Inclusive Backchannel Communication in Hybrid Meetings</h3>
<p>Authors: Jens Emil Grønbæk, Qianqian Mu, Eve Hoggan, Marcel Borowski, Susanne Bødker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148087">Link</a></p>
<h3>DISCERN: Designing Decision Support Interfaces to Investigate the Complexities of Workplace Social Decision-Making With Line Managers</h3>
<p>Authors: Kate Nowak, Lindy Le, Shamsi Iqbal, Pranav Khadpe, Jina Suh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147698">Link</a></p>
<h3>The Effects of Update Interval and Reveal Method on Writer Comfort in Synchronized Shared-Editors</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yen-Ting Yeh, Nikhita Joshi, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148285">Link</a></p>
<h3>Exploring the Effectiveness of Time-lapse Screen Recording for Self-Reflection in Work Context</h3>
<p>Authors: Donghan Hu, Sang Won Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148168">Link</a></p>
<h2>Working with Data A</h2>
<h3>Generative Echo Chamber? Effect of LLM-Powered Search Systems on Diverse Information Seeking</h3>
<p>BEST_PAPER</p>
<p>Authors: Ziang Xiao, Nikhil Sharma, Q. Vera Liao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147446">Link</a></p>
<h3>SwapVid: Integrating Video Viewing and Document Exploration with Direct Manipulation</h3>
<p>Authors: Kazuki Takashima, Kotaro Hara, Kazuyuki Fujita, Taichi Murakami, Yoshifumi Kitamura</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147489">Link</a></p>
<h3>rTisane: Externalizing conceptual models for data analysis increases engagement with domain knowledge and improves statistical model quality</h3>
<p>BEST_PAPER</p>
<p>Authors: Jeffrey Heer, Eunice Jun, Edward Misback, Rene Just</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147809">Link</a></p>
<h3>Odds and Insights: Decision Quality in Exploratory Data Analysis Under Uncertainty</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Matthew Kay, Michael Correll, Abhraneel Sarma, Yuan Cui, Xiaoying Pu, Eli Brown</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146941">Link</a></p>
<h3>Using Open Data to Automatically Generate Localized Analogies</h3>
<p>Authors: Daniel Goldstein, Sofia Eleni Spatharioti, Jake Hofman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147137">Link</a></p>
<h2>Immersive Experiences: Design and Evaluation</h2>
<h3>Milliways: Taming Multiverses through Principled Evaluation of Data Analysis Paths</h3>
<p>Authors: Matthew Kay, Abhraneel Sarma, Kyle Hwang, Jessica Hullman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146939">Link</a></p>
<p>Abstract: Multiverse analyses involve conducting all combinations of reasonable choices in a data analysis process. A reader of a study containing a multiverse analysis might question—are all the choices included in the multiverse reasonable and equally justifiable? How much do results vary if we make different choices in the analysis process? In this work, we identify principles for validating the composition of, and interpreting the uncertainty in, the results of a multiverse analysis. We present Milliways, a novel interactive visualisation system to support principled evaluation of multiverse analyses. Milliways provides interlinked panels presenting result distributions, individual analysis composition, multiverse code specification, and data summaries. Milliways supports interactions to sort, filter and aggregate results based on the analysis specification to identify decisions in the analysis process to which the results are sensitive. To represent the two qualitatively different types of uncertainty that arise in multiverse analyses—probabilistic uncertainty from estimating unknown quantities of interest such as regression coefficients, and possibilistic uncertainty from choices in the data analysis—Milliways uses consonance curves and probability boxes. Through an evaluative study with five users familiar with multiverse analysis, we demonstrate how Milliways can support multiverse analysis tasks, including a principled assessment of the results of a multiverse analysis.</p>
<h3>Development and Validation of the Collision Anxiety Questionnaire for VR Applications</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Julius Tietenberg, Patrizia Ring, Katharina Emmerich, Maic Masuch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147339">Link</a></p>
<p>Abstract: The high degree of sensory immersion is a distinctive feature of head-mounted virtual reality (VR) systems. While the visual detachment from the real world enables unique immersive experiences, users risk collisions due to their inability to perceive physical obstacles in their environment. Even the mere anticipation of a collision can adversely affect the overall experience and erode user confidence in the VR system. However, there are currently no valid tools for assessing collision anxiety. We present the iterative development and validation of the Collision Anxiety Questionnaire (CAQ), involving an exploratory and a confirmatory factor analysis with a total of 159 participants. The results provide evidence for both discriminant and convergent validity and a good model fit for the final CAQ with three subscales: general collision anxiety, orientation, and interpersonal collision anxiety. By utilizing the CAQ, researchers can examine potential confounding effects of collision anxiety and evaluate methods for its mitigation.</p>
<h3>Assessing User Apprehensions About Mixed Reality Artifacts and Applications: The Mixed Reality Concerns (MRC) Questionnaire</h3>
<p>Authors: Aodi Chen, Luu Viet Trinh Le, John Uschold, Christopher Katins, Paweł W. Woźniak, Ihsan Tumay, Thomas Kosch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146992">Link</a></p>
<p>Abstract: Current research in Mixed Reality (MR) presents a wide range of novel use cases for blending virtual elements with the real world. This yet-to-be-ubiquitous technology challenges how users currently work and interact with digital content. While offering many potential advantages, MR technologies introduce new security, safety, and privacy challenges. Thus, it is relevant to understand users' apprehensions towards MR technologies, ranging from security concerns to social acceptance. To address this challenge, we present the Mixed Reality Concerns (MRC) Questionnaire, designed to assess users' concerns towards MR artifacts and applications systematically. The development followed a structured process considering previous work, expert interviews, iterative refinements, and confirmatory tests to analytically validate the questionnaire. The MRC Questionnaire offers a new method of assessing users' critical opinions to compare and assess novel MR artifacts and applications regarding security, privacy, social implications, and trust.</p>
<h3>Virtual Unreality: Augmentation-Oriented Ideation Through Design Cards</h3>
<p>Authors: Marc Hassenzahl, Daniel Courtney, Robin Neuhaus, Madlen Kneile, Ronda Ringfort-Felner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148278">Link</a></p>
<p>Abstract: While realism is a common design goal for virtual reality (VR), VR also offers opportunities that are impossible in the real world (e.g., telekinesis). So far, there is no design support to exploit the potential of such “impossible” augmentations, especially for serious applications. We developed a card set and a workshop format, which features 15 opportunities to facilitate the ideation of augmentation-oriented VR. We piloted the method in five workshops with people in the early stages of developing a VR application (N=35). Participants found the cards easy to use and to inspire viable new concepts that differed from earlier ideas. Analysis of the concepts with interaction criticism identified two strategies: (1) augmentations that are only loosely related to the purpose of the application, simply to increase “fun”, and (2) augmentations that are closely related to the core purpose and thereby subtly facilitate its fulfillment. The latter has the greater potential.</p>
<h3>Evaluating Navigation and Comparison Performance of Computational Notebooks on Desktop and in Virtual Reality</h3>
<p>Authors: Yalong Yang, Chris North, Sungwon In, Eric Krokos, Kirsten Whitley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146704">Link</a></p>
<p>Abstract: The computational notebook serves as a versatile tool for data analysis. However, its conventional user interface falls short of keeping pace with the ever-growing data-related tasks, signaling the need for novel approaches. With the rapid development of interaction techniques and computing environments, there is a growing interest in integrating emerging technologies in data-driven workflows. Virtual reality, in particular, has demonstrated its potential in interactive data visualizations. In this work, we aimed to experiment with adapting computational notebooks into VR and verify the potential benefits VR can bring. We focus on the navigation and comparison aspects as they are primitive components in analysts' workflow. To further improve comparison, we have designed and implemented a Branching&amp;Merging functionality. We tested computational notebooks on the desktop and in VR, both with and without the added Branching&amp;Merging capability. We found VR significantly facilitated navigation compared to desktop, and the ability to create branches enhanced comparison.</p>
<h2>Understanding Immersive Experiences</h2>
<h3>Fast-Forward Reality: Authoring Error-Free Context-Aware Policies with Real-Time Unit Tests in Extended Reality</h3>
<p>Authors: Kashyap Todi, Tanya Jonker, Tianyi Wang, Xun Qian, Xuhai "Orson" Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147548">Link</a></p>
<p>Abstract: Advances in ubiquitous computing have enabled end-user authoring of context-aware policies (CAPs) that control smart devices based on specific contexts of the user and environment. However, authoring CAPs accurately and avoiding run-time errors is challenging for end-users as it is difficult to foresee CAP behaviors under complex real-world conditions. We propose Fast-Forward Reality, an Extended Reality (XR) based authoring workflow that enables end-users to iteratively author and refine CAPs by validating their behaviors via simulated unit test cases. We develop a computational approach to automatically generate test cases based on the authored CAP and the user's context history. Our system delivers each test case with immersive visualizations in XR, facilitating users to verify the CAP behavior and identify necessary refinements. We evaluated Fast-Forward Reality in a user study (N=12). Our authoring and validation process improved the accuracy of CAPs and the users provided positive feedback on the system usability.</p>
<h3>Towards Building Condition-Based Cross-Modality Intention-Aware Human-AI Cooperation under VR Environment</h3>
<p>Authors: Ziyao He, Yunpeng Song, Shiyuan Li, Zhongmin Cai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147782">Link</a></p>
<p>Abstract: To address critical challenges in effectively identifying user intent and forming relevant information presentations and recommendations in VR environments, we propose an innovative condition-based multi-modal human-AI cooperation framework. It highlights the intent tuples (intent, condition, intent prompt, action prompt) and 2-Large-Language-Models (2-LLMs) architecture. This design, utilizes ``condition'' as the core to describe tasks, dynamically match user interactions with intentions, and empower generations of various tailored multi-modal AI responses. The architecture of 2-LLMs separates the roles of intent detection and action generation, decreasing the prompt length and helping with generating appropriate responses. We implemented a VR-based intelligent furniture purchasing system based on the proposed framework and conducted a three-phase comparative user study. The results conclusively demonstrate the system's superiority in time efficiency and accuracy, intention conveyance improvements, effective product acquisitions, and user satisfaction and cooperation preference. Our framework provides a promising approach towards personalized and efficient user experiences in VR.</p>
<h3>Predicting the Noticeability of Dynamic Virtual Elements in Virtual Reality</h3>
<p>Authors: Yukang Yan, Yi Fei Cheng, Zhipeng Li, David Lindlbauer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148043">Link</a></p>
<p>Abstract: While Virtual Reality (VR) systems can present virtual elements such as notifications anywhere, designing them so they are not missed by or distracting to users is highly challenging for content creators. To address this challenge, we introduce a novel approach to predict the noticeability of virtual elements. It computes the visual saliency distribution of what users see, and analyzes the temporal changes of the distribution with respect to the dynamic virtual elements that are animated. The computed features serve as input for a long short-term memory (LSTM) model that predicts whether a virtual element will be noticed. Our approach is based on data collected from 24 users in different VR environments performing tasks such as watching a video or typing. We evaluate our approach (n = 12), and show that it can predict the timing of when users notice a change to a virtual element within 2.56 sec compared to a ground truth, and demonstrate the versatility of our approach with a set of applications. We believe that our predictive approach opens the path for computational design tools that assist VR content creators in creating interfaces that automatically adapt virtual elements based on noticeability.</p>
<h3>Just Undo It: Exploring Undo Mechanics in Multi-User Virtual Reality</h3>
<p>Authors: Julian Rasch, Yannick Weiss, Florian Perzl, Florian Müller</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147280">Link</a></p>
<p>Abstract: With the proliferation of VR and a metaverse on the horizon, many multi-user activities are migrating to the VR world, calling for effective collaboration support. As one key feature, traditional collaborative systems provide users with undo mechanics to reverse errors and other unwanted changes. While undo has been extensively researched in this domain and is now considered industry standard, it is strikingly absent for VR systems in research and industry.</p>
<p>This work addresses this research gap by exploring different undo techniques for basic object manipulation in different collaboration modes in VR. We conducted a study involving 32 participants organized in teams of two. Here, we studied users' performance and preferences in a tower stacking task, varying the available undo techniques and their mode of collaboration. The results suggest that users desire and use undo in VR and that the choice of the undo technique impacts users' performance and social connection.</p>
<h2>Immersive Experiences: UIs and Personalisation</h2>
<h3>UI Mobility Control in XR: Switching UI Positionings between Static, Dynamic, and Self Entities</h3>
<p>Authors: Yang Zhang, Ruofei Du, Alex Olwal, Siyou Pei, David Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147970">Link</a></p>
<p>Abstract: Extended reality (XR) has the potential for seamless user interface (UI) transitions across people, objects, and environments. However, the design space, applications, and common practices of 3D UI transitions remain underexplored. To address this gap, we conducted a need-finding study with 11 participants, identifying and distilling a taxonomy based on three types of UI placements --- affixed to static, dynamic, or self entities. We further surveyed 113 commercial applications to understand the common practices of 3D UI mobility control, where only 6.2% of these applications allowed users to transition UI between entities. In response, we built interaction prototypes to facilitate UI transitions between entities. We report on results from a qualitative user study (N=14) on 3D UI mobility control using our FingerSwitches technique, which suggests that perceived usefulness is affected by types of entities and environments. We aspire to tackle a vital need in UI mobility within XR.</p>
<h3>ProInterAR: A Visual Programming Platform for Creating Immersive AR Interactions</h3>
<p>Authors: Karan Singh, Hongbo Fu, Hui Ye, Jiaye Leng, Pengfei Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148242">Link</a></p>
<p>Abstract: AR applications commonly contain diverse interactions among different AR contents. Creating such applications requires creators to have advanced programming skills for scripting interactive behaviors of AR contents, repeated transferring and adjustment of virtual contents from virtual to physical scenes, testing by traversing between desktop interfaces and target AR scenes, and digitalizing AR contents. Existing immersive tools for prototyping/authoring such interactions are tailored for domain-specific applications. To support programming general interactive behaviors of real object(s)/environment(s) and virtual object(s)/environment(s) for novice AR creators, we propose ProInterAR, an integrated visual programming platform to create immersive AR applications with a tablet and an AR-HMD. Users can construct interaction scenes by creating virtual contents and augmenting real contents from the view of an AR-HMD, script interactive behaviors by stacking blocks from a tablet UI, and then execute and control the interactions in the AR scene. We showcase a wide range of AR application scenarios enabled by ProInterAR, including AR game, AR teaching, sequential animation, AR information visualization, etc. Two usability studies validate that novice AR creators can easily program various desired AR applications using ProInterAR.</p>
<h3>MineXR: Mining Personalized Extended Reality Interfaces</h3>
<p>Authors: Kashyap Todi, Yukang Yan, Missie Smith, Hyunsung Cho, Mark Parent, Tanya Jonker, David Lindlbauer, Hrvoje Benko</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147924">Link</a></p>
<p>Abstract: Extended Reality (XR) interfaces offer engaging user experiences, but their effective design requires a nuanced understanding of user behavior and preferences. This knowledge is challenging to obtain without the widespread adoption of XR devices. We introduce MineXR, a design mining workflow and data analysis platform for collecting and analyzing personalized XR user interaction and experience data. MineXR enables elicitation of personalized interfaces from participants of a data collection: for any particular context, participants create interface elements using application screenshots from their own smartphone, place them in the environment, and simultaneously preview the resulting XR layout on a headset. Using MineXR, we contribute a dataset of personalized XR interfaces collected from 31 participants, consisting of 695 XR widgets created from 178 unique applications. We provide insights for XR widget functionalities, categories, clusters, UI element types, and placement. Our open-source tools and data support researchers and designers in developing future XR interfaces.</p>
<h3>VirtuWander: Enhancing Multi-modal Interaction for Virtual Tour Guidance through Large Language Models</h3>
<p>Authors: Linping Yuan, Wei Zeng, Liangwei Wang, Bingchuan Jiang, Zhan Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148243">Link</a></p>
<p>Abstract: Tour guidance in virtual museums encourages multi-modal interactions to boost user experiences, concerning engagement, immersion, and spatial awareness. Nevertheless, achieving the goal is challenging due to the complexity of comprehending diverse user needs and accommodating personalized user preferences. Informed by a formative study that characterizes guidance-seeking contexts, we establish a multi-modal interaction design framework for virtual tour guidance. We then design VirtuWander, a two-stage innovative system using domain-oriented large language models to transform user inquiries into diverse guidance-seeking contexts and facilitate multi-modal interactions. The feasibility and versatility of VirtuWander are demonstrated with virtual guiding examples that encompass various touring scenarios and cater to personalized preferences. We further evaluate VirtuWander through a user study within an immersive simulated museum. The results suggest that our system enhances engaging virtual tour experiences through personalized communication and knowledgeable assistance, indicating its potential for expanding into real-world scenarios.</p>
<h2>Immersive Experiences: Creating and Communicating</h2>
<h3>Elastica: Adaptive Live Augmented Presentations with Elastic Mappings Across Modalities</h3>
<p>Authors: Li-Yi Wei, Deepali Aneja, Haijun Xia, Rubaiat Habib Kazi, Yining Cao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147635">Link</a></p>
<p>Abstract: Augmented presentations offer compelling storytelling by combining speech content, gestural performance, and animated graphics in a congruent manner. The expressiveness of these presentations stems from the harmonious coordination of spoken words and graphic elements, complemented by smooth animations aligned with the presenter's gestures. However, achieving such desired congruence in a live presentation poses significant challenges due to the unpredictability and imprecision inherent in presenters' real-time actions. Existing methods either leveraged rigid mapping without predefined states or required the presenters to conform to predefined animations. We introduce adaptive presentations that dynamically adjust predefined graphic animations to real-time speech and gestures. Our approach leverages script following and motion warping to establish elastic mappings that generate runtime graphic parameters coordinating speech, gesture, and predefined animation state. Our evaluation demonstrated that the proposed adaptive presentation can effectively mitigate undesired visual artifacts caused by performance deviations and enhance the expressiveness of resulting presentations.</p>
<h3>Unlocking Understanding: An Investigation of Multimodal Communication in Virtual Reality Collaboration</h3>
<p>Authors: Ryan P. McMahan, Eugene Taranta, Yahya Hmaiti, Mykola Maslych, Ravi Kiran Kattoju, Joseph LaViola, Ryan Ghamandi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146938">Link</a></p>
<p>Abstract: Communication in collaboration, especially synchronous, remote communication, is crucial to the success of task-specific goals. Insufficient or excessive forms of communication may lead to detrimental effects on task performance while increasing mental fatigue. However, identifying which combinations of communication modalities provide the most efficient transfer of information in collaborative settings will greatly improve collaboration. To investigate this, we developed a remote, synchronous, asymmetric VR collaborative assembly task application, where users play the role of either mentor or mentee, and were exposed to different combinations of three communication modalities: voice, gestures, and gaze. Through task-based experiments with 25 pairs of participants (50 individuals), we evaluated quantitative and qualitative data and found that gaze did not differ significantly from multiple combinations of communication modalities. Our qualitative results indicate that mentees experienced more difficulty and frustration in completing tasks than mentors, with both types of users preferring all three modalities to be present.</p>
<h3>Meaning Follows Purpose: Unravelling the Architectural Design Conventions in the Contemporary Metaverse</h3>
<p>Authors: Andrew Vande Moere, Adalberto Simeone, Jihae Han</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147826">Link</a></p>
<p>Abstract: Thousands of people regularly meet, work and play in the architectural spaces that the metaverse offers today. Yet despite the creative potential to disrupt how the built environment is represented, there exists a prevalent belief that the architectural design of the metaverse is rather conventional and reliant on simulating physical reality. We investigated this claim by conducting a design critique study of the most apparent architectural design conventions within the current most popular metaverse platforms, as determined by a scoping review and Google Trends analysis. Based on the opinions of 21 architectural experts on the design of interiors, buildings, and plazas within these platforms, we elicited three overarching design conventions that capture the representation, engagement, and purpose of metaverse architecture. By discussing the impact of these conventions on architectural quality, we inform the future design of metaverse spaces to more purposefully, and perhaps less frequently, use realism to convey meaning. </p>
<h3>LLMR: Real-time Prompting of Interactive Worlds using Large Language Models</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Fernanda De La Torre, Cathy Mengying Fang, Han Huang, Jaron Lanier, Judith Amores, Andrzej Banburski-Fahey</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146847">Link</a></p>
<p>Abstract: We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR's cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.</p>
<h3>Using the Visual Language of Comics to Alter Sensations in Augmented Reality</h3>
<p>Authors: Kasper Hornbæk, Henning Pohl, Arpit Bhatia, Hasti Seifi, Teresa Hirzle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147047">Link</a></p>
<p>Abstract: Augmented Reality (AR) excels at altering what we see but non-visual sensations are difficult to augment. To augment non-visual sensations in AR, we draw on the visual language of comic books. Synthesizing comic studies, we create a design space describing how to use comic elements (e.g., onomatopoeia) to depict non-visual sensations (e.g., hearing). To demonstrate this design space, we built eight demos, such as speed lines to make a user think they are faster and smell lines to make a scent seem stronger. We evaluate these elements in a qualitative user study (N=20) where participants performed everyday tasks with comic elements added as augmentations. All participants stated feeling a change in perception for at least one sensation, with perceived changes detected by between four participants (touch) and 15 participants (hearing). The elements also had positive effects on emotion and user experience, even when participants did not feel changes in perception.</p>
<h2>Highlight on Health</h2>
<h3>Shared Responsibility in Collaborative Tracking for Children with Type 1 Diabetes and their Parents</h3>
<p>Authors: Yoon Jeong Cha, Sun Young Park, Mark Newman, Alice Wou, Yasemin Gunal, Joyce Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147031">Link</a></p>
<h3>Learning About Social Context From Smartphone Data: Generalization Across Countries and Daily Life Moments</h3>
<p>Authors: Aurel Ruben Mäder, Lakmal Meegahapola, Daniel Gatica-Perez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148104">Link</a></p>
<h3>Somaesthetic Meditation Wearable: Exploring the Effect of Targeted Warmth Technology on Meditators' Experiences</h3>
<p>Authors: Oren Zuckerman, Talia Ezer, Jonathan Giron, Hadas Erel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148124">Link</a></p>
<h3>Using and Appropriating Technology to Support The Menopause Journey in the UK</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Aisling Ann O'Kane, Marianela Ciolfi Felice, Emily Lopez Burst</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147124">Link</a></p>
<h3>"It's Sink or Swim": Exploring Patients' Challenges and Tool Needs for Self-Management of Postoperative Acute Pain</h3>
<p>Authors: Sylvain Bédard, M. Gabrielle Pagé, Jinghui Cheng, Mélanie Lussier, Souleima Zghab</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146987">Link</a></p>
<h3>Individual Differences and Technology Affordances Combine to Predict Mobile Social Media Distraction Behaviors and Consequences</h3>
<p>Authors: Peter Monge, Emily Sidnam-Mauch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147042">Link</a></p>
<h3>"Speech is Silver, Silence is Golden " Analyzing Micro-communication Strategies between Visually Impaired Runners and their Guides</h3>
<p>Authors: Giulia Barbareschi, Kai Kunze, Christopher Kim, George Chernyshov, Tarika Kumar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147500">Link</a></p>
<h3>"If This Person is Suicidal, What Do I Do?": Designing Computational Approaches to Help Online Volunteers Respond to Suicidality</h3>
<p>Authors: Haiyi Zhu, Cindy Liu, Sunniva Liu, Logan Stapleton, Stevie Chancellor, Robert Kraut, Irene Hong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147747">Link</a></p>
<h3>Mindfulness-based Embodied Tangible Interactions for Stroke Rehabilitation at Home</h3>
<p>BEST_PAPER</p>
<p>Authors: Catherine Holloway, Wen Mo, Preetham Nagaraj</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146728">Link</a></p>
<h3>Quantifying the Pollan Effect: Investigating the Impact of Emerging Psychiatric Interventions on Online Mental Health Discourse</h3>
<p>Authors: Munmun De Choudhury, Sachin Pendse, Neha Kumar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146755">Link</a></p>
<h3>Holding AI to Account: Challenges for the Delivery of Trustworthy AI in Healthcare</h3>
<p>Authors: Mark Rouncefield, Peter Tolmie, Rob Procter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150872">Link</a></p>
<h3>“If Someone Walks In On Us Talking, Pretend to be My Friend, Not My Therapist": Challenges and Opportunities for Digital Mental Health Support in Saudi Arabia</h3>
<p>Authors: Nigel Shadbolt, Max Van Kleek, Deemah Alateeq, Sarah Aldaweesh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147711">Link</a></p>
<h2>Highlight on Interaction and Cultures</h2>
<h3>Commoning as a Strategy for HCI Research and Design in South Asia</h3>
<p>Authors: Robert Soden, Aarjav Chauhan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147596">Link</a></p>
<h3>Better Little People Pictures: Generative Creation of Demographically Diverse Anthropographics</h3>
<p>Authors: Lauren Perera, Wesley Willett, Priya Dhawka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147622">Link</a></p>
<h3>Design With Rural-To-Urban Migrant Women: Opportunities and Challenges in Designing within a Precarious Marriage Context in South China</h3>
<p>Authors: Yuchao Zhao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147663">Link</a></p>
<h3>Justice-oriented Design Listening: Participatory Ecoacoustics with a Ghanaian Forest Community</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Alan Blackwell, Emmanuel Acheampong, Joycelyn Longdon, Jennifer Gabrys, Benjamin Ossom, Michelle Westerlaken, Adham Ashton-Butt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147917">Link</a></p>
<h3>Politics of the Past: Understanding the Role of Memory, Postmemory, and Remembrance in Navigating the History of Migrant Families</h3>
<p>Authors: Cosmin Munteanu, Carolina Reyes Marquez, Marisol Wong-Villacres, Mohammad Rashidujjaman Rifat, Syed Ishtiaque Ahmed, Nabila Chowdhury, Azhagu Meena SP, Natasha Shokri, Negin Dahya, Cibeles Valera</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146983">Link</a></p>
<h3>Migrant Farmworkers' Experiences of Agricultural Technologies: Implications for Worker Sociality and Desired Change</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Olivia Doggett, Priyank Chandra, Matt Ratto</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147193">Link</a></p>
<h3>Play Across Boundaries: Exploring Cross-Cultural Maldaimonic Game Experiences</h3>
<p>Authors: Shruti Chandra, Sota Kobuki, Katie Seaborn, Satoru Iseya, Shun Hidaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147448">Link</a></p>
<h3>Air/time Travel: Rethinking Appropriation in Global HCI and Futures of Electronic Exchange</h3>
<p>Authors: Christopher Csikszentmihalyi, Daniel Mwesigwa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148174">Link</a></p>
<h3>Low-Resourced Languages and Online Knowledge Repositories: A Need-Finding Study.</h3>
<p>Authors: Hellina Hailu Nigatu, Sarah Chasins, John Canny</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147539">Link</a></p>
<h2>Highlight on Fabrication</h2>
<h3>Towards More Sustainable Interactive Textiles: A Literature Review on The Use of Biomaterials for eTextiles.</h3>
<p>Authors: Sofía Guridi, Emmi Pouta, Matteo Iannacchero</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147272">Link</a></p>
<h3>ExCell: High Expansion Ratio Moisture-Responsive Wooden Actuators for DIY Shape-Changing and Deployable Structures</h3>
<p>Authors: Shuhong Wang, Lining Yao, Tucker Rae-Grant</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147588">Link</a></p>
<h3>Flextiles: Designing Customisable Shape-Change in Textiles with SMA-Actuated Smocking Patterns</h3>
<p>Authors: Alice Haynes, Jürgen Steimle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147340">Link</a></p>
<h3>Evaluating ActuAir: Building Occupants' Experiences of a Shape-Changing Air Quality Display</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: David Kirk, Abigail Durrant, Eleni Margariti, Vasilis Vlachokyriakos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146904">Link</a></p>
<h2>Highlight on Immersive Interactions</h2>
<h3>ARCADIA: A Gamified Mixed Reality System for Emotional Regulation and Self-Compassion</h3>
<p>Authors: José Luis Soler-Domínguez, Samuel Navas-Medrano, Patricia Pons</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147990">Link</a></p>
<p>Abstract: Mental health and wellbeing have become one of the significant challenges in global society, for which emotional regulation strategies hold the potential to offer a transversal approach to addressing them. However, the persistently declining adherence of patients to therapeutic interventions, coupled with the limited applicability of current technological interventions across diverse individuals and diagnoses, underscores the need for innovative solutions. We present ARCADIA, a Mixed-Reality platform strategically co-designed with therapists to enhance emotional regulation and self-compassion. ARCADIA comprises several gamified therapeutic activities, with a strong emphasis on fostering patient motivation. Through a dual study involving therapists and mental health patients, we validate the fully functional prototype of ARCADIA. Encouraging results are observed in terms of system usability, user engagement, and therapeutic potential. These findings lead us to believe that the combination of Mixed Reality and gamified therapeutic activities could be a significant tool in the future of mental health.</p>
<h3>Implementation of Virtual Reality Motivated Physical Activity via Omnidirectional Treadmill in a Supported Living Facility for Older Adults: A Mixed-Methods Evaluation.</h3>
<p>Authors: Leonie Cooper, Hannah Bradwell, Rory Baxter, Ray Jones, Katie Jane Edwards, Anna Whittaker, Simone Tomaz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148214">Link</a></p>
<p>Abstract: Virtual reality (VR) can support healthy ageing, but few devices have been trialed with frail older adults to increase physical activity. We conducted a preliminary mixed-methods implementation evaluation of an omnidirectional VR treadmill and a static VR experience with seven older adults over a six-week period in a supported living facility. Frequency of use and pre-post physical functioning measures were collected, mainly to establish technology suitability based on person characteristics. Diary entries following technology use, resident focus group and staff interview revealed technology acceptance and perceived potential for increasing physical activity, health and wellbeing through accessing virtual environments, which motivated continued activity. Results demonstrated technology suitability for a range of older adults with various mobility and physical impairments. However, residents noted interest in a seated treadmill for physical activity without perceived risks of falls with standing treadmills. Staff raised considerations around care home implementations including usability, cost and space.</p>
<h3>MobileGravity: Mobile Simulation of a High Range of Weight in Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Niels Henze, Tien-Julian Ho, Alexander Kalus, Johannes Klein, Lee-Ann Seegets</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147373">Link</a></p>
<p>Abstract: Simulating accurate weight forces in Virtual Reality (VR) is an unsolved challenge. Therefore, providing real weight sensations by transferring liquid mass has emerged as a promising approach. However, key objectives conceptually interfere with each other. In particular, previous designs that support a high range of weight or high flow rate lack mobility. In this work, we present MobileGravity, a system, that decouples the weight-changing object from the liquid supply and the pump. It enables weight changes of up to 1 kg at a rate of 235 g/s and allows the user to walk around freely. Through a study with 30 participants, we show that the system enables users to perceive the weight of different virtual objects and enhances realism, as well as enjoyment.</p>
<h3>Behind the Scenes: Adapting Cinematography and Editing Concepts to Navigation in Virtual Reality</h3>
<p>Authors: Dorota Glowacka, Alan Medlar, Mari Lehtikari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147397">Link</a></p>
<p>Abstract: Teleportation is a popular method of navigation in virtual reality (VR) because it does not induce symptoms of VR sickness, such as nausea and disorientation. However, teleportation may reduce spatial awareness, causing users to miss important aspects of their surroundings. We present ACTIVE, a novel approach to teleportation that uses techniques from cinematography to enhance the user experience of navigation in VR. ACTIVE adapts heuristics from continuity editing to dynamically reposition and reorient the camera after teleportation. This approach aims to improve the aesthetic quality of entities and environmental features while respecting users' intended trajectory through the virtual environment. In a user study, we found that even though ACTIVE did not improve users' recall of which entities were present in the environment, it increased engagement by significantly improving aesthetic appeal. Lastly, despite removing some agency from users, ACTIVE had no impact on presence or VR sickness compared to teleportation.</p>
<h3>The Impact of Avatar Completeness on Embodiment and the Detectability of Hand Redirection in Virtual Reality</h3>
<p>Authors: Anthony Tang, André Zenner, Antonio Krüger, Martin Feick, Simon Seibert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147279">Link</a></p>
<p>Abstract: To enhance interactions in VR, many techniques introduce offsets between the virtual and real-world position of users’ hands. Nevertheless, such hand redirection (HR) techniques are only effective as long as they go unnoticed by users—not disrupting the VR experience. While several studies consider how much unnoticeable redirection can be applied, these focus on mid-air floating hands that are disconnected from users’ bodies. Increasingly, VR avatars are embodied as being directly connected with the user’s body, which provide more visual cue anchoring, and may therefore reduce the unnoticeable redirection threshold. In this work, we studied more complete avatars and their effect on the sense of embodiment and the detectability of HR. We found that higher avatar completeness increases embodiment, and we provide evidence for the absence of practically relevant effects on the detectability of HR.</p>
<h3>A Survey On Measuring Presence in Mixed Reality</h3>
<p>Authors: Tanh Tran, Tobias Langlotz, Holger Regenbrecht</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148206">Link</a></p>
<p>Abstract: Presence is a defining element of virtual reality (VR), but it is also increasingly used when assessing mixed reality (MR) experiences. The increased interest in measuring presence in MR and recent works underpinning the specific nature of presence in MR raise the question of the current state and practice of assessing presence in MR. To address this question, we present an analysis of more than 320 studies that report on presence measurements in MR. Our analysis showed that questionnaires are the dominant measurement but also identify problematic trends that stem from the lack of a generally agreed-upon concept or measurement for presence in MR. More specifically, we show that using measurements that are not validated in MR or custom questionnaires limiting the comparability of results is commonplace and could contribute to a looming replication crisis in an increasingly relevant field.</p>
<h3>On the Benefits of Image-Schematic Metaphors when Designing Mixed Reality Systems</h3>
<p>Authors: Jingyi Li, Per Ola Kristensson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146697">Link</a></p>
<p>Abstract: A Mixed Reality (MR) system encompasses various aspects, such as visualization and spatial registration of user interface elements, user interactions and interaction feedback. Image-schematic metaphors (ISMs) are universal knowledge structures shared by a wide range of users. They hold a theoretical promise of facilitating greater ease of learning and use for interactive systems without costly adaptations. This paper investigates whether image-schematic metaphors (ISMs) can improve user learning, by comparing an existing MR instruction authoring system with or without ISM enhancements. In a user study with 32 participants, we found that the ISM-enhanced system significantly improved task performance, learnability and mental efficiency compared to the baseline. Participants also rated the ISM-enhanced system significantly higher in terms of perspicuity, efficiency, and novelty. These results empirically demonstrate multiple benefits of ISMs when integrated into the design of this MR system and encourage further studies to explore the wider applicability of ISMs in user interface design.</p>
<h2>Highlight on AI</h2>
<h3>Mind The Gap: Designers and Standards on Algorithmic System Transparency for Users</h3>
<p>Authors: bianca schor, Chris Norval, Jat Singh, Ellen Charlesworth</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147422">Link</a></p>
<p>Abstract: Many call for algorithmic systems to be more transparent, yet it is often unclear for designers how to do so in practice. Standards are emerging that aim to support designers in building transparent systems, e.g by setting testable transparency levels, but their efficacy in this regard is not yet understood. In this paper, we use the <code>Standard for Transparency of Autonomous Systems' (IEEE 7001) to explore designers' understanding of algorithmic system transparency, and the degree to which their perspectives align with the standard's recommendations. Our mixed-method study reveals participants consider transparency important, difficult to implement, and welcome support. However, despite IEEE 7001's potential, many did not find its recommendations particularly appropriate. Given the importance and increased attention on transparency, and because standards like this purport to guide system design, our findings reveal the need for</code>bridging the gap,' through (i) raising designers’ awareness about the importance of algorithmic system transparency, alongside (ii) better engagement between stakeholders (i.e. standards bodies, designers, users). We further identify opportunities towards developing transparency best practices, as means to help drive more responsible systems going forward.</p>
<h3>I lose vs. I earn: Consumer perceived price fairness toward algorithmic (vs. human) price discrimination</h3>
<p>Authors: Xiaoping Zhang, Xusen Cheng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147741">Link</a></p>
<p>Abstract: Many companies are turning to algorithms to determine prices. However, little research has been done to investigate consumers’ perceived price fairness when price discrimination is implemented by either a human or an algorithm. The results of two experiments with 2 (price-setting agent: algorithm vs. human) × 2 (price discrimination: advantaged vs. disadvantaged) between-subjects design reveal that consumers perceive disadvantaged price discrimination as being more unfair when it is implemented by a human (vs. algorithm). Conversely, they perceive advantaged price discrimination as being more unfair when it is implemented by an algorithm (vs. human). This difference is caused by distinct attribution processes. Consumers are more likely to externalize disadvantaged price discrimination implemented by a human than an algorithm (i.e., attributing it to the unintentionality of price-setting agents), while they are more likely to internalize advantaged price discrimination implemented by a human than an algorithm (i.e., attributing it to perceived personal luck). Based on these findings, we discuss how designers and managers can design and utilize algorithms to implement price discrimination that reduces consumer perception of price unfairness. We believe that reasonable disclosure of algorithmic clues to consumers can maximize the benefits of price discrimination strategies.</p>
<h3>Towards a Non-Ideal Methodological Framework for Responsible ML</h3>
<p>Authors: Ramaravind Kommiya Mothilal, Syed Ishtiaque Ahmed, Shion Guha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148062">Link</a></p>
<p>Abstract: Though ML practitioners increasingly employ various Responsible ML (RML) strategies, their methodological approach in practice is still unclear. In particular, the constraints, assumptions, and choices of practitioners with technical duties--such as developers, engineers, and data scientists---are often implicit, subtle, and under-scrutinized in HCI and related fields. We interviewed 22 technically oriented ML practitioners across seven domains to understand the characteristics of their methodological approaches to RML through the lens of ideal and non-ideal theorizing of fairness. We find that practitioners’ methodological approaches fall along a spectrum of idealization. While they structured their approaches through ideal theorizing, such as by abstracting RML workflow from the inquiry of applicability of ML, they did not systematically document nor pay deliberate attention to their non-ideal approaches, such as diagnosing imperfect conditions. We end our paper with a discussion of a new methodological approach, inspired by elements of non-ideal theory, to structure technical practitioners’ RML process and facilitate collaboration with other stakeholders.</p>
<h3>(Beyond) Reasonable Doubt: Challenges that Public Defenders Face in Scrutinizing AI in Court</h3>
<p>Authors: Niloufar Salehi, Angela Jin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146685">Link</a></p>
<p>Abstract: Accountable use of AI systems in high-stakes settings relies on making systems contestable. In this paper we study efforts to contest AI systems in practice by studying how public defenders scrutinize AI in court. We present findings from interviews with 17 people in the U.S. public defense community to understand their perceptions of and experiences scrutinizing computational forensic software (CFS) --- automated decision systems that the government uses to convict and incarcerate, such as facial recognition, gunshot detection, and probabilistic genotyping tools. We find that our participants faced challenges assessing and contesting CFS reliability due to difficulties (a) navigating how CFS is developed and used, (b) overcoming judges and jurors’ non-critical perceptions of CFS, and (c) gathering CFS expertise. To conclude, we provide recommendations that center the technical, social, and institutional context to better position interventions such as performance evaluations to support contestability in practice. </p>
<h3>“The bus is nothing without us”: Making Visible the Labor of Bus Operators amid the Ongoing Push Towards Transit Automation</h3>
<p>Authors: Sarah Fox, Alice Xiaodi Tang, Chinar Mehta, Bonnie Fan, Nikolas Martelaro, Hunter Akridge</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147433">Link</a></p>
<p>Abstract:  This paper describes how the complexity of circumstances bus operators manage presents unique challenges to the feasibility of high-level automation in public transit. Avoiding an overly rationalized view of bus operators' labor is critical to ensure the introduction of automation technologies does not compromise public wellbeing, the dignity of transit workers, or the integrity of critical public infrastructure. Our findings from a group interview study show that bus operators take on work — undervalued by those advancing automation technologies — to ensure the well-being of passengers and community members. Notably, bus operators are positioned to function as shock absorbers during social crises in their communities and in moments of technological breakdown as new systems come on board. These roles present a critical argument against the rapid push toward driverless automation in public transit. We conclude by identifying opportunities for participatory design and collaborative human-machine teaming for a more just future of transit.</p>
<h3>Care-Based Eco-Feedback Augmented with Generative AI: Fostering Pro-Environmental Behavior through Emotional Attachment</h3>
<p>Authors: Adrian Holzer, Bruno Kocher, Manon Berney, Vladimir Macko, Abdessalam Ouaazki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147985">Link</a></p>
<p>Abstract: Lights out! With the escalating climate crisis, eco-feedback has gained prominence over the last decade. However, traditional approaches could be underperforming as they often use data-driven strategies and assume that people only need additional information about their consumption to change behavior. A proposed path to overcome this issue is to design eco-feedback to foster emotional connections with users. However, not much is known about the effectiveness of such designs. In this paper, we propose a novel care-based eco-feedback system. Central to the system is a Tamagotchi-inspired digital character named INFI who gets its life force from the user's energy savings. Additionally, we harness the latest advancements in generative artificial intelligence to enhance emotional attachment through conversational interactions that users can have with INFI. The results of a randomized controlled experiment (N=420) convey the fact that this design increases emotional attachment, which in turn increases energy-saving behavior.</p>
<h3>DeepTreeSketch: Neural Graph Prediction for Faithful 3D Tree Modeling from Sketches</h3>
<p>Authors: Ruiyuan Zhang, Naoto Yokoya, Zhanglin Cheng, Zhihao Liu, Yu LI, Fangyuan Tu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147555">Link</a></p>
<p>Abstract: We present DeepTreeSketch, a novel AI-assisted sketching system that enables users to create realistic 3D tree models from 2D freehand sketches. Our system leverages a tree graph prediction network, TGP-Net, to learn the underlying structural patterns of trees from a large collection of 3D tree models. The TGP-Net simulates the iterative growth of botanical trees and progressively constructs the 3D tree structures in a bottom-up manner. Furthermore, our system supports a flexible sketching mode for both precise and coarse control of the tree shapes by drawing branch strokes and foliage strokes, respectively. Combined with a procedural generation strategy, users can freely control the foliage propagation with diverse and fine details. We demonstrate the expressiveness, efficiency, and usability of our system through various experiments and user studies. Our system offers a practical tool for 3D tree creation, especially for natural scenes in games, movies, and landscape applications.</p>
<h3>Amplifying Human Capabilities in Prostate Cancer Diagnosis: An Empirical Study of Current Practices and AI Potentials in Radiology</h3>
<p>Authors: Volkmar Pipek, Sheree May Saßmannshausen, Aparecido Fabiano Pinatti de Carvalho, Mark Rouncefield, Nazmun Ontika</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147429">Link</a></p>
<p>Abstract: This paper examines the potential of Human-Centered AI (HCAI) solutions to support radiologists in diagnosing prostate cancer. Prostate cancer is one of the most prevalent and increasing cancers among men. The scarcity of radiologists raises concerns about their ability to address the growing demand for prostate cancer diagnosis, leading to a significant surge in the workload of radiologists. Drawing on an HCAI approach, we sought to understand the current practices concerning radiologists' work on detecting and diagnosing prostate cancer, as well as the challenges they face. The findings from our empirical studies point toward the potential that AI has to expedite informed decision-making and enhance accuracy, efficiency, and consistency. This is particularly beneficial for collaborative prostate cancer diagnosis processes. We discuss these results and introduce design recommendations and HCAI concepts for the domain of prostate cancer diagnosis, with the aim of amplifying the professional capabilities of radiologists.</p>
<h3>Data Ethics Emergency Drill: A Toolbox for Discussing Responsible AI for Industry Teams</h3>
<p>Authors: Dylan Rees, Paul Marshall, David Hopkinson, Vanessa Aisyahsari Hanschke, Merve Alanyali</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147218">Link</a></p>
<p>Abstract: Researchers urge technology practitioners such as data scientists to consider the impacts and ethical implications of algorithmic decisions. However, unlike programming, statistics, and data management, discussion of ethical implications is rarely included in standard data science training. To begin to address this gap, we designed and tested a toolbox called the data ethics emergency drill (DEED) to help data science teams discuss and reflect on the ethical implications of their work. The DEED is a roleplay of a fictional ethical emergency scenario that is contextually situated in the team’s specific workplace and applications. This paper outlines the DEED toolbox and describes three studies carried out with two different data science teams that iteratively shaped its design. Our findings show that practitioners can apply lessons learnt from the roleplay to real-life situations, and how the DEED opened up conversations around ethics and values.</p>
<h3>JupyterLab in Retrograde: Contextual Notifications That Highlight Fairness and Bias Issues for Data Scientists</h3>
<p>BEST_PAPER</p>
<p>Authors: Aleksander Binion, Ahmad Bamba, Luca Dovichi, Kevin Bryson, Arthur Borem, Blase Ur, Galen Harrison</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147904">Link</a></p>
<p>Abstract: Current algorithmic fairness tools focus on auditing completed models, neglecting the potential downstream impacts of iterative decisions about cleaning data and training machine learning models. In response, we developed Retrograde, a JupyterLab environment extension for Python that generates real-time, contextual notifications for data scientists about decisions they are making regarding protected classes, proxy variables, missing data, and demographic differences in model performance. Our novel framework uses automated code analysis to trace data provenance in JupyterLab, enabling these notifications. In a between-subjects online experiment, 51 data scientists constructed loan-decision models with Retrograde providing notifications continuously throughout the process, only at the end, or never. Retrograde's notifications successfully nudged participants to account for missing data, avoid using protected classes as predictors, minimize demographic differences in model performance, and exhibit healthy skepticism about their models.</p>
<h3>Understanding Contestability on the Margins: Implications for the Design of Algorithmic Decision-making in Public Services</h3>
<p>Authors: Sohini Upadhyay, Naveena Karusala, Rajesh Veeraraghavan, Krzysztof Gajos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148034">Link</a></p>
<p>Abstract: Policymakers have established that the ability to contest decisions made by or with algorithms is core to responsible artificial intelligence (AI). However, there has been a disconnect between research on contestability of algorithms, and what the situated practice of contestation looks like in contexts across the world, especially amongst communities on the margins. We address this gap through a qualitative study of follow-up and contestation in accessing public services for land ownership in rural India and affordable housing in the urban United States. We find there are significant barriers to exercising rights and contesting decisions, which intermediaries like NGO workers or lawyers work with communities to address. We draw on the notion of accompaniment in global health to highlight the open-ended work required to support people in navigating violent social systems. We discuss the implications of our findings for key aspects of contestability, including building capacity for contestation, human review, and the role of explanations. We also discuss how sociotechnical systems of algorithmic decision-making can embody accompaniment by taking on a higher burden of preventing denials and enabling contestation.</p>
<h3>In-Between Visuals and Visible: The Impacts of Text-to-Image Generative AI Tools on Digital Image-making Practices in the Global South</h3>
<p>Authors: Syed Ishtiaque Ahmed, Arundhuti Dey, Sadaf Khan, Dipannita Nandi, Nusrat Jahan Mim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147687">Link</a></p>
<p>Abstract: This paper joins the growing body of HCI work on critical AI studies and focuses on the impact of Generative Artificial Intelligence (GAI) tools in Bangladesh. While the West has started to examine the limitations and risks associated with these tools, their impacts on the Global South have remained understudied. Based on our interviews, focus group discussions (FGD), and social media-based qualitative study, this paper reports how popular text-to-image GAI tools (ex., DALL-E, Midjourney,  Stable Diffusion, Firefly) are affecting various image-related local creative fields. We report how these tools limit the creative explorations of marginal artists, struggle to understand linguistic nuances, fail to generate local forms of art and architecture, and misrepresent the diversity among citizens in the image production process. Drawing from a rich body of work on critical image theory, postcolonial computing, and design politics, we explain how our findings are pertinent to HCI's broader interest in social justice, decolonization, and global development.</p>
<h2>Highlight on Learning and Education</h2>
<h3>Emergency Remote Education in Nigeria: Challenges and Design Opportunities</h3>
<p>Authors: Rebecca Nicholson, Opeyemi Dele-Ajayi, Kemi Fasae, Rebecca Strachan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147787">Link</a></p>
<h3>Establishing Heuristics for Improving the Usability of GUI Machine Learning Tools for Novice Users</h3>
<p>Authors: Haifa Al-Shammare, Malak Baslyman, Asma Yamani</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148181">Link</a></p>
<h3>Envisioning Support-Centered Technologies for Language Practice and Use: Needs and Design Opportunities for Immigrant English Language Learners (ELLs)</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Geoff Kaufman, Adinawa Adjagbodjou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146672">Link</a></p>
<h3>Understanding Takeovers and Telestration in Laparoscopic Surgery to Inform Telementoring System Design</h3>
<p>Authors: Jocelyne Troccaz, Sandrine Voros, Geoffroy Canlorbe, Ignacio Avellino, Solène Lambert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147383">Link</a></p>
<h3>WriteUpRight: Regulating Children’s Handwriting Body Posture by Unobstrusively Error Amplification via Slow Visual Stimuli on Tablets</h3>
<p>Authors: Chenyang Wang, Daniel Tozadore, Pierre Dillenbourg, Barbara Bruno</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146950">Link</a></p>
<h3>Interrupting for Microlearning: Understanding Perceptions and Interruptibility of Proactive Conversational Microlearning Services</h3>
<p>Authors: Uichin Lee, Chanhee Lee, Jiwook Lee, Minyeong Kim, Youngji Koh, Auk Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148333">Link</a></p>
<h3>The Realities of Evaluating Educational Technology in School Settings</h3>
<p>Authors: Susan Lechelt, Rebecca Nicholson, Ahmed Kharrufa, Abrar Almjally, Anthony Trory, Kate Howland, Megan Venn-Wycherley, Vidya Sarangapani</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150648">Link</a></p>
<h2>Highlight on Input and Control Techniques</h2>
<h3>Ultrasonic Mid-Air Haptics on the Face: Effects of Lateral Modulation Frequency and Amplitude on Users’ Responses</h3>
<p>Authors: Xu Sun, Bingjian Liu, Ruiheng Lan, Qingfeng Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148049">Link</a></p>
<h3>Model-based Evaluation of Recall-based Interaction Techniques</h3>
<p>Authors: Bruno Fruchard, Gilles Bailly, Julien Gori</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147569">Link</a></p>
<h3>Behavioral Differences between Tap and Swipe: Observations on Time, Error, Touch-point Distribution, and Trajectory for Tap-and-swipe Enabled Targets</h3>
<p>Authors: Hiroki Usuba, Junichi Sato, Shota Yamanaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147678">Link</a></p>
<h3>Impact of Fingernails Length on Mobile Tactile Interaction</h3>
<p>Authors: Céline Coutrix, Camélia Prost</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147406">Link</a></p>
<h3>Controlling the Rooms: How People Prefer Using Gestures to Control Their Smart Homes</h3>
<p>Authors: Susanne Boll, Heiko Mueller, Masoumehsadat Hosseini</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147598">Link</a></p>
<h3>Grip-Reach-Touch-Repeat: A Refined Model of Grasp to Encompass One-Handed Interaction with Arbitrary Form Factor Devices</h3>
<p>Authors: Marcos Serrano, Tao Xu, Liang He, Chaoyi Wu, Anne Roudaut, Kaixing Zhao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146671">Link</a></p>
<h3>Take a Seat, Make a Gesture: Charting User Preferences for On-Chair and From-Chair Gesture Input</h3>
<p>Authors: Alexandru-Tudor Andrei, Radu-Daniel Vatavu, Laura-Bianca Bilius</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147142">Link</a></p>
<h3>Simulating Interaction Movements via Model Predictive Control</h3>
<p>Authors: Florian Fischer, Arthur Fleig, Markus Klar, Jörg Müller, Miroslav Bachinski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150926">Link</a></p>
<h2>Highlight on Security and Privacy</h2>
<h3>Exploring Privacy Practices of Female mHealth Apps in a Post-Roe World</h3>
<p>Authors: Ruba Abu-Salma, Mark Warner, Dilisha Patel, Ina Kaleva, Lisa Malki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147278">Link</a></p>
<h3>Counting Carrds: Investigating Personal Disclosure and Boundary Management in Transformative Fandom</h3>
<p>Authors: Kelly Wang, Dan Bially Levy, Kien Nguyen, Abigail Marsh, Ada Lerner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147455">Link</a></p>
<h3>Stochastic Machine Witnesses at Work: Today's Critiques of Taylorism are Inadequate for Workplace Surveillance Epistemologies of the Future</h3>
<p>Authors: Sandy Gould</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147223">Link</a></p>
<h3>‘We Do Not Have the Capacity to Monitor All Media’: A Design Case Study on Cyber Situational Awareness in Computer Emergency Response Teams</h3>
<p>BEST_PAPER</p>
<p>Authors: Christian Reuter, Markus Bayer, Thea Riebe, Marc-André Kaufhold</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146975">Link</a></p>
<h3>Analyzing Security and Privacy Advice During the 2022 Russian Invasion of Ukraine on Twitter</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Stefan Dietze, Sascha Fahl, Noah Wöhler, Harshini Sri Ramulu, Christian Stransky, Dominik Wermke, Juliane Schmüser, Felix Bensmann, Dimitar Dimitrov, Sebastian Schellhammer, Yasemin Acar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147984">Link</a></p>
<h3>In Focus, Out of Privacy: The Wearer's Perspective on the Privacy Dilemma of Camera Glasses</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Adrian Dabrowski, Shreya Tomar, Divyanshu Bhardwaj, Katharina Krombholz, Alexander Ponticello</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147215">Link</a></p>
<h3>The Impact of Risk Appeal Approaches on Users’ Sharing Confidential Information</h3>
<p>Authors: Peter Story, Elham Al Qahtani, Mohamed Shehab</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148170">Link</a></p>
<h2>Highlight on Games and Play</h2>
<h3>Comic-making to Study Game-making: Using Comics in Qualitative Longitudinal Research on Game Development</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Annakaisa Kultima, Solip Park, Perttu Hämäläinen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147421">Link</a></p>
<h3>Understanding Neurodiverse Social Play Between Autistic and Non-Autistic Children</h3>
<p>Authors: Alison Oldfield, Oussama Metatla, Brooke Morris, Hayati Havlucu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147697">Link</a></p>
<h3>Ecological In/Congruence: Becoming Sensitised to Nature in Video Games through Humanistic First-Person Research</h3>
<p>Authors: Oğuz 'Oz' Buruk, Velvet Spors, Juho Hamari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147799">Link</a></p>
<h3>Community, Storytelling, and Play: Making and Breaking Rituals in Destiny 2</h3>
<p>Authors: Bjarke Larsen, Elin Carstensdottir</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147767">Link</a></p>
<h3>A Design Framework for Reflective Play</h3>
<p>Authors: Matthew Whitby, Seth Cooper, Elisa Mekler, Ioanna Iacovides, Kutub Gandhi, Josh Aaron Miller, Mehmet Kosa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146677">Link</a></p>
<h3>Playing on Hard Mode: Accessibility, Difficulty and Joy in Video Game Adoption for Gamers with Disabilities</h3>
<p>Authors: Jon Froehlich, James Fogarty, Jesse Martinez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146616">Link</a></p>
<h3>Outplay Your Weaker Self: A Mixed-Methods Study on Gamification to Overcome Procrastination in Academia</h3>
<p>Authors: Sofia Schöbel, Harald von Korflesch, Manuel Schmidt-Kraepelin, Ali Sunyaev, Mathias Ullrich, Jeanine Kirchner-Krath</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147416">Link</a></p>
<h2>Highlight on Diversity In HCI</h2>
<h3>A Playbook to be Proud of: Making the Case for LGBTQ+ Inclusive User Account Design</h3>
<p>Authors: Morgan Ames, Beatrice Fadrigon, Jane Lupica, Princess Gordon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148092">Link</a></p>
<h3>Unpacking Norms, Narratives, and Nourishment: A Feminist HCI Critique on Food Tracking Technologies</h3>
<p>Authors: Max Birk, Daisy O'Neill, Regan Mandryk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148303">Link</a></p>
<h3>Cruising Queer HCI on the DL: A Literature Review of LGBTQ+ People in HCI</h3>
<p>Authors: Ellen Simpson, Haiyi Zhu, Jed Brubaker, Sarah Fox, Jordan Taylor, Anh-Ton Tran</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147332">Link</a></p>
<h3>Silver-Tongued and Sundry: Exploring Intersectional Pronouns with ChatGPT</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Takao Fujii, Madeleine Steeds, Katie Seaborn</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148287">Link</a></p>
<h3>Deus Ex Machina and Personas from Large Language Models: Investigating the Composition of AI-Generated Persona Descriptions</h3>
<p>Authors: Jianxing Chi, Chang Liu, Joni Salminen, Essi Häyhänen, Wenjing Pian, Bernard Jansen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148256">Link</a></p>
<h3>Designing an Archive of Feelings: Queering Tangible Interaction with Button Portraits</h3>
<p>Authors: Noura Howell, Sylvia Janicki, Alexandra Teixeira Riggs, Anne Sullivan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147424">Link</a></p>
<h3>Designing Diverse Pathways for Participation</h3>
<p>Authors: Lisa Hofer, Ralf Vetter, Anna Blumenkranz, Jeanette Falk, Moritz Kubesch, Christopher Frauenberger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146734">Link</a></p>
<h3>SustAInable: How Values in the Form of Individual Motivation Shape Algorithms’ Outcomes. An Example Promoting Ecological and Social Sustainability</h3>
<p>Authors: Siegmar Otto, Sarah Zabel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147851">Link</a></p>
<h3>Conceptualising Fatness within HCI: A Call for Fat Liberation</h3>
<p>Authors: Aisha Sobey</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147550">Link</a></p>
<h3>Blueprints: Systematizing Behavior Change Designs - The Case of Social Comparison Theory</h3>
<p>Authors: Geke Ludden, Mailin Lemke, Roelof de Vries</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150871">Link</a></p>
<h2>Highlight on Communities and Online Platforms</h2>
<h3>Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool</h3>
<p>Authors: Zoya Katashinskaya, Liudmila Zavolokina, Daniel Gordon Jones, Kilian Sprenkamp, Gerhard Schwabe</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147239">Link</a></p>
<h3>"Caption it in an Accessible Way That is Also Enjoyable": Characterizing User-Driven Captioning Practices on TikTok</h3>
<p>Authors: Jon Froehlich, Tessa Eagle, Emma McDonnell, Leah Findlater, Kathryn Ringland, Soo Hyun Moon, Pitch Sinlapanuntakul</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147777">Link</a></p>
<h3>SolarClub: Supporting Renewable Energy Communities through an Interactive Coordination System</h3>
<p>Authors: Hannah Knox, Georgia Panagiotidou, Kyrill Potapov, Michael Fell, Farhan Samanani, Enrico Costanza, Sonia Nkatha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146855">Link</a></p>
<h3>Examining the Role of Peer Acknowledgements on Social Annotations: Unraveling the Psychological Underpinnings</h3>
<p>Authors: Haolun Wu, Susanne Lajoie, Xiaoshan Huang, Xue Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147427">Link</a></p>
<h3>"Community Guidelines Make this the Best Party on the Internet": An In-Depth Study of Online Platforms' Content Moderation Policies</h3>
<p>Authors: Brennan Schaffner, Jay Shen, Genevieve Lakier, Chenhao Tan, Jacqueline Mei, Siyuan Cheng, Marshini Chetty, Arjun Nitin Bhagoji, Grace Wang, Nick Feamster</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148026">Link</a></p>
<h3>A Quantitative Approach to Identifying Emergent Editor Roles in Open Street Map</h3>
<p>Authors: Bowen Zhang, Dipto Sarkar, Jennings Anderson, Robert Soden</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147183">Link</a></p>
<h3>Insights Into Legacy: Issues of Handover from a Partner-Initiated Project</h3>
<p>Authors: Boriana Koleva, Jocelyn Spence, Steven Benford, Emily Thorn</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146665">Link</a></p>
<h2>Highlight on Creative HCI</h2>
<h3>Thinking with Sound: Exploring the Experience of Listening to an Ultrasonic Art Installation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Nick Bryan-Kinns, Andrew McPherson, Nicole Robson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147210">Link</a></p>
<h3>What Counts as ‘Creative’ Work? Articulating Four Epistemic Positions in Creativity-Oriented HCI Research</h3>
<p>BEST_PAPER</p>
<p>Authors: Sarah Fdili Alaoui, Marianela Ciolfi Felice, Wendy Mackay, Stacy Hsueh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148122">Link</a></p>
<h3>The Illusion of Increased Customization: Framing Choices as a Creative Process Increases Perceived Customization</h3>
<p>Authors: Maarten Bos, Alice Moon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146702">Link</a></p>
<h3>Heart and Soul: The Ethics of Biometric Capture in Immersive Artistic Performance</h3>
<p>Authors: Ryan Kelly, Margaret Osborne, Lucy Sparrow, Ben Loveridge, Solange Glasser, Caiti Galwey</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147399">Link</a></p>
<h3>Entangling Entanglement: A Diffractive Dialogue on HCI and Musical Interactions</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Landon Morrison, Andrew McPherson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147415">Link</a></p>
<h3>Living with Cyanobacteria: Exploring Materiality in Caring for Microbes in Everyday Life</h3>
<p>Authors: Jiwei Zhou, Elvin Karana, Zjenja Doubrovski, Elisa Giaccardi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147186">Link</a></p>
<h3>PhotoScout: Synthesis-Powered Multi-Modal Image Search</h3>
<p>Authors: Qiaochu Chen, Celeste Barnaby, Chenglong Wang, Isil Dillig</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147573">Link</a></p>
<h3>"Please Be Nice": Robot Responses to User Bullying - Measuring Performance Across Aggression Levels</h3>
<p>Authors: Yushan Pan, Di Wu, Yiming Luo, Hao Wang, Shihao Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147077">Link</a></p>
<h3>GustosonicSense: Towards understanding the design of playful gustosonic eating experiences</h3>
<p>Authors: Florian Mueller, Flora Salim, Zhuying Li, Yan Wang, Humphrey Obie, John Grundy</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148023">Link</a></p>
<h3>A Design Framework for Ingestible Play</h3>
<p>Authors: Florian Mueller, Zhuying Li, Nathan Semertzidis, Yan Wang, Josh Andres, Stefan Greuter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150650">Link</a></p>
<h3>Algorithmic Ways of Seeing: Using Object Detection to Facilitate Art Exploration</h3>
<p>Authors: Peter Kun, Louie Meyer, Johanne Engel Aaen, Anitamalina Regitse Tranberg, Sebastian Risi, Anders Løvlie, Matthias Freiberger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147105">Link</a></p>
<h2>Highlight on Design and Design Methods</h2>
<h3>What's the Rush?: Alternative Values in Navigation Technologies for Urban Placemaking</h3>
<p>Authors: Carolina Nobre, Taneea Agrawaal, Robert Soden, Aarjav Chauhan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147044">Link</a></p>
<h3>Input Visualization: Collecting and Modifying Data with Visual Representations</h3>
<p>Authors: Jordan Louis, Nathalie Bressa, Wesley Willett, Samuel Huron</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147820">Link</a></p>
<h3>Multimedia-Enabled 911: Exploring 911 Callers’ Experience of Call Taker Controlled Video Calling in Simulated Emergencies</h3>
<p>Authors: Wolfgang Stuerzlinger, Punyashlok Dash, Benett Axtell, Carman Neustaedter, Denise Y. Geiskkovitch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148116">Link</a></p>
<h3>eKichabi v2: Designing and Scaling a Dual-Platform Technology in Rural Tanzania</h3>
<p>Authors: Yunqi Wang, Richard Anderson, Fanchong Wang, Yunwei Zhao, Hosea Mpogole, Alexander Metzger, Hans Easton, Ananditha Raghunath, XunMei Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147861">Link</a></p>
<h3>Designing a Data-Driven Survey System: Leveraging Participants' Online Data to Personalize Surveys</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Michelle Mazurek, Kévin Huguenin, Bertil Chapuis, Lev Velykoivanenko, Kavous Salehzadeh Niksirat, Stefan Teofanovic</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147705">Link</a></p>
<h3>“Is Text-Based Music Search Enough to Satisfy Your Needs?” A New Way to Discover Music with Images</h3>
<p>Authors: Hyorim Shin, Jeongeun Park, Ha Young Kim, Changhoon Oh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148282">Link</a></p>
<h3>Writing out the Storm: Designing and Evaluating Tools for Weather Risk Messaging</h3>
<p>Authors: Priyank Chandra, Lydia Chilton, Sophia Jit, Robert Soden, Jennifer Spinney</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147048">Link</a></p>
<h3>“What’s Your Name Again?”: How Race and Gender Dynamics Impact Codesign Processes and Output</h3>
<p>Authors: Judith Uchidiuno, Erik Harpstead, Ross Higashi, Jonaya Kemper, Jessica Hammer, Jaemarie Solyst</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150848">Link</a></p>
<h2>Highlight on HCI For Caring</h2>
<h3>CareJournal: A Voice-Based Conversational Agent for Supporting Care Communications</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mingyi Li, John Rudnik, Sharadhi Raghuraj, Robin Brewer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147253">Link</a></p>
<h3>Let’s Talk About Death: Existential Conversations with Chatbots</h3>
<p>Authors: Ruben Albers, Marc Hassenzahl</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147858">Link</a></p>
<h3>Unpacking ICT-supported Social Connections and Support of Late-life Migration: From the Lens of Social Convoys</h3>
<p>Authors: Shuai Ma, Yuling Sun, Ying Lei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147033">Link</a></p>
<h3>Networks of care in digital domestic labour economies</h3>
<p>Authors: Adrian Petterson, Olivia Doggett, Priyank Chandra, Isabella Jaimes Rodriguez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147318">Link</a></p>
<h3>Hostile Systems: A Taxonomy of Harms Articulated by Citizens Living with Socio-Economic Deprivation</h3>
<p>Authors: Adam Parnaby, Clara Crivellaro, Ahmed Kharrufa, Colin Watson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148328">Link</a></p>
<h3>Digital Comprehensibility Assessment of Simplified Texts among Persons with Intellectual Disabilities</h3>
<p>Authors: Sarah Ebling, Andreas Säuberli, Silvana Deilen, Silvia Hansen-Schirra, Laura Schiffl, Patrick Haller, Franz Holzknecht</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147152">Link</a></p>
<h3>Understanding Antenatal Care Needs through Co-Creation with Roma Women to Inform the Design of mHealth Technologies</h3>
<p>Authors: Caroline Claisse, Mabel Lie, Abigail Durrant</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146924">Link</a></p>
<h2>Highlight on Chatbots and LLMs</h2>
<h3>AI is Entering Regulated Territory: Understanding the Supervisors' Perspective for Model Justifiability in Financial Crime Detection</h3>
<p>Authors: Astrid Bertrand, James Eagan, Winston Maxwell, Joshua Brand</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147023">Link</a></p>
<p>Abstract: Artificial intelligence (AI) has the potential to bring significant benefits to highly regulated industries such as healthcare or banking. Adoption, however, remains low. AI's entry into complex socio-techno-legal systems raises issues of transparency, specifically for regulators. However, the perspective of supervisors, regulators who monitor compliance with applicable financial regulations, has rarely been studied. This paper focuses on understanding the needs of supervisors in anti-money laundering (AML) to better inform the design of AI justifications and explanations in highly regulated fields. Through scenario-based workshops with 13 supervisors and 6 banking professionals, we outline the auditing practices and socio-technical context of the supervisor. By combining the workshops’ insights with an analysis of compliance requirements, we identify the AML obligations that conflict with AI opacity. We then formulate seven needs that supervisors have for model justifiability. We discuss the role of explanations as reliable evidence on which to base justifications.</p>
<h3>HILL: A Hallucination Identifier for Large Language Models</h3>
<p>Authors: Sven Eckhardt, Florian Leiser, Ali Sunyaev, Alexander Mädche, Valentin Leuthe, Gerhard Schwabe, Merlin Knaeble</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147556">Link</a></p>
<p>Abstract: Large language models (LLMs) are prone to hallucinations, i.e., nonsensical, unfaithful, and undesirable text. Users tend to overrely on LLMs and corresponding hallucinations which can lead to misinterpretations and errors. To tackle the problem of overreliance, we propose HILL, the Hallucination Identifier for Large Language Models. First, we identified design features for HILL with a Wizard of Oz approach with nine participants. Subsequently, we implemented HILL based on the identified design features and evaluated HILL's interface design by surveying 17 participants. Further, we investigated HILL's functionality to identify hallucinations based on an existing question-answering dataset and five user interviews. We find that HILL can correctly identify and highlight hallucinations in LLM responses which enables users to handle LLM responses with more caution. With that, we propose an easy-to-implement adaptation to existing LLMs and demonstrate the relevance of user-centered designs of AI artifacts.</p>
<h3>Synlogue with Aizuchi-bot: Investigating the Co-Adaptive and Open-Ended Interaction Paradigm</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Dominique Chen, Olaf Witkowski, Kazumi Yoshimura</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147480">Link</a></p>
<p>Abstract: In contrast to dialogue, wherein the exchange of completed messages occurs through turn-taking, synlogue is a mode of conversation characterized by co-creative processes, such as mutually complementing incomplete utterances and cooperative overlaps of backchannelings. Such co-creative conversations have the potential to alleviate social divisions in contemporary information environments. This study proposed the design concept of a synlogue based on literature in linguistics and anthropology and explored features that facilitate synlogic interactions in computer-mediated interfaces. Through an experiment, we focused on aizuchi, an important backchanneling element that drives synlogic conversation, and compared the speech and perceptual changes of participants when a bot dynamically uttered aizuchi or otherwise silent in a situation simulating an online video call. Consequently, we discussed the implications for interaction design based on our qualitative and quantitative analysis of the experiment. The synlogic perspective presented in this study is expected to facilitate HCI researchers to achieve more convivial forms of communication.</p>
<h3>Empowering Calibrated (Dis-)Trust in Conversational Agents: A User Study on the Persuasive Power of Limitation Disclaimers vs. Authoritative Style</h3>
<p>Authors: Luise Metzger, Johannes Kraus, Linda Miller, Martin Baumann</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148239">Link</a></p>
<p>Abstract: While conversational agents based on Large Language Models (LLMs) can drive progress in many domains, they are prone to generating faulty information. To ensure an efficient, safe, and satisfactory user experience maximizing benefits of these systems, users must be empowered to judge the reliability of system outputs. In this, both disclaimers and agents' communicative style are pivotal design instances. </p>
<p>In an online study with 594 participants, we investigated how these affect users' trust and a mock-up agent's persuasiveness, based on an established framework from social psychology. While prior information on potential inaccuracies or faulty information did not affect trust, an authoritative communicative style elicited more trust. Also, a trusted agent was more persuasive resulting in more positive attitudes regarding the subject of the conversation. Results imply that disclaimers on agents' limitations fail to effectively alter users' trust but can be supported by appropriate communicative style during interaction.</p>
<h3>DiaryMate: Understanding User Perceptions and Experience in Human-AI Collaboration for Personal Journaling</h3>
<p>Authors: Hwajung Hong, Donghoon Shin, Taewan Kim, Young-Ho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148343">Link</a></p>
<p>Abstract: With their generative capabilities, large language models (LLMs) have transformed the role of technological writing assistants from simple editors to writing collaborators. Such a transition emphasizes the need for understanding user perception and experience, such as balancing user intent and the involvement of LLMs across various writing domains in designing writing assistants. In this study, we delve into the less explored domain of personal writing, focusing on the use of LLMs in introspective activities. Specifically, we designed DiaryMate, a system that assists users in journal writing with LLM. Through a 10-day field study (N=24), we observed that participants used the diverse sentences generated by the LLM to reflect on their past experiences from multiple perspectives. However, we also observed that they are over-relying on the LLM, often prioritizing its emotional expressions over their own. Drawing from these findings, we discuss design considerations when leveraging LLMs in a personal writing practice.</p>
<h2>Text Entry Techniques</h2>
<h3>PonDeFlick: A Japanese Text Entry on Smartwatch Commonalizing Flick Operation with Smartphone Interface</h3>
<p>Authors: Kai Akamine, Akihiro Tamura, Tsuneo Kato, Ryotaro Tsuchida</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147586">Link</a></p>
<h3>ARTiST: Automated Text Simplification for Task Guidance in Augmented Reality</h3>
<p>Authors: Jing Qian, Guande Wu, Sonia Castelo Quispe, Shaoyu Chen, João Rulff, Claudio Silva</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147808">Link</a></p>
<h3>Exploration of Foot-based Text Entry Techniques for Virtual Reality Environments</h3>
<p>Authors: Liangyuting Zhang, Hongyu Yang, Hai-Ning Liang, Pourang Irani, Lingyun Yu, Tingjie Wan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146722">Link</a></p>
<h3>A Tool for Capturing Smartphone Screen Text</h3>
<p>Authors: Songyan Teng, Simon D'Alfonso, Vassilis Kostakos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147910">Link</a></p>
<h2>Writing and AI C</h2>
<h3>CharacterMeet: Supporting Creative Writers' Entire Story Character Construction Processes Through Conversation with LLM-Powered Chatbot Avatars</h3>
<p>Authors: Mingming Fan, Pan Hui, Shan Jin, Hua Xuan Qin, Ze Gao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146770">Link</a></p>
<p>Abstract: Support for story character construction is as essential as characters are for stories. Building upon past research on early character construction stages, we explore how conversation with chatbot avatars embodying characters powered by more recent technologies could support the entire character construction process for creative writing. Through a user study (N=14) with creative writers, we examine thinking and usage patterns of CharacterMeet, a prototype system allowing writers to progressively manifest characters through conversation while customizing context, character appearance, voice, and background image. We discover that CharacterMeet facilitates iterative character construction. Specifically, participants, including those with more linear usual approaches, alternated between writing and personalized exploration through visualization of ideas on CharacterMeet while visuals and audio enhanced immersion. Our findings support research on iterative creative processes and the growing potential of personalizable generative AI creativity support tools. We present design implications for leveraging chatbot avatars in the creative writing process.</p>
<h3>PANDALens: Towards AI-Assisted In-Context Writing on OHMD During Travels</h3>
<p>Authors: Can Liu, Yang Chen, Shengdong Zhao, Lucia Wang, Runze Cai, Nuwan Janaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146640">Link</a></p>
<p>Abstract: While effective for recording and sharing experiences, traditional in-context writing tools are relatively passive and unintelligent, serving more like instruments rather than companions. This reduces primary task (e.g., travel) enjoyment and hinders high-quality writing. Through formative study and iterative development, we introduce PANDALens, a Proactive AI Narrative Documentation Assistant built on an Optical See-Through Head Mounted Display that supports personalized documentation in everyday activities. PANDALens observes multimodal contextual information from user behaviors and environment to confirm interests and elicit contemplation, and employs Large Language Models to transform such multimodal information into coherent narratives with significantly reduced user effort. A real-world travel scenario comparing PANDALens with a smartphone alternative confirmed its effectiveness in improving writing quality and travel enjoyment while minimizing user effort. Accordingly, we propose design guidelines for AI-assisted in-context writing, highlighting the potential of transforming them from tools to intelligent companions.</p>
<h3>AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation</h3>
<p>Authors: Angelora Cooper, Osnat Mokryn, Andrew Kun, Orit Shaer, Hagit Ben Shoshan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147572">Link</a></p>
<p>Abstract: The growing availability of generative AI technologies such as large language models (LLMs) has significant implications for creative work. This paper explores twofold aspects of integrating LLMs into the creative process – the divergence stage of idea generation, and the convergence stage of evaluation and selection of ideas. We devised a collaborative group-AI Brainwriting ideation framework,  which incorporated  an LLM as an enhancement into the group ideation process, and evaluated the idea generation process and the resulted solution space. To assess the potential of using LLMs in the idea evaluation process, we design an evaluation engine and compared it to idea ratings assigned by three expert and six novice evaluators. Our findings suggest that integrating LLM in Brainwriting could enhance both the ideation process and its outcome. We also provide evidence that LLMs can support idea evaluation.  We conclude by discussing implications for HCI education and practice.</p>
<h3>LegalWriter: An Intelligent Writing Support System for Structured and Persuasive Legal Case Writing for Novice Law Students</h3>
<p>Authors: Thiemo Wambsganss, Florian Weber, Matthias Soellner, Seyed Parsa Neshaei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147647">Link</a></p>
<p>Abstract: Novice students in law courses or students who encounter legal education face the challenge of acquiring specialized and highly concept-oriented knowledge. Structured and persuasive writing combined with the necessary domain knowledge is challenging for many learners. Recent advances in machine learning (ML) have shown the potential to support learners in complex writing tasks. To test the effects of ML-based support on students' legal writing skills, we developed the intelligent writing support system \textit{LegalWriter}. We evaluated the system's effectiveness with 62 students. We showed that students who received intelligent writing support based on their errors wrote more structured and persuasive case solutions with a better quality of legal writing than the current benchmark. At the same time, our results demonstrated the positive effects on the students' writing processes.</p>
<h2>Social Activism C</h2>
<h3>Social Justice in HCI: A Systematic Literature Review</h3>
<p>Authors: Alyssa Sheehan, Ashley Boone, Christopher Le Dantec, Lynn Dombrowski, Kathryn Ringland, Ishita Chordia, Angela D. R. Smith, Leya Breanna Baltaxe-Admony</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148051">Link</a></p>
<h3>Seam Work and Simulacra of Societal Impact in Networking Research: A Critical Technical Practice Approach</h3>
<p>Authors: Jen Liu, Phoebe Sengers, Gloire Rubambiza, Hakim Weatherspoon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146610">Link</a></p>
<h3>Addressing Interpersonal Harm in Online Gaming Communities: The Opportunities and Challenges for a Restorative Justice Approach</h3>
<p>Authors: Niloufar Salehi, Shagun Jhaver, Sijia Xiao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150929">Link</a></p>
<h3>A Human-Centered Review of Algorithms in Homelessness Research</h3>
<p>Authors: Erina Seh-Young Moon, Shion Guha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147715">Link</a></p>
<h2>Designing with Users</h2>
<h3>Older Adults Imagining Future Technologies in Participatory Design Workshops: Supporting Continuity in the Pursuit of Meaningful Activities</h3>
<p>Authors: Ryan Kelly, Wei Zhao, Melissa Rogerson, Jenny Waycott</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147953">Link</a></p>
<h3>Co-design Partners as Transformative Learners: Imagining Ideal Technology for Schools by Centering Speculative Relationships</h3>
<p>Authors: Michael Chang, Arturo Cortez, Sidney D'Mello, Thomas Breideband, Thomas M Philip, Richmond Wong, Ashieda McKoy</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147225">Link</a></p>
<h3>Co-Designing Situated Displays for Family Co-Regulation with ADHD Children</h3>
<p>Authors: Clarisse Bonang, Kimberley Lakes, Jesus Beltran, Lucas Silva, Aehong Min, Elissa Monteiro, Arpita Bhattacharya, Gillian Hayes, Franceli Cibrian, Sabrina Schuck, Daniel Epstein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148144">Link</a></p>
<h3>Guidelines for Integrating Value Sensitive Design in Responsible AI Toolkits</h3>
<p>Authors: Celine Mougenot, Marios Constantinides, Malak Sadek, Daniele Quercia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148342">Link</a></p>
<h3>Co-design Accessible Public Robots: Insights from People with Mobility Disability, Robotic Practitioners and Their Collaborations</h3>
<p>Authors: Sarah Fox, Nikolas Martelaro, Alesandra Baca Vazquez, Franklin Mingzhe Li, Howard Han, Daragh Byrne</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147032">Link</a></p>