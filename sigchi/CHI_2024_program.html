<h2>Behavior Change</h2>
<h3>SoniWeight Shoes: Investigating Effects and Personalization of a Wearable Sound Device for Altering Body Perception, Behavior and Emotion</h3>
<p>Authors: Amar D'Adamo, Marte Roel Lesur, Laia Turmo Vidal, Mohammad Mahdi Dehshibi, Daniel De La Prida, Joaquin Diaz Duran, Luis Antonio Azpicueta-Ruiz, Aleksander Väljamäe, Ana Tajadura-Jiménez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148202">Link</a></p>
<h3>EcoSanté Lifestyle Intervention: Encourage Reflections on the Connections between Health and Environment</h3>
<p>Authors: Pei-Yi (Patricia) Kuo, Mike Horn</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150654">Link</a></p>
<h3>Exploring the Lived Experience of Behavior Change Technologies: Towards an Existential Model of Behavior Change for HCI</h3>
<p>Authors: Amon Rapp, Arianna Boldi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150910">Link</a></p>
<h3>Me, My Health, and My Watch: How Children with ADHD Understand Smartwatch Health Data</h3>
<p>Authors: Elizabeth Ankrah, Franceli Cibrian, Lucas Silva, Arya Tavakoulnia, Jesus Beltran, Sabrina Schuck, Kimberley Lakes, Gillian Hayes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150927">Link</a></p>
<h2>Hand and Gaze</h2>
<h3>GazePointAR: A Context-Aware Multimodal Voice Assistant for Pronoun Disambiguation in Wearable Augmented Reality</h3>
<p>Authors: Jaewook Lee, Jun Wang, Elizabeth Brown, Liam Chu, Sebastian Rodriguez, Jon Froehlich</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147184">Link</a></p>
<p>Abstract: Voice assistants (VAs) like Siri and Alexa are transforming human-computer interaction; however, they lack awareness of users' spatiotemporal context, resulting in limited performance and unnatural dialogue. We introduce GazePointAR, a fully-functional context-aware VA for wearable augmented reality that leverages eye gaze, pointing gestures, and conversation history to disambiguate speech queries. With GazePointAR, users can ask "what's over there?" or "how do I solve this math problem?" simply by looking and/or pointing. We evaluated GazePointAR in a three-part lab study (N=12): (1) comparing GazePointAR to two commercial systems, (2) examining GazePointAR's pronoun disambiguation across three tasks; (3) and an open-ended phase where participants could suggest and try their own context-sensitive queries. Participants appreciated the naturalness and human-like nature of pronoun-driven queries, although sometimes pronoun use was counter-intuitive. We then iterated on GazePointAR and conducted a first-person diary study examining how GazePointAR performs in-the-wild. We conclude by enumerating limitations and design considerations for future context-aware VAs.</p>
<h3>QuadStretcher: A Forearm-Worn Skin Stretch Display for Bare-Hand Interaction in AR/VR</h3>
<p>Authors: Taejun Kim, Youngbo Shim, YoungIn Kim, Sunbum Kim, Jaeyeon Lee, Geehyuk Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148253">Link</a></p>
<p>Abstract: The paradigm of bare-hand interaction has become increasingly prevalent in Augmented Reality (AR) and Virtual Reality (VR) environments, propelled by advancements in hand tracking technology. However, a significant challenge arises in delivering haptic feedback to users’ hands, due to the necessity for the hands to remain bare. In response to this challenge, recent research has proposed an indirect solution of providing haptic feedback to the forearm. In this work, we present QuadStretcher, a skin stretch display featuring four independently controlled stretching units surrounding the forearm. While achieving rich haptic expression, our device also eliminates the need for a grounding base on the forearm by using a pair of counteracting tactors, thereby reducing bulkiness. To assess the effectiveness of QuadStretcher in facilitating immersive barehand experiences, we conducted a comparative user evaluation (n = 20) with a baseline solution, Squeezer. The results confirmed that QuadStretcher outperformed Squeezer in terms of expressing force direction and heightening the sense of realism, particularly in 3-DoF VR interactions such as pulling a rubber band, hooking a fishing rod, and swinging a tennis racket. We further discuss the design insights gained from qualitative user interviews, presenting key takeaways for future forearm-haptic systems aimed at advancing AR/VR bare-hand experiences.</p>
<h3>ArmDeformation: Inducing the Sensation of Arm Deformation in Virtual Reality Using Skin-Stretching</h3>
<p>Authors: Yilong Lin, Peng Zhang, Eyal Ofek, Seungwoo Je</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147750">Link</a></p>
<p>Abstract: With the development of virtual reality (VR) technology, research is being actively conducted on how incorporating multisensory feedback can create the illusion that virtual avatars are perceived as an extension of the body in VR. In line with this research direction, we introduce ArmDeformation, a wearable device employing skin-stretching to enhance virtual forearm ownership during arm deformation illusion. We conducted five user studies with 98 participants. Using a developed tabletop device, we confirmed the optimal number of actuators and the ideal skin-stretching design effectively increases the user's body ownership. Additionally, we explored the maximum visual threshold for forearm bending and the minimum detectable bending direction angle when using skin-stretching in VR. Finally, our study demonstrates that using ArmDeformation in VR applications enhances user realism and enjoyment compared to relying on visual feedback alone.</p>
<h3>CLERA: A Unified Model for Joint Cognitive Load and Eye Region Analysis in the Wild</h3>
<p>Authors: Li Ding, Jack Terwilliger, Aishni Parab, Meng Wang, Lex Fridman, Bruce Mehler, Bryan Reimer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150827">Link</a></p>
<p>Abstract: Non-intrusive, real-time analysis of the dynamics of the eye region allows us to monitor humans’ visual attention allocation and estimate their mental state during the performance of real-world tasks, which can potentially benefit a wide range of human-computer interaction (HCI) applications. While commercial eye-tracking devices have been frequently employed, the difficulty of customizing these devices places unnecessary constraints on the exploration of more efficient, end-to-end models of eye dynamics. In this work, we propose CLERA, a unified model for Cognitive Load and Eye Region Analysis, which achieves precise keypoint detection and spatiotemporal tracking in a joint-learning framework. Our method demonstrates significant efficiency and outperforms prior work on tasks including cognitive load estimation, eye landmark detection, and blink estimation. We also introduce a large-scale dataset of 30k human faces with joint pupil, eye-openness, and landmark annotation, which aims to support future HCI research on human factors and eye-related analysis.</p>
<h3>How Gaze Visualization Facilitates Initiation of Informal Communication in 3D Virtual Spaces</h3>
<p>Authors: Junko Ichino, Masahiro Ide, Takehito Yoshiki, Hitomi Yokoyama, Hirotoshi Asano, Hideo Miyachi, daisuke okabe</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150879">Link</a></p>
<p>Abstract: This study explores how gaze visualization in virtual spaces facilitates the initiation of informal communication. Three styles of gaze cue visualization (arrow, bubbles, and miniature avatar) with two types of gaze behavior (one-sided gaze and joint gaze) were evaluated. 96 participants used either a non-visualized gaze cue or one of the three visualized gaze cues. The results showed that all visualized gaze cues facilitated the initiation of informal communication more effectively than the non-visualized gaze cue. For one-sided gaze, overall, bubbles had more positive effects on the gaze receiver’s behaviors and experiences than the other two visualized gaze cues, although the only statistically significant difference was in the verbal reaction rates. For joint gaze, all three visualized gaze cues had positive effects on the receiver’s behaviors and experiences. The design implications of the gaze visualization and the confederate-based evaluation method contribute to research on informal communication and social virtual reality.</p>
<h2>Privacy for Immersive Tracking</h2>
<h3>Privacy in Immersive Extended Reality: Exploring User Perceptions, Concerns, and Coping Strategies</h3>
<p>Authors: Hilda Hadan, Derrick Wang, Lennart Nacke, Leah Zhang-Kennedy</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147162">Link</a></p>
<p>Abstract: Extended Reality (XR) technology is changing online interactions, but its granular data collection sensors may be more invasive to user privacy than web, mobile, and the Internet of Things technologies. Despite an increased interest in studying developers' concerns about XR device privacy, user perceptions have rarely been addressed. We surveyed 464 XR users to assess their awareness, concerns, and coping strategies around XR data in 18 scenarios. Our findings demonstrate that many factors, such as data types and sensitivity, affect users' perceptions of privacy in XR. However, users' limited awareness of XR sensors' granular data collection capabilities, such as involuntary body signals of emotional responses, restricted the range of privacy-protective strategies they used. Our results highlight a need to enhance users' awareness of data privacy threats in XR, design privacy-choice interfaces tailored to XR environments, and develop transparent XR data practices.</p>
<h3>"I know even if you don't tell me": Understanding Users' Privacy Preferences Regarding AI-based Inferences of Sensitive Information for Personalization</h3>
<p>Authors: Sumit Asthana, Jane Im, Zhe Chen, Nikola Banovic</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148250">Link</a></p>
<p>Abstract: Personalization improves user experience by tailoring interactions relevant to each user's background and preferences. However, personalization requires information about users that platforms often collect without their awareness or their enthusiastic consent. Here, we study how the transparency of AI inferences on users' personal data affects their privacy decisions and sentiments when sharing data for personalization. We conducted two experiments where participants (N=877) answered questions about themselves for personalized public arts recommendations. Participants indicated their consent to let the system use their inferred data and explicitly provided data after awareness of inferences. Our results show that participants chose restrictive consent decisions for sensitive and incorrect inferences about them and for their answers that led to such inferences. Our findings expand existing privacy discourse to inferences and inform future directions for shaping existing consent mechanisms in light of increasingly pervasive AI inferences.</p>
<h3>Kinetic Signatures: A Systematic Investigation of Movement-Based User Identification in Virtual Reality</h3>
<p>Authors: Jonathan Liebers, Patrick Laskowski, Florian Rademaker, Leon Sabel, Jordan Hoppen, Uwe Gruenefeld, Stefan Schneegass</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147796">Link</a></p>
<p>Abstract: Behavioral Biometrics in Virtual Reality (VR) enable implicit user identification by leveraging the motion data of users' heads and hands from their interactions in VR. This spatiotemporal data forms a Kinetic Signature, which is a user-dependent behavioral biometric trait. Although kinetic signatures have been widely used in recent research, the factors contributing to their degree of identifiability remain mostly unexplored. Drawing from existing literature, this work systematically examines the influence of static and dynamic components in human motion. We conducted a user study (N = 24) with two sessions to reidentify users across different VR sports and exercises after one week. We found that the identifiability of a kinetic signature depends on its inherent static and dynamic factors, with the best combination allowing for 90.91 % identification accuracy after one week had passed. Therefore, this work lays a foundation for designing and refining movement-based identification protocols in immersive environments.</p>
<h3>Awareness, Intention, (In)Action: Individuals' Reactions to Data Breaches</h3>
<p>Authors: Peter Mayer, Yixin Zou, Byron M. Lowens, PhD, Hunter Dyer, Khue Le, Florian Schaub, Adam Aviv</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150899">Link</a></p>
<p>Abstract: Data breaches are prevalent. We provide novel insights into individuals’ awareness, perception, and responses to breaches that affect them through two online surveys: a main survey (𝑛=413) in which we presented participants with up to three breaches that affected them, and a follow-up survey (𝑛=108) in which we investigated whether the main study participants followed through with their intentions to act. Overall, 73% of participants were affected by at least one breach, but participants were unaware of 74% of breaches affecting them. While some reported intention to take action, most participants believed the breach would not impact them. We also found a sizeable intention-behavior gap. Participants did not follow through with their intention when they were apathetic about breaches, considered potential costs, forgot, or felt resigned about taking action. Our findings suggest that breached organizations should be held accountable for more proactively informing and protecting affected consumers.</p>
<h3>Don't Accept All and Continue: Exploring Nudges for More Deliberate Interaction With Tracking Consent Notices</h3>
<p>Authors: Nina Gerber, Alina Stöver, Justin Peschke, Verena Zimmermann</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150877">Link</a></p>
<p>Abstract: Legal frameworks rely on users to make an informed decision about data collection, e.g., by accepting or declining the use of tracking technologies. In practice, however, users hardly interact with tracking consent notices on a deliberate website per website level, but usually accept or decline optional tracking technologies altogether in a habituated behavior.We explored the potential of three different nudge types (color highlighting, social cue, timer) and default settings to interrupt this auto-response in an experimental between-subject design with 167 participants.We did not find statistically significant differences regarding the buttons clicked. Our results showed that opt-in default settings significantly decrease tracking technology use acceptance rates. These results are a first step towards understanding the effects of different nudging concepts on users’ interaction with tracking consent notices.</p>
<h2>Privacy and Trust</h2>
<h3>Computing and the Stigmatized: Trust, Surveillance, and Spatial Politics with the Sex Workers in Bangladesh</h3>
<p>BEST_PAPER</p>
<p>Authors: Pratyasha Saha, Nadira Nowsher, Ayien Utshob Baidya, Nusrat Jahan Mim, Syed Ishtiaque Ahmed, S M Taiabul Haque</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148106">Link</a></p>
<h3>Lies, Deceit, and Hallucinations: Player Perception and Expectations Regarding Trust and Deception in Games</h3>
<p>Authors: Michael Yin, Emi Wang, Chuoxi Ng, Robert Xiao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146790">Link</a></p>
<h3>Reliability Criteria for News Websites</h3>
<p>Authors: Hendrik Heuer, Elena Glassman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150911">Link</a></p>
<h3>Un-Paradoxing Privacy: Considering Hopeful Trust</h3>
<p>Authors: Bran Knowles, Stacey Conchie</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150903">Link</a></p>
<h3>“I Can’t Believe It’s Not Custodial!”: Usable Trustless Decentralized Key Management</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Tanusree Sharma, Vivek Nair, Henry Wang, Yang Wang, Dawn Song</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147386">Link</a></p>
<h2>Bodies and Movement in Immersive Realities</h2>
<h3>ShareYourReality: Investigating Haptic Feedback and Agency in Virtual Avatar Co-embodiment</h3>
<p>Authors: Karthikeya Puttur Venkatraj, Wo Meijer, Monica Perusquia-Hernandez, Gijs Huisman, Abdallah El Ali</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147264">Link</a></p>
<p>Abstract: Virtual co-embodiment enables two users to share a single avatar in Virtual Reality (VR). During such experiences, the illusion of shared motion control can break during joint-action activities, highlighting the need for position-aware feedback mechanisms. Drawing on the perceptual crossing paradigm, we explore how haptics can enable non-verbal coordination between co-embodied participants. In a within-subjects study (20 participant pairs), we examined the effects of vibrotactile haptic feedback (None, Present) and avatar control distribution (25-75%, 50-50%, 75-25%) across two VR reaching tasks (Targeted, Free-choice) on participants’ Sense of Agency (SoA), co-presence, body ownership, and motion synchrony. We found (a) lower SoA in the free-choice with haptics than without, (b) higher SoA during the shared targeted task, (c) co-presence and body ownership were significantly higher in the free-choice task, (d) players’ hand motions synchronized more in the targeted task. We provide cautionary considerations when including haptic feedback mechanisms for avatar co-embodiment experiences.</p>
<h3>Process, Roles, Tools, and Team: Understanding the Emerging Medium of Virtual Reality Theatre</h3>
<p>Authors: Michaelah Wales, Michael Wheeler, Gabriele Cimolino, Laura Levin, Jayna Mees, T.C. Nicholas Graham</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147875">Link</a></p>
<p>Abstract: Virtual reality (VR) theatre artists are combining theatre production and game development practices to create live performances in VR. To date, little is known about VR theatre creators' experiences of this process or how staging a play in VR might affect the audience's experience. To capture the experience of developing a VR theatre production we interviewed the production team behind the VR play You Should Have Stayed Home. Members of this team felt the process was a learning experience and shared the lessons they plan to incorporate into their future work. We report on the team's efforts to understand the VR theatre medium, how this team was constructed, and challenges that they encountered. In this paper we present the opportunities that the production team members identified for creating novel experiences for VR audiences, and their own needs as creators.</p>
<h3>TimeTunnel: Integrating Spatial and Temporal Motion Editing for Character Animation in Virtual Reality</h3>
<p>Authors: Qian Zhou, David Ledo, George Fitzmaurice, Fraser Anderson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147369">Link</a></p>
<p>Abstract: Editing character motion in Virtual Reality is challenging as it requires working with both spatial and temporal data using controls with multiple degrees of freedom. The spatial and temporal controls are separated, making it difficult to adjust poses over time and predict the effects across adjacent frames. To address this challenge, we propose TimeTunnel, an immersive motion editing interface that integrates spatial and temporal control for 3D character animation in VR. TimeTunnel provides an approachable editing experience via KeyPoses and Trajectories. KeyPoses are a set of representative poses automatically computed to concisely depict motion. Trajectories are 3D animation curves that pass through the joints of KeyPoses to represent in-betweens. TimeTunnel integrates spatial and temporal control by superimposing Trajectories and KeyPoses onto a 3D character. We conducted two studies to evaluate TimeTunnel. In our quantitative study, TimeTunnel reduced the amount of time required for editing motion, and saved effort in locating target poses. Our qualitative study with domain experts demonstrated how TimeTunnel is an approachable interface that can simplify motion editing, while still preserving a direct representation of motion.</p>
<h3>A Systematic Review and Meta-analysis of the Effectiveness of Body Ownership Illusions in Virtual Reality</h3>
<p>Authors: Aske Mottelson, Andreea Muresan, Kasper Hornbæk, Guido Makransky</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150754">Link</a></p>
<p>Abstract: Body ownership illusions (BOIs) occur when participants experience that their actual body is replaced by a body shown in virtual reality (VR). Based on a systematic review of the cumulative evidence on BOIs from 111 research articles published in 2010 to 2021, this article summarizes the findings of empirical studies of BOIs. Following the PRISMA guidelines, the review points to diverse experimental practices for inducing and measuring body ownership. The two major components of embodiment measurement, body ownership and agency, are examined. The embodiment of virtual avatars generally leads to modest body ownership and slightly higher agency. We also find that BOI research lacks statistical power and standardization across tasks, measurement instruments, and analysis approaches. Furthermore, the reviewed studies showed a lack of clarity in fundamental terminology, constructs, and theoretical underpinnings. These issues restrict scientific advances on the major components of BOIs, and together impede scientific rigor and theory-building.</p>
<h2>Children and Family B</h2>
<h3>CHAITok: A Proof-of-Concept System Supporting Children's Sense of Data Autonomy on Social Media</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ge Wang, Jun Zhao, Samantha-Kaye Johnston, Zhilin Zhang, Max Van Kleek, Nigel Shadbolt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147781">Link</a></p>
<h3>"It's Not a Replacement:'' Enabling Parent-Robot Collaboration to Support In-Home Learning Experiences of Young Children</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Hui-Ru Ho, Edward Hubbard, Bilge Mutlu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147068">Link</a></p>
<h3>Cuddling Up With a Print-Braille Book: How Intimacy and Access Shape Parents' Reading Practices with Children</h3>
<p>Authors: Cameron Cassidy, Isabela Figueira, Sohyeon Park, Jin Seo Kim, Emory Edwards, Stacy Branham</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146954">Link</a></p>
<h3>“It looks useful, works just fine, but will it replace me ?" Understanding Special Educators’ Perception of Social Robots for Autism Care in India</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: B Ashwini, ATMADEEP GHOSHAL, Venkata Ratnadeep Suri, Krishnaveni Achary, Jainendra Shukla</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147134">Link</a></p>
<h2>Communication and Collaboration</h2>
<h3>Understanding Entrainment in Human Groups: Optimising Human-Robot Collaboration from Lessons Learned during Human-Human Collaboration</h3>
<p>Authors: Eike Schneiders, Christopher Fourie, Stanley Celestin, Julie Shah, Malte Jung</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147674">Link</a></p>
<p>Abstract: Successful entrainment during collaboration positively affects trust, willingness to collaborate, and likeability towards collaborators. In this paper, we present a mixed-method study to investigate characteristics of successful entrainment leading to pair and group-based synchronisation. Drawing inspiration from industrial settings, we designed a fast-paced, short-cycle repetitive task. Using motion tracking, we investigated entrainment in both dyadic and triadic task completion. Furthermore, we utilise audio-video recordings and semi-structured interviews to contextualise participants' experiences. This paper contributes to the Human-Computer/Robot Interaction (HCI/HRI) literature using a human-centred approach to identify entrainment characteristics during pair- and group-based collaboration. We present five characteristics related to successful entrainment. These are related to the occurrence of entrainment, leader-follower patterns, interpersonal communication, the importance of the point-of-assembly, and the value of acoustic feedback. Finally, based on our findings, we present three design considerations for future research and design on collaboration with robots.</p>
<h3>Investigating the Potential of Group Recommendation Systems As a Medium of Social Interactions: A Case of Spotify Blend Experiences between Two Users</h3>
<p>Authors: Daehyun Kwak, Soobin Park, Inha Cha, Hankyung Kim, Youn-kyung Lim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147752">Link</a></p>
<p>Abstract: Designing user experiences for group recommendation systems (GRS) is challenging, requiring a nuanced understanding of the influence of social interactions between users. Using Spotify Blend as a real-world case of music GRS, we conducted empirical studies to investigate intricate social interactions among South Korean users in GRS. Through a preliminary survey about Blend experiences in general, we narrowed the focus for the main study to relationships between two users who are acquainted or close. Building on this, we conducted a 21-day diary study and interviews with 30 participants (15 pairs) to probe more in-depth interpersonal dynamics within Blend. Our findings reveal that users engaged in implicit social interactions, including tacit understanding of their companions and indirect communication. We conclude by discussing the newly discovered value of GRS as a social catalyst, along with design attributes and challenges for the social experiences it mediates.</p>
<h3>Mitigating Barriers to Public Social Interaction with Meronymous Communication</h3>
<p>BEST_PAPER</p>
<p>Authors: Nouran Soliman, Hyeonsu Kang, Matt Latzke, Jonathan Bragg, Joseph Chee Chang, Amy Zhang, David Karger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147447">Link</a></p>
<p>Abstract: In communities with social hierarchies, fear of judgment can discourage communication. While anonymity may alleviate some social pressure, fully anonymous spaces enable toxic behavior and hide the social context that motivates people to participate and helps them tailor their communication. We explore a design space of meronymous communication, where people can reveal carefully chosen aspects of their identity and also leverage trusted endorsers to gain credibility. We implemented these ideas in a system for scholars to meronymously seek and receive paper recommendations on Twitter and Mastodon. A formative study with 20 scholars confirmed that scholars see benefits to participating but are deterred due to social anxiety. From a month-long public deployment, we found that with meronymity, junior scholars could comfortably ask "newbie" questions and get responses from senior scholars who they normally found intimidating. Responses were also tailored to the aspects about themselves that junior scholars chose to reveal. </p>
<h3>Examining Voice Community Use</h3>
<p>Authors: Robin Brewer, Sam Ankenbauer, Manahil Hashmi, Pooja Upadhyay</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150925">Link</a></p>
<p>Abstract: Visual online communities can present accessibility challenges to older adults or people with vision and motor disabilities. Motivated by this challenge, accessibility and HCI researchers have called for voice-based communities to support aging and disability. This paper extends prior work on voice community design and short-term use by providing empirical data on how people interact with voice communities over time and intentional instances of non-use. We conducted a one-year study with 43 blind and low vision older adults, of whom 21 used a voice-based community. We use vignettes to unpack five different voice community member roles - the obligatory poster, routine poster, cross-platform lurker, busy socialite, and visual expertise seeker - and discuss community interactions over time. Findings show how participation varied based on engagement in other communities and ways that participants sought interaction. We discuss (1) how to design voice communities for member roles and (2) the implications of synchronous and asynchronous voice community interaction in voice-only communities.</p>
<h3>Engaged and Affective Virtual Agents: Their Impact on Social Presence, Trustworthiness, and Decision-Making in the Group Discussion</h3>
<p>Authors: Hanseob Kim, Bin Han, Jieun Kim, MUHAMMAD FIRDAUS LUBIS, Gerard Kim, Jae-In Hwang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147980">Link</a></p>
<p>Abstract: This study investigates how different virtual agent (VA) behaviors influence subjects' perceptions and group decision-making.
Participants carried out 
experimental group discussions with a VA exhibiting varying levels of engagement and affective behavior.
Engagement refers to the VA's focus on the group task, whereas affective behavior reflects the VA's emotional state.
The findings revealed that VA's engagements effectively captured participants' attention even in the group setting and enhanced group synergy, thereby facilitating more in-depth discussion and producing better consensus.
On the other hand, VA's affective behavior negatively affected the
perceived social presence and trustworthiness. Consequently, 
in the context of group discussion, participants preferred the engaged and non-affective VA to the non-engaged and affective VA.
The study provides valuable insights for improving the VA's behavioral design as a team member for collaborative tasks.</p>
<h2>Emotions and User Experience</h2>
<h3>EmoWear: Exploring Emotional Teasers for Voice Message Interaction on Smartwatches</h3>
<p>Authors: Pengcheng An, Jiawen Zhu, Zibo Zhang, Yifei Yin, Qingyuan Ma, Che Yan, Linghao Du, Jian Zhao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147276">Link</a></p>
<h3>ReactGenie: A Development Framework for Complex Multimodal Interactions Using Large Language Models</h3>
<p>Authors: Jackie Yang, Karina Li, Daniel Wan Rosli, Shuning Zhang, Yuhan Zhang, Yingtian Shi, Anisha Jain, Tianshi Li, Monica Lam, James Landay</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147488">Link</a></p>
<h3>Investigating the Effects of Self-selected Pleasant Scents on Text Composition and Transcription Performance</h3>
<p>Authors: Wendy Haw, Yuan Ren, Kianna Ng, Ahmed Arif</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147458">Link</a></p>
<h3>Digital Knick-Knacks: Standalone Audiovisual Digital Possessions or Embellishments in Digital Environments</h3>
<p>Authors: Matthew Lakier, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147325">Link</a></p>
<h3>Frustration: Still a Common User Experience</h3>
<p>Authors: Morten Hertzum, Kasper Hornbæk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150750">Link</a></p>
<h2>Environmental Activism</h2>
<h3>Eternagram: Probing Player Attitudes Towards Climate Change Using a ChatGPT-driven Text-based Adventure</h3>
<p>Authors: Qinshi Zhang, Latisha Besariani Hendra, Suifang Zhou, Pengfei Zhou, Jussi Holopainen, RAY LC</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147145">Link</a></p>
<h3>Technical Mentality: Principles for HCI Research and Practice</h3>
<p>Authors: Gabrielle Benabdallah, Nadya Peek</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148115">Link</a></p>
<h3>Promoting Eco-Friendly Behaviour through Virtual Reality - Implementation and Evaluation of Immersive Feedback Conditions of a Virtual CO2 Calculator</h3>
<p>Authors: Carolin Wienrich, Stephanie Vogt, Nina Döllinger, David Obremski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148025">Link</a></p>
<h3>From Surplus and Scarcity towards Abundance: Understanding the Use of ICT in Food Resource Sharing Practices</h3>
<p>Authors: Philip Engelbutzeder, Dave Randall, Marvin Landwehr, Konstantin Aal, Gunnar Stevens, Volker Wulf</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150852">Link</a></p>
<h3>Post-growth Human–Computer Interaction</h3>
<p>Authors: Vishal Sharma, Neha Kumar, Bonnie Nardi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150905">Link</a></p>
<h2>Health Ecosystems</h2>
<h3>Towards AI-Driven Healthcare: Systematic Optimization, Linguistic Analysis, and Clinicians’ Evaluation of Large Language Models for Smoking Cessation Interventions</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Paul Calle, Ruosi Shao, Yunlong Liu, Emily Hébert, Darla Kendzor, Jordan Neil, Michael Businelle, Chongle Pan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147450">Link</a></p>
<h3>PsiNet: Toward Understanding the Design of Brain-to-Brain Interfaces for Augmenting Inter-Brain Synchrony</h3>
<p>BEST_PAPER</p>
<p>Authors: Nathan Semertzidis, Michaela Vranic-Peters, Xiao Fang, Rakesh Patibanda, Aryan Saini, Don Samitha Elvitigala, Florian Mueller</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146996">Link</a></p>
<h3>Societal-Scale Human-AI Interaction Design? How Hospitals and Companies are Integrating Pervasive Sensing into Mental Healthcare</h3>
<p>Authors: Angel Hsing-Chi Hwang, Dan Adler, Meir Friedenberg, Qian Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148145">Link</a></p>
<h3>Clinician-Facing AI in the Wild: Taking Stock of the Sociotechnical Challenges and Opportunities for HCI</h3>
<p>Authors: Hubert Zając, Dana Li, Xiang Dai, Jonathan Frederik Carlsen, Finn Kensing, Tariq Andersen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150869">Link</a></p>
<h3>“We are Researchers, but we are also Humans”: Creating a Design Space for Managing Graduate Student Stress</h3>
<p>Authors: Fujiko Robledo Yamamoto, Amy Voida, Stephen Voida</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150823">Link</a></p>
<h2>Hybrid and Immersive Experiences</h2>
<h3>Factors Influencing Engagement in Hybrid Virtual and Augmented Reality</h3>
<p>Authors: Yue Li, Eugene Ch'ng, Sue Cobb</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150873">Link</a></p>
<p>Abstract: Hybridity in immersive technologies has not been studied for factors that are likely to influence engagement. A noticeable factor is the spatial enclosure that defines where users meet. This involves a mutual object of interest, contents that the users may generate around the object, and the proximity between users. This study examines these factors, namely how object interactivity, user-generated contents (UGC) and avatar proximity influence engagement. We designed a Hybrid Virtual and Augmented Reality (HVAR) environment that supports paired users to experience cultural heritage in both Virtual Reality (VR) and Augmented Reality (AR). A user study was conducted with 60 participants, providing assessments of engagement and presence via questionnaires, together with mobile electroencephalogram (mEEG) and user activity data that measures VR user engagement in real-time. Our findings provide insights into how engagement between users can occur in HVAR environments for the future hybrid reality with multi-device connectivity.</p>
<h3>Visual Noise Cancellation: Exploring Visual Discomfort and Opportunities for Vision Augmentations</h3>
<p>Authors: Junlei Hong, Tobias Langlotz, Jonathan Sutton, Holger Regenbrecht</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150772">Link</a></p>
<p>Abstract: Acoustic noise control or cancellation (ANC) is a commonplace component of modern audio headphones. ANC aims to actively mitigate disturbing environmental noise for a quieter and improved listening experience. ANC is digitally controlling frequency and amplitude characteristics of sound. Much less explored is visual noise and active visual noise control, which we address here. We first explore visual noise and scenarios in which visual noise arises based on findings from four workshops we conducted. We then introduce the concept of visual noise cancellation (VNC) and how it can be used to reduce identified effects of visual noise. In addition, we developed head-worn demonstration prototypes to practically explore the concept of active VNC with selected scenarios in a user study. Finally, we discuss the application of VNC, including vision augmentations that moderate the user's view of the environment to address perceptual needs and to provide augmented reality content.</p>
<h3>\textit{Cohabitant}: The Design, Implementation, and Evaluation of a Virtual Reality Application for Interfaith Learning and Empathy Building</h3>
<p>Authors: Mohammad Rashidujjaman Rifat, Reem Ayad, Ashratuz Zavin Asha, Bingjian Huang, Selin Okman, Dina Sabie, Hasan Shahid Ferdous, Robert Soden, Syed Ishtiaque Ahmed</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147831">Link</a></p>
<p>Abstract: Lack of interfaith communication often gives rise to prejudice and group-based conflict in multi-faith societies. Nurturing this communication via interfaith learning may reduce this conflict by fostering interfaith empathy. HCI has a dearth of knowledge on interfaith coexistence and empathy building. To address this gap, we present the design, implementation, and usability of \textit{Cohabitant}: a virtual reality (VR) application that promotes interfaith learning and empathy. \textit{Cohabitant}'s design is theoretically underpinned by Allport's intergroup contact theory and informed by insights from a participatory workshop we ran with members of three religious groups: Christians, Hindus, and Muslims. Our evaluation study, combining quantitative and qualitative data from 30 participants, suggests that \textit{Cohabitant} may enhance general interpersonal empathy, but falls short for ethnocultural empathy. We discuss the possible design and policy implications of using this kind of VR technology for interfaith learning and empathy building.</p>
<h3>Navigating the Virtual Gaze: Social Anxiety's Role in VR proxemics</h3>
<p>Authors: Beatriz Mello, Robin Welsch, Marissa Verbokkem, Pascal Knierim, Martin Dechant</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148238">Link</a></p>
<p>Abstract: For individuals with Social Anxiety (SA), interacting with others can be a challenging experience, a concern that extends into the virtual world. While technology has made significant strides in creating more realistic virtual human agents (VHA), the interplay of gaze and interpersonal distance when interacting with VHAs is often neglected. This paper investigates the effect of dynamic and static Gaze animations in VHAs on interpersonal distance and their relation to SA. A Bayesian analysis shows that static centered and dynamic centering gaze led participants to stand closer to VHAs than static averted and dynamic averting gaze, respectively. In the static gaze conditions, this pattern was found to be reversed in SA: participants with higher SA kept larger distances for static-centered gaze than for averted gaze VHAs. These findings update theory, elucidate how nuanced interactions with VHAs must be designed, and offer renewed guidelines for pleasant VHA interaction design.</p>
<h2>Assistive Interactions: Audio Interactions and d/Deaf and Hard of Hearing Users</h2>
<h3>Audio Engineering by People Who Are deaf and Hard of Hearing: Balancing Confidence and Limitations</h3>
<p>Authors: Keita Ohshiro, Mark Cartwright</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146895">Link</a></p>
<h3>Look Once to Hear: Target Speech Hearing with Noisy Examples</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Bandhav Veluri, Malek Itani, Tuochao Chen, Takuya Yoshioka, Shyamnath Gollakota</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147319">Link</a></p>
<h3>Communication, Collaboration, and Coordination in a Co-located Shared Augmented Reality Game: Perspectives From Deaf and Hard of Hearing People</h3>
<p>Authors: Sanzida Mojib Luna, Jiangnan Xu, Konstantinos Papangelis, Garreth Tigwell, Nicolas LaLone, Michael Saker, Alan Chamberlain, Samuli Laato, John Dunham, Yihong Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147649">Link</a></p>
<h3>"Voices Help Correlate Signs and Words": Analyzing Deaf and Hard-of-Hearing (DHH) TikTokers’ Content, Practices, and Pitfalls</h3>
<p>Authors: Jiaxun Cao, Xuening Peng, Fan Liang, Xin Tong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148325">Link</a></p>
<h2>Online Toxicity</h2>
<h3>Counterspeakers’ Perspectives: Unveiling Barriers and AI Needs in the Fight against Online Hate</h3>
<p>Authors: Jimin Mun, Cathy Buerger, Jenny Liang, Joshua Garland, Maarten Sap</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147002">Link</a></p>
<h3>“Vulnerable, Victimized, and Objectified”: Understanding Ableist Hate and Harassment Experienced by Disabled Content Creators on Social Media</h3>
<p>Authors: Sharon Heung, Lucy Jiang, Shiri Azenkot, Aditya Vashistha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147153">Link</a></p>
<h3>"It’s Not What We Were Trying to Get At, but I Think Maybe It Should Be": Learning How to Do Trauma-Informed Design With a Data Donation Platform for Online Dating Sexual Violence</h3>
<p>Authors: Wenqi Zheng, Emma Walquist, Isha Datey, Xiangyu Zhou, Kelly Berishaj, Melissa McDonald, Michele Parkhill, Dongxiao Zhu, Douglas Zytko</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147295">Link</a></p>
<h3>"I Got Flagged for Supposed Bullying, Even Though It Was in Response to Someone Harassing Me About My Disability.": A Study of Blind TikTokers’ Content Moderation Experiences</h3>
<p>Authors: Yao Lyu, Jie Cai, Anisa Callis, Kelley Cotter, John Carroll</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146733">Link</a></p>
<h3>Malicious Selling Strategies in Livestream E-commerce: A Case Study of Alibaba’s Taobao and ByteDance’s TikTok</h3>
<p>Authors: Qunfang Wu, Yisi Sang, Dakuo Wang, Zhicong Lu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150847">Link</a></p>
<h2>Knowledge Workers and Crowdworkers</h2>
<h3>"Are we all in the same boat?" Customizable and Evolving Avatars to Improve Worker Engagement and Foster a Sense of Community in Online Crowd Work</h3>
<p>Authors: Esra de Groot, Ujwal Gadiraju</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146646">Link</a></p>
<h3>How Low is Low? Crowdworker Perceptions of Microtask Payments in Work versus Leisure Situations</h3>
<p>Authors: Ling Jiang, Christian Wagner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147248">Link</a></p>
<h3>LabelAId: Just-in-time AI Interventions for Improving Human Labeling Quality and Domain Knowledge in Crowdsourcing Systems</h3>
<p>Authors: Chu Li, Zhihan Zhang, Esteban Safranchik, Michael Saugstad, Chaitanyashareef Kulkarni, Xiaoyu Huang, Shwetak Patel, Vikram Iyer, Tim Althoff, Jon Froehlich</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147498">Link</a></p>
<h3>How Knowledge Workers Think Generative AI Will (Not) Transform Their Industries</h3>
<p>Authors: Allison Woodruff, Renee Shelby, Patrick Kelley, Steven Rousso-Schindler, Jamila Smith-Loud, Lauren Wilcox</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147564">Link</a></p>
<h3>“Sometimes it’s Like Putting the Track in Front of the Rushing Train”: Having to Be ‘On Call’ for Work Limits the Temporal Flexibility of Crowdworkers</h3>
<p>Authors: Laura Lascau, Duncan Brumby, Sandy Gould, Anna Cox</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150655">Link</a></p>
<h2>Mid-air Haptics</h2>
<h3>Designing Distinguishable Mid-Air Ultrasound Tactons with Temporal Parameters</h3>
<p>Authors: Chungman Lim, Gunhyuk Park, Hasti Seifi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147761">Link</a></p>
<h3>Controlled-STM: A two-stage model to predict user’s Perceived Intensity for Multi-point Spatiotemporal Modulation in Ultrasonic Mid-air Haptics</h3>
<p>Authors: Zhouyang Shen, Zak Morgan, Madhan Kumar Vasudevan, Marianna Obrist, Diego Martinez Plasencia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147738">Link</a></p>
<h3>Designing Haptic Feedback for Sequential Gestural Inputs</h3>
<p>Authors: Shan Xu, Sarah Sykes, Parastoo Abtahi, Tovi Grossman, Daylon Walden, Michael Glueck, Carine Rognon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147360">Link</a></p>
<h3>Expressive, Scalable, Mid-Air Haptics with Synthetic Jets</h3>
<p>Authors: Vivian Shen, Chris Harrison, Craig Shultz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150752">Link</a></p>
<h2>Workers, Work Practices and AI</h2>
<h3>The Role of Inclusion, Control, and Ownership in Workplace AI-Mediated Communication</h3>
<p>Authors: Kowe Kadoma, Marianne Aubin Le Quere, Xiyu Fu, Christin Munsch, Danaë Metaxa, Mor Naaman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147700">Link</a></p>
<p>Abstract: Given large language models' (LLMs) increasing integration into workplace software, it is important to examine how biases in the models may impact workers. For example, stylistic biases in the language suggested by LLMs may cause feelings of alienation and result in increased labor for individuals or groups whose style does not match. We examine how such writer-style bias impacts inclusion, control, and ownership over the work when co-writing with LLMs. In an online experiment, participants wrote hypothetical job promotion requests using either hesitant or self-assured autocomplete suggestions from an LLM and reported their subsequent perceptions. We found that the style of the AI model did not impact perceived inclusion. However, individuals with higher perceived inclusion did perceive greater agency and ownership, an effect more strongly impacting participants of minoritized genders. Feelings of inclusion mitigated a loss of control and agency when accepting more AI suggestions.</p>
<h3>“There is a Job Prepared for Me Here”: Understanding How Short Video and Live-streaming Platforms Empower Ageing Job Seekers in China</h3>
<p>Authors: PiaoHong Wang, Siying Hu, Bo Wen, Zhicong Lu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147237">Link</a></p>
<p>Abstract: In recent years, the global unemployment rate has remained persistently high. Compounding this issue, the ageing population in China often encounters additional challenges in finding employment due to prevalent age discrimination in daily life. However, with the advent of social media, there has been a rise in the popularity of short videos and live-streams for recruiting ageing workers. To better understand the motivations of ageing job seekers to engage with these video-based recruitment methods and to explore the extent to which such platforms can empower them, we conducted an interview-based study with ageing job seekers who have had exposure to these short recruitment videos and live-streaming channels. Our findings reveal that these platforms can provide a job-seeking choice that is particularly friendly to ageing job seekers, effectively improving their disadvantaged situation.</p>
<h3>Deconstructing the Veneer of Simplicity: Co-Designing Introductory Generative AI Workshops with Local Entrepreneurs</h3>
<p>Authors: Yasmine Kotturi, Angel Anderson, Glenn Ford, Michael Skirpan, Jeffrey Bigham</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147681">Link</a></p>
<p>Abstract: Generative AI platforms and features are permeating many aspects of work. Entrepreneurs from lean economies in particular are well positioned to outsource tasks to generative AI given limited resources. In this paper, we work to address a growing disparity in use of these technologies by building on a four-year partnership with a local entrepreneurial hub dedicated to equity in tech and entrepreneurship. Together, we co-designed an interactive workshops series aimed to onboard local entrepreneurs to generative AI platforms. Alongside four community-driven and iterative workshops with entrepreneurs across five months, we conducted interviews with 15 local entrepreneurs and community providers. We detail the importance of communal and supportive exposure to generative AI tools for local entrepreneurs, scaffolding actionable use (and supporting non-use), demystifying generative AI technologies by emphasizing entrepreneurial power, while simultaneously deconstructing the veneer of simplicity to address the many operational skills needed for successful application.</p>
<h3>How Do Data Analysts Respond to AI Assistance? A Wizard-of-Oz Study</h3>
<p>Authors: Ken Gu, Madeleine Grunde-McLaughlin, Andrew McNutt, Jeffrey Heer, Tim Althoff</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146787">Link</a></p>
<p>Abstract: Data analysis is challenging as analysts must navigate nuanced decisions that may yield divergent conclusions. AI assistants have the potential to support analysts in planning their analyses, enabling more robust decision making. Though AI-based assistants that target code execution (e.g., Github Copilot) have received significant attention, limited research addresses assistance for both analysis execution and planning. In this work, we characterize helpful planning suggestions and their impacts on analysts’ workflows. We first review the analysis planning literature and crowd-sourced analysis studies to categorize suggestion content. We then conduct a Wizard-of-Oz study (n=13) to observe analysts’ preferences and reactions to planning assistance in a realistic scenario. Our findings highlight subtleties in contextual factors that impact suggestion helpfulness, emphasizing design implications for supporting different abstractions of assistance, forms of initiative, increased engagement, and alignment of goals between analysts and assistants.</p>
<h3>Building Knowledge through Action: Considerations for Machine Learning in the Workplace</h3>
<p>Authors: Siân Lindley, Denise Wilkins</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150819">Link</a></p>
<p>Abstract: Innovations in machine learning are enabling organisational knowledge bases to be automatically generated from working people’s activities. The potential for these to shift the ways in which knowledge is produced and shared raises questions about what types of knowledge might be inferred from working people’s actions, how these can be used to support work, and what the broader ramifications of this might be. This paper draws on findings from studies of (i) collaborative actions, and (ii) knowledge actions, to explore how these actions might (i) inform automatically generated knowledge bases, and (ii) be better supported through technological innovation. We triangulate findings to develop a framework of actions that are performed as part of everyday work, and use this to explore how mining those actions could result in knowledge being explicitly and implicitly contributed to a knowledge base. We draw on these possibilities to highlight implications and considerations for responsible design.</p>
<h2>Learning and Working</h2>
<h3>Contrasting Perspectives of Workers: Exploring Labor Relations in Workplace Automation and Potential Interventions</h3>
<p>Authors: Hee Rin Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147381">Link</a></p>
<h3>Designing Instructions using Self-Determination Theory to Improve Motivation and Engagement for Learning Craft</h3>
<p>Authors: Hitesh Dhiman, Gustavo Rovelo Ruiz, Raf Ramakers, Danny Leen, Carsten Röcker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147763">Link</a></p>
<h3>Learning from Hybrid Craft: Investigating and Reflecting on Innovating and Enlivening Traditional Craft through Literature Review</h3>
<p>Authors: Guanhong Liu, Qingyuan Shi, Yuan Yao, Yuan-Ling Feng, Tianyu Yu, Beituo Liu, Zhijun Ma, Li Huang, Yuting Diao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147895">Link</a></p>
<h3>SharedNeRF: Leveraging Photorealistic and View-dependent Rendering for Real-time and Remote Collaboration</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mose Sakashita, Bala Kumaravel, Nicolai Marquardt, Andrew Wilson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147720">Link</a></p>
<h3>Lessons Learnt from a Multimodal Learning Analytics Deployment In-the-wild</h3>
<p>Authors: Roberto Martinez-Maldonado, Vanessa Echeverria, Gloria Fernandez-Nieto, Lixiang Yan, Linxuan Zhao, Riordan Alfredo, Xinyu Li, Samantha Dix, Hollie Jaggard, Rosie Wotherspoon, Abra Osborne, Simon Buckingham Shum, Dragan Gasevic</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150775">Link</a></p>
<h2>Better Future Worlds and AI</h2>
<h3>How Culture Shapes What People Want From AI</h3>
<p>Authors: Xiao Ge, Chunchen Xu, Daigo Misaki, Hazel Rose Markus, Jeanne L. Tsai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148201">Link</a></p>
<p>Abstract: There is an urgent need to incorporate the perspectives of culturally diverse groups into AI developments. We present a novel conceptual framework for research that aims to expand, reimagine, and reground mainstream visions of AI using independent and interdependent cultural models of the self and the environment. Two survey studies support this framework and provide preliminary evidence that people apply their cultural models when imagining their ideal AI. Compared with European American respondents, Chinese respondents viewed it as less important to control AI and more important to connect with AI, and were more likely to prefer AI with capacities to influence. Reflecting both cultural models, findings from African American respondents resembled both European American and Chinese respondents. We discuss study limitations and future directions and highlight the need to develop culturally responsive and relevant AI to serve a broader segment of the world population.</p>
<h3>Charting the Future of AI in Project-Based Learning: A Co-Design Exploration with Students</h3>
<p>Authors: Chengbo Zheng, Kangyu Yuan, Bingcan Guo, Reza Hadi Mogavi, Zhenhui Peng, Shuai Ma, Xiaojuan Ma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147096">Link</a></p>
<p>Abstract: Students' increasing use of Artificial Intelligence (AI) presents new challenges for assessing their mastery of knowledge and skills in project-based learning (PBL). This paper introduces a co-design study to explore the potential of students' AI usage data as a novel material for PBL assessment. We conducted workshops with 18 college students, encouraging them to speculate an alternative world where they could freely employ AI in PBL while needing to report this process to assess their skills and contributions. Our workshops yielded various scenarios of students' use of AI in PBL and ways of analyzing such usage grounded by students' vision of how educational goals may transform. We also found that students with different attitudes toward AI exhibited distinct preferences in how to analyze and understand their use of AI. Based on these findings, we discuss future research opportunities on student-AI interactions and understanding AI-enhanced learning.</p>
<h3>Socio-technical Imaginaries: Envisioning and Understanding AI Parenting Supports through Design Fiction</h3>
<p>Authors: Melina Petsolari, Seray Ibrahim, Petr Slovak</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147338">Link</a></p>
<p>Abstract: How might emerging modalities (e.g., NLP) be leveraged to transform the provision of parenting support? To explore the role of AI technologies in supporting parenting behaviour—and child-well-being—we surveyed 92 parents to gather their perspectives on nine future-oriented scenarios. We used Design Fiction and Speed Dating to understand parents needs and preferences around the design of agent-based supports. We explore the perceived benefits of AI assistants (i.e., receiving objective feedback, managing emotions and personalised guidance) and the most voiced concerns (i.e., AI undermining parental authority, replacing human interactions, and promoting lazy parenting). Finally, we highlight a number of plausible design directions based on the scenarios that parents were positive about.</p>
<h3>MindTalker: Navigating the Complexities of AI-Enhanced Social Engagement for People with Early-Stage Dementia</h3>
<p>Authors: Anna Xygkou, Chee Siang Ang, Panote Siriaraya, Jonasz Kopecki, Alexandra Covaci, Eiman Kanjo, Wan-Jou She</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146659">Link</a></p>
<p>Abstract: People living with dementia are at risk of social isolation, and conversational AI agents can potentially support such individuals by reducing their loneliness. In our study, a conversational AI agent, called MindTalker, co-designed with therapists and utilizing the GPT-4 Large Language Model (LLM), was developed to support people with early-stage dementia, allowing them to experience a new type of “social relationship” that could be extended to real life. Eight PwD engaged with MindTalker for one month or even longer, and data was collected from interviews. Our findings emphasized that participants valued the novelty of AI, but sought more consistent, deeper interactions. They desired a personal touch from AI, while stressing the irreplaceable value of human interactions. The findings underscore the complexities of AI engagement dynamics, where participants commented on the artificial nature of AI, highlighting important insights into the future design of conversational AI for this population.</p>
<h2>Microoganism and Fossil Interactions</h2>
<h3>Microbial Revolt: Redefining biolab tools and practices for more-than-human care ecologies</h3>
<p>Authors: Yuning Chen, Larissa Pschetz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147452">Link</a></p>
<h3>PaleoScan: Low-Cost Easy-to-Use High-Volume Fossil Scanning</h3>
<p>Authors: Claudio Silva, Yurii Piadyk, João Rulff, Daniele Panozzo, Maria Beatriz Silva, Antonio Alamo Feitosa Saraiva, Naiara Cipriano Oliveira, Flaviana Jorge de Lima, Renan Alfredo Machado Bantim, Otavio Gomes, Akinobu Watanabe</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147092">Link</a></p>
<h3>Go-Go Biome: Evaluation of a Casual Game for Gut Health Engagement and Reflection</h3>
<p>Authors: Nandini Pasumarthy, Shreyas Nisal, Jessica Danaher, Elise van den Hoven, Rohit Ashok Khot</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147393">Link</a></p>
<h3>(Re)activate, (Re)direct, (Re)arrange: Exploring the Design Space of Direct Interactions with Flavobacteria</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Clarice Risseeuw, Holly McQuillan, Joana Martins, Elvin Karana</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148167">Link</a></p>
<h2>Wellbeing and Mental Health A</h2>
<h3>On Stress: Combining Human Factors and Biosignals to Inform the Placement and Design of a Skin-like Stress Sensor</h3>
<p>Authors: Yasser Khan, Matthew Mauriello, Parsa Nowruzi, Akshara Motani, Grace Hon, Nicholas Vitale, Jinxing Li, Jayoung Kim, Amir Foudeh, Dalton Duvio, Erika Shols, Megan Chesnut, James Landay, Jan Liphardt, Leanne Williams, Keith D. Sudheimer, Boris Murmann, Zhenan Bao, Pablo Paredes Castro</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147821">Link</a></p>
<h3>Reading Between the Lines: Identifying the Linguistic Markers of Anhedonia for the Stratification of Depression</h3>
<p>Authors: Bridianne O'Dea, Taylor Braund, Philip J Batterham, Mark E Larsen, Nick Glozier, Alexis E Whitton</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147595">Link</a></p>
<h3>"Waves Push Me to Slumberland": Reducing Pre-Sleep Stress through Spatio-Temporal Tactile Displaying of Music.</h3>
<p>Authors: Hui Zhang, Ruixiao Zheng, Shirao Yang, Wanyi Wei, Huafeng Shan, Jianwei Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146869">Link</a></p>
<h3>MoodCapture: Depression Detection using In-the-Wild Smartphone Images</h3>
<p>Authors: Subigya Nepal, Arvind Pillai, Weichen Wang, Tess Griffin, Amanda Collins, Michael Heinz, Damien Lekkas, Shayan Mirjafari, Matthew Nemesure, George Price, Nicholas Jacobson, Andrew Campbell</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148165">Link</a></p>
<h3>Patient Acceptance of Self-Monitoring on a Smartwatch in a Routine Digital Therapy: A Mixed-Methods Study</h3>
<p>Authors: Camille Nadal, Caroline Earley, Angel Enrique, Corina Sas, Derek Richards, Gavin Doherty</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150631">Link</a></p>
<h2>Algorithmic Trust and Censorship</h2>
<h3>Dealing with Uncertainty: Understanding the Impact of Prognostic Versus Diagnostic Tasks on Trust and Reliance in Human-AI Decision Making</h3>
<p>Authors: Sara Salimzadeh, Gaole He, Ujwal Gadiraju</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147300">Link</a></p>
<h3>Impact of Model Interpretability and Outcome Feedback on Trust in AI</h3>
<p>Authors: Daehwan Ahn, Abdullah Almaatouq, Monisha Gulabani, Kartik Hosanagar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147213">Link</a></p>
<h3>Exposed or Erased: Algorithmic Censorship of Nudity in Art</h3>
<p>Authors: Piera Riccio, Thomas Hofmann, Nuria Oliver</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148324">Link</a></p>
<h3>Trust in AI-assisted Decision Making: Perspectives from Those Behind the System and Those for Whom the Decision is Made</h3>
<p>Authors: Oleksandra Vereschak, Fatemeh Alizadeh, Gilles Bailly, Baptiste Caramiaux</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147306">Link</a></p>
<h3>Understanding Public Perceptions of AI Conversational Agents: A Cross-Cultural Analysis</h3>
<p>Authors: Zihan Liu, Han Li, Anfan Chen, Renwen Zhang, YI-CHIEH LEE</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148182">Link</a></p>
<h2>Chronic Conditions B</h2>
<h3>Charting the COVID Long Haul Experience - A Longitudinal Exploration of Symptoms, Activity, and Clinical Adherence</h3>
<p>Authors: Jessica Pater, Shaan Chopra, Jeanne Carroll, Juliette Zaccour, Taha Liaqat, Fayika Farhat Nova, Tammy Toscos, Shion Guha, Fen Lei Chang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147234">Link</a></p>
<h3>Designing online peer support for parents of adolescents at risk of mental health challenges</h3>
<p>Authors: Ling Wu, Joshua Paolo Seguin, Dharshani Chandrasekara, Mairead Cardamone-Breen, Jue Xie, Roisin McNaney, Tom Bartindale, Patrick Olivier, Marie B H Yap</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147515">Link</a></p>
<h3>Co-designing Customizable Clinical Dashboards with Multidisciplinary Teams: Bridging the Gap in Chronic Disease Care</h3>
<p>Authors: Diogo Branco, Margarida Móteiro, Raquel Bouça-Machado, Rita Miranda, Tiago Reis, Élia Decoroso, Rita Cardoso, Joana Ramalho, Filipa Rato, Joana Malheiro, Diana Miranda, Verónica Caniça, Filipa Pona-Ferreira, Daniela Guerreiro, Mariana Leitão, Alexandra Braz, Joaquim J Ferreira, Tiago Guerreiro</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147322">Link</a></p>
<h3>Platforming PCOS Treatment Online: FemTech Logics of Care</h3>
<p>Authors: Taru Jain, Preeti Mudliar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146795">Link</a></p>
<h3>“Is it Even Giving the Correct Reading or Not?”: How Trust and Relationships Mediate Blood Pressure Management in India</h3>
<p>Authors: Nimisha Karnatak, Brooke Loughrin, Tiffany Kuo, Odeline Mateu-Silvernail, Indrani Medhi Thies, William Thies, Mohit Jain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150874">Link</a></p>
<h2>Conversational Agents</h2>
<h3>Apple’s Knowledge Navigator: Why Doesn’t that Conversational Agent Exist Yet?</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Amanda Newendorp, Mohammadamin Sanaei, Arthur Perron, Hila Sabouni, Nikoo Javadpour, Maddie Sells, Katherine Nelson, Michael Dorneich, Stephen Gilbert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147981">Link</a></p>
<h3>Towards Designing a Question-Answering Chatbot for Online News: Understanding Questions and Perspectives</h3>
<p>Authors: Md Naimul Hoque, Ayman Mahfuz, Mayukha Kindi, Naeemul Hassan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147565">Link</a></p>
<h3>Cooking With Agents: Designing Context-aware Voice Interaction</h3>
<p>BEST_PAPER</p>
<p>Authors: Razan Jaber, Sabrina Zhong, Sanna Kuoppamäki, Aida Hosseini, Iona Gessinger, Duncan Brumby, Benjamin Cowan, Donald McMillan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147273">Link</a></p>
<h3>"It's a Fair Game", or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents</h3>
<p>Authors: Zhiping Zhang, Michelle Jia, Hao-Ping (Hank) Lee, Bingsheng Yao, Sauvik Das, Ada Lerner, Dakuo Wang, Tianshi Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147902">Link</a></p>
<h3>Metaphors in Voice User Interfaces: A Slippery Fish</h3>
<p>Authors: Smit Desai, Michael Twidale</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150773">Link</a></p>
<h2>Flavor and Food Interactions</h2>
<h3>FoodSkin: Fabricating Edible Gold Leaf Circuits on Food Surfaces</h3>
<p>Authors: Kunihiro Kato, Kaori Ikematsu, Hiromi Nakamura, Hinako Suzaki, Yuki Igarashi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148251">Link</a></p>
<h3>From Plating to Tasting: Towards Understanding the Choreography of Computational Food</h3>
<p>Authors: Jialin Deng, Nathalie Overdevest, Patrick Olivier, Florian Mueller</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147646">Link</a></p>
<h3>Füpop: "Real Food" Flavor Delivery via Focused Ultrasound</h3>
<p>Authors: Katherine Song, Szu Ting Tung, Alexis Kim, Eric Paulos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147226">Link</a></p>
<h2>Haptics: Electrical Stimulation</h2>
<h3>Understanding User Acceptance of Electrical Muscle Stimulation in Human-Computer Interaction</h3>
<p>Authors: Sarah Faltaous, Julie Williamson, Marion Koelle, Max Pfeiffer, Jonas Keppel, Stefan Schneegass</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147978">Link</a></p>
<h3>Designing Unobtrusive Modulated Electrotactile Feedback on Fingertip Edge to Assist Blind and Low Vision (BLV) People in Comprehending Charts</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Chutian Jiang, Yinan FAN, Junan Xie, Emily Kuang, Kaihao Zhang, Mingming Fan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147036">Link</a></p>
<h3>TacTex: A Textile Interface with Seamlessly-Integrated Electrodes for High-Resolution electrotactile Stimulation</h3>
<p>Authors: Hongnan Lin, Xuanyou Liu, Shengsheng Jiang, Qi Wang, Ye Tao, Guanyun Wang, Wei Sun, Teng Han, Feng Tian</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146969">Link</a></p>
<h3>Paired-EMS: Enhancing Electrical Muscle Stimulation (EMS)-based Force Feedback Experience by Stimulating Both Muscles in Antagonistic Pairs</h3>
<p>Authors: Chia-Yu Cheng, Yu Chen, Sitaresmi Handani, Avijit Balabantaray, Mike Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146902">Link</a></p>
<h2>Mental Health B</h2>
<h3>Exploring Context-Aware Mental Health Self-Tracking Using Multimodal Smart Speakers in Home Environments</h3>
<p>Authors: Jieun Lim, Youngji Koh, Auk Kim, Uichin Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147776">Link</a></p>
<h3>Co-designing the Collaborative Digital Musical Instruments for Group Music Therapy</h3>
<p>Authors: Yuan-Ling Feng, Zhaoguo Wang, Yuan Yao, Hanxuan Li, Yuting Diao, Yu Peng, Haipeng Mi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147511">Link</a></p>
<h3>Approaches for tailoring between-session mental health therapy activities</h3>
<p>Authors: Bruna Oewel, Patricia Arean, Elena Agapie</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147860">Link</a></p>
<h3>Challenges and Opportunities for the Design of Inclusive Digital Mental Health Tools: Understanding Culturally Diverse Young People's Experiences</h3>
<p>Authors: Ewan Soubutts, Pranita Shrestha, Brittany Davidson, Chengcheng Qu, Charlotte Mindel, Aaron Sefi, Paul Marshall, Roisin McNaney</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146990">Link</a></p>
<h3>Feeling Stressed and Unproductive? A Field Evaluation of a Therapy-Inspired Digital Intervention for Knowledge Workers</h3>
<p>Authors: Kevin Chow, Thomas Fritz, Liisa Holsti, Skye Barbic, Joanna McGrenere</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150820">Link</a></p>
<h2>Reproductive Rights and Privacy</h2>
<h3>Unpacking the Lived Experience of Collaborative Pregnancy Tracking</h3>
<p>Authors: Xi Lu, Jacquelyn Powell, Elena Agapie, Yunan Chen, Daniel Epstein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148254">Link</a></p>
<h3>“Our Users' Privacy is Paramount to Us”: A Discourse Analysis of How Period and Fertility Tracking App Companies Address the Roe v Wade Overturn</h3>
<p>Authors: Qiurong Song, Rie Helene (Lindy) Hernandez, Yubo Kou, Xinning Gui</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146889">Link</a></p>
<h3>"I Deleted It After the Overturn of Roe v. Wade": Understanding Women's Privacy Concerns Toward Period-Tracking Apps in the Post Roe v. Wade Era</h3>
<p>Authors: Jiaxun Cao, Hiba Laabadli, Chase Mathis, Rebecca Stern, Pardis Emami-Naeini</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147370">Link</a></p>
<h3>Teen Reproductive Health Information Seeking and Sharing Post-Roe</h3>
<p>Authors: Umama Dewan, Cora Sula, Nora McDonald</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146968">Link</a></p>
<h3>“I Did Watch ‘The Handmaid’s Tale’”: Threat Modeling Privacy Post-Roe in the United States</h3>
<p>Authors: Nora McDonald, Nazanin Andalibi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150756">Link</a></p>
<h2>Universal Accessibility B</h2>
<h3>RASSAR: Room Accessibility and Safety Scanning in Augmented Reality</h3>
<p>Authors: Xia Su, Kaiming Cheng, Han Zhang, Jaewook Lee, Qiaochu LIU, Wyatt Olson, Jon Froehlich</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148045">Link</a></p>
<h3>A Design Space for Vision Augmentations and Augmented Human Perception using Digital Eyewear</h3>
<p>Authors: Tobias Langlotz, Jonathan Sutton, Holger Regenbrecht</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147983">Link</a></p>
<h3>“I never realized sidewalks were a big deal”: A Case Study of a Community-Driven Sidewalk Accessibility Assessment using Project Sidewalk</h3>
<p>Authors: Chu Li, Katrina Ma, Michael Saugstad, Kie Fujii, Molly Delaney, Yochai Eisenberg, Delphine Labbé, Judy Shanley, Devon Snyder, Florian P Thomas, Jon Froehlich</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147783">Link</a></p>
<h3>A Virtual Reality Scene Taxonomy: Identifying and Designing Accessible Scene-Viewing Techniques</h3>
<p>Authors: Rachel Franz, Sasa Junuzovic, Martez Mott</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150645">Link</a></p>
<h2>Learning Programming with AI</h2>
<h3>How Beginning Programmers and Code LLMs (Mis)read Each Other</h3>
<p>Authors: Sydney Nguyen, Hannah McLean Babe, Yangtian Zi, Arjun Guha, Carolyn Anderson, Molly Feldman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146777">Link</a></p>
<p>Abstract: Generative AI models, specifically large language models (LLMs), have made strides towards the long-standing goal of text-to-code generation. This progress has invited numerous studies of user interaction. However, less is known about the struggles and strategies of non-experts, for whom each step of the text-to-code problem presents challenges: describing their intent in natural language, evaluating the correctness of generated code, and editing prompts when the generated code is incorrect. This paper presents a large-scale controlled study of how 120 beginning coders across three academic institutions approach writing and editing prompts. A novel experimental design allows us to target specific steps in the text-to-code process and reveals that beginners struggle with writing and editing prompts, even for problems at their skill level and when correctness is automatically determined. Our mixed-methods evaluation provides insight into student processes and perceptions with key implications for non-expert Code LLM use within and outside of education.</p>
<h3>Teach AI How to Code: Using Large Language Models as Teachable Agents for Programming Education</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Hyoungwook Jin, Seonghee Lee, Hyungyu Shin, Juho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148146">Link</a></p>
<p>Abstract: This work investigates large language models (LLMs) as teachable agents for learning by teaching (LBT). LBT with teachable agents helps learners identify knowledge gaps and discover new knowledge. However, teachable agents require expensive programming of subject-specific knowledge. While LLMs as teachable agents can reduce the cost, LLMs' expansive knowledge as tutees discourages learners from teaching. We propose a prompting pipeline that restrains LLMs' knowledge and makes them initiate "why" and "how" questions for effective knowledge-building. We combined these techniques into TeachYou, an LBT environment for algorithm learning, and AlgoBo, an LLM-based tutee chatbot that can simulate misconceptions and unawareness prescribed in its knowledge state. Our technical evaluation confirmed that our prompting pipeline can effectively configure AlgoBo's problem-solving performance. Through a between-subject study with 40 algorithm novices, we also observed that AlgoBo's questions led to knowledge-dense conversations (effect size=0.71). Lastly, we discuss design implications, cost-efficiency, and personalization of LLM-based teachable agents.</p>
<h3>ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12</h3>
<p>Authors: Liuqing Chen, Shuhong Xiao, Yunnong Chen, Ruoyu Wu, Yaxuan Song, Lingyun Sun</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147770">Link</a></p>
<p>Abstract: As Computational Thinking (CT) continues to permeate younger age groups in K-12 education, established CT platforms such as Scratch face challenges in catering to these younger learners, particularly those in the elementary school (ages 6-12). Through formative investigation with Scratch experts, we uncover three key obstacles to children's autonomous Scratch learning: artist's block in project planning, bounded creativity in asset creation, and inadequate coding guidance during implementation. To address these barriers, we introduce ChatScratch, an AI-augmented system to facilitate autonomous programming learning for young children. ChatScratch employs structured interactive storyboards and visual cues to overcome artist's block, integrates digital drawing and advanced image generation technologies to elevate creativity, and leverages Scratch-specialized Large Language Models (LLMs) for professional coding guidance. Our study shows that, compared to Scratch, ChatScratch efficiently fosters autonomous programming learning, and contributes to the creation of high-quality, personally meaningful Scratch projects for children.</p>
<h3>“It’s Weird That it Knows What I Want”: Usability and Interactions with Copilot for Novice Programmers</h3>
<p>Authors: James Prather, Brent Reeves, Paul Denny, Brett Becker, Juho Leinonen, Andrew Luxton-Reilly, Garrett Powell, James Finnie-Ansley, Eddie Antonio Santos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150774">Link</a></p>
<p>Abstract: Recent developments in deep learning have resulted in code-generation models that produce source code from natural language and code-based prompts with high accuracy. This is likely to have profound effects in the classroom, where novices learning to code can now use free tools to automatically suggest solutions to programming exercises and assignments. However, little is currently known about how novices interact with these tools in practice. We present the first study that observes students at the introductory level using one such code auto-generating tool, Github Copilot, on a typical introductory programming (CS1) assignment. Through observations and interviews we explore student perceptions of the benefits and pitfalls of this technology for learning, present new observed interaction patterns, and discuss cognitive and metacognitive difficulties faced by students. We consider design implications of these findings, specifically in terms of how tools like Copilot can better support and scaffold the novice programming experience.</p>
<h2>Research Methods and Tools A</h2>
<h3>Designing a Card-Based Design Tool to Bridge Academic Research &amp; Design Practice For Societal Resilience</h3>
<p>BEST_PAPER</p>
<p>Authors: Novia Nurain, Chia-Fang Chung, Clara Caldeira, Kay Connelly</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147574">Link</a></p>
<h3>Playing with Perspectives and Unveiling the Autoethnographic Kaleidoscope in HCI – A Literature Review of Autoethnographies</h3>
<p>Authors: Annika Kaltenhauser, Evropi Stefanidi, Johannes Schöning</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148280">Link</a></p>
<h3>The Future of HCI-Policy Collaboration</h3>
<p>Authors: Qian Yang, Richmond Wong, Steven Jackson, Sabine Junginger, Margaret Hagan, Thomas Gilbert, John Zimmerman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147277">Link</a></p>
<h3>DiaryHelper: Exploring the Use of an Automatic Contextual Information Recording Agent for Elicitation Diary Study</h3>
<p>Authors: Junze Li, Changyang He, Jiaxiong Hu, Boyang Jia, Alon Halevy, Xiaojuan Ma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147624">Link</a></p>
<h3>CoAIcoder: Examining the Effectiveness of AI-assisted Human-to-Human Collaboration in Qualitative Analysis</h3>
<p>Authors: Jie Gao, Kenny Tsu Wei Choo, Junming Cao, Roy Ka-Wei Lee, Simon Perrault</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150647">Link</a></p>
<h2>AI for Researchers and Educators</h2>
<h3>PaperWeaver: Enriching Topical Paper Alerts by Contextualizing Recommended Papers with User-collected Papers</h3>
<p>Authors: Yoonjoo Lee, Hyeonsu Kang, Matt Latzke, Juho Kim, Jonathan Bragg, Joseph Chee Chang, Pao Siangliulue</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147172">Link</a></p>
<p>Abstract: With the rapid growth of scholarly archives, researchers subscribe to "paper alert" systems that periodically provide them with recommendations of recently published papers that are similar to previously collected papers. However, researchers sometimes struggle to make sense of nuanced connections between recommended papers and their own research context, as existing systems only present paper titles and abstracts. To help researchers spot these connections, we present PaperWeaver, an enriched paper alerts system that provides contextualized text descriptions of recommended papers based on user-collected papers. PaperWeaver employs a computational method based on Large Language Models (LLMs) to infer users’ research interests from their collected papers, extract context-specific aspects of papers, and compare recommended and collected papers on these aspects. Our user study (N=15) showed that participants using PaperWeaver were able to better understand the relevance of recommended papers and triage them more confidently when compared to a baseline that presented the related work sections from recommended papers.</p>
<h3>Integrating measures of replicability into scholarly search: Challenges and opportunities</h3>
<p>Authors: Chuhao Wu, Tatiana Chakravorti, John Carroll, Sarah Rajtmajer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146636">Link</a></p>
<p>Abstract: Challenges to reproducibility and replicability have gained widespread attention, driven by large replication projects with lukewarm success rates. A nascent work has emerged developing algorithms to estimate the replicability of published findings. The current study explores ways in which AI-enabled signals of confidence in research might be integrated into the literature search. We interview 17 PhD researchers about their current processes for literature search and ask them to provide feedback on a replicability estimation tool. Our findings suggest that participants tend to confuse replicability with generalizability and related concepts. Information about replicability can support researchers throughout the research design processes. However, the use of AI estimation is debatable due to the lack of explainability and transparency. The ethical implications of AI-enabled confidence assessment must be further studied before such tools could be widely accepted. We discuss implications for the design of technological tools to support scholarly activities and advance replicability.</p>
<h3>How AI Processing Delays Foster Creativity: Exploring Research Question Co-Creation with an LLM-based Agent</h3>
<p>Authors: Yiren Liu, Si Chen, Haocong Cheng, Mengxia Yu, Xiao Ran, Andrew Mo, Yiliu Tang, Yun Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146979">Link</a></p>
<p>Abstract: Developing novel research questions (RQs) often requires extensive literature reviews, especially in interdisciplinary fields. To support RQ development through human-AI co-creation, we leveraged Large Language Models (LLMs) to build an LLM-based agent system named CoQuest. We conducted an experiment with 20 HCI researchers to examine the impact of two interaction designs: breadth-first and depth-first RQ generation. The findings revealed that participants perceived the breadth-first approach as more creative and trustworthy upon task completion. Conversely, during the task, participants considered the depth-first generated RQs as more creative. Additionally, we discovered that AI processing delays allowed users to reflect on multiple RQs simultaneously, leading to a higher quantity of generated RQs and an enhanced sense of control. Our work makes both theoretical and practical contributions by proposing and evaluating a mental model for human-AI co-creation of RQs. We also address potential ethical issues, such as biases and over-reliance on AI, advocating for using the system to improve human research creativity rather than automating scientific inquiry. The system’s source is available at: https://github.com/yiren-liu/coquest.</p>
<h3>"This is not a data problem": Algorithms and Power in Public Higher Education in Canada</h3>
<p>Authors: Kelly McConvey, Shion Guha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147823">Link</a></p>
<p>Abstract: Algorithmic decision-making is increasingly being adopted across public higher education. The expansion of data-driven practices by post-secondary institutions has occurred in parallel with the adoption of New Public Management approaches by neoliberal administrations. In this study, we conduct a qualitative analysis of an in-depth ethnographic case study of data and algorithms in use at a public college in Ontario, Canada. We identify the data, algorithms, and outcomes in use at the college. We assess how the college's processes and relationships support those outcomes and the different stakeholders' perceptions of the college's data-driven systems. In addition, we find that the growing reliance on algorithmic decisions leads to increased student surveillance, exacerbation of existing inequities, and the automation of the faculty-student relationship. Finally, we identify a cycle of increased institutional power perpetuated by algorithmic decision-making, and driven by a push towards financial sustainability.</p>
<h3>PaperPlain: Making Medical Research Papers Approachable to Healthcare Consumers with Natural Language Processing</h3>
<p>Authors: Tal August, Lucy Lu Wang, Jonathan Bragg, Marti Hearst, Andrew Head, Kyle Lo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150900">Link</a></p>
<p>Abstract: When seeking information not covered in patient-friendly documents, healthcare consumers may turn to the research literature. Reading medical papers, however, can be a challenging experience. To improve access to medical papers, we introduce a novel interactive interface---Paper Plain---with four features enabled by natural language processing: definitions of unfamiliar terms, in-situ plain language section summaries, a collection of key questions that guides readers to answering passages, and plain language summaries of those passages. We evaluate Paper Plain, finding that participants who used Paper Plain had an easier time reading research papers without a loss in paper comprehension compared to those who used a typical PDF reader. Altogether, the study results suggest that guiding readers to relevant passages and providing plain language summaries alongside the original paper content can make reading medical papers easier and give readers more confidence to approach these papers.</p>
<h2>Crisis Informatics</h2>
<h3>Choosing the Right Reality: A Comparative Analysis of Tangibility in Immersive Trauma Simulations</h3>
<p>Authors: Jakob Uhl, Rodrigo Gutierrez, Georg Regal, Helmut Schrom-Feiertag, Benjamin Schuster, Manfred Tscheligi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147464">Link</a></p>
<h3>Comparison of Spatial Visualization Techniques for Radiation in Augmented Reality</h3>
<p>Authors: Fintan McGee, Roderick McCall, Joan Baixauli</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146651">Link</a></p>
<h3>Exploring the Design Space of Optical See-through AR Head-Mounted Displays to Support First Responders in the Field</h3>
<p>Authors: Kexin Zhang, Brianna Cochran, Ruijia Chen, Lance Hartung, Bryce Sprecher, Ross Tredinnick, Kevin Ponto, Suman Banerjee, Yuhang Zhao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146943">Link</a></p>
<h3>Transitioning Cognitive Aids into Decision Support Platforms: Requirements and Design Guidelines</h3>
<p>Authors: Angela Mastrianni, Aleksandra Sarcevic, Allison Hu, Lynn Almengor, Peyton Tempel, Sarah Gao, Randall Burd</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150760">Link</a></p>
<h2>Curating Online Content B</h2>
<h3>Bystanders of Online Moderation: Examining the Effects of Witnessing Post-Removal Explanations</h3>
<p>Authors: Shagun Jhaver, Himanshu Rathi, Koustuv Saha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148129">Link</a></p>
<h3>Community Begins Where Moderation Ends: Peer Support and Its Implications for Community-Based Rehabilitation</h3>
<p>Authors: Yubo Kou, Renkai Ma, Zinan Zhang, Yingfan Zhou, Xinning Gui</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146823">Link</a></p>
<h3>Agency Aspirations: Understanding Users’ Preferences And Perceptions Of Their Role In Personalised News Curation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Anna Rezk, Auste Simkute, Ewa Luger, John Vines, Chris Elsden, Michael Evans, Rhianne Jones</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147968">Link</a></p>
<h3>Wikibench: Community-Driven Data Curation for AI Evaluation on Wikipedia</h3>
<p>Authors: Tzu-Sheng Kuo, Aaron Halfaker, Zirui Cheng, Jiwoo Kim, Meng-Hsin Wu, Tongshuang Wu, Kenneth Holstein, Haiyi Zhu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146778">Link</a></p>
<h3>Empirical Investigation of Accessibility Bug Reports in Mobile Platforms: A Chromium Case Study</h3>
<p>Authors: Wajdi Aljedaani, Mohamed Wiem Mkaouer, Marcelo Eler, Marouane Kessentini</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147552">Link</a></p>
<h2>Body and Wellbeing</h2>
<h3>Critiquing Menstrual Pain Technologies through the Lens of Feminist Disability Studies</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Joo Young Park, Stacy Hsueh, Nadia Campo Woytuk, Xuni Huang, Marianela Ciolfi Felice, Madeline Balaam</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147659">Link</a></p>
<h3>Enhancing Auto-Generated Baseball Highlights via Win Probability and Bias Injection Method</h3>
<p>Authors: Kieun Park, Hajin Lim, Joonhwan Lee, Bongwon Suh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146747">Link</a></p>
<h3>Understanding the Effect of Reflective Iteration on Individuals’ Physical Activity Planning</h3>
<p>Authors: Kefan Xu, Xinghui (Erica) Yan, Myeonghan Ryu, Mark Newman, Rosa Arriaga</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148178">Link</a></p>
<h3>Sensible and Sensitive AI for Worker Wellbeing: Factors that Inform Adoption and Resistance for Information Workers</h3>
<p>BEST_PAPER</p>
<p>Authors: Vedant Das Swain, Lan Gao, Abhirup Mondal, Gregory Abowd, Munmun De Choudhury</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146807">Link</a></p>
<h3>Thrown from Normative Ground: Exploring the Potential of Disorientation as a Critical Methodological Strategy in HCI</h3>
<p>Authors: Heidi Biggs, Shaowen Bardzell</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147235">Link</a></p>
<h2>Fabrication and Dynamic Structures</h2>
<h3>Reconfigurable Interfaces by Shape Change and Embedded Magnets</h3>
<p>Authors: Himani Deshpande, Bo Han, Kongpyung (Justin) Moon, Andrea Bianchi, Clement Zheng, Jeeeun Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147224">Link</a></p>
<h3>ConeAct: A Multistable Actuator for Dynamic Materials</h3>
<p>Authors: Yuyu Lin, Jesse Gonzalez, Zhitong Cui, Yash Rajeev Banka, Alexandra Ion</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147261">Link</a></p>
<h3>TensionFab: Fabrication of Room-scale Surface Structures From the Tension-Active Form of Planar Modules</h3>
<p>Authors: Yahui Lyu, Taiga Urata, Alessandro Garzanti, Ziyuan Jiang, Carlos Garcia Fernandez, Yasuaki Kakehi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146649">Link</a></p>
<h3>Robotic Metamaterials: A Modular System for Hands-On Configuration of Ad-Hoc Dynamic Applications</h3>
<p>Authors: Zhitong Cui, Shuhong Wang, Violet Yinuo Han, Tucker Rae-Grant, Willa Yunqi Yang, Alan Zhu, Scott Hudson, Alexandra Ion</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147544">Link</a></p>
<h3>Nothing Like Compilation: How Professional Digital Fabrication Workflows Go Beyond Extruding, Milling, and Machines</h3>
<p>Authors: Mare Hirsch, Gabrielle Benabdallah, Jennifer Jacobs, Nadya Peek</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/156318">Link</a></p>
<h2>Indigeonus Communities and Cutural Heritage A</h2>
<h3>Griot-Style Methodology: Longitudinal Study of Navigating Design With Unwritten Stories</h3>
<p>Authors: Lindah Kotut, Neelma Bhatti, Taha Hassan, Derek Haqq, Morva Saaty</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147144">Link</a></p>
<h3>Where Generalized Equitable Design Practice Meet Specific Indigenous Communities</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Kari Noe, Nurit Kirshenbaum</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148185">Link</a></p>
<h3>Critical Heritage Studies as a Lens to Understand Short Video Sharing of Intangible Cultural Heritage on Douyin</h3>
<p>Authors: Huanchen Wang, Minzhu Zhao, Wanyang Hu, Yuxin Ma, Zhicong Lu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147828">Link</a></p>
<h3>Cultivating Spoken Language Technologies for Unwritten Languages</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Thomas Reitmaier, Dani Kalarikalayil Raju, Ondrej Klejch, Electra Wallington, Nina Markl, Jennifer Pearson, Matt Jones, Peter Bell, Simon Robinson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147443">Link</a></p>
<h2>Indigeonus Communities and Cutural Heritage B</h2>
<h3>Partiality and Misconception: Investigating Cultural Representativeness in Text-to-Image Models</h3>
<p>Authors: Lili Zhang, Xi Liao, Zaijia Yang, Baihang Gao, Chunjie Wang, Qiuling Yang, Deshun Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148011">Link</a></p>
<h3>Examining the "Local" in ICT4D: A Postcolonial Perspective on Participation</h3>
<p>Authors: Pedro Ferreira</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146929">Link</a></p>
<h3>On the Role of Materials Experience for Novel Interactions with Digital Representations of Historical Pop-up and Movable Books</h3>
<p>Authors: Willemijn Elkhuizen, Jeff Love, Stefano Parisi, Elvin Karana</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147645">Link</a></p>
<h3>Cosmovision Of Data: An Indigenous Approach to Technologies for Self-Determination</h3>
<p>BEST_PAPER</p>
<p>Authors: Carlos Guerrero Millan, Bettina Nissen, Larissa Pschetz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148200">Link</a></p>
<h2>Learning and Teaching Technologies C</h2>
<h3>Enhancing ESL Learners' Experience and Performance through Gradual Adjustment of Video Speed during Extensive Viewing</h3>
<p>Authors: Yu-Jung Chung, Chen-Wei Hsu, Meng-Hsun Chan, Fu-Yin Cherng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147456">Link</a></p>
<h3>A Piece of Theatre: Investigating How Teachers Design LLM Chatbots to Assist Adolescent Cyberbullying Education</h3>
<p>Authors: Michael Hedderich, Natalie Bazarova, Wenting Zou, Ryun Shim, Xinda Ma, Qian Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147517">Link</a></p>
<h3>Morphing Matter for Teens: Research Processes as a Template for Cross-Disciplinary Activities</h3>
<p>Authors: Lea Albaugh, Melinda Chen, Sunniva Liu, Harshika Jain, Alisha Collins, Lining Yao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147219">Link</a></p>
<h3>Toward Supporting Adaptation: Exploring Affect’s Role in Cognitive Load when Using a Literacy Game</h3>
<p>Authors: Minghao Cai, Genaro Rebolledo Mendez, Gisele Arevalo, Sin Sze Tang, Yalmaz Abdullah, Carrie Demmans Epp</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147807">Link</a></p>
<h3>Time-Turner: A Bichronous Learning Environment to Support Positive In-class Multitasking of Online Learners</h3>
<p>BEST_PAPER</p>
<p>Authors: Sahar Mavali, Dongwook Yoon, Luanne Sinnamon, Sidney Fels</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147103">Link</a></p>
<h2>Movement and Motor Learning A</h2>
<h3>Real-time 3D Target Inference via Biomechanical Simulation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Hee-Seung Moon, Yi-Chi Liao, Chenyu Li, Byungjoo Lee, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147400">Link</a></p>
<h3>WAVE: Anticipatory Movement Visualization for VR Dancing</h3>
<p>Authors: Markus Laattala, Roosa Piitulainen, Nadia Ady, Monica Tamariz, Perttu Hämäläinen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147795">Link</a></p>
<h3>Designing for Human Operations on the Moon: Challenges and Opportunities of Navigational HUD Interfaces</h3>
<p>Authors: Leonie Bensch, Tommy Nilsson, Jan Wulkop, Paul Demedeiros, Nicolas Herzberger, Michael Preutenborbeck, Andreas Gerndt, Frank Flemisch, Florian Dufresne, Georgia Albuquerque, Aidan Cowley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148215">Link</a></p>
<h3>Watch This! Observational Learning in VR Promotes Better Far Transfer than Active Learning for a Fine Psychomotor Task</h3>
<p>Authors: Isabel Fitton, Elizabeth Dark, Manoela Milena Oliveira da Silva, Jeremy Dalton, Michael Proulx, Christopher Clarke, Christof Lutteroth</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146854">Link</a></p>
<h2>Movement and Motor Learning B</h2>
<h3>Metrics of Motor Learning for Analyzing Movement Mapping in Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Difeng Yu, Mantas Cibulskis, Erik Mortensen, Mark Schram Christensen, Joanna Bergström</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147038">Link</a></p>
<h3>WieldingCanvas: Interactive Sketch Canvases for Freehand Drawing in VR</h3>
<p>Authors: Xiaohui Tan, Zhenxuan He, Can Liu, Mingming Fan, Tianren Luo, Zitao Liu, Mi Tian, Teng Han, Feng Tian</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147341">Link</a></p>
<h3>Better Definition and Calculation of Throughput and Effective Parameters for Steering to Account for Subjective Speed-accuracy Tradeoffs</h3>
<p>Authors: Nobuhito Kasahara, Yosuke Oba, Shota Yamanaka, Anil Ufuk Batmaz, Wolfgang Stuerzlinger, Homei Miyashita</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147190">Link</a></p>
<h3>Design Space of Visual Feedforward And Corrective Feedback in XR-Based Motion Guidance Systems</h3>
<p>Authors: Xingyao Yu, Benjamin Lee, Michael Sedlmair</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147637">Link</a></p>
<h2>Privacy in Real Contexts</h2>
<h3>An Investigation of US Universities' Implementation of FERPA Student Directory Policies and Student Privacy Preferences</h3>
<p>Authors: Sarah Radway, Katherine Quintanilla, Cordelia Ludden, Daniel Votipka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146893">Link</a></p>
<h3>Out-of-Device Privacy Unveiled: Designing and Validating the Out-of-Device Privacy Scale (ODPS)</h3>
<p>Authors: Habiba Farzand, Karola Marky, Mohamed Khamis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147478">Link</a></p>
<h3>"We Have No Security Concerns": Understanding the Privacy-Security Nexus in Telehealth for Audiologists and Speech-Language Pathologists</h3>
<p>Authors: Faiza Tazi, Josiah Dykstra, Prashanth Rajivan, Sanchari Das</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147706">Link</a></p>
<h3>On the Feasibility of Predicting Users' Privacy Concerns using Contextual Labels and Personal Preferences</h3>
<p>Authors: yaqing YANG, Tony Li, Haojian Jin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147126">Link</a></p>
<h2>Designing for Privacy</h2>
<h3>Encoding Privacy: Sociotechnical Dynamics of Data Protection Compliance Work</h3>
<p>Authors: Rohan Grover</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147127">Link</a></p>
<h3>Redesigning Privacy with User Feedback: The Case of Zoom Attendee Attention Tracking</h3>
<p>Authors: Tony Li, Arshia Arya, Haojian Jin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148211">Link</a></p>
<h3>Designing Accessible Obfuscation Support for Blind Individuals’ Visual Privacy Management</h3>
<p>Authors: Lotus Zhang, Abigale Stangl, Tanusree Sharma, Yu-Yun Tseng, Inan Xu, Danna Gurari, Yang Wang, Leah Findlater</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147347">Link</a></p>
<h3>An Empathy-Based Sandbox Approach to Bridge the Privacy Gap among Attitudes, Goals, Knowledge, and Behaviors</h3>
<p>Authors: Chaoran Chen, Weijun Li, Wenxin Song, Yanfang Ye, Yaxing Yao, Toby Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146765">Link</a></p>
<h2>Social Activism A</h2>
<h3>"We happen to be different and different is not bad": Designing for Intersectional Fat-Positive Information-Seeking</h3>
<p>Authors: Rebecca Jonas, Ankolika De, Kelley Cotter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147459">Link</a></p>
<h3>Negotiating Sociotechnical Boundaries: Moderation Work to Counter Racist Attacks in Online Communities</h3>
<p>Authors: Qunfang Wu, Tayara Romero, Bryan Semaan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146991">Link</a></p>
<h3>Examining the Unique Online Risk Experiences and Mental Health Outcomes of LGBTQ+ versus Heterosexual Youth</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Tangila Islam Tanni, Mamtaj Akter, Joshua Anderson, Mary Jean Amon, Pamela Wisniewski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146887">Link</a></p>
<h3>“Some Hope, Many Despair”: Experiences of the Normalization within Online Dating among Queer Women in a Closeted Society</h3>
<p>Authors: Seora Park, Hajin Lim, Joonhwan Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147298">Link</a></p>
<h3>See Widely, Think Wisely: Toward Designing a Generative Multi-agent System to Burst Filter Bubbles</h3>
<p>Authors: Yu Zhang, Jingwei Sun, Li Feng, Cen Yao, Mingming Fan, Liuxin Zhang, Qianying Wang, Xin Geng, Yong Rui</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148309">Link</a></p>
<h2>Social Activism B</h2>
<h3>Socioeconomic Class in Physical Activity Wearables Research and Design</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Whitney-Jocelyn Kouaho, Daniel Epstein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147491">Link</a></p>
<h3>Engaging recently incarcerated and gang affiliated Black and Latino/a young adults in designing social collocated applications for mixed reality smart glasses through community-based participatory design workshops.</h3>
<p>BEST_PAPER</p>
<p>Authors: Richard Martinez, kurt squire</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146915">Link</a></p>
<h3>Evaluating the Experience of LGBTQ+ People Using Large Language Model Based Chatbots for Mental Health Support</h3>
<p>Authors: Zilin Ma, Yiyang Mei, Yinru Long, Zhaoyuan Su, Krzysztof Gajos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146739">Link</a></p>
<h2>Sound Interaction</h2>
<h3>Show, Not Tell: A Human-AI Collaborative Approach for Designing Sound Awareness Systems</h3>
<p>Authors: Jeremy Huang, Reyna Wood, Hriday Chhabria, Dhruv Jain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147942">Link</a></p>
<h3>Interactive Shape Sonification for Tumor Localization in Breast Cancer Surgery</h3>
<p>Authors: Laura Schütz, Trishia El Chemaly, Emmanuelle Weber, Anh Thien Doan, Jacqueline Tsai, Christoph Leuze, Bruce Daniel, Nassir Navab</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147377">Link</a></p>
<h3>Using Low-frequency Sound to Create Non-contact Sensations On and In the Body</h3>
<p>Authors: Waseem Hassan, Asier Marzo, Kasper Hornbæk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147059">Link</a></p>
<h3>Remembering through Sound: Co-creating Sound-based Mementos together with People with Blindness</h3>
<p>Authors: MinYoung Yoo, William Odom, Arne Berger, Samuel Barnett, Sadhbh Kenny, Priscilla Lo, Samien Shamsher, Gillian Russell, Lauren Knight</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147012">Link</a></p>
<h2>Working with Data B</h2>
<h3>Automatic Macro Mining from Interaction Traces at Scale</h3>
<p>Authors: Forrest Huang, Gang Li, Tao Li, Yang Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147479">Link</a></p>
<h3>Bridging the Gulf of Envisioning: Cognitive Challenges in Prompt Based Interactions with LLMs</h3>
<p>Authors: Hariharan Subramonyam, Christopher Pondoc, Colleen Seifert, Maneesh Agrawala, Roy Pea</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147633">Link</a></p>
<h3>If in a Crowdsourced Data Annotation Pipeline, a GPT-4</h3>
<p>Authors: Zeyu He, Chieh-Yang Huang, Chien-Kuang Ding, Shaurya Rohatgi, Ting-Hao Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148078">Link</a></p>
<h3>SEAM-EZ: Simplifying Stateful Analytics through Visual Programming</h3>
<p>Authors: Zhengyan Yu, Hun Namkung, Jiang Guo, Henry Milner, Joel Goldfoot, Yang Wang, Vyas Sekar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146955">Link</a></p>
<h3>Spreadsheets on Interactive Surfaces: Breaking through the Grid with the Pen</h3>
<p>Authors: Vincent Cavez, Caroline Appert, Emmanuel Pietriga</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150829">Link</a></p>
<h2>Working Practices and Tools A</h2>
<h3>Lessons From Working in the Metaverse: Challenges, Choices, and Implications from a Case Study</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Hyanghee Park, Daehwan Ahn, Joonhwan Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148220">Link</a></p>
<h3>ChunkyEdit: Text-first video interview editing via chunking</h3>
<p>Authors: Mackenzie Leake, Wilmot Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148086">Link</a></p>
<h3>The Hidden Toll of Instant Messaging Use in Remote Work: Interaction Dynamics Between Subordinates and Supervisors</h3>
<p>Authors: Chia Hsin Lee, Chien Wen (Tina) Yuan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147176">Link</a></p>
<h3>"If the Machine Is As Good As Me, Then What Use Am I?" – How the Use of ChatGPT Changes Young Professionals' Perception of Productivity and Accomplishment</h3>
<p>Authors: Charlotte Kobiella, Yarhy Flores López, Franz Waltenberger, Fiona Draxler, Albrecht Schmidt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148304">Link</a></p>
<h3>Analysis and Implementation of Nanotargeting on LinkedIn Based on Publicly Available Non-PII</h3>
<p>Authors: Angel Merino, José González-Cabañas, Ángel Cuevas, Rubén Cuevas</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147940">Link</a></p>
<h2>Assistive Technologies for Learning and Information with Neurodiversity</h2>
<h3>Discovering Accessible Data Visualizations for People with ADHD</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Tien Tran, Hae-Na Lee, Ji Hwan Park</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147522">Link</a></p>
<h3>Collaborative School Mental Health System: Leveraging a Conversational Agent for Enhancing Children's Executive Function</h3>
<p>Authors: Doeun Park, Myounglee Choo, Minseo Cho, Jinwoo Kim, Yee-Jin Shin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146654">Link</a></p>
<h3>Examining the Use of VR as a Study Aid for University Students with ADHD</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Isabelle Cuber, Juliana Goncalves de Souza, Irene Jacobs, Caroline Lowman, David Shepherd, Thomas Fritz, Joshua Langberg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148326">Link</a></p>
<h3>Narrating Routines through Game Dynamics: Impact of a Gamified Routine Management App for Autistic Individuals</h3>
<p>Authors: Bogoan Kim, Dayoung Jeong, Hwajung Hong, Kyungsik Han</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147891">Link</a></p>
<h3>StarRescue: the Design and Evaluation of A Turn-Taking Collaborative Game for Facilitating Autistic Children's Social Skills</h3>
<p>Authors: Rongqi Bei, Yajie Liu, Yihe Wang, Yuxuan Huang, Ming Li, Yuhang Zhao, Xin Tong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147262">Link</a></p>
<h2>Smart Homes and Cities</h2>
<h3>Better to Ask Than Assume: Proactive Voice Assistants’ Communication Strategies That Respect User Agency in a Smart Home Environment</h3>
<p>Authors: Jeesun Oh, Wooseok Kim, Sungbae Kim, Hyeonjeong Im, Sangsu Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147244">Link</a></p>
<h3>Signs of the Smart City: Exploring the Limits and Opportunities of Transparency</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Eric Corbett, Graham Dove</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147824">Link</a></p>
<h3>More than just informed: The importance of consent facets in smart homes</h3>
<p>Authors: Yi-Shyuan Chiang, Omar Khan, Adam Bates, Camille Cobb</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148007">Link</a></p>
<h3>Connecting Home: Human-Centric Setup Automation in the Augmented Smart Home</h3>
<p>Authors: Marius Schenkluhn, Michael Knierim, Francisco Kiss, Christof Weinhardt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147010">Link</a></p>
<h3>FLUID-IoT : Flexible and Fine-Grained Access Control in Shared IoT Environments via Multi-user UI Distribution</h3>
<p>Authors: Sunjae Lee, Minwoo Jeong, Daye Song, Junyoung Choi, Seoyun Son, Jean Song, Insik Shin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147714">Link</a></p>
<h2>Online Communities: Engagement B</h2>
<h3>Not What it Used to Be: Characterizing Content and User-base Changes in Newly Created Online Communities</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Alex Atcheson, Vinay Koshy, Karrie Karahalios</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147485">Link</a></p>
<h3>Observer Effect in Social Media Use</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Koustuv Saha, Pranshu Gupta, Gloria Mark, Emre Kiciman, Munmun De Choudhury</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148032">Link</a></p>
<h3>Choosing What You Want Versus Getting What You Want: An Experiment with Choice in Video Ad Placement</h3>
<p>Authors: Silas Hsu, Karrie Karahalios</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147760">Link</a></p>
<h3>Recordkeeping in Voice-based Remote Community Engagement</h3>
<p>Authors: Md Adnanul Islam, Dan Richardson, Manika Saha, Delvin Varghese, Tom Bartindale, Pratyasha Saha, Muhamad Risqi U. Saputra, Patrick Olivier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148203">Link</a></p>
<h3>Behind the Pup-ularity Curtain: Understanding the Motivations, Challenges, and Work Performed in Creating and Managing Pet Influencer Accounts</h3>
<p>Authors: Suhyeon Yoo, Kevin Pu, Khai Truong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147143">Link</a></p>
<h2>Exercising and Sports</h2>
<h3>Exploring Opportunities for Augmenting Homes to Support Exercising</h3>
<p>Authors: Michelle Adiwangsa, Penny Sweetser, Duncan Stevenson, Hanna Suominen, Mingze Xi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148103">Link</a></p>
<h3>Grand Challenges in SportsHCI</h3>
<p>Authors: Don Samitha Elvitigala, Armağan Karahanoğlu, Andrii Matviienko, Laia Turmo Vidal, Dees Postma, Michael Jones, Maria Montoya, Daniel Harrison, Lars Elbæk, Florian Daiber, Lisa Burr, Rakesh Patibanda, Paolo Buono, Perttu Hämäläinen, Robby van Delden, Regina Bernhaupt, Xipei Ren, Vincent van Rheden, Fabio Zambetta, Elise van den Hoven, Carine Lallemand, Dennis Reidsma, Florian Mueller</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146749">Link</a></p>
<h3>Enhancing Home Exercise Experiences with Video Motion-Tracking for Automatic Display Height Adjustment</h3>
<p>Authors: Xinyu Chen, Yuqi Li, Jintao Chen, Jiabao Li, Chong Wang, Pinyan Tang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147402">Link</a></p>
<h3>Born to Run, Programmed to Play: Mapping the Extended Reality Exergames Landscape</h3>
<p>Authors: Sukran Karaosmanoglu, Sebastian Cmentowski, Lennart Nacke, Frank Steinicke</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148327">Link</a></p>
<h3>Is it just a score? Understanding Training Load Management Practices Beyond Sports Tracking</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Armağan Karahanoğlu, Aykut Coşkun, Dees Postma, Bouke Scheltinga, Ruben Gouveia, Dennis Reidsma, Jasper Reenalda</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147430">Link</a></p>
<h2>Autonomous Vehicles</h2>
<h3>Exploring the Impact of Interconnected External Interfaces in Autonomous Vehicles on Pedestrian Safety and Experience</h3>
<p>Authors: Tram Tran, Callum Parker, Marius Hoggenmüller, Yiyuan Wang, Martin Tomitsch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148231">Link</a></p>
<h3>"It Must Be Gesturing Towards Me": Gesture-Based Interaction between Autonomous Vehicles and Pedestrians</h3>
<p>Authors: Xiang Chang, Zihe Chen, Xiaoyan Dong, Yuxin Cai, Tingmin Yan, Haolin Cai, Zherui Zhou, Guyue Zhou, Jiangtao Gong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147022">Link</a></p>
<h3>Multi-Modal eHMIs: The Relative Impact of Light and Sound in AV-Pedestrian Interaction</h3>
<p>Authors: Debargha Dey, Toros Senan, Bart Hengeveld, Mark Colley, Azra Habibovic, Wendy Ju</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148159">Link</a></p>
<h3>Light it Up: Evaluating Versatile Autonomous Vehicle-Cyclist External Human-Machine Interfaces</h3>
<p>Authors: Ammar Al-Taie, Graham Wilson, Euan Freeman, Frank Pollick, Stephen Brewster</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148184">Link</a></p>
<h3>One Size Does Not Fit All: Designing and Evaluating Criticality-Adaptive Displays in Highly Automated Vehicles</h3>
<p>Authors: Yaohan Ding, Lesong Jia, Na Du</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147703">Link</a></p>
<h2>Locomotion in Virtual Environments</h2>
<h3>Doorways Do Not Always Cause Forgetting: Studying the Effect of Locomotion Technique and Doorway Visualization in Virtual Reality</h3>
<p>Authors: Thomas van Gemert, Sean Chew, Yiannis Kalaitzoglou, Joanna Bergström</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148003">Link</a></p>
<p>Abstract: The “doorway effect” predicts that crossing an environmental boundary affects memory negatively. In virtual reality (VR), we can design the crossing and the appearance of such boundaries in non-realistic ways. However, it is unclear whether locomotion techniques like teleportation, which avoid crossing the boundary altogether, still induce the effect. Furthermore, it is unclear how different appearances of a doorway act as a boundary and thus induce the effect. To address these questions, we conducted two lab studies. First, we conceptually replicated prior doorway effect studies in VR using natural walking and teleportation. Second, we investigated the effect of five doorway visualizations, ranging from doors to portals. The results show no difference in object recognition performance due to the presence of a doorway, locomotion technique, or doorway visualization. We discuss the implications of these findings on the role of boundaries in event-based memory and the design of boundary interactions in VR.</p>
<h3>Exploring Experience Gaps Between Active and Passive Users During Multi-user Locomotion in VR</h3>
<p>Authors: Tianren Luo, Fenglin Lu, Jiafu Lv, Xiaohui Tan, Chang Liu, Fangzhi Yan, Jin Huang, Chun Yu, Teng Han, Feng Tian</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146669">Link</a></p>
<p>Abstract: Multi-user locomotion in VR has grown increasingly common, posing numerous challenges. A key factor contributing to these challenges is the gaps in experience between active and passive users during co-locomotion. Yet, there remains a limited understanding of how and to what extent these experiential gaps manifest in diverse multi-user co-locomotion scenarios. This paper systematically explores the gaps in physiological and psychological experience indicators between active and passive users across various locomotion situations. Such situations include when active users walk, fly by joystick, or teleport, and passive users stand still or look around. We also assess the impact of factors such as sub-locomotion type, speed/teleport-interval, motion sickness susceptibility, etc. Accordingly, we delineate acceptability disparities between active and passive users, offering insights into leveraging notable experimental findings to mitigate discomfort during co-locomotion through avoidance or intervention.</p>
<h3>Investigating Virtual Reality Locomotion Techniques with Blind People</h3>
<p>Authors: Renato Ribeiro, Inês Gonçalves, Manuel Piçarra, Letícia Seixas Pereira, Carlos Duarte, André Rodrigues, João Guerreiro</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147547">Link</a></p>
<p>Abstract: Many Virtual Reality (VR) locomotion techniques have been proposed, but those explored for and with blind people are often custom-made or require specialized equipment. Consequently, it is unclear how popular techniques can support blind people's VR locomotion, blocking access to most VR experiences. We implemented three popular techniques -- Arm Swinging, Linear Movement (joystick-based steering), and Point &amp; Teleport -- with minor adaptations for accessibility. We conducted a study with 14 blind participants consisting of navigation tasks with these techniques and a semi-structured interview. We found no differences in overall performance (e.g., completion time), but contrasting preferences. Findings highlight the challenges and advantages of each technique and participants’ strategies. We discuss, among others, how augmenting the techniques enabled blind people to navigate in VR, the greater control of movement of Arm Swinging, the simplicity and familiarity of Linear Movement, and the potential for efficiency and for scanning the environment of Point &amp; Teleport. </p>
<h3>The Effect of Spatial Audio on Curvature Gains in VR Redirected Walking</h3>
<p>Authors: Maarten Gerritse, Michael Rietzler, Christof van Nimwegen, Julian Frommel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146928">Link</a></p>
<p>Abstract: Redirected walking (RDW) is a technique that allows users to navigate larger physical spaces in virtual reality (VR) environments by manipulating the users' view of the virtual world. In this study, we investigate the effect of adding spatial audio elements to curvature gains in RDW aiming to increase the perceptual threshold for the manipulation and allowing for higher levels of unnoticed redirection. We conducted a user study (n = 18), evaluating perceptual thresholds across conditions with and without spatial audio elements across different curvature gains. We found that spatial audio can significantly increase thresholds with a large effect size. This finding indicates the value of spatial audio for RDW. It could facilitate higher levels of redirection, while maintaining a convincing experience, leading to more freedom to navigate virtual environments in even smaller physical spaces.</p>
<h3>Stacked Retargeting: Combining Redirected Walking and Hand Redirection to Expand Haptic Retargeting's Coverage</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Aldrich Clarence, Jarrod Knibbe, Maxime Cordeil, Michael Wybrow</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148329">Link</a></p>
<p>Abstract: We present Stacked Retargeting—combining haptic retargeting and redirected walking—to maximise the use of passive proxy objects for VR haptics. Haptic retargeting work to date has considered stationary reaching and grasping interactions, and this inherently limits a proxy object’s scope. We consider exactly where this reaching and grasping occurs from, to increase the potential of each proxy. We present (a) a staged approach to implementing Stacked Retargeting, (b) five redirected walking approaches that enable users to arrive anywhere at the site of interaction, and (c) a usability magnitude estimation evaluation of these techniques. We demonstrate how Stacked Retargeting can meaningfully increase the practical use of proxy objects for VR haptics without degrading the user experience.</p>
<h2>Supporting Communication and Intimacy</h2>
<h3>Rehearsal: Simulating Conflict to Teach Conflict Resolution</h3>
<p>Authors: Omar Shaikh, Valentino Chai, Michele Gelfand, Diyi Yang, Michael Bernstein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147513">Link</a></p>
<p>Abstract: Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill -- one that can be learned through deliberate practice -- but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual "what if?" scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own setting. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations. In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training. Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67%, while doubling their use of cooperative strategies. Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills.</p>
<h3>Seeking Soulmate via Voice: Understanding Promises and Challenges of Online Synchronized Voice-Based Mobile Dating</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Chenxinran Shen, Yan Xu, RAY LC, Zhicong Lu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147442">Link</a></p>
<p>Abstract: Online dating has become a popular way for individuals to connect with potential romantic partners. Many dating apps use personal profiles that include a headshot and self-description, allowing users to present themselves and search for compatible matches. However, this traditional model often has limitations. In this study, we explore a non-traditional voice-based dating app called “Soul”. Unlike traditional platforms that rely heavily on profile information, Soul facilitates user interactions through voice-based communication. We conducted semi-structured interviews with 18 dedicated Soul users to investigate how they engage with the platform and perceive themselves and others in this unique dating environment. Our findings indicate that the role of voice as a moderator influences impression management and shapes perceptions between the sender and the receiver of the voice. Additionally, the synchronous voice-based and community-based dating model offers benefits to users in the Chinese cultural context. Our study contributes to understanding the affordances introduced by voice-based interactions in online dating in China.</p>
<h3>A Change of Scenery: Transformative Insights from Retrospective VR Embodied Perspective-Taking of Conflict With a Close Other</h3>
<p>Authors: Seraphina Yong, Leo Cui, Evan Suma Rosenberg, Svetlana Yarosh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147966">Link</a></p>
<p>Abstract: Close relationships are irreplaceable social resources, yet prone to high-risk conflict. Building on findings from the fields of HCI, virtual reality, and behavioral therapy, we evaluate the unexplored potential of retrospective VR-embodied perspective-taking to fundamentally influence conflict resolution in close others. We develop a biographically-accurate Retrospective Embodied Perspective-Taking system (REPT) and conduct a mixed-methods evaluation of its influence on close others’ reflection and communication, compared to video-based reflection methods currently used in therapy (treatment as usual, or TAU). Our key findings provide evidence that REPT was able to significantly improve communication skills and positive sentiment of both partners during conflict, over TAU. The qualitative data also indicated that REPT surpassed basic perspective-taking by exclusively stimulating users to embody and reflect on both their own and their partner’s experiences at the same level. In light of these findings, we provide implications and an agenda for social embodiment in HCI design: conceptualizing the use of ‘embodied social cognition,’ and envisioning socially-embodied experiences as an interactive context.</p>
<h3>"Delete it and Move On": Digital Management of Shared Sexual Content after a Breakup</h3>
<p>Authors: Kathryn Coduto, Allison McDonald</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147003">Link</a></p>
<p>Abstract: Sexting is a common and healthy behavior in romantic and sexual relationships. However, not every relationship lasts. When a relationship ends, the fate of sexual content that was previously shared can be a source of discomfort, anxiety, or fear for individuals who may no longer trust their former partners. In extreme cases, intimate content may be leaked or misused by its recipient. To investigate opportunities for building safer sexting tools with breakups in mind, we conducted a survey with 310 U.S. adults who have sexted in the last year. We asked about their sexting practices, communication practices within their relationship about sexting, and preferences for their own sexting content after a breakup. We find that most people save sexts in some form, either actively (e.g., via screenshots) or passively (e.g., in chat history). There is no consensus around what one should do with an ex's content: although most (55%) want their content to be deleted at the end of a relationship, many others don't care (25%) or even hope their ex keeps the material (11%). However, most have never spoken to their partner about this preference. We end with design recommendations that support sexting while keeping the entire relationship lifecycle in mind.</p>
<h3>Sharing Frissons among Online Video Viewers: Exploring the Design of Affective Communication for Aesthetic Chills</h3>
<p>Authors: Zeyu Huang, Xinyi Cao, Yuanhao Zhang, Xiaojuan Ma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147357">Link</a></p>
<p>Abstract: On online video platforms, viewers often lack a channel to sense others’ and express their affective state on the fly compared to co-located group-viewing. This study explored the design of complementary affective communication specifically for effortless, spontaneous sharing of frissons during video watching. Also known as aesthetic chills, frissons are instant psycho-physiological reactions like goosebumps and shivers to arousing stimuli. We proposed an approach that unobtrusively detects viewers’ frissons using skin electrodermal activity sensors and presents the aggregated data alongside online videos. Following a design process of brainstorming, focus group interview (N=7), and design iterations, we proposed three different designs to encode viewers’ frisson experiences, namely, ambient light, icon, and vibration. A mixed-methods within-subject study (N=48) suggested that our approach offers a non-intrusive and efficient way to share viewers’ frisson moments, increases the social presence of others as if watching together, and can create affective contagion among viewers.</p>
<h2>Arts and Creative AI</h2>
<h3>Art or Artifice? Large Language Models and the False Promise of Creativity</h3>
<p>Authors: Tuhin Chakrabarty, Philippe Laban, Divyansh Agarwal, Smaranda Muresan, Chien-Sheng Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147597">Link</a></p>
<p>Abstract: Researchers have argued that large language models (LLMs) exhibit high-quality writing capabilities from blogs to stories. However, evaluating objectively the creativity of a piece of writing is challenging. Inspired by the Torrance Test of Creative Thinking (TTCT), which measures creativity as a process, we use the Consensual Assessment Technique and propose Torrance Test of Creative Writing (TTCW) to evaluate creativity as product. TTCW consists of 14 binary tests organized into the original dimensions of Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative writers and implement a human assessment of 48 stories written either by professional authors or LLMs using TTCW. Our analysis shows that LLM-generated stories pass 3-10X less TTCW tests than stories written by professionals. In addition, we explore the use of LLMs as assessors to automate the TTCW evaluation, revealing that none of the LLMs positively correlate with the expert assessments.</p>
<h3>Authors' Values and Attitudes Towards AI-bridged Scalable Personalization of Creative Language Arts</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Taewook Kim, Hyomin Han, Eytan Adar, Matthew Kay, John Chung</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147512">Link</a></p>
<p>Abstract: Generative AI has the potential to create a new form of interactive media: AI-bridged creative language arts (CLA), which bridge the author and audience by personalizing the author's vision to the audience's context and taste at scale. However, it is unclear what the authors' values and attitudes would be regarding AI-bridged CLA. To identify these values and attitudes, we conducted an interview study with 18 authors across eight genres (e.g., poetry, comics) by presenting speculative but realistic AI-bridged CLA scenarios. We identified three benefits derived from the dynamics between author, artifact, and audience: those that 1) authors get from the process, 2) audiences get from the artifact, and 3) authors get from the audience. We found how AI-bridged CLA would either promote or reduce these benefits, along with authors' concerns. We hope our investigation hints at how AI can provide intriguing experiences to CLA audiences while promoting authors' values.</p>
<h3>Generative AI in Creative Practice: ML-Artist Folk Theories of T2I Use, Harm, and Harm-Reduction</h3>
<p>Authors: Renee Shelby, Shalaleh Rismani, Negar Rostamzadeh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148258">Link</a></p>
<p>Abstract: Understanding how communities experience algorithms is necessary to mitigate potential harmful impacts. This paper presents folk theories of text-to-image (T2I) models to enrich understanding of how artist communities experience creative machine learning systems. This research draws on data collected from a workshop with 15 artists from 10 countries who incorporate T2I models in their creative practice. Through reflexive thematic analysis of workshop data, we highlight artist folk theories of T2I use, harm, and harm reduction. Folk theories of use envision T2I models as an artistic medium, a mundane tool, and locate true creativity as rising above model affordances. Theories of harm articulate T2I models as harmed by engineering efforts to eliminate glitches and product policy efforts to limit functionality. Theories of harm-reduction orient towards protecting T2I models for creative practice through transparency and distributed governance. We examine how these theories relate, and conclude by discussing how folk theorization informs responsible AI efforts.</p>
<h3>Jess+: AI and robotics with inclusive music-making</h3>
<p>Authors: Craig Vear, Adrian Hazzard, Solomiya Moroz, Johann Benerradi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147296">Link</a></p>
<p>Abstract: This paper discusses the findings from a cross-sector research project investigating how a digital score created using AI and robot-ics might stimulate new creative opportunities and relationships within the practices of an inclusive music ensemble. Through the concept of a digital score [65], AI and a robotic arm were introduced into an ensemble’s musical practice to evaluate the impact and ben-efits of using autonomous systems to challenge barriers around a disabled musician's access to creative music-making. Throughout the development process we placed an emphasis on involvement and togetherness of not only the AI and robots' contribution to shared creativity amongst the ensemble, but also to the social as-pects of the creative process across the team of musicians, develop-ers, researchers and supporting organisations. The findings were surprising with many aspects of the project exceeding the expecta-tions of the original aims. In short, all the musicians benefited from the introduction of these unfamiliar technologies with practices enhanced and relationships transformed. </p>
<h2>Assistive Interactions: Navigation and Visualisation for Users Who are Blind or Low Vision</h2>
<h3>Navigating Real-World Challenges: A Quadruped Robot Guiding System for Visually Impaired People in Diverse Environments</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: SHAOJUN CAI, Ashwin Ram, Zhengtai Gou, Mohd Alqama Shaikh, Yu-An Chen, Yingjia Wan, Kotaro Hara, Shengdong Zhao, David Hsu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147169">Link</a></p>
<h3>TADA: Making Node-link Diagrams Accessible to Blind and Low-Vision People</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yichun Zhao, Miguel Nacenta, Mahadeo Sukhai, Sowmya Somanath</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147533">Link</a></p>
<h3>Umwelt: Accessible Structured Editing of Multi-Modal Data Representations</h3>
<p>Authors: Jonathan Zong, Isabella Pedraza Pineros, Mengzhu (Katie) Chen, Daniel Hajas, Arvind Satyanarayan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146952">Link</a></p>
<h3>How Do Low-Vision Individuals Experience Information Visualization?</h3>
<p>Authors: Yanan Wang, Yuhang Zhao, Yea-Seul Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147037">Link</a></p>
<h3>“Customization is Key”: Reconfigurable Textual Tokens for Accessible Data Visualizations</h3>
<p>Authors: Shuli Jones, Isabella Pedraza Pineros, Daniel Hajas, Jonathan Zong, Arvind Satyanarayan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146771">Link</a></p>
<h2>Attention: multitasking and Interruptions</h2>
<h3>Supporting Task Switching with Reinforcement Learning</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Alexander Lingler, Dinara Talypova, Jussi Jokinen, Antti Oulasvirta, Philipp Wintersberger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147418">Link</a></p>
<h3>Augmented Reality Cues Facilitate Task Resumption after Interruptions in Computer-Based and Physical Tasks</h3>
<p>Authors: Kilian Bahnsen, Lucas Tiemann, Lucas Plabst, Tobias Grundgeiger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147918">Link</a></p>
<h3>Heads-Up Multitasker: Simulating Attention Switching On Optical Head-Mounted Displays</h3>
<p>Authors: Yunpeng Bai, Aleksi Ikkala, Antti Oulasvirta, Shengdong Zhao, Lucia Wang, Pengzhi Yang, Peisen Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147957">Link</a></p>
<h3>SplitBody: Reducing Mental Workload while Multitasking via Muscle Stimulation</h3>
<p>BEST_PAPER</p>
<p>Authors: Romain Nith, Yun Ho, Pedro Lopes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146989">Link</a></p>
<h3>Improving Attention Using Wearables via Haptic and Multimodal Rhythmic Stimuli</h3>
<p>Authors: Nathan Whitmore, Samantha Chan, Jingru Zhang, Patrick Chwalek, Sam Chin, Pattie Maes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147209">Link</a></p>
<h2>Creative Media and AI</h2>
<h3>ContextCam: Bridging Context Awareness with Creative Human-AI Image Co-Creation</h3>
<p>Authors: Xianzhe Fan, Zihan Wu, Chun Yu, Fenggui Rao, Weinan Shi, Teng Tu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148054">Link</a></p>
<p>Abstract: The rapid advancement of AI-generated content (AIGC) promises to transform various aspects of human life significantly. This work particularly focuses on the potential of AIGC to revolutionize image creation, such as photography and self-expression. We introduce ContextCam, a novel human-AI image co-creation system that integrates context awareness with mainstream AIGC technologies like Stable Diffusion. ContextCam provides user's image creation process with inspiration by extracting relevant contextual data, and leverages Large Language Model-based (LLM) multi-agents to co-create images with the user. A study with 16 participants and 136 scenarios revealed that ContextCam was well-received, showcasing personalized and diverse outputs as well as interesting user behavior patterns. Participants provided positive feedback on their engagement and enjoyment when using ContextCam, and acknowledged its ability to inspire creativity.</p>
<h3>InkBrush: A Sketching Tool for 3D Ink Painting</h3>
<p>Authors: Zhihao Yao, Qirui Sun, Beituo Liu, Yao Lu, Guanhong Liu, Xing-Dong Yang, Haipeng Mi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147709">Link</a></p>
<p>Abstract: InkBrush is a new sketch-based 3D drawing tool for creating 3D ink paintings using free-form 3D ink strokes. It offers a digital calligraphy brush and various editing tools to generate realistic ink-like brush strokes with attributes like hairy edges, ink drips, and scattered dots. Users can adjust parameters such as moisture, color, darkness, dryness, and stroke style to customize the appearance of the brush strokes. The development of InkBrush was guided by a design study involving artists and designers. It was developed as a plugin for Blender, a popular 3D modeling tool, and its effectiveness and usability were evaluated through a user study involving 75 participants. Preliminary feedback from the participants was overwhelmingly positive, indicating that InkBrush was intuitive and easy to use. Following this, we also sought in-depth assessments from experts in ink painting and 3D design. Their evaluations further demonstrated the effectiveness of InkBrush.</p>
<h3>TutoAI: a cross-domain framework for AI-assisted mixed-media tutorial creation on physical tasks</h3>
<p>Authors: Yuexi Chen, Vlad Morariu, Anh Truong, Zhicheng Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147303">Link</a></p>
<p>Abstract: Mixed-media tutorials, which integrate videos, images, text, and diagrams to teach procedural skills, offer more browsable alternatives than timeline-based videos. However, manually creating such tutorials is tedious, and existing automated solutions are often restricted to a particular domain. While AI models hold promise, it is unclear how to effectively harness their powers, given the multi-modal data involved and the vast landscape of models. We present TutoAI, a cross-domain framework for AI-assisted mixed-media tutorial creation on physical tasks. First, we distill common tutorial components by surveying existing work; then, we present an approach to identify, assemble, and evaluate AI models for component extraction; finally, we propose guidelines for designing user interfaces (UI) that support tutorial creation based on AI-generated components. We show that TutoAI has achieved higher or similar quality compared to a baseline model in preliminary user studies. </p>
<h3>OutlineSpark: Igniting AI-powered Presentation Slides Creation from Computational Notebooks through Outlines</h3>
<p>Authors: Fengjie Wang, Yanna Lin, Leni Yang, Haotian Li, Mingyang Gu, Min Zhu, Huamin Qu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147593">Link</a></p>
<p>Abstract: Computational notebooks are widely utilized for exploration and analysis. However, creating slides to communicate analysis results from these notebooks is quite tedious and time-consuming. Researchers have proposed automatic systems for generating slides from notebooks, which, however, often do not consider the process of users conceiving and organizing their messages from massive code cells. Those systems ask users to go directly into the slide creation process, which causes potentially ill-structured slides and burdens in further refinement. Inspired by the common and widely recommended slide creation practice: drafting outlines first and then adding concrete content, we introduce OutlineSpark, an AI-powered slide creation tool that generates slides from a slide outline written by the user. The tool automatically retrieves relevant notebook cells based on the outlines and converts them into slide content. We evaluated OutlineSpark with 12 users. Both the quantitative and qualitative feedback from the participants verify its effectiveness and usability.</p>
<h3>Prompting for Discovery: Flexible Sense-Making for AI Art-Making with Dreamsheets</h3>
<p>Authors: Shm Almeda, J.D. Zamfirescu-Pereira, Kyu Won Kim, Pradeep Mani Rathnam, Bjoern Hartmann</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147361">Link</a></p>
<p>Abstract: Design space exploration (DSE) for Text-to-Image (TTI) models entails navigating a vast, opaque space of possible image outputs, through a commensurately vast input space of hyperparameters and prompt text. Perceptually small movements in prompt-space can surface unexpectedly disparate images. How can interfaces support end-users in reliably steering prompt-space explorations towards interesting results?
Our design probe, DreamSheets, supports user-composed exploration strategies with LLM-assisted prompt construction and large-scale simultaneous display of generated results, hosted in a spreadsheet interface. 
Two studies, a preliminary lab study and an extended two-week study where five expert artists developed custom TTI sheet-systems, reveal various strategies for targeted TTI design space exploration---such as using templated text generation to define and layer semantic <code>axes'' for exploration. We identified patterns in exploratory structures across our participants' sheet-systems: configurable exploration</code>units'' that we distill into a UI mockup, and generalizable UI components to guide future interfaces.</p>
<h2>Digital Healthcare and Communication</h2>
<h3>A case for "little English" in Nurse Notes from the Telehealth Intervention Program for Seniors: Implications for Future Design and Research</h3>
<p>Authors: Veena Calambur, DongWhan Jun, Melody Schiaffino, Zhan Zhang, Jina Huh-Yoo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146808">Link</a></p>
<p>Abstract: Community telehealth programs (CTPs) enable low-income older adults to receive telehealth services in community settings (e.g., retirement homes). The Telehealth Intervention Program for Seniors (TIPS) is a CTP that provides vital sign monitoring services managed by remote nurses. TIPS has successfully recruited and retained Limited English Proficient (LEP) participants, but lack of language services might hinder LEP participants' equitable access to care. We conducted a two-part mixed-methods study. We first qualitatively analyzed 40 nurse notes to identify challenges nurses encounter gathering information due to language barriers and the workarounds they employed to address these. We then tested our qualitative findings on 23,975 nurse notes to quantify and compare how these challenges and workarounds scale between LEP and English-proficient TIPS participants. We present future research implications beyond low-hanging solutions, such as automated translation services, and discuss how novel technological solutions can support and ameliorate nurse workarounds and caregiver burden.</p>
<h3>Leveraging Implementation Science in Human-Centred Design for Digital Health</h3>
<p>Authors: Alex Waddell, Joshua Paolo Seguin, Ling Wu, Peta Stragalinos, Joe Wherton, Jessica Watterson, Christopher Prawira, Patrick Olivier, Victoria Manning, Dan Lubman, Jasmin Grigg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146775">Link</a></p>
<p>Abstract: There are increasing concerns that digital interventions in healthcare settings could be better designed for scalable and sustained use. Implementation science is the scientific study of how to embed evidence-based interventions in practice. Calls to integrate implementation science and Human-Centred Design methods have focused on integrating design methods within implementation science processes. By contrast, we present a novel approach to integrating implementation science within Human-Centred Design for digital health interventions. Our approach leverages the socio-technical Nonadoption, abandonment, scale-up, spread, and sustainability (NASSS) framework within the distinct phases of the Double Diamond process. To illustrate our proposal we demonstrate its application in the redesign of a brief health promotion intervention to reduce the risk of alcohol-attributable breast cancer in women attending routine mammography. We discuss reflections on the approach and implications for future research that targets implementation within design. </p>
<h3>Promoting Engagement in Remote Patient Monitoring Using Asynchronous Messaging</h3>
<p>Authors: Salaar Liaqat, Daniyal Liaqat, Nisha Patel, Tatiana Son, Tiago Falk, Robert Wu, Andrea Gershon, Alex Mariakakis, Eyal de Lara</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148308">Link</a></p>
<p>Abstract: Remote patient monitoring is becoming increasingly instrumental to healthcare delivery but can substantially hamper the interpersonal communication that underlies standard clinical practice. In this work, we explore the benefits imparted to patients, clinicians, and researchers by an asynchronous messaging feature within a platform called COVIDFree@Home. We created COVIDFree@Home to assist the healthcare system in a large metropolitan city in North America during the COVID-19 pandemic. Clinicians used COVIDFree@Home to monitor the self-reported symptoms and vital signs of over 350 COVID-19 patients post-infection. Using thematic analysis of user-initiated messages, we found the messaging feature helped maintain protocol adherence while allowing patients to ask questions about their health and clinicians to convey empathetic care. This feedback cycle also led to higher quality data for hospitalization prediction, as the revisions significantly improved the AUROC of a machine learning model trained on demographic variables, vital signs data, and self-reported symptoms from 0.53 to 0.59. </p>
<h3>To Reach the Unreachable: Exploring the Potential of VR Hand Redirection for Upper Limb Rehabilitation</h3>
<p>Authors: Peixuan Xiong, Yukai Zhang, Nandi Zhang, Shihan Fu, Xin Li, Yadan Zheng, Jinni ZHOU, Xiquan Hu, Mingming Fan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147545">Link</a></p>
<p>Abstract: Rehabilitation therapies are widely employed to assist people with motor impairments in regaining control over their affected body parts. Nevertheless, factors such as fatigue and low self-efficacy can hinder patient compliance during extensive rehabilitation processes. Utilizing hand redirection in virtual reality (VR) enables patients to accomplish seemingly more challenging tasks, thereby bolstering their motivation and confidence. While previous research has investigated user experience and hand redirection among able-bodied people, its effects on motor-impaired people remain unexplored. In this paper, we present a VR rehabilitation application that harnesses hand redirection. Through a user study and semi-structured interviews, we examine the impact of hand redirection on the rehabilitation experiences of people with motor impairments and its potential to enhance their motivation for upper limb rehabilitation. Our findings suggest that patients are not sensitive to hand movement inconsistency, and the majority express interest in incorporating hand redirection into future long-term VR rehabilitation programs.</p>
<h3>Investigating the Mechanisms by which Prevalent Online Community Behaviors Influence Responses to Misinformation: Do Perceived Norms Really Act as a Mediator?</h3>
<p>Authors: Zhila Aghajari, Eric Baumer, Allison Lazard, Nabarun Dasgupta, Dominic DiFranzo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148042">Link</a></p>
<p>Abstract: This study addresses two currently open questions about  how behaviors of online community members influence others' responses to misinformation. First, in contrast to prior work, it directly measures norm perception to address whether (1) norm perception actually acts as a mediator, (2) others' behaviors directly influence individuals' responses to misinformation, (3) both direct and mediated effects occur. Second, it investigates norm perceptions about a behavior that is not readily observable in online communities, but is prone to misinformation, specifically, vaccination. To do so, it experimentally manipulates the prevalence of communicating about vaccination (an unobservable behavior) within an online community. The results demonstrate no evidence of a direct effect---the causal relationship between prevalence of communicating a behavior and intentions to respond to misinformation only occurs via norm perception as a mediator. The paper highlights implications of these findings for designing community-centered interventions to influence perceived norms, thereby mitigating misinformation spread and impacts.</p>
<h2>Ethics of AI</h2>
<h3>Fair Machine Guidance to Enhance Fair Decision Making in Biased People</h3>
<p>Authors: Mingzhe Yang, Hiromi Arai, Naomi Yamashita, Yukino Baba</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147109">Link</a></p>
<p>Abstract: Teaching unbiased decision-making is crucial for addressing biased decision-making in daily life. Although both raising awareness of personal biases and providing guidance on unbiased decision-making are essential, the latter topics remains under-researched. In this study, we developed and evaluated an AI system aimed at educating individuals on making unbiased decisions using fairness-aware machine learning. In a between-subjects experimental design, 99 participants who were prone to bias performed personal assessment tasks. They were divided into two groups: a) those who received AI guidance for fair decision-making before the task and b) those who received no such guidance but were informed of their biases. The results suggest that although several participants doubted the fairness of the AI system, fair machine guidance prompted them to reassess their views regarding fairness, reflect on their biases, and modify their decision-making criteria. Our findings provide insights into the design of AI systems for guiding fair decision-making in humans.</p>
<h3>Exploring the Association between Moral Foundations and Judgements of AI Behaviour</h3>
<p>Authors: Joe Brailsford, Frank Vetere, Eduardo Velloso</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147538">Link</a></p>
<p>Abstract: How do individual differences in personal morality affect perceptions and judgments of morally contentious behaviours from AI systems? By applying Moral Foundations Theory (MFT) to the context of AI, this study sought to develop a predictive Bayesian model for assessing moral judgements based on individual differences in moral constitution. Participants (N=240) were asked to assess six different scenarios, carefully designed to elicit reflection on the behaviour of AI systems. Together, with results from the Moral Foundations Questionnaire, we performed both Bayesian modelling and reflexive thematic analysis to investigate the associations between individual differences in moral foundations and judgements of the AI systems. Results revealed a mild association between individual MFT scores and judgments of AI behaviours. Qualitative responses suggested a participant’s technical understanding of AI systems, rather than intrinsic moral values, predominantly influenced their judgments, with those who judged the behaviour as wrong tending to anthropomorphise the AI systems behaviour.</p>
<h3>Which Artificial Intelligences Do People Care About Most? A Conjoint Experiment on Moral Consideration</h3>
<p>Authors: Ali Ladak, Jamie Harris, Jacy Anthis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147255">Link</a></p>
<p>Abstract: Many studies have identified particular features of artificial intelligences (AI), such as their autonomy and emotion expression, that affect the extent to which they are treated as subjects of moral consideration. However, there has not yet been a comparison of the relative importance of features as is necessary to design and understand increasingly capable, multi-faceted AI systems. We conducted an online conjoint experiment in which 1,163 participants evaluated descriptions of AIs that varied on these features. All 11 features increased how morally wrong participants considered it to harm the AIs. The largest effects were from human-like physical bodies and prosociality (i.e., emotion expression, emotion recognition, cooperation, and moral judgment). For human-computer interaction designers, the importance of prosociality suggests that, because AIs are often seen as threatening, the highest levels of moral consideration may only be granted if the AI has positive intentions.</p>
<h3>The Illusion of Artificial Inclusion</h3>
<p>Authors: William Agnew, Stevie Bergman, Jennifer Chien, Mark Diaz, Seliem El-Sayed, Jaylen Pittman, Shakir Mohamed, Kevin McKee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147179">Link</a></p>
<p>Abstract: Human participants play a central role in the development of modern artificial intelligence (AI) technology, in psychological science, and in user research. Recent advances in generative AI have attracted growing interest to the possibility of replacing human participants in these domains with AI surrogates. We survey several such "substitution proposals" to better understand the arguments for and against substituting human participants with modern generative AI. Our scoping review indicates that the recent wave of these proposals is motivated by goals such as reducing the costs of research and development work and increasing the diversity of collected data. However, these proposals ignore and ultimately conflict with foundational values of work with human participants: representation, inclusion, and understanding. This paper critically examines the principles and goals underlying human participation to help chart out paths for future work that truly centers and empowers participants.</p>
<h3>“They only care to show us the wheelchair”: disability representation in text-to-image AI models</h3>
<p>Authors: Kelly Avery Mack, Rida Qadri, Remi Denton, Shaun Kane, Cynthia Bennett</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147662">Link</a></p>
<p>Abstract: This paper reports on disability representation in images output from text-to-image (T2I) generative AI systems. Through eight focus groups with 25 people with disabilities, we found that models repeatedly presented reductive archetypes for different disabilities. Often these representations reflected broader societal stereotypes and biases, which our participants were concerned to see reproduced through T2I. Our participants discussed further challenges with using these models including the current reliance on prompt engineering to reach satisfactorily diverse results. Finally, they offered suggestions for how to improve disability representation with solutions like showing multiple, heterogeneous images for a single prompt and including the prompt with images generated. Our discussion reflects on tensions and tradeoffs we found among the diverse perspectives shared to inform future research on representation-oriented generative AI system evaluation metrics and development processes.</p>
<h2>Explainable AI</h2>
<h3>User Characteristics in Explainable AI: The Rabbit Hole of Personalization?</h3>
<p>Authors: Robert Nimmo, Marios Constantinides, Ke Zhou, Daniele Quercia, Simone Stumpf</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148017">Link</a></p>
<p>Abstract: As Artificial Intelligence (AI) becomes ubiquitous, the need for Explainable AI (XAI) has become critical for transparency and trust among users. A significant challenge in XAI is catering to diverse users, such as data scientists, domain experts, and end-users. Recent research has started to investigate how users' characteristics impact interactions with and user experience of explanations, with a view to personalizing XAI. However, are we heading down a rabbit hole by focusing on unimportant details? Our research aimed to investigate how user characteristics are related to using, understanding, and trusting an AI system that provides explanations. Our empirical study with 149 participants who interacted with an XAI system that flagged inappropriate comments showed that very few user characteristics mattered; only age and the personality trait openness influenced actual understanding. Our work provides evidence to reorient user-focused XAI research and question the pursuit of personalized XAI based on fine-grained user characteristics.</p>
<h3>Incremental XAI: Memorable Understanding of AI with Incremental Explanations</h3>
<p>Authors: Jessica Bo, Pan Hao, Brian Lim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147050">Link</a></p>
<p>Abstract: Many explainable AI (XAI) techniques strive for interpretability by providing concise salient information, such as sparse linear factors. However, users either only see inaccurate global explanations, or highly-varying local explanations. We propose to provide more detailed explanations by leveraging the human cognitive capacity to accumulate knowledge by incrementally receiving more details. Focusing on linear factor explanations (factors × values = outcome), we introduce Incremental XAI to automatically partition explanations for general and atypical instances by providing Base + Incremental factors to help users read and remember more faithful explanations. Memorability is improved by reusing base factors and reducing the number of factors shown in atypical cases. In modeling, formative, and summative user studies, we evaluated the faithfulness, memorability and understandability of Incremental XAI against baseline explanation methods. This work contributes towards more usable explanation that users can better ingrain to facilitate intuitive engagement with AI.</p>
<h3>Why the Fine, AI? The Effect of Explanation Level on Citizens' Fairness Perception of AI-based Discretion in Public Administrations</h3>
<p>Authors: Saja Aljuneidi, Wilko Heuten, Larbi Abdenebaoui, Maria Wolters, Susanne Boll</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147920">Link</a></p>
<p>Abstract: The integration of Artificial Intelligence into decision-making processes within public administration extends to AI-systems that exercise administrative discretion. This raises fairness concerns among citizens, possibly leading to AI-systems abandonment. Uncertainty persists regarding explanation elements impacting citizens' perception of fairness and technology adoption level. In a video-vignette online-survey (N=847), we investigated the impact of explanation levels on citizens' perceptions of informational fairness, distributive fairness, and system adoption level. We enhanced explanations in three stages: none, factor explanations, culminating in factor importance explanations. We found that more detailed explanations improved informational and distributive fairness perceptions, but did not affect citizens' willingness to reuse the system. Interestingly, citizens with higher AI-literacy expressed greater willingness to adopt the system, regardless of the explanation levels. Qualitative findings revealed that greater human involvement and appeal mechanisms could positively influence citizens' perceptions. Our findings highlight the importance of citizen-centered design of AI-based decision-making in public administration.</p>
<h3>EXMOS: Explanatory Model Steering through Multifaceted Explanations and Data Configurations</h3>
<p>Authors: Aditya Bhattacharya, Simone Stumpf, Lucija Gosak, Gregor Stiglic, Katrien Verbert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146863">Link</a></p>
<p>Abstract: Explanations in interactive machine-learning systems facilitate debugging and improving prediction models. However, the effectiveness of various global model-centric and data-centric explanations in aiding domain experts to detect and resolve potential data issues for model improvement remains unexplored. This research investigates the influence of data-centric and model-centric global explanations in systems that support healthcare experts in optimising models through automated and manual data configurations. We conducted quantitative (n=70) and qualitative (n=30) studies with healthcare experts to explore the impact of different explanations on trust, understandability and model improvement. Our results reveal the insufficiency of global model-centric explanations for guiding users during data configuration. Although data-centric explanations enhanced understanding of post-configuration system changes, a hybrid fusion of both explanation types demonstrated the highest effectiveness. Based on our study results, we also present design implications for effective explanation-driven interactive machine-learning systems.</p>
<h3>The Who in XAI: How AI Background Shapes Perceptions of AI Explanations</h3>
<p>Authors: Upol Ehsan, Samir Passi, Q. Vera Liao, Larry Chan, I-Hsiang Lee, Michael Muller, Mark Riedl</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147327">Link</a></p>
<p>Abstract: Explainability of AI systems is critical for users to take informed actions. Understanding who opens the black-box of AI is just as important as opening it. We conduct a mixed-methods study of how two different groups—people with and without AI background—perceive different types of AI explanations. Quantitatively, we share user perceptions along five dimensions. Qualitatively, we describe how AI background can influence interpretations, elucidating the differences through lenses of appropriation and cognitive heuristics. We find that (1) both groups showed unwarranted faith in numbers for different reasons and (2) each group found value in different explanations beyond their intended design. Carrying critical implications for the field of XAI, our findings showcase how AI generated explanations can have negative consequences despite best intentions and how that could lead to harmful manipulation of trust. We propose design interventions to mitigate them. </p>
<h2>Fabrication, Circuits and Tangibles</h2>
<h3>E-Acrylic: Electronic-Acrylic Composites for Making Interactive Artifacts</h3>
<p>Authors: Bo Han, Xin Liu, Ching Chiuan Yen, Clement Zheng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147806">Link</a></p>
<h3>Painting Inferno: Novel Heat and Stiffness Control Methods with Carbon Nanomaterial Conductive Heating Paint</h3>
<p>Authors: Yutaka Tokuda, Tatsuya Kobayashi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147168">Link</a></p>
<h3>SnapInflatables: Designing Inflatables with Snap-through Instability for Responsive Interaction</h3>
<p>Authors: Yue Yang, Lei Ren, Chuang Chen, Bin Hu, Zhuoyi Zhang, Xinyan Li, Yanchen Shen, Kuangqi Zhu, Junzhe Ji, Yuyang Zhang, Yongbo Ni, Jiayi Wu, Qi Wang, Jiang WU, Lingyun Sun, Ye Tao, Guanyun Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148172">Link</a></p>
<h3>LaCir: A multilayered laser-cuttable material to co-fabricate circuitry and structural components.</h3>
<p>Authors: Niels Buch, Carlos Tejada, Daniel Ashbrook, Valkyrie Savage</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148299">Link</a></p>
<h3>Design Space Exploration for Board-level Circuits: Exploring Alternatives in Component-based Design</h3>
<p>Authors: Richard Lin, Rohit Ramesh, Parth Pandhare, Kai Jun Tay, Prabal Dutta, Bjoern Hartmann, Ankur Mehta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147466">Link</a></p>
<h2>Fabrication: 3D Printing B</h2>
<h3>CeraMetal: A New Approach to Low-Cost Metal 3D Printing with Bronze Clay</h3>
<p>Authors: Leah Buechley, Jaime Gould, Fiona Bell</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147951">Link</a></p>
<h3>Palette-PrintAR: augmented reality design and simulation for multicolor resin 3D printing</h3>
<p>Authors: Gabriel Lipkowitz, Joseph DeSimone</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147395">Link</a></p>
<h3>Understanding the Challenges of OpenSCAD Users for 3D Printing</h3>
<p>Authors: J Gonzalez Avila, Thomas Pietrzak, Audrey Girouard, Géry Casiez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146848">Link</a></p>
<h3>Touch-n-Go: Designing and Fabricating Touch Fastening Structures by FDM 3D Printing</h3>
<p>Authors: Lingyun Sun, Deying Pan, Yuyang Zhang, Hongyi Hu, Junzhe Ji, Yue Tao, Shanghua Lou, Boyi Lian, Yitao Fan, Ye Tao, Guanyun Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147487">Link</a></p>
<h3>WeaveSlicer: Expanding the Range of Printable Geometries in Clay</h3>
<p>Authors: Camila Friedman-Gerlicz, Deanna Gelosi, Fiona Bell, Leah Buechley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147620">Link</a></p>
<h2>Gaze Interaction in Immersive Environments</h2>
<h3>Towards an Eye-Brain-Computer Interface: Combining Gaze with the Stimulus-Preceding Negativity for Target Selections in XR</h3>
<p>Authors: G S Rajshekar Reddy, Michael Proulx, Leanne Hirshfield, Anthony Ries</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146977">Link</a></p>
<p>Abstract: Gaze-assisted interaction techniques enable intuitive selections without requiring manual pointing but can result in unintended selections, known as Midas touch. A confirmation trigger eliminates this issue but requires additional physical and conscious user effort. Brain-computer interfaces (BCIs), particularly passive BCIs harnessing anticipatory potentials such as the Stimulus-Preceding Negativity (SPN) - evoked when users anticipate a forthcoming stimulus - present an effortless implicit solution for selection confirmation. Within a VR context, our research uniquely demonstrates that SPN has the potential to decode intent towards the visually focused target. We reinforce the scientific understanding of its mechanism by addressing a confounding factor - we demonstrate that the SPN is driven by the user's intent to select the target, not by the stimulus feedback itself. Furthermore, we examine the effect of familiarly placed targets, finding that SPN may be evoked quicker as users acclimatize to target locations; a key insight for everyday BCIs.</p>
<h3>Gaze on the Go: Effect of Spatial Reference Frame on Visual Target Acquisition During Physical Locomotion in Extended Reality</h3>
<p>Authors: Pavel Manakhov, Ludwig Sidenmark, Ken Pfeuffer, Hans Gellersen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146967">Link</a></p>
<p>Abstract: Spatial interaction relies on fast and accurate visual acquisition. In this work, we analyse how visual acquisition and tracking of targets presented in a head-mounted display is affected by the user moving linearly at walking and jogging paces. We study four reference frames in which targets can be presented: Head and World where targets are affixed relative to the head and environment, respectively; HeadDelay where targets are presented in the head coordinate system but follow head movement with a delay, and novel Path where targets remain at fixed distance in front of the user, in the direction of their movement. Results of our study in virtual reality demonstrate that the more stable the target is relative to the environment, the faster and more precise it can be fixated. The results have practical significance as head-mounted displays enable interaction during mobility, and in particular when eye tracking is considered as input.</p>
<h3>MOSion: Gaze Guidance with Motion-triggered Visual Cues by Mosaic Patterns</h3>
<p>Authors: Arisa Kohtani, Shio Miyafuji, Keishiro Uragaki, Hidetaka Katsuyama, Hideki Koike</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148121">Link</a></p>
<p>Abstract: We propose a gaze-guiding method called MOSion to adjust the guiding strength reacted to observers’ motion based on a high-speed projector and the afterimage effect in the human vision system. Our method decomposes the target area into mosaic patterns to
embed visual cues in the perceived images. The patterns can only direct the attention of the moving observers to the target area. The stopping observer can see the original image with little distortion because of light integration in the visual perception. The pre computation of the patterns provides the adaptive guiding effect without tracking devices and computational costs depending on the movements. The evaluation and the user study show that the mosaic decomposition enhances the perceived saliency with a few visual artifacts, especially in moving conditions. Our method embedded in white lights works in various situations such as planar posters, advertisements, and curved objects.</p>
<h3>FocusFlow: 3D Gaze-Depth Interaction in Virtual Reality Leveraging Active Visual Depth Manipulation</h3>
<p>Authors: Chenyang Zhang, Tiansu Chen, Eric Shaffer, Elahe Soltanaghai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146886">Link</a></p>
<p>Abstract: Gaze interaction presents a promising avenue in Virtual Reality (VR) due to its intuitive and efficient user experience. Yet, the depth control inherent in our visual system remains underutilized in current methods. In this study, we introduce FocusFlow, a hands-free interaction method that capitalizes on human visual depth perception within the 3D scenes of Virtual Reality. We first develop a binocular visual depth detection algorithm to understand eye input characteristics. We then propose a layer-based user interface and introduce the concept of "Virtual Window" that offers an intuitive and robust gaze-depth VR interaction, despite the constraints of visual depth accuracy and precision spatially at further distances. Finally, to help novice users actively manipulate their visual depth, we propose two learning strategies that use different visual cues to help users master visual depth control. Our user studies on 24 participants demonstrate the usability of our proposed virtual window concept as a gaze-depth interaction method. In addition, our findings reveal that the user experience can be enhanced through an effective learning process with adaptive visual cues, helping users to develop muscle memory for this brand-new input mechanism. We conclude the paper by discussing potential future research topics of gaze-depth interaction.</p>
<h3>Snap, Pursuit and Gain: Virtual Reality Viewport Control by Gaze</h3>
<p>Authors: Hock Siang Lee, Florian Weidner, Ludwig Sidenmark, Hans Gellersen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147889">Link</a></p>
<p>Abstract: Head-mounted displays let users explore virtual environments through a viewport that is coupled with head movement. In this work, we investigate gaze as an alternative modality for viewport control, enabling exploration of virtual worlds with less head movement.
We designed three techniques that leverage gaze based on different eye movements: Dwell Snap for viewport rotation in discrete steps, Gaze Gain for amplified viewport rotation based on gaze angle, and Gaze Pursuit for central viewport alignment of gaze targets. All three techniques enable 360-degree viewport control through naturally coordinated eye and head movement.
We evaluated the techniques in comparison with controller snap and head amplification baselines, for both coarse and precise viewport control, and found them to be as fast and accurate. We observed a high variance in performance which may be attributable to the different degrees to which humans tend to support gaze shifts with head movement.</p>
<h2>Gig Workers</h2>
<h3>"At the end of the day, I am accountable": Gig Workers' Self-Tracking for Multi-Dimensional Accountability Management</h3>
<p>Authors: Rie Helene (Lindy) Hernandez, Qiurong Song, Yubo Kou, Xinning Gui</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147575">Link</a></p>
<h3>Silent Delivery: Practices and Challenges of Delivering Among Deaf or Hard of Hearing Couriers</h3>
<p>Authors: Shi Chen, Xiaodong Wang, Weijun Li, Jingao Zhang, Yuge Qi, Jiaqi Teng, Zhihan Zeng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147217">Link</a></p>
<h3>Bodywork at Work: Attending to Bodily Needs in Gig, Shift, and Knowledge Work</h3>
<p>Authors: Deepika Yadav, Kasper Karlgren, Riyaj Shaikh, Karey Helms, Donald McMillan, Barry Brown, Airi Lampinen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148300">Link</a></p>
<h3>GigSousveillance: Designing Gig Worker Centric Sousveillance Tools</h3>
<p>Authors: Kimberly Do, Maya De Los Santos, Michael Muller, Saiph Savage</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147008">Link</a></p>
<h3>Not Just A Dot on The Map: Food Delivery Workers as Infrastructure</h3>
<p>Authors: Riyaj Shaikh, Anubha Singh, Barry Brown, Airi Lampinen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147254">Link</a></p>
<h2>Haptics and Immersive Interactions</h2>
<h3>Augmenting Perceived Length of Handheld Controllers: Effects of Object Handle Properties</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Chaeyong Park, Seungmoon Choi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147414">Link</a></p>
<p>Abstract: In the realm of virtual reality (VR), shape-changing controllers have emerged as a means to enhance visuo-haptic congruence during user interactions. The major emphasis has been placed on manipulating the inertia tensor of a shape-changing controller to control the perceived shape. This paper delves deeper by exploring how the material properties of the controller's handle, distinct from the inertial information, affect the perceived shape, focusing on the perceived length. We conducted three perceptual experiments to examine the effects of the handle's softness, thermal conductivity, and texture, respectively.  Results demonstrated that a softer handle increases the perceived length, whereas a handle with higher thermal conductivity reduces it. Texture, in the form of varying bumps, also alters the length perception. These results provide more comprehensive knowledge of the intricate relationship between perceived length and controller handle properties, expanding the design alternatives for shape-changing controllers for immersive VR experiences.</p>
<h3>VeeR: Exploring the Feasibility of Deliberately Designing VR Motion that Diverges from Mundane, Everyday Physical Motion to Create More Entertaining VR Experiences</h3>
<p>Authors: Pin Chun Lu, Che Wei Wang, Yu Lun Hsu, Alvaro Lopez, Ching-Yi Tsai, Chiao-Ju Chang, Wei Tian Mireille Tan, LI-CHUN LU, Mike Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148319">Link</a></p>
<p>Abstract: This paper explores the feasibility of deliberately designing VR motion that diverges from users’ physical movements to turn mundane, everyday transportation motion (e.g., metros, trains, and cars) into more entertaining VR motion experiences, in contrast to prior car-based VR approaches that synchronize VR motion to physical car movement exactly. To gain insight into users’ preferences for veering rate and veering direction for turning (left/right) and pitching (up/down) during the three phases of acceleration (accelerating, cruising, and decelerating), we conducted a formative, perceptual study (n=24) followed by a VR experience evaluation (n=18), all conducted on metro trains moving in a mundane, straight-line motion. Results showed that participants preferred relatively high veering rates, and preferred pitching upward during acceleration and downward during deceleration. Furthermore, while veering decreased comfort as expected, it significantly enhanced immersion (p&lt;.01) and entertainment (p&lt;.001) and the overall experience, with comfort being considered, was preferred by 89% of participants.</p>
<h3>InflatableBots: Inflatable Shape-Changing Mobile Robots for Large-Scale Encountered-Type Haptics in VR</h3>
<p>Authors: Ryota Gomi, Ryo Suzuki, Kazuki Takashima, Kazuyuki Fujita, Yoshifumi Kitamura</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147815">Link</a></p>
<p>Abstract: We introduce InflatableBots, shape-changing inflatable robots for large-scale encountered-type haptics in VR. Unlike traditional inflatable shape displays, which are immobile and limited in interaction areas, our approach combines mobile robots with fan-based inflatable structures. This enables safe, scalable, and deployable haptic interactions on a large scale. We developed three coordinated inflatable mobile robots, each of which consists of an omni-directional mobile base and a reel-based inflatable structure. The robot can simultaneously change its height and position rapidly (horizontal: 58.5 cm/sec, vertical: 10.4 cm/sec, from 40 cm to 200 cm), which allows for quick and dynamic haptic rendering of multiple touch points to simulate various body-scale objects and surfaces in real-time across large spaces (3.5 m x 2.5 m). We evaluated our system with a user study (N = 12), which confirms the unique advantages in safety, deployability, and large-scale interactability to significantly improve realism in VR experiences. </p>
<h3>Experiencing Dynamic Weight Changes in Virtual Reality Through Pseudo-Haptics and Vibrotactile Feedback</h3>
<p>Authors: Carolin Stellmacher, Feri Pujianto, Tanja Kojic, Jan-Niklas Voigt-Antons, Johannes Schöning</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147460">Link</a></p>
<p>Abstract: Virtual reality (VR) objects react dynamically to users' touch interactions in real-time. However, experiencing changes in weight through the haptic sense remains challenging with consumer VR controllers due to their limited vibrotactile feedback. While prior works successfully applied pseudo-haptics to perceive absolute weight by manipulating the control-display (C/D) ratio, we continuously adjusted the C/D ratio to mimic weight changes. Vibrotactile feedback additionally emphasises the modulation in the virtual object's physicality. In a study (N=18), we compared our multimodal technique with pseudo-haptics alone and a baseline condition to assess participants' experiences of weight changes. Our findings demonstrate that participants perceived varying degrees of weight change when the C/D ratio was adjusted, validating its effectiveness for simulating dynamic weight in VR. However, the additional vibrotactile feedback did not improve weight change perception. This work extends the understanding of designing haptic experiences for lightweight VR systems by leveraging perceptual mechanisms.</p>
<h3>Exploring Mobile Devices as Haptic Interfaces for Mixed Reality</h3>
<p>Authors: Carolin Stellmacher, Florian Mathis, Yannick Weiss, Meagan Loerakker, Nadine Wagener, Johannes Schöning</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148298">Link</a></p>
<p>Abstract: Dedicated handheld controllers facilitate haptic experiences of virtual objects in mixed reality (MR). However, as mobile MR becomes more prevalent, we observe the emergence of controller-free MR interactions. To retain immersive haptic experiences, we explore the use of mobile devices as a substitute for specialised MR controller. In an exploratory gesture elicitation study (n = 18), we examined users' (1) intuitive hand gestures performed with prospective mobile devices and (2) preferences for real-time haptic feedback when exploring haptic object properties. Our results reveal three haptic exploration modes for the mobile device, as an object, hand substitute, or as an additional tool, and emphasise the benefits of incorporating the device's unique physical features into the object interaction. This work expands the design possibilities using mobile devices for tangible object interaction, guiding the future design of mobile devices for haptic MR experiences.</p>
<h2>Haptics: Force, Thermal and Tactile Feedback</h2>
<h3>Stick&amp;Slip: Altering Fingerpad Friction via Liquid Coatings</h3>
<p>Authors: Alex Mazursky, Jacob Serfaty, Pedro Lopes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148219">Link</a></p>
<h3>HIFU Embossment of Acrylic Sheets</h3>
<p>Authors: Ayaka Tsutsui, Tatsuki Fushimi, Takahito Murakami, Ryosei Kojima, Kengo Tanaka, Yoichi Ochiai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147095">Link</a></p>
<h3>Shaping Compliance: Inducing Haptic Illusion of Compliance in Different Shapes with Electrotactile Grains</h3>
<p>Authors: Arata Jingu, Nihar Sabnis, Paul Strohmeier, Jürgen Steimle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147156">Link</a></p>
<h3>AirPush: A Pneumatic Wearable Haptic Device Providing Multi-Dimensional Force Feedback on a Fingertip</h3>
<p>Authors: Yuxin Ma, Tianze Xie, Peng Zhang, Hwan Kim, Seungwoo Je</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148229">Link</a></p>
<h3>ALCool: Utilizing Alcohol's Evaporative Cooling for Ubiquitous Cold Sensation Feedback</h3>
<p>Authors: Takumi Hamazaki, Taiki Takami, Keigo Ushiyama, Izumi Mizoguchi, Hiroyuki Kajimoto</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148230">Link</a></p>
<h2>Health and AI C</h2>
<h3>Memoro: Using Large Language Models to Realize a Concise Interface for Real-Time Memory Augmentation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Wazeer Zulfikar, Samantha Chan, Pattie Maes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147083">Link</a></p>
<p>Abstract: People have to remember an ever-expanding volume of information. Wearables that use information capture and retrieval for memory augmentation can help but can be disruptive and cumbersome in real-world tasks, such as in social settings. To address this, we developed Memoro, a wearable audio-based memory assistant with a concise user interface. Memoro uses a large language model (LLM) to infer the user’s memory needs in a conversational context, semantically search memories, and present minimal suggestions. The assistant has two interaction modes: Query Mode for voicing queries and Queryless Mode for on-demand predictive assistance, without explicit query. Our study of (N=20) participants engaged in a real-time conversation, demonstrated that using Memoro reduced device interaction time and increased recall confidence while preserving conversational quality. We report quantitative results and discuss the preferences and experiences of users. This work contributes towards utilizing LLMs to design wearable memory augmentation systems that are minimally disruptive.</p>
<h3>Artful Path to Healing: Using Machine Learning for Visual Art Recommendation to Prevent and Reduce Post-Intensive Care Syndrome (PICS)</h3>
<p>Authors: Bereket YILMA, Chan Mi Kim, Gerald C. Cupchik, Luis Leiva</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147432">Link</a></p>
<p>Abstract: Staying in the intensive care unit (ICU) is often traumatic, leading to post-intensive care syndrome (PICS), which encompasses physical, psychological, and cognitive impairments. Currently, there are limited interventions available for PICS. Studies indicate that exposure to visual art may help address the psychological aspects of PICS and be more effective if it is personalized. We develop Machine Learning-based Visual Art Recommendation Systems (VA RecSys) to enable personalized therapeutic visual art experiences for post-ICU patients. We investigate four state-of-the-art VA RecSys engines, evaluating the relevance of their recommendations for therapeutic purposes compared to expert-curated recommendations. We conduct an expert pilot test and a large-scale user study (n=150) to assess the appropriateness and effectiveness of these recommendations. Our results suggest all recommendations enhance temporal affective states. Visual and multimodal VA RecSys engines compare favourably with expert-curated recommendations, indicating their potential to support the delivery of personalized art therapy for PICS prevention and treatment.</p>
<h3>Explainable Notes: Examining How to Unlock Meaning in Medical Notes with Interactivity and Artificial Intelligence</h3>
<p>Authors: Hita Kambhamettu, Danaë Metaxa, Kevin Johnson, Andrew Head</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147476">Link</a></p>
<p>Abstract: Medical progress notes have recently become available to patients at an unprecedented scale. Progress notes offer patients insight into their care that they cannot find elsewhere. That said, reading a note requires patients to contend with the language, unspoken assumptions, and clutter common to clinical documentation. As the health system reinvents many of its interfaces to incorporate AI assistance, this paper examines what intelligent interfaces could do to help patients read their progress notes. In a qualitative study, we examine the needs of patients as they read a progress note. We then formulate a vision for the explainable note, an augmented progress note that provides support for directing attention, phrase-level understanding, and tracing lines of reasoning. This vision manifests in a set of patient-inspired opportunities for advancing intelligent interfaces for writing and reading progress notes.</p>
<h3>ConverSense: An Automated Approach to Assess Patient-Provider Interactions using Social Signals</h3>
<p>Authors: Manas Satish Bedmutha, Anuujin Tsedenbal, Kelly Tobar, Sarah Borsotto, Kimberly Sladek, Deepansha Singh, Reggie Casanova-Perez, Emily Bascom, Brian Wood, Janice Sabin, Wanda Pratt, Andrea Hartzler, Nadir Weibel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148138">Link</a></p>
<p>Abstract: Patient-provider communication influences patient health outcomes, and analyzing such communication could help  providers identify opportunities for improvement, leading to better care. Interpersonal communication can be assessed through “social-signals” expressed in non-verbal, vocal behaviors like interruptions, turn-taking, and pitch. To automate this assessment, we introduce a machine-learning pipeline that ingests audiostreams of conversations and tracks the magnitude of four social-signals:  dominance, interactivity, engagement, and warmth. This pipeline is embedded into ConverSense, a web-application for providers to visualize their communication patterns, both within and across visits. Our user study with 5 clinicians and 10 patient visits demonstrates ConverSense's potential to provide feedback on communication challenges, as well as the need for this feedback to be contextualized within the specific underlying visit and patient interaction. Through this novel approach that uses data-driven self-reflection, ConverSense can help providers improve their communication with patients to deliver improved quality of care.</p>
<h3>Sketching AI Concepts with Capabilities and Examples: AI Innovation in the Intensive Care Unit</h3>
<p>Authors: Nur Yildirim, Susanna Zlotnikov, Deniz Sayar, Jeremy Kahn, Leigh Bukowski, Sher Shah Amin, Kathryn Riman, Billie Davis, John Minturn, Andrew J King, Dan Ricketts, Lu Tang, Venkatesh Sivaraman, Adam Perer, Sarah M. Preum, James McCann, John Zimmerman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146925">Link</a></p>
<p>Abstract: Advances in artificial intelligence (AI) have enabled unprecedented capabilities, yet innovation teams struggle when envisioning AI concepts. Data science teams think of innovations users do not want, while domain experts think of innovations that cannot be built. A lack of effective ideation seems to be a breakdown point. How might multidisciplinary teams identify buildable and desirable use cases? This paper presents a first hand account of ideating AI concepts to improve critical care medicine. As a team of data scientists, clinicians, and HCI researchers, we conducted a series of design workshops to explore more effective approaches to AI concept ideation and problem formulation. We detail our process, the challenges we encountered, and practices and artifacts that proved effective. We discuss the research implications for improved collaboration and stakeholder engagement, and discuss the role HCI might play in reducing the high failure rate experienced in AI innovation.</p>
<h2>Input, Interaction and Time</h2>
<h3>User Performance in Consecutive Temporal Pointing: An Exploratory Study</h3>
<p>Authors: Dawon Lee, Sunjun Kim, Junyong Noh, Byungjoo Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147090">Link</a></p>
<h3>Waiting Time Perceptions for Faster Count-downs/ups Are More Sensitive Than Slower Ones: Experimental Investigation and Its Application</h3>
<p>Authors: Takanori Komatsu, Chenxi Xie, Seiji Yamada</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146709">Link</a></p>
<h3>Mouse2Vec: Learning Reusable Semantic Representations of Mouse Behaviour</h3>
<p>Authors: Guanhua Zhang, Zhiming Hu, Mihai Bâce, Andreas Bulling</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147945">Link</a></p>
<h3>The Effect of Latency on Movement Time in Path-steering</h3>
<p>Authors: Shota Yamanaka, Wolfgang Stuerzlinger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147611">Link</a></p>
<h2>Interaction and Perception in Immersive Environments</h2>
<h3>MAF: Exploring Mobile Acoustic Field for Hand-to-Face Gesture Interactions</h3>
<p>Authors: Yongjie Yang, Tao Chen, Yujing Huang, Xiuzhen Guo, Longfei Shangguan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147716">Link</a></p>
<p>Abstract: We present MAF, a novel acoustic sensing approach that leverages the commodity hardware in bone conduction earphones for hand-to-face gesture interactions. Briefly, by shining audio signals with bone conduction earphones, we observe that these signals not only propagate along the surface of the human face but also dissipate into the air, creating an acoustic field that envelops the individual’s head. We conduct benchmark studies to understand how various hand-to-face gestures and human factors influence this acoustic field. Building on the insights gained from these initial studies, we then propose a deep neural network combined with signal preprocessing techniques. This combination empowers MAF to effectively detect, segment, and subsequently recognize a variety of hand-to-face gestures, whether in close contact with the face or above it. Our comprehensive evaluation based on 22 participants demonstrates that MAF achieves an average gesture recognition accuracy of 92% across ten different gestures tailored to users' preferences.</p>
<h3>PhoneInVR: An Evaluation of Spatial Anchoring and Interaction Techniques for Smartphone Usage in Virtual Reality</h3>
<p>Authors: Fengyuan Zhu, Mauricio Sousa, Ludwig Sidenmark, Tovi Grossman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147762">Link</a></p>
<p>Abstract: When users wear a virtual reality (VR) headset, they lose access to their smartphone and accompanying apps. Past work has proposed smartphones as enhanced VR controllers, but little work has explored using existing smartphone apps and performing traditional smartphone interactions while in VR. In this paper, we consider three potential spatial anchorings for rendering smartphones in VR: On top of a tracked physical smartphone which the user holds (Phone-locked), on top of the user’s empty hand, as if holding a virtual smartphone (Hand-locked), or in a static position in front of the user (World-locked). 
We conducted a comparative study of target acquisition, swiping, and scrolling tasks across these anchorings using direct Touch or above-the-surface Pinch. Our findings indicate that physically holding a smartphone with Touch improves accuracy and speed for all tasks, and Pinch performed better with virtual smartphones. These findings provide a valuable foundation to enable smartphones in VR. </p>
<h3>Exploring Visualizations for Precisely Guiding Bare Hand Gestures in Virtual Reality</h3>
<p>Authors: Xizi Wang, Ben Lafreniere, Jian Zhao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147775">Link</a></p>
<p>Abstract: Bare hand interaction in augmented or virtual reality (AR/VR) systems, while intuitive, often results in errors and frustration. However, existing methods, such as a static icon or a dynamic tutorial, can only inform simple and coarse hand gestures and lack corrective feedback. This paper explores various visualizations for enhancing precise hand interaction in VR. Through a comprehensive two-part formative study with 11 participants, we identified four types of essential information for visual guidance and designed different visualizations that manifest these information types. We further distilled four visual designs and conducted a controlled lab study with 15 participants to assess their effectiveness for various single- and double-handed gestures. Our results demonstrate that visual guidance significantly improved users' gesture performance, reducing time and workload while increasing confidence. Moreover, we found that the visualization did not disrupt most users' immersive VR experience or their perceptions of hand tracking and gesture recognition reliability.</p>
<h3>Assessing the Influence of Visual Cues in Virtual Reality on the Spatial Perception of Physical Thermal Stimuli</h3>
<p>Authors: Sebastian Günther, Alexandra Skogseide, Robin Buhlmann, Max Mühlhäuser</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148210">Link</a></p>
<p>Abstract: Advancements in haptics for Virtual Reality (VR) increased the quality of immersive content. Particularly, recent efforts to provide realistic temperature sensations have gained traction, but most often require very specialized or large complex devices to create precise thermal actuations. However, being largely detached from the real world, such a precise correspondence between the physical location of thermal stimuli and the shown visuals in VR might not be necessary for an authentic experience. In this work, we contribute the findings of a controlled experiment with 20 participants, investigating the spatial localization accuracy of thermal stimuli while having matching and non-matching visual cues of a virtual heat source in VR. Although participants were highly confident in their localization decisions, their ability to accurately pinpoint thermal stimuli was notably deficient.</p>
<h3>Improving Electromyographic Muscle Response Times through Visual and Tactile Prior Stimulation in Virtual Reality</h3>
<p>Authors: Jessica Sehrt, Leonardo Leite Ferreira, Karsten Weyers, Amir Mahmood, Thomas Kosch, Valentin Schwind</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148137">Link</a></p>
<p>Abstract: Electromyography (EMG) enables hands-free interactions by detecting muscle activity at different human body locations. Previous studies have demonstrated that input performance based on isometric contractions is muscle-dependent and can benefit from synchronous biofeedback. However, it remains unknown whether stimulation before interaction can help to localize and tense a muscle faster. In a response-based VR experiment (N=21), we investigated whether prior stimulation using visual or tactile cues at four different target muscles (biceps, triceps, upper leg, calf) can help reduce the time to perform isometric muscle contractions. The results show that prior stimulation decreases EMG reaction times with visual, vibrotactile, and electrotactile cues. Our experiment also revealed important findings regarding learning and fatigue at the different body locations. We provide qualitative insights into the participants' perceptions and discuss potential reasons for the improved interaction. We contribute with implications and use cases for prior stimulated muscle activation.</p>
<h2>Politics of Data</h2>
<h3>Products of Positionality: How Tech Workers Shape Identity Concepts in Computer Vision</h3>
<p>BEST_PAPER</p>
<p>Authors: Morgan Scheuerman, Jed Brubaker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147182">Link</a></p>
<h3>SalChartQA: Question-driven Saliency on Information Visualisations</h3>
<p>Authors: Yao Wang, Weitian Wang, Abdullah Abdelhafez, Mayar Elfares, Zhiming Hu, Mihai Bâce, Andreas Bulling</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147419">Link</a></p>
<h3>"Things on the Ground are Different": Utility, Survival and Ethics in Multi-Device Ownership and Smartphone Sharing</h3>
<p>Authors: Lindah Kotut, Hummd Alikhan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148190">Link</a></p>
<h3>A Canary in the AI Coal Mine: American Jews May Be Disproportionately Harmed by Intellectual Property Dispossession in Large Language Model Training</h3>
<p>Authors: Heila Precel, Allison McDonald, Brent Hecht, Nicholas Vincent</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148186">Link</a></p>
<h3>When the Body Became Data: Historical Data Cultures and Anatomical Illustration</h3>
<p>Authors: Michael Correll, Laura Garrison</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146916">Link</a></p>
<h2>Reality-Virtuality Continuum: Interaction and Collaboration</h2>
<h3>From Real to Virtual: Exploring Replica-Enhanced Environment Transitions along the Reality-Virtuality Continuum</h3>
<p>Authors: Fabian Pointecker, Judith Friedl-Knirsch, Hans-Christian Jetter, Christoph Anthes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146699">Link</a></p>
<p>Abstract: Recent Head-Mounted Displays enable users to perceive the real environment using a video-based see-through mode and the fully virtual environment within a single display. Leveraging these advancements, we present a generic concept to seamlessly transition between the real and virtual environment, with the goal of supporting users in engaging with and disengaging from any real environment into Virtual Reality. This transition process uses a digital replica of the real environment and incorporates various stages of Milgram’s Reality-Virtuality Continuum, along with visual transitions that facilitate gradual navigation between them. We implemented the overall transition concept and four object-based transition techniques. The overall transition concept and four techniques were evaluated in a qualitative user study, focusing on user experience, the use of the replica and visual coherence. </p>
<p>The results of the user study show, that most participants stated that the replica facilitates the cognitive processing of the transition and supports spatial orientation.</p>
<h3>Blended Whiteboard: Physicality and Reconfigurability in Remote Mixed Reality Collaboration</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jens Emil Grønbæk, Juan Sánchez Esquivel, Germán Leiva, Eduardo Velloso, Hans Gellersen, Ken Pfeuffer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147453">Link</a></p>
<p>Abstract: The whiteboard is essential for collaborative work. To preserve its physicality in remote collaboration, Mixed Reality (MR) can blend real whiteboards across distributed spaces.
Going beyond reality, MR can further enable interactions like panning and zooming in a virtually reconfigurable infinite whiteboard. However, this reconfigurability conflicts with the sense of physicality. To address this tension, we introduce Blended Whiteboard, a remote collaborative MR system enabling reconfigurable surface blending across distributed physical whiteboards. Blended Whiteboard supports a unique collaboration style, where users can sketch on their local whiteboards but also reconfigure the blended space to facilitate transitions between loosely and tightly coupled work. We describe design principles inspired by proxemics; supporting users in changing between facing each other and being side-by-side, and switching between navigating the whiteboard synchronously and independently. Our work shows exciting benefits and challenges of combining physicality and reconfigurability in the design of distributed MR whiteboards.</p>
<h3>SwitchSpace: Understanding Context-Aware Peeking Between VR and Desktop Interfaces</h3>
<p>Authors: Johann Wentzel, Fraser Anderson, George Fitzmaurice, Tovi Grossman, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147514">Link</a></p>
<p>Abstract: Cross-reality tasks, like creating or consuming virtual reality (VR) content, often involve inconvenient or distracting switches between desktop and VR. An initial formative study explores cross-reality switching habits, finding most switches are momentary "peeks" between interfaces, with specific habits determined by current context. The results inform a design space for context-aware "peeking" techniques that allow users to view or interact with desktop from VR, and vice versa, without fully switching. We implemented a set of peeking techniques and evaluated them in two levels of a cross-reality task: one requiring only viewing, and another requiring input and viewing. Peeking techniques made task completion faster, with increased input accuracy and reduced perceived workload.</p>
<h3>Seated-WIP: Enabling Walking-in-Place Locomotion for Stationary Chairs in Confined Spaces</h3>
<p>BEST_PAPER</p>
<p>Authors: Liwei Chan, Tzu-Wei Mi, ZHUNG HAO HSUEH, Yi-Ci Huang, Ming Yun Hsu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147661">Link</a></p>
<p>Abstract: We introduce Seated-WIP, a footstep-based locomotion technique tailored for users seated in confined spaces such as on an airplane. It emulates real-world walking using forefoot or rearfoot in-place stepping, enhancing embodiment while reducing fatigue for pro- longed interactions. Our footstep-locomotion maps users’ footstep motions to four locomotion actions: walking forward, turning-in- place, walking backward, and sidestepping. Our first study examined embodiment and fatigue levels across various sitting positions using forefoot, rearfoot, and fullfoot stepping methods. While all these methods effectively replicated walking, users favored the forefoot and rearfoot methods due to reduced fatigue. In our sec- ond study, we compared the footstep-locomotion to leaning- and controller-locomotion on a multitasking navigation task. Results indicate that footstep locomotion offers the best embodied sense of walking and has comparable fatigue levels to controller-locomotion, albeit with slightly reduced efficiency than controller-locomotion. In seated VR environments, footstep locomotion offers a harmonious blend of embodiment, fatigue mitigation, and efficiency.</p>
<h3>Volumetric Hybrid Workspaces: Interactions with Objects in Remote and Co-located Telepresence</h3>
<p>Authors: Andrew Irlitti, Mesut Latifoglu, Thuong Hoang, Brandon Syiem, Frank Vetere</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147499">Link</a></p>
<p>Abstract: Volumetric telepresence aims to create a shared space, allowing people in local and remote settings to collaborate seamlessly. Prior telepresence examples typically have asymmetrical designs, with volumetric capture in one location and objects in one format. In this paper, we present a volumetric telepresence mixed reality system that supports real-time, symmetrical, multi-user, partially distributed interactions, using objects in multiple formats, across multiple locations. We align two volumetric environments around a common spatial feature to create a shared workspace for remote and co-located people using objects in three formats: physical, virtual, and volumetric. We conducted a study with 18 participants over 6 sessions, evaluating how telepresence workspaces support spatial coordination and hybrid communication for co-located and remote users undertaking collaborative tasks. Our findings demonstrate the successful integration of remote spaces, effective use of proxemics and deixis to support negotiation, and strategies to manage interactivity in hybrid workspaces.</p>
<h2>Smart Textiles</h2>
<h3>Ecothreads: Prototyping Biodegradable E-textiles Through Thread-based Fabrication</h3>
<p>Authors: Jingwen Zhu, Lily Winagle, Cindy Hsin-Liu Kao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147320">Link</a></p>
<h3>KnitScape: Computational Design and Yarn-Level Simulation of Slip and Tuck Colorwork Knitting Patterns</h3>
<p>Authors: Hannah Twigg-Smith, Emily Whiting, Nadya Peek</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147407">Link</a></p>
<h3>Expressive Clothing: Understanding Hobbyist-Sewers' Visions for Self-Expression Through Clothing</h3>
<p>Authors: Sabrina Lakhdhir, Charles Perin, Sowmya Somanath</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147610">Link</a></p>
<h3>Desktop Biofibers Spinning: An Open-Source Machine for Exploring Biobased Fibers and their Application Towards Sustainable Smart Textile Design</h3>
<p>Authors: Eldy Lazaro Vasquez, Mirela Alistar, Laura Devendorf, Michael Rivera</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147405">Link</a></p>
<h3>IntelliTex: Fabricating Low-cost and Washable Functional Textiles using A Double-coating Process</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yuecheng Peng, Danchang Yan, Haotian Chen, Yue Yang, Ye Tao, Weitao Song, Lingyun Sun, Guanyun Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146867">Link</a></p>
<h2>Education and AI B</h2>
<h3>Scientific and Fantastical: Creating Immersive, Culturally Relevant Learning Experiences with Augmented Reality and Large Language Models</h3>
<p>Authors: Alan Cheng, Meng Guo, Melissa Ran, Arpit Ranasaria, Arjun Sharma, Anthony Xie, Khuyen Le, Bala Vinaithirthan, Shihe (Tracy) Luan, David Wright, Andrea Cuadra, Roy Pea, James Landay</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147314">Link</a></p>
<p>Abstract: Motivating children to learn is a major challenge in education. One way to inspire motivation to learn is through immersion. We combine the immersive potential of augmented reality (AR), narrative, and large language models (LLMs) to bridge fantasy with reality in a mobile application, Moon Story, that teaches elementary schoolers astronomy and environmental science. Our system also builds upon learning theories such as culturally-relevant pedagogy. Using our application, a child embarks on a journey inspired by Chinese mythology, engages in real-world AR activities, and converses with a fictional character powered by a LLM. We conducted a controlled experiment (N=50) with two conditions: one using an LLM and one that was hard-coded. Both conditions resulted in learning gains, high engagement levels, and increased science learning motivation. Participants in the LLM condition also wrote more relevant answers. Finally, participants of both Chinese and non-Chinese heritage found the culturally-based narrative compelling.</p>
<h3>VIVID: Human-AI Collaborative Authoring of Vicarious Dialogues from Lecture Videos</h3>
<p>Authors: Seulgi Choi, Hyewon Lee, Yoonjoo Lee, Juho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148330">Link</a></p>
<p>Abstract: The lengthy monologue-style online lectures cause learners to lose engagement easily. Designing lectures in a “vicarious dialogue” format can foster learners’ cognitive activities more than monologue-style. However, designing online lectures in a dialogue style catered to the diverse needs of learners is laborious for instructors. We conducted a design workshop with eight educational experts and seven instructors to present key guidelines and the potential use of large language models (LLM) to transform a monologue lecture script into pedagogically meaningful dialogue. Applying these design guidelines, we created VIVID which allows instructors to collaborate with LLMs to design, evaluate, and modify pedagogical dialogues. In a within-subjects study with instructors (N=12), we show that VIVID helped instructors select and revise dialogues efficiently, thereby supporting the authoring of quality dialogues. Our findings demonstrate the potential of LLMs to assist instructors with creating high-quality educational dialogues across various learning stages.</p>
<h3>Exploring AI Problem Formulation with Children via Teachable Machines</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Utkarsh Dwivedi, Salma Elsayed-Ali, Elizabeth Bonsignore, Hernisa Kacorri</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147040">Link</a></p>
<p>Abstract: Emphasizing problem formulation in AI literacy activities with children is vital, yet we lack empirical studies on their structure and affordances. We propose that participatory design involving teachable machines facilitates problem formulation activities. To test this, we integrated problem reduction heuristics into storyboarding and invited a university-based intergenerational design team of 10 children (ages 8-13) and 9 adults to co-design a teachable machine. We find that children draw from personal experiences when formulating AI problems; they assume voice and video capabilities, explore diverse machine learning approaches, and plan for error handling. Their ideas promote human involvement in AI, though some are drawn to more autonomous systems. Their designs prioritize values like capability, logic, helpfulness, responsibility, and obedience, and a preference for a comfortable life, family security, inner harmony, and excitement as end-states. We conclude by discussing how these results can inform the design of future participatory AI activities. </p>
<h3>Mathemyths: Leveraging Large Language Models to Teach Mathematical Language through Child-AI Co-Creative Storytelling</h3>
<p>Authors: Chao Zhang, Xuechen Liu, Katherine Ziska, Soobin Jeon, Chi-Lin Yu, Ying Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148341">Link</a></p>
<p>Abstract: Mathematical language is a cornerstone of a child's mathematical development, and children can effectively acquire this language through storytelling with a knowledgeable and engaging partner. In this study, we leverage the recent advances in large language models to conduct free-form, creative conversations with children. Consequently, we developed Mathemyths, a joint storytelling agent that takes turns co-creating stories with children while integrating mathematical terms into the evolving narrative. This paper details our development process, illustrating how prompt-engineering can optimize LLMs for educational contexts. Through a user study involving 35 children aged 4-8 years, our results suggest that when children interacted with Mathemyths, their learning of mathematical language was comparable to those who co-created stories with a human partner. However, we observed differences in how children engaged with co-creation partners of different natures. Overall, we believe that LLM applications, like Mathemyths, offer children a unique conversational experience pertaining to focused learning objectives.</p>
<h3>Testing, Socializing, Exploring: Characterizing Middle Schoolers’ Approaches to and Conceptions of ChatGPT</h3>
<p>Authors: Yasmine Belghith, Atefeh Mahdavi Goloujeh, Brian Magerko, Duri Long, Tom McKlin, Jessica Roberts</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148187">Link</a></p>
<p>Abstract: As generative AI rapidly enters everyday life, educational interventions for teaching about AI need to cater to how young people, in particular middle schoolers who are at a critical age for reasoning skills and identity formation, conceptualize and interact with AI. We conducted nine focus groups with 24 middle school students to elicit their interests, conceptions of, and approaches to a popular generative AI tool, ChatGPT. We highlight a) personally and culturally-relevant topics to this population, b) three distinct approaches in students' open-ended interactions with ChatGPT: AI testing-oriented, AI socializing-oriented, and content exploring-oriented, and 3) an improved understanding of youths' conceptions and misconceptions of generative AI. While misconceptions highlight gaps in understanding what generative AI is and how it works, most learners show interest in learning about what AI is and what it can do. We discuss the implications of these conceptions for designing AI literacy interventions in museums.</p>
<h2>Users Privacy Needs</h2>
<h3>Personalizing Privacy Protection With Individuals' Regulatory Focus: Would You Preserve or Enhance Your Information Privacy?</h3>
<p>Authors: Reza Ghaiumy Anaraky, Yao Li, Hichang Cho, Danny Yuxing Huang, Kaileigh Angela Byrne, Bart Knijnenburg, Oded Nov</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146995">Link</a></p>
<h3>Towards Understanding Family Privacy and Security Literacy Conversations at Home: Design Implications for Privacy Literacy Interfaces</h3>
<p>Authors: Kenan Alghythee, Adel Hrncic, Karthik Singh, Sumanth Kunisetty, Yaxing Yao, Nikita Soni</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147976">Link</a></p>
<h3>Do You Need to Touch? Exploring Correlations between Personal Attributes and Preferences for Tangible Privacy Mechanisms</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Sarah Delgado Rodriguez, Priyasha Chatterjee, Anh Dao Phuong, Florian Alt, Karola Marky</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147786">Link</a></p>
<h3>"I know what you did last semester": Understanding Privacy Expectations and Preferences in the Smart Campus</h3>
<p>Authors: Injung Kim, Adam Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148155">Link</a></p>
<h3>“It doesn’t tell me anything about how my data is used”: User Perceptions of Data Collection Purposes</h3>
<p>Authors: Lin Kyi, Abraham Mhaidli, Cristiana Teixeira Santos, Franziska Roesner, Asia Biega</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148272">Link</a></p>
<h2>Wellbeing and Mental Health C</h2>
<h3>The Role of AI in Peer Support for Young People: A Study of Preferences for Human- and AI-Generated Responses</h3>
<p>Authors: Jordyn Young, Laala M Jawara, Diep Nguyen, Brian Daly, Jina Huh-Yoo, Afsaneh Razi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148227">Link</a></p>
<h3>The Social Journal: Investigating Technology to Support and Reflect on Social Interactions</h3>
<p>Authors: Sophia Sakel, Tabea Blenk, Albrecht Schmidt, Luke Haliburton</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147877">Link</a></p>
<h3>S-ADL: Exploring Smartphone-based Activities of Daily Living to Detect Blood Alcohol Concentration in a Controlled Environment</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Hansoo Lee, Auk Kim, Sang Won Bae, Uichin Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146856">Link</a></p>
<h3>Exploring an Extended Reality Floatation Tank Experience to Reduce the Fear of Being in Water</h3>
<p>Authors: Maria Montoya, Hannah Qiao, Prasanth Sasikumar, Don Samitha Elvitigala, Sarah Jane Pell, Suranga Nanayakkara, Florian Mueller</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148060">Link</a></p>
<h2>Accessibility and Aging</h2>
<h3>Designing a Multisensory VR Game Prototype for Older Adults - the Acceptability and Design Implications</h3>
<p>Authors: Xiaoxuan Li, Xiangshi Ren, Xin Suzuki, Naoaki Yamaji, Kin Wa Fung, Yasuyuki Gondo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146682">Link</a></p>
<h3>Exploring the Opportunity of Augmented Reality (AR) in Supporting Older Adults to Explore and Learn Smartphone Applications</h3>
<p>Authors: Xiaofu Jin, Wai Tong, Xiaoying Wei, Xian Wang, Emily Kuang, Xiaoyu Mo, Huamin Qu, Mingming Fan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146706">Link</a></p>
<h3>Reducing Search Space on Demand Helps Older Adults Find Mobile UI Features Quickly, on Par With Younger Adults</h3>
<p>Authors: Ja Eun Yu, Debaleena Chattopadhyay</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147297">Link</a></p>
<h3>Toward Making Virtual Reality (VR) More Inclusive for Older Adults: Investigating Aging Effect on Target Selection and Manipulation Tasks in VR</h3>
<p>Authors: Zhiqing Wu, Duotun Wang, Shumeng Zhang, Yuru Huang, Zeyu Wang, Mingming Fan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147356">Link</a></p>
<h3>HelpCall: Designing Informal Technology Assistance for Older Adults via Videoconferencing</h3>
<p>Authors: Teerapaun Tanprasert, Jiamin Dai, Joanna McGrenere</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147212">Link</a></p>
<h2>User Security Needs</h2>
<h3>A First Look into Targeted Clickbait and its Countermeasures: The Power of Storytelling</h3>
<p>Authors: Ankit Shrestha, Audrey Flood, Saniat Sohrawardi, Matthew Wright, Mahdi Nasrullah Al-Ameen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146835">Link</a></p>
<h3>Not as easy as just update: Survey of System Administrators and Patching Behaviours</h3>
<p>Authors: Adam Jenkins, Linsen Liu, Maria Wolters, Kami Vaniea</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147837">Link</a></p>
<h3>Understanding User-Perceived Security Risks and Mitigation Strategies in the Web3 Ecosystem</h3>
<p>Authors: Janice Jianing SI, Tanusree Sharma, Kanye Ye WANG</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146662">Link</a></p>
<h3>Self-Efficacy and Security Behavior: Results from a Systematic Review of Research Methods</h3>
<p>Authors: Nele Borgert, Luisa Jansen, Imke Böse, Jennifer Friedauer, Angela Sasse, Malte Elson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147732">Link</a></p>
<h3>A Comparative Long-Term Study of Fallback Authentication Schemes</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Leona Lassak, Philipp Markert, Maximilian Golla, Elizabeth Stobert, Markus Dürmuth</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148199">Link</a></p>
<h2>Assistive Interactions: Solutions for d/Deaf and Hard of Hearing Users</h2>
<h3>Towards Inclusive Video Commenting: Introducing Signmaku for the Deaf and Hard-of-Hearing</h3>
<p>Authors: Si Chen, Haocong Cheng, Jason Situ, Desirée Kirst, Suzy Su, Saumya Malhotra, Lawrence Angrave, Qi Wang, Yun Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146831">Link</a></p>
<h3>How Users Experience Closed Captions on Live Television: Quality Metrics Remain a Challenge</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mariana Arroyo Chavez, Molly Feanny, Matthew Seita, Bernard Thompson, Keith Delk, Skyler Officer, Abraham Glasser, Raja Kushalnagar, Christian Vogler</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146961">Link</a></p>
<h3>Assessment of Sign Language-Based versus Touch-Based Input for Deaf Users Interacting with Intelligent Personal Assistants</h3>
<p>Authors: Nina Tran, Paige DeVries, Matthew Seita, Raja Kushalnagar, Abraham Glasser, Christian Vogler</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147208">Link</a></p>
<h3>Unspoken Sound: Identifying Trends in Non-Speech Audio Captioning on YouTube</h3>
<p>Authors: Lloyd May, Keita Ohshiro, Khang Dang, Sripathi Sridhar, Jhanvi Pai, Magdalena Fuentes, Sooyeon Lee, Mark Cartwright</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146864">Link</a></p>
<h3>Towards Co-Creating Access and Inclusion: A Group Autoethnography on a Hearing Individual's Journey Towards Effective Communication in Mixed-Hearing Ability Higher Education Settings</h3>
<p>Authors: Si Chen, James Waller, Matthew Seita, Christian Vogler, Raja Kushalnagar, Qi Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147946">Link</a></p>
<h2>Assistive Interactions: Everyday Interactions for Users Who are Blind or Low Vision</h2>
<h3>Help Supporters: Exploring the Design Space of Assistive Technologies to Support Face-to-Face Help Between Blind and Sighted Strangers</h3>
<p>Authors: Yuanyang Teng, Connor Courtien, David Rios, Yves Tseng, Jacqueline Gibson, Maryam Aziz, Avery Reyna, Rajan Vaish, Brian Smith</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147252">Link</a></p>
<h3>Visual Cues for Data Analysis Features Amplify Challenges for Blind Spreadsheet Users</h3>
<p>Authors: Minoli Perera, Bongshin Lee, Eun Kyoung Choe, Kim Marriott</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146687">Link</a></p>
<h3>A Contextual Inquiry of People with Vision Impairments in Cooking</h3>
<p>Authors: Franklin Mingzhe Li, Michael Xieyang Liu, Shaun Kane, Patrick Carrington</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147075">Link</a></p>
<h3>Towards Inclusive Source Code Readability Based on the Preferences of Programmers with Visual Impairments</h3>
<p>Authors: Maulishree Pandey, Steve Oney, Andrew Begel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146818">Link</a></p>
<h3>FetchAid: Making Parcel Lockers More Accessible to Blind and Low Vision People With Deep-learning Enhanced Touchscreen Guidance, Error-Recovery Mechanism, and AR-based Search Support</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zhitong Guan, Zeyu Xiong, Mingming Fan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147721">Link</a></p>
<h2>Assistive Interactions: Social and Collaborative Interactions for Users Who or Blind or Low Vision</h2>
<h3>"I Don't Really Get Involved In That Way": Investigating Blind and Visually Impaired Individuals’ Experiences of Joint Attention with Sighted People</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Katherine Jones, Ute Leonards, Oussama Metatla</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147896">Link</a></p>
<h3>BubbleCam: Engaging Privacy in Remote Sighted Assistance</h3>
<p>Authors: Jingyi Xie, Rui Yu, He Zhang, Sooyeon Lee, Syed Masum Billah, John Carroll</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147457">Link</a></p>
<h3>Conveying Emotions through Shape-changing to Children with and without Visual Impairment</h3>
<p>Authors: Isabel Neto, Yuhan Hu, Filipa Correia, Filipa Rocha, Guy Hoffman, Hugo Nicolau, Ana Paiva</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147053">Link</a></p>
<h3>Unblind Text Inputs: Predicting Hint-text of Text Input in Mobile Apps via LLM</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zhe Liu, Chunyang Chen, Junjie Wang, Mengzhuo Chen, Boyu Wu, Yuekai Huang, Jun Hu, Qing Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147794">Link</a></p>
<h3>Designing to Support Blind and Visually Impaired Older Adults in Managing the Invisible Labor of Social Participation: Opportunities and Challenges</h3>
<p>Authors: Pranali Shinde, Aqueasha Martin-Hammond</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148126">Link</a></p>
<h2>Assistive Technologies</h2>
<h3>Designing Gaze-Assisted Upper-Body Gesture Interaction with and for People with Spinal Muscular Atrophy in VR</h3>
<p>Authors: Jingze Tian, Yingna Wang, Keye Yu, Liyi Xu, Junan Xie, Franklin Mingzhe Li, yafeng niu, Mingming Fan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147764">Link</a></p>
<h3>Beyond Repairing with Electronic Speech: Towards Embodied Communication and Assistive Technology</h3>
<p>Authors: Humphrey Curtis, Timothy Neate</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147301">Link</a></p>
<h3>People with Disabilities Redefining Identity through Robotic and Virtual Avatars: A Case Study in Avatar Robot Cafe</h3>
<p>Authors: Yuji Hatada, Giulia Barbareschi, Kazuaki Takeuchi, Hiroaki Kato, Kentaro Yoshifuji, Kouta Minamizawa, Takuji Narumi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148080">Link</a></p>
<h3>“Can It Be Customized According to My Motor Abilities?”: Toward Designing User-Defined Head Gestures for People with Dystonia</h3>
<p>Authors: Qin Sun, Yunqi Hu, Mingming Fan, Jingting Li, Su-Jing Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148234">Link</a></p>
<h3>Barriers to Photosensitive Accessibility in Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Laura South, Caglar Yildirim, Amy Pavel, Michelle Borkin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147690">Link</a></p>
<h2>Assistive Technologies: Work  Independent Living with Neurodiversity</h2>
<h3>Designing for Strengths: Opportunities to Support Neurodiversity in the Workplace</h3>
<p>Authors: Kaely Hall, Parth Arora, Rachel Lowy, Jennifer Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148212">Link</a></p>
<h3>Collaborative Job Seeking for People with Autism: Challenges and Design Opportunities</h3>
<p>Authors: Zinat Ara, Amrita Ganguly, Donna Peppard, Dongjun Chung, Slobodan Vucetic, Vivian Genaro Motti, Sungsoo Ray Hong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148323">Link</a></p>
<h3>“It’s the only thing I can trust”: Envisioning Large Language Model Use by Autistic Workers for Communication Assistance</h3>
<p>Authors: JiWoong Jang, Sanika Moharana, Patrick Carrington, Andrew Begel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147834">Link</a></p>
<h3>Understanding Online Job and Housing Search Practices of Neurodiverse Young Adults to Support Their Independence</h3>
<p>Authors: Ha-Kyung Kong, Saloni Yadav, Rachel Lowy, Daniella Ruzinov, Jennifer Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146962">Link</a></p>
<h3>Towards Digital Independence: Identifying the Tensions between Autistic Young Adults and Their Support Network When Mediating Social Media</h3>
<p>Authors: Spring Cullen, Elizabeth Johnson, Pamela Wisniewski, Xinru Page</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146625">Link</a></p>
<h2>Augmented Stories</h2>
<h3>Comfortable Mobility vs. Attractive Scenery: The Key to Augmenting Narrative Worlds in Outdoor Locative Augmented Reality Storytelling</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: HYERIM PARK, Aram Min, Hyunjin Lee, Maryam Shakeri, Ikbeom Jeon, Woontack Woo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147164">Link</a></p>
<h3>Investigating the Design of Augmented Narrative Spaces Through Virtual-Real Connections: A Systematic Literature Review</h3>
<p>Authors: Jae-eun Shin, Hayun Kim, HYERIM PARK, Woontack Woo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147128">Link</a></p>
<h3>AudioXtend: Assisted Reality Visual Accompaniments for Audiobook Storytelling During Everyday Routine Tasks</h3>
<p>Authors: Felicia Tan, Peisen Xu, Ashwin Ram, Wei Zhen Suen, Shengdong Zhao, Yun Huang, Christophe Hurter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148039">Link</a></p>
<h3>Jigsaw: Authoring Immersive Storytelling Experiences with Augmented Reality and Internet of Things</h3>
<p>Authors: Lei Zhang, Daekun Kim, Youjean Cho, Ava Robinson, Yu Jiang Tham, Rajan Vaish, Andrés Monroy-Hernández</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147993">Link</a></p>
<h3>Augmented Reality at Zoo Exhibits: A Design Framework for Enhancing the Zoo Experience</h3>
<p>Authors: Brandon Syiem, Sarah Webber, Ryan Kelly, Qiushi Zhou, Jorge Goncalves, Eduardo Velloso</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148105">Link</a></p>
<h2>Chronic Conditions A</h2>
<h3>Good Days, Bad Days: Understanding the Trajectories of Technology Use During Chronic Fatigue Syndrome</h3>
<p>Authors: Léa Paymal, Sarah Homewood</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147030">Link</a></p>
<h3>MigraineTracker: Examining Patient Experiences with Goal-Directed Self-Tracking for a Chronic Health Condition</h3>
<p>BEST_PAPER</p>
<p>Authors: Yasaman Sefidgar, Carla Castillo, Shaan Chopra, Liwei Jiang, Tae Jones, Anant Mittal, Hyeyoung Ryu, Jessica Schroeder, Allison Cole, Natalia Murinova, Sean Munson, James Fogarty</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147528">Link</a></p>
<h3>PD-Insighter: A Visual Analytics System to Monitor Daily Actions for Parkinson's Disease Treatment</h3>
<p>Authors: Jade Kandel, Chelsea Duppen, Qian Zhang, Howard Jiang, Angelos Angelopoulos, Ashley Neall, Pranav Wagh, Daniel Szafir, Henry Fuchs, Michael Lewek, Danielle Szafir</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148175">Link</a></p>
<h3>Creating Safe Places: Understanding the Lived Experiences of Families Managing Cystic Fibrosis in Young Children</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zhaoyuan Su, Sunil P. Kamath, Pornchai Tirakitsoontorn, Yunan Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147391">Link</a></p>
<h3>GlucoMaker: Enabling Collaborative Customization of Glucose Monitors</h3>
<p>Authors: Sabrina Lakhdhir, Chehak Nayar, Fraser Anderson, Helene Fournier, Liisa Holsti, Irina Kondratova, Charles Perin, Sowmya Somanath</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147409">Link</a></p>
<h2>Chronic Conditions C</h2>
<h3>“I think it saved me. I think it saved my heart”: The Complex Journey From Self-Tracking With Wearables To Diagnosis</h3>
<p>Authors: Rachel Keys, Paul Marshall, Graham Stuart, Aisling Ann O'Kane</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148252">Link</a></p>
<h3>"It's like a glimpse into the future": Exploring the Role of Blood Glucose Prediction Technologies for Type 1 Diabetes Self-Management</h3>
<p>Authors: Clara-Maria Barth, Jürgen Bernard, Elaine M. Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148048">Link</a></p>
<h3>HIV Client Perspectives on Digital Health in Malawi</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Lisa Orii, Caryl Feldacker, Jacqueline Huwa, Agness Thawani, Evelyn Viola, Christine Kiruthu-Kamamia, Odala Sande, Hannock Tweya, Richard Anderson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147847">Link</a></p>
<h3>“Obviously, Nothing's Gonna Happen in Five Minutes”: How Adolescents and Young Adults Infrastructure Resources to Learn Type 1 Diabetes Management</h3>
<p>Authors: Tian Xu, Emily Jost, Laurel H. Messer, Paul Cook, Gregory Forlenza, Sriram Sankaranarayanan, Casey Fiesler, Stephen Voida</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148225">Link</a></p>
<h2>Coding with AI</h2>
<h3>Validating AI-Generated Code with Live Programming</h3>
<p>Authors: Kasra Ferdowsi, Ruanqianqian (Lisa) Huang, Michael James, Nadia Polikarpova, Sorin Lerner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146703">Link</a></p>
<p>Abstract: AI-powered programming assistants are increasingly gaining popularity, with GitHub Copilot alone used by over a million developers worldwide. These tools are far from perfect, however, producing code suggestions that may be incorrect in subtle ways. As a result, developers face a new challenge: validating AI's suggestions. This paper explores whether Live Programming (LP), a continuous display of a program's runtime values, can help address this challenge. To answer this question, we built a Python editor that combines an AI-powered programming assistant with an existing LP environment. Using this environment in a between-subjects study (N=17), we found that by lowering the cost of validation by execution, LP can mitigate over- and under-reliance on AI-generated programs and reduce the cognitive load of validation for certain types of tasks.</p>
<h3>Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT &amp; NetLogo Chat</h3>
<p>Authors: John Chen, Xi Lu, Yuzhou Du, Michael Rejtig, Ruth Bagley, Mike Horn, Uri Wilensky</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148257">Link</a></p>
<p>Abstract: Large Language Models (LLMs) have the potential to fundamentally change the way people engage in computer programming. Agent-based modeling (ABM) has become ubiquitous in natural and social sciences and education, yet no prior studies have explored the potential of LLMs to assist it. We designed NetLogo Chat to support the learning and practice of NetLogo, a programming language for ABM. To understand how users perceive, use, and need LLM-based interfaces, we interviewed 30 participants from global academia, industry, and graduate schools. Experts reported more perceived benefits than novices and were more inclined to adopt LLMs in their workflow. We found significant differences between experts and novices in their perceptions, behaviors, and needs for human-AI collaboration. We surfaced a knowledge gap between experts and novices as a possible reason for the benefit gap. We identified guidance, personalization, and integration as major needs for LLM-based interfaces to support the programming of ABM.</p>
<h3>Ivie: Lightweight Anchored Explanations of Just-Generated Code</h3>
<p>Authors: Litao Yan, Alyssa Hwang, Zhiyuan Wu, Andrew Head</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147626">Link</a></p>
<p>Abstract: Programming assistants have reshaped the experience of programming into one where programmers spend less time writing and more time critically examining code. In this paper, we explore how programming assistants can be extended to accelerate the inspection of generated code. We introduce an extension to the programming assistant called Ivie, or instantly visible in-situ explanations. When using Ivie, a programmer's generated code is instantly accompanied by explanations positioned just adjacent to the code. Our design was optimized for extremely low-cost invocation and dismissal. Explanations are compact and informative. They describe meaningful expressions, from individual variables to entire blocks of code. We present an implementation of Ivie that forks VS Code, applying a modern LLM for timely segmentation and explanation of generated code. In a lab study, we compared Ivie to a contemporary baseline tool for code understanding. Ivie improved understanding of generated code, and was received by programmers as a highly useful, low distraction, desirable complement to the programming assistant.</p>
<h3>Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Hussein Mozannar, Gagan Bansal, Adam Fourney, Eric Horvitz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146797">Link</a></p>
<p>Abstract: Code-recommendation systems, such as Copilot and CodeWhisperer, have the potential to improve programmer productivity by suggesting and auto-completing code. However, to fully realize their potential, we must understand how programmers interact with these systems and identify ways to improve that interaction. To seek insights about human-AI collaboration with code recommendations systems, we studied GitHub Copilot, a code-recommendation system used by millions of programmers daily. 
We developed CUPS, a taxonomy of common programmer activities when interacting with Copilot. Our study of 21 programmers, who completed coding tasks and retrospectively labeled their sessions with CUPS, showed that CUPS can help us understand how programmers interact with code-recommendation systems, revealing inefficiencies and time costs. Our insights reveal how programmers interact with Copilot and motivate new interface designs and metrics. </p>
<h3>CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs</h3>
<p>Authors: Majeed Kazemitabaar, Runlong Ye, Xiaoning Wang, Austin Henley, Paul Denny, Michelle Craig, Tovi Grossman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147379">Link</a></p>
<p>Abstract: Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student's incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI's unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.</p>
<h2>Colors</h2>
<h3>Exploring Interactive Color Palettes for Abstraction-Driven Exploratory Image Colorization</h3>
<p>Authors: Xinyu Shi, Mingyu Liu, Ziqi Zhou, Ali Neshati, Ryan Rossi, Jian Zhao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147505">Link</a></p>
<h3>Cieran: Designing Sequential Colormaps via In-Situ Active Preference Learning</h3>
<p>Authors: Matt-Heun Hong, Zachary Sunberg, Danielle Szafir</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147642">Link</a></p>
<h3>Palette, Purpose, Prototype: The Three Ps of Color Design and How Designers Navigate Them</h3>
<p>Authors: Lena Hegemann, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147335">Link</a></p>
<h3>Color Maker: a Mixed-Initiative Approach to Creating Accessible Color Maps</h3>
<p>Authors: Amey Salvi, Kecheng Lu, Michael Papka, Yunhai Wang, Khairi Reda</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147098">Link</a></p>
<h3>Piet: Facilitating Color Authoring for Motion Graphics Video</h3>
<p>BEST_PAPER</p>
<p>Authors: Xinyu Shi, Yinghou Wang, Yun Wang, Jian Zhao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147118">Link</a></p>
<h2>Creative Professionals and AI A</h2>
<h3>Unlocking Creator-AI Synergy: Challenges, Requirements, and Design Opportunities in AI-Powered Short-Form Video Production</h3>
<p>Authors: Jini Kim, Hajun Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147507">Link</a></p>
<p>Abstract: The emergence of AI-Powered Short-Form Video Generators (ASVG) has showcased the potential to streamline production time and foster creative ideas. Despite their widespread adoption, research has underexplored ASVG, especially from creators’ perspectives. To evaluate the role of ASVG as creator-centered collaborators, we conducted mixed-method research: (1) interviews (N = 17) and (2) a participatory design workshop (N = 12) with short-form video creators. In our interviews, we investigated creators’ production process and challenges in creating short-form videos. In participatory workshops, short-form video creators envisioned AI-powered video tools, addressing their requirements and AI collaboration perceptions. Our findings indicate ASVGs can provide various advantages including inspiration, swift access to video sources, and automated highlight generation. To put things in perspective, we also underscore concerns arising from AI collaboration, including potential creator identity dilution, reduced creative output, and information bubble. We also discuss design considerations when designing ASVG to retain their creative values.</p>
<h3>ReelFramer: Human-AI Co-Creation for News-to-Video Translation</h3>
<p>Authors: Sitong Wang, Samia Menon, Tao Long, Keren Henderson, Dingzeyu Li, Kevin Crowston, Mark Hansen, Jeffrey Nickerson, Lydia Chilton</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147933">Link</a></p>
<p>Abstract: Short videos on social media are the dominant way young people consume content. News outlets aim to reach audiences through news reels---short videos conveying news---but struggle to translate traditional journalistic formats into short, entertaining videos. To translate news into social media reels, we support journalists in reframing the narrative. In literature, narrative framing is a high-level structure that shapes the overall presentation of a story. We identified three narrative framings for reels that adapt social media norms but preserve news value, each with a different balance of information and entertainment. We introduce ReelFramer, a human-AI co-creative system that helps journalists translate print articles into scripts and storyboards. ReelFramer supports exploring multiple narrative framings to find one appropriate to the story. AI suggests foundational narrative details, including characters, plot, setting, and key information. ReelFramer also supports visual framing; AI suggests character and visual detail designs before generating a full storyboard. Our studies show that narrative framing introduces the necessary diversity to translate various articles into reels, and establishing foundational details helps generate scripts that are more relevant and coherent. We also discuss the benefits of using narrative framing and foundational details in content retargeting.</p>
<h3>Understanding Nonlinear Collaboration between Human and AI Agents: A Co-design Framework for Creative Design</h3>
<p>Authors: Jiayi Zhou, Renzhong Li, Junxiu Tang, Tan Tang, Haotian Li, Weiwei Cui, Yingcai Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148154">Link</a></p>
<p>Abstract: Creative design is a nonlinear process where designers generate diverse ideas in the pursuit of an open-ended goal and converge towards consensus through iterative remixing.
In contrast, AI-powered design tools often employ a linear sequence of incremental and precise instructions to approximate design objectives.
Such operations violate customary creative design practices and thus hinder AI agents' ability to complete creative design tasks.
To explore better human-AI co-design tools, we first summarize human designers’ practices through a formative study with 12 design experts.
Taking graphic design as a representative scenario, we formulate a nonlinear human-AI co-design framework and develop a proof-of-concept prototype, OptiMuse. 
We evaluate OptiMuse and validate the nonlinear framework through a comparative study.
We notice a subconscious change in people's attitudes towards AI agents, shifting from perceiving them as mere executors to regarding them as opinionated colleagues. 
This shift effectively fostered the exploration and reflection processes of individual designers.</p>
<h3>PlantoGraphy: Incorporating Iterative Design Process into Generative Artificial Intelligence for Landscape Rendering</h3>
<p>Authors: Rong Huang, Haichuan Lin, Chuanzhang Chen, Kang Zhang, Wei Zeng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147560">Link</a></p>
<p>Abstract: Landscape renderings are realistic images of landscape sites, allowing stakeholders to perceive better and evaluate design ideas. While recent advances in Generative Artificial Intelligence (GAI) enable automated generation of landscape renderings, the end-to-end methods are not compatible with common design processes, leading to insufficient alignment with design idealizations and limited cohesion of iterative landscape design. Informed by a formative study for comprehending design requirements, we present PlantoGraphy, an iterative design system that allows for interactive configuration of GAI models to accommodate human-centered design practice. A two-stage pipeline is incorporated: first, the concretization module transforms conceptual ideas into concrete scene layouts with a domain-oriented large language model; and second, the illustration
module converts scene layouts into realistic landscape renderings with a layout-guided diffusion model fine-tuned through Low-Rank Adaptation. PlantoGraphy has undergone a series of performance evaluations and user studies, demonstrating its effectiveness in landscape rendering generation and the high recognition of its interactive functionality.</p>
<h3>Fashioning Creative Expertise with Generative AI:  Graphical Interfaces for Design Space Exploration Better Support Ideation Than Text Prompts</h3>
<p>Authors: Richard Davis, Thiemo Wambsganss, Wei Jiang, Kevin Gonyop Kim, Tanja Käser, Pierre Dillenbourg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147024">Link</a></p>
<p>Abstract: This paper investigates the potential impact of deep generative models on the work of creative professionals. We argue that current generative modeling tools lack critical features that would make them useful creativity support tools, and introduce our own tool, generative.fashion, which was designed with theoretical principles of design space exploration in mind. Through qualitative studies with fashion design apprentices, we demonstrate how generative.fashion supported both divergent and convergent thinking, and compare it with a state-of-the-art text-based interface using Stable Diffusion. In general, the apprentices preferred generative.fashion, citing the features explicitly designed to support ideation. In two follow-up studies, we provide quantitative results that support and expand on these insights. We conclude that text-only prompts in existing models restrict creative exploration, especially for novices. Our work demonstrates that interfaces which are theoretically aligned with principles of design space exploration are essential for unlocking the full creative potential of generative AI.</p>
<h2>Creative Professionals and AI B</h2>
<h3>LumiMood: A Creativity Support Tool for Designing the Mood of a 3D Scene</h3>
<p>Authors: Jeongseok Oh, Seungju Kim, SeungJun Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148271">Link</a></p>
<p>Abstract: The aesthetic design of 3D scenes in game content enhances players' experience by inducing desired emotions. Creating emotionally engaging scenes involves designing low-level features, such as color distribution, contrast, and brightness. This study presents LumiMood, an AI-driven creativity support tool (CST) that automatically adjusts lighting and post-processing to create moods for 3D scenes. LumiMood supports designers by synthesizing reference images, creating mood templates, and providing intermediate design steps. Our formative study with 10 designers identified distinct challenges in mood design based on the participants' experience levels. A user study involving 40 designers revealed that using LumiMood benefits the designers by streamlining workflow, improving precision, and increasing mood intention accuracy. Results indicate that LumiMood supports clarifying mood concepts and improves interpretation of lighting and post-processing, thus resolving the challenges. We observe the effect of template based designing and discuss considerable factors for AI-driven CSTs for users with varying levels of experiences.</p>
<h3>C2Ideas: Supporting Creative Interior Color Design Ideation with a Large Language Model</h3>
<p>Authors: Yihan Hou, Manling YANG, Hao Cui, Lei WANG, Jie Xu, Wei Zeng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147389">Link</a></p>
<p>Abstract: Interior color design is a creative process that endeavors to allocate colors to furniture and other elements within an interior space. While much research focuses on generating realistic interior designs, these automated approaches often misalign with user intention and disregard design rationales. Informed by a need-finding preliminary study, we develop C2Ideas, an innovative system for designers to creatively ideate color schemes enabled by an intent-aligned and domain-oriented large language model. C2Ideas integrates a three-stage process: Idea Prompting stage distills user intentions into color linguistic prompts; Word-Color Association stage transforms the prompts into semantically and stylistically coherent color schemes; and Interior Coloring stage assigns colors to interior elements complying with design principles. We also develop an interactive interface that enables flexible user refinement and interpretable reasoning. C2Ideas has undergone a series of indoor cases and user studies, demonstrating its effectiveness and high recognition of interactive functionality by designers.</p>
<h3>TypeDance: Creating Semantic Typographic Logos from Image through Personalized Generation</h3>
<p>Authors: Shishi Xiao, Liangwei Wang, Xiaojuan Ma, Wei Zeng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146619">Link</a></p>
<p>Abstract: Semantic typographic logos harmoniously blend typeface and imagery to represent semantic concepts while maintaining legibility. Conventional methods using spatial composition and shape substitution are hindered by the conflicting requirement for achieving seamless spatial fusion between geometrically dissimilar typefaces and semantics. While recent advances made AI generation of semantic typography possible, the end-to-end approaches exclude designer involvement and disregard personalized design. This paper presents TypeDance, an AI-assisted tool incorporating design rationales with the generative model for personalized semantic typographic logo design. It leverages combinable design priors extracted from uploaded image exemplars and supports type-imagery mapping at various structural granularity, achieving diverse aesthetic designs with flexible control. Additionally, we instantiate a comprehensive design workflow in TypeDance, including ideation, selection, generation, evaluation, and iteration. A two-task user evaluation, including imitation and creation, confirmed the usability of TypeDance in design across different usage scenarios.</p>
<h3>When Teams Embrace AI: Human Collaboration Strategies in Generative Prompting in a Creative Design Task</h3>
<p>Authors: Ziyi Qiu, Yuanning Han, JIALE CHENG, RAY LC</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147669">Link</a></p>
<p>Abstract: Studies of Generative AI (GenAI)-assisted creative workflows have focused on individuals overcoming challenges of prompting to produce what they envisioned. When designers work in teams, how do collaboration and prompting influence each other, and how do users perceive generative AI and their collaborators during the co-prompting process? We engaged students with design or performance backgrounds, and little exposure to GenAI, to work in pairs with GenAI to create stage designs based on a creative theme. We found two patterns of collaborative prompting focused on generating story descriptions first, or visual imagery first. GenAI tools helped participants build consensus in the task, and allowed for discussion of the prompting strategies. Participants perceived GenAI as efficient tools rather than true collaborators, suggesting that human partners reduced the reliance on their use. This work highlights the importance of human-human collaboration when working with GenAI tools, suggesting systems that take advantage of shared human expertise in the prompting process.</p>
<h3>Is Resistance Futile?: Early Career Game Developers, Generative AI, and Ethical Skepticism</h3>
<p>Authors: Josiah Boucher, Gillian Smith, Yunus Telliel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146874">Link</a></p>
<p>Abstract: This paper presents a study that examines developer perceptions and usage of generative AI (GAI) in a summer professional development program for game development interns focused on mobile game design. GAI applications are in common usage worldwide, yet the impacts of this technology in game development remain relatively underexplored. Through a qualitative study using ethnographic interviews and participatory observation, this paper explores how GAI impacted the workflows, creative processes, and professional identities of early career game developers. We present a case of GAI integration that was not a straightforward adoption. Focusing on the interns' resistance, negotiation, and reimagining, we show that the interns were actively developing a new professional culture both with and against generative AI. For the interns, their ethical commitments to fellow game developers and the future of their profession were as important as their practical concerns about usability, utility, and efficacy of GAI tools.</p>
<h2>Data Visualization: Charts</h2>
<h3>Do You See What I See? A Qualitative Study Eliciting High-Level Visualization Comprehension</h3>
<p>Authors: Ghulam Jilani Quadri, Arran Zeyu Wang, Zhehao Wang, Jennifer Adorno, Paul Rosen, Danielle Szafir</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146696">Link</a></p>
<h3>Effects of Point Size and Opacity Adjustments in Scatterplots</h3>
<p>Authors: Gabriel Strain, Andrew J. Stewart, Paul Warren, Caroline Jay</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147175">Link</a></p>
<h3>Spatial Audio-Enhanced Multimodal Graph Rendering for Efficient Data Trend Learning on Touchscreen Devices</h3>
<p>Authors: Wilfredo Robinson Moore, Medhani Kalal, Jennifer Tennison, Nicholas Giudice, Jenna Gorlewicz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146668">Link</a></p>
<h3>VisTorch: Interacting with Situated Visualizations using Handheld Projectors</h3>
<p>Authors: Biswaksen Patnaik, Huaishu Peng, Niklas Elmqvist</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147315">Link</a></p>
<h3>To Cut or Not To Cut? A Systematic Exploration of Y-Axis Truncation</h3>
<p>Authors: Sheng Long, Matthew Kay</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147733">Link</a></p>
<h2>Data Visualization: Geospatial and Multimodal</h2>
<h3>DeepSee: Multidimensional Visualizations of Seabed Ecosystems</h3>
<p>Authors: Adam Coscia, Haley Sapers, Noah Deutsch, Malika Khurana, John Magyar, Sergio Parra, Daniel Utter, Rebecca Wipfler, David W. Caress, Eric Martin, Jennifer Paduan, Maggie Hendrie, Santiago Lombeyda, Hillary Mushkin, Alex Endert, Scott Davidoff, Victoria Orphan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146725">Link</a></p>
<h3>SalienTime: User-driven Selection of Salient Time Steps for Large-Scale Geospatial Data Visualization</h3>
<p>Authors: Juntong Chen, Haiwen Huang, Huayuan Ye, Zhong Peng, Chenhui Li, Changbo Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147827">Link</a></p>
<h3>Data Cubes in Hand: A Design Space of Tangible Cubes for Visualizing 3D Spatio-Temporal Data in Mixed Reality</h3>
<p>Authors: Shuqi He, Haonan Yao, Luyan Jiang, Kaiwen Li, Nan Xiang, Yue Li, Hai-Ning Liang, Lingyun Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146834">Link</a></p>
<h3>Understanding Reader Takeaways in Thematic Maps Under Varying Text, Detail, and Spatial Autocorrelation</h3>
<p>Authors: Arlen Fan, Fan Lei, Michelle Mancenido, Alan MacEachren, Ross Maciejewski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148161">Link</a></p>
<h3>MAIDR: Making Statistical Visualizations Accessible with Multimodal Data Representation</h3>
<p>Authors: JooYoung Seo, Yilin Xia, Bongshin Lee, Sean McCurry, Yu Jun Yam</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146802">Link</a></p>
<h2>Dementia Care</h2>
<h3>Evolving Presentation of Self: The Influence of Dementia Communication Challenges on Everyday Interactions</h3>
<p>Authors: Yvon Ruitenburg, Minha Lee, Panos Markopoulos, Wijnand IJsselsteijn</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147523">Link</a></p>
<h3>Mnemosyne - Supporting Reminiscence for Individuals with Dementia in Residential Care Settings</h3>
<p>Authors: Andrea Baumann, Peter Shaw, Ludwig Trotter, Sarah Clinch, Nigel Davies</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147516">Link</a></p>
<h3>Technology-Mediated Non-pharmacological Interventions for Dementia: Needs for and Challenges in Professional, Personalized and Multi-Stakeholder Collaborative Interventions</h3>
<p>BEST_PAPER</p>
<p>Authors: Yuling Sun, Zhennan Yi, Xiaojuan Ma, JUNYAN MAO, Xin Tong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146988">Link</a></p>
<h3>Family Caregiver Experiences of Using a Mobile App for Music-based Training to Support Dementia Care</h3>
<p>Authors: Dianna Vidas, Zara Thompson, Ryan Kelly, Jenny Waycott, Jeanette Tamplin, Tanara Vieira Sousa, Lars Kulik, Amit Lampit, Nicola T. Lautenschlager, Felicity Baker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147009">Link</a></p>
<h3>Design Opportunities for Care Transitions in Dementia: Understanding Informal Caregivers' Experiences Through a Practice-Informed Approach</h3>
<p>Authors: Maarten Houben, Rens Brankaert, Maudy Gosen, Veerle Van Overloop, Wijnand IJsselsteijn</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147643">Link</a></p>
<h2>Digital Wellbeing A</h2>
<h3>Real-World Winds: Micro Challenges to Promote Balance Post Smartphone Overload</h3>
<p>Authors: Nađa Terzimehić, Julia Huber, Sarah Aragon-Hahner, Sven Mayer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146849">Link</a></p>
<h3>StayFocused: Examining the Effects of Reflective Prompts and Chatbot Support on Compulsive Smartphone Use</h3>
<p>Authors: Zhuoyang LI, Minhui Liang, RAY LC, Yuhan Luo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148192">Link</a></p>
<h3>Attention Receipts: Utilizing the Materiality of Receipts to Improve Screen-time Reflection on YouTube</h3>
<p>Authors: Anup Sathya, Ken Nakagaki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147812">Link</a></p>
<h3>A Longitudinal In-the-Wild Investigation of Design Frictions to Prevent Smartphone Overuse</h3>
<p>Authors: Luke Haliburton, David Grüning, Frederik Riedel, Albrecht Schmidt, Nađa Terzimehić</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147365">Link</a></p>
<h3>InteractOut: Leveraging Interaction Proxies as Input Manipulation Strategies for Reducing Smartphone Overuse</h3>
<p>Authors: Tao Lu, Hongxiao Zheng, Tianying Zhang, Xuhai "Orson" Xu, Anhong Guo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147313">Link</a></p>
<h2>Digital Wellbeing B</h2>
<h3>Time2Stop: Adaptive and Explainable Human-AI Loop for Smartphone Overuse Intervention</h3>
<p>Authors: Adiba Orzikulova, Han Xiao, Zhipeng Li, Yukang Yan, Yuntao Wang, Yuanchun Shi, Marzyeh Ghassemi, Sung-Ju Lee, Anind Dey, Xuhai "Orson" Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146643">Link</a></p>
<h3>“I finally felt I had the tools to control these urges”: Empowering Students to Achieve Their Device Use Goals With the Reduce Digital Distraction Workshop</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ulrik Lyngs, Kai Lukoff, Petr Slovak, Michael Inzlicht, Maureen Freed, Hannah Andrews, Claudine Tinsman, Laura Csuka, Lize Alberts, Victoria Oldemburgo de Mello, Guido Makransky, Kasper Hornbæk, Max Van Kleek, Nigel Shadbolt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147658">Link</a></p>
<h3>MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention</h3>
<p>Authors: Ruolan Wu, Chun Yu, Xiaole Pan, Yujia Liu, Ningning Zhang, Yue Fu, Yuhan Wang, Zhi Zheng, Li Chen, Qiaolei Jiang, Xuhai "Orson" Xu, Yuanchun Shi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146884">Link</a></p>
<h3>“You Can Find a Part of my Life in Every Single App”: An Interview Study of What Makes Smartphone Applications Special to Their Users</h3>
<p>Authors: Kasper Hornbæk, Ulrik Lyngs, Olga Iarygina, Mikael B. Skov</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148169">Link</a></p>
<h3>Navigating User-System Gaps: Understanding User-Interactions in User-Centric Context-Aware Systems for Digital Well-being Intervention</h3>
<p>Authors: Inyeop Kim, Uichin Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147725">Link</a></p>
<h2>Education and AI A</h2>
<h3>From Primary Education to Premium Workforce: Drawing on K-12 Approaches for Developing AI Literacy</h3>
<p>Authors: Magnus Høholt Kaspersen, Line Musaeus, Karl-Emil Bilstrup, Marianne Graves Petersen, Ole Sejer Iversen, Christian Dindler, Peter Dalsgaard</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147388">Link</a></p>
<p>Abstract: Advances in artificial intelligence present a need for fostering AI literacy in workplaces. While there is a lack of research on how this can be achieved, there are documented successful approaches in child-computer interaction (CCI), albeit aimed at K-12 education. We present an in-vivo explorative case study of how CCI approaches can be adopted for adult professionals via a full-day workshop developed in collaboration with a trade union to upskill workers. Analyzing data from pre- and post-surveys, a follow-up survey, and materials produced by participants (n=53), we demonstrate how this increased participants’ knowledge of AI while their self-efficacy and empowerment did not improve. This is similar to findings from K-12 education, pointing to self-efficacy and empowerment as major challenges for AI literacy across sectors. We discuss the role of ambassadorships and professional organizations in addressing these issues, and indicate research directions for the CHI community.</p>
<h3>More than Model Documentation: Uncovering Teachers' Bespoke Information Needs for Informed Classroom Integration of ChatGPT</h3>
<p>Authors: Mei Tan, Hariharan Subramonyam</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147621">Link</a></p>
<p>Abstract: ChatGPT has entered classrooms, circumventing typical training and vetting procedures. Unlike other educational technologies, it placed teachers in direct contact with the versatility of generative AI. Consequently, teachers are urgently tasked to assess its capabilities to inform their use of ChatGPT. However, it is unclear what support teachers have and need and whether existing documentation, such as model cards, provides adequate direction for educators in this new paradigm. By interviewing 22 middle- and high-school ELA and Social Studies teachers, we connect the discourse on AI transparency and documentation with educational technology integration, highlighting the information needs of teachers. Our findings reveal that teachers confront significant information gaps, lacking clarity on exploring ChatGPT's capabilities for bespoke learning tasks and ensuring its fit with the needs of diverse learners. As a solution, we propose a framework for interactive model documentation that empowers teachers to navigate the interplay between pedagogical and technical knowledge. </p>
<h3>The Promise and Peril of ChatGPT in Higher Education: Opportunities, Challenges, and Design Implications</h3>
<p>Authors: Hyanghee Park, Daehwan Ahn</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147256">Link</a></p>
<p>Abstract: A growing number of students in higher education are using ChatGPT for various educational purposes, ranging from seeking information to writing essays. Although many universities have officially banned the use of ChatGPT because of its potential harm and unintended consequences, it is still important to uncover how students leverage ChatGPT for learning, what challenges emerge, and how we can make better use of ChatGPT in higher education. Thus, we conducted focus group workshops and a series of participatory design sessions with thirty students who have actively interacted with ChatGPT for one semester in university and with other five stakeholders (e.g., professors, AI experts). Based on these, this paper identifies real opportunities and challenges of utilizing and designing ChatGPT for higher education.</p>
<h3>Teaching artificial intelligence in extracurricular contexts through narrative-based learnersourcing</h3>
<p>Authors: Dylan Moore, Sophia Moore, Bansharee Ireen, Winston Iskandar, Grigory Artazyan, Elizabeth Murnane</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147257">Link</a></p>
<p>Abstract: Collaborative technology provides powerful opportunities to engage young people in active learning experiences that are inclusive, immersive, and personally meaningful. In particular, interactive narratives have proven to be effective scaffolds for learning, and learnersourcing has emerged as a promising student-driven approach to enable personalized education and quality control at-scale. We introduce the first synthesis of these ideas in the context of teaching artificial intelligence (AI), which is now seen as a critical component of 21st-century education. Specifically, we explore the design of a narrative-based learnersourcing platform where engagement is centered around a learner-made choose-your-own-adventure story. In grounding our approach, we draw from pedagogical literature, digital storytelling, and recent work on learnersourcing. We report on our iterative, learner-centered design process as well as our study findings that demonstrate the platform’s positive effects on knowledge gains, interest in AI concepts, and the overall user experience of narrative-based learnersourcing technology.</p>
<h3>ml-machine.org: Infrastructuring a Research Product to Disseminate AI Literacy in Education</h3>
<p>Authors: Karl-Emil Bilstrup, Magnus Høholt Kaspersen, Niels Olof Bouvin, Marianne Graves Petersen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148135">Link</a></p>
<p>Abstract: ml-machine.org is a web- and micro:bit-based educational tool for building machine learning models designed to enable more widespread teaching of AI literacy in secondary education. It has been designed as a research product in collaboration with partners from the educational sector, including the Danish Broadcasting Corporation and the Micro:bit Educational Foundation. ml-machine.org currently has more than 5000 unique users and is used in schools and teacher training. It is publicly available and promoted on the broadcasting corporation's platforms. We describe the two-year process of developing and disseminating ml-machine.org. Based on interviews with partners and educators, we report on how ml-machine.org supports inquiry into the adoption and appropriation of such educational tools. We also provide insights on working with formal education infrastructures in order to scale and integrate a research product into teacher practices. Based on these experiences, we propose infrastructure as a novel quality of research products.</p>
<h2>Ethics of Digital Technologies A</h2>
<h3>BLIP: Facilitating the Exploration of Undesirable Consequences of Digital Technologies</h3>
<p>Authors: Rock Pang, Sebastin Santy, Rene Just, Katharina Reinecke</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146666">Link</a></p>
<h3>Perceptions of Fairness in Technology-Mediated Marketplaces</h3>
<p>Authors: Andrew Chong, Ji Su Yoo, Coye Cheshire</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147651">Link</a></p>
<h3>STILE: Exploring and Debugging Social Biases in Pre-trained Text Representations</h3>
<p>Authors: Samia Kabir, Lixiang Li, Tianyi Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147326">Link</a></p>
<h3>An Ontology of Dark Patterns Knowledge: Foundations, Definitions, and a Pathway for Shared Knowledge-Building</h3>
<p>Authors: Colin Gray, Cristiana Teixeira Santos, Nataliia Bielova, Thomas Mildner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147221">Link</a></p>
<h3>Beyond Dark Patterns: A Concept-Based Framework for Ethical Software Design</h3>
<p>Authors: Evan Caragay, Katherine Xiong, Jonathan Zong, Daniel Jackson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147293">Link</a></p>
<h2>Evaluating AI Technologies A</h2>
<h3>Are We Asking the Right Questions?: Designing for Community Stakeholders’ Interactions with AI in Policing</h3>
<p>Authors: Md Romael Haque, Devansh Saxena, Katy Weathington, Joseph Chudzik, Shion Guha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147789">Link</a></p>
<p>Abstract: Research into recidivism risk prediction in the criminal justice system has garnered significant attention from HCI, critical algorithm studies, and the emerging field of human-AI decision-making. This study focuses on algorithmic crime mapping, a prevalent yet underexplored form of algorithmic decision support (ADS) in this context. We conducted experiments and follow-up interviews with 60 participants, including community members, technical experts, and law enforcement agents (LEAs), to explore how lived experiences, technical knowledge, and domain expertise shape interactions with the ADS, impacting human-AI decision-making. Surprisingly, we found that domain experts (LEAs) often exhibited anchoring bias, readily accepting and engaging with the first crime map presented to them. Conversely, community members and technical experts were more inclined to engage with the tool, adjust controls, and generate different maps. Our findings highlight that all three stakeholders were able to provide critical feedback regarding AI design and use - community members questioned the core motivation of the tool, technical experts drew attention to the elastic nature of data science practice, and LEAs suggested redesign pathways such that the tool could complement their domain expertise.</p>
<h3>Human-LLM Collaborative Annotation Through Effective Verification of LLM Labels</h3>
<p>Authors: Xinru Wang, Hannah Kim, Sajjadur Rahman, Kushan Mitra, Zhengjie Miao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147019">Link</a></p>
<p>Abstract: Large language models (LLMs) have shown remarkable performance across various natural language processing (NLP) tasks, indicating their significant potential as data annotators. Although LLM-generated annotations are more cost-effective and efficient to obtain, they are often erroneous for complex or domain-specific tasks and may introduce bias when compared to human annotations. Therefore, instead of completely replacing human annotators with LLMs, we need to leverage the strengths of both LLMs and humans to ensure the accuracy and reliability of annotations. This paper presents a multi-step human-LLM collaborative approach where (1) LLMs generate labels and provide explanations, (2) a verifier assesses the quality of LLM-generated labels, and (3) human annotators re-annotate a subset of labels with lower verification scores. To facilitate human-LLM collaboration, we make use of LLM's ability to rationalize its decisions. LLM-generated explanations can provide additional information to the verifier model as well as help humans better understand LLM labels. We demonstrate that our verifier is able to identify potentially incorrect LLM labels for human re-annotation. Furthermore, we investigate the impact of presenting LLM labels and explanations on human re-annotation through crowdsourced studies.</p>
<h3>"AI enhances our performance, I have no doubt this one will do the same": The Placebo effect is robust to negative descriptions of AI</h3>
<p>Authors: Agnes Kloft, Robin Welsch, Thomas Kosch, Steeven Villa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148294">Link</a></p>
<p>Abstract: Heightened AI expectations facilitate performance in human-AI interactions through placebo effects. While lowering expectations to control for placebo effects is advisable, overly negative expectations could induce nocebo effects. In a letter discrimination task, we informed participants that an AI would either increase or decrease their performance by adapting the interface, when in reality, no AI was present in any condition. A Bayesian analysis showed that participants had high expectations and performed descriptively better irrespective of the AI description when a sham-AI was present. Using cognitive modeling, we could trace this advantage back to participants gathering more information. A replication study verified that negative AI descriptions do not alter expectations, suggesting that performance expectations with AI are biased and robust to negative verbal descriptions. We discuss the impact of user expectations on AI interactions and evaluation.</p>
<h3>An Evaluation of Situational Autonomy for Human-AI Collaboration in a Shared Workspace Setting</h3>
<p>Authors: Vildan Salikutluk, Janik Schöpper, Franziska Herbert, Katrin Scheuermann, Eric Frodl, Dirk Balfanz, Frank Jäkel, Dorothea Koert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147227">Link</a></p>
<p>Abstract: Designing interactions for human-AI teams (HATs) can be challenging due to an AI agent's potential autonomy. Previous work suggests that higher autonomy does not always improve team performance, and situation-dependent autonomy adaptation might be beneficial. However, there is a lack of systematic empirical evaluations of such autonomy adaptation in human-AI interaction. Therefore, we propose a cooperative task in a simulated shared workspace to investigate effects of fixed levels of AI autonomy and situation-dependent autonomy adaptation on team performance and user satisfaction. We derive adaptation rules for AI autonomy from previous work and a pilot study. We implement these rule for our main experiment and find that team performance was best when humans collaborated with an agent adjusting its autonomy based on the situation. Additionally, users rated this agent highest in terms of perceived intelligence. From these results, we discuss the influence of varying autonomy degrees on HATs in shared workspaces.</p>
<h3>Evaluating the Utility of Conformal Prediction Sets for AI-Advised Image Labeling</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Dongping Zhang, Angelos Chatzimparmpas, Negar Kamali, Jessica Hullman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146876">Link</a></p>
<p>Abstract: As deep neural networks are more commonly deployed in high-stakes domains, their black-box nature makes uncertainty quantification challenging. We investigate the effects of presenting conformal prediction sets---a distribution-free class of methods for generating prediction sets with specified coverage---to express uncertainty in AI-advised decision-making. Through a large online experiment, we compare the utility of conformal prediction sets to displays of Top-$1$ and Top-$k$ predictions for AI-advised image labeling. In a pre-registered analysis, we find that the utility of prediction sets for accuracy varies with the difficulty of the task: while they result in accuracy on par with or less than Top-$1$ and Top-$k$ displays for easy images, prediction sets excel at assisting humans in labeling out-of-distribution (OOD) images, especially when the set size is small. Our results empirically pinpoint practical challenges of conformal prediction sets and provide implications on how to incorporate them for real-world decision-making.</p>
<h2>Eye and Face</h2>
<h3>EyeEcho: Continuous and Low-power Facial Expression Tracking on Glasses</h3>
<p>Authors: Ke Li, Ruidong Zhang, Siyuan Chen, Boao Chen, Mose Sakashita, Francois Guimbretiere, Cheng Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146746">Link</a></p>
<h3>Uncovering and Addressing Blink-Related Challenges in Using Eye Tracking for Interactive Systems</h3>
<p>Authors: Jesse Grootjen, Henrike Weingärtner, Sven Mayer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147069">Link</a></p>
<h3>MELDER: The Design and Evaluation of a Real-time Silent Speech Recognizer for Mobile Devices</h3>
<p>Authors: Laxmi Pandey, Ahmed Arif</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146951">Link</a></p>
<h3>ReHEarSSE: Recognizing Hidden-in-the-Ear Silently Spelled Expressions</h3>
<p>Authors: Xuefu Dong, Yifei Chen, Yuuki Nishiyama, Kaoru Sezaki, Yuntao Wang, Ken Christofferson, Alex Mariakakis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147342">Link</a></p>
<h3>Watch Your Mouth: Silent Speech Recognition with Depth Sensing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Xue Wang, Zixiong Su, Jun Rekimoto, Yang Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147350">Link</a></p>
<h2>Fabrication: 3D Printing A</h2>
<h3>SolderlessPCB: Reusing Electronic Components in PCB Prototyping through Detachable 3D Printed Housings</h3>
<p>Authors: Zeyu Yan, Jiasheng Li, Zining Zhang, Huaishu Peng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146974">Link</a></p>
<h3>The Effect of Orientation on the Readability and Comfort of 3D-Printed Braille</h3>
<p>Authors: Eduardo Puerta, Tarik Crnovrsanin, Laura South, Cody Dunne</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147955">Link</a></p>
<h3>SketchPath: Using Digital Drawing to Integrate the Gestural Qualities of Craft in CAM-Based Clay 3D Printing</h3>
<p>BEST_PAPER</p>
<p>Authors: Devon Frost, Raina Lee, Eun-Ha Paek, Jennifer Jacobs</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148134">Link</a></p>
<h3>Throwing Out Conventions: Reimagining Craft-Centered CNC Tool Design through the Digital Pottery Wheel</h3>
<p>BEST_PAPER</p>
<p>Authors: Ilan Moyer, Sam Bourgault, Devon Frost, Jennifer Jacobs</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147769">Link</a></p>
<h3>3D Printing Locally Activated Visual-Displays Embedded in 3D Objects via Electrically Conductive and Thermochromic Materials</h3>
<p>Authors: Kongpyung (Justin) Moon, Zofia Marciniak, Ryo Suzuki, Andrea Bianchi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147413">Link</a></p>
<h2>Finance and Money</h2>
<h3>Shortchanged: Uncovering and Analyzing Intimate Partner Financial Abuse in Consumer Complaints</h3>
<p>Authors: Arkaprabha Bhattacharya, Kevin Lee, Vineeth Ravi, Jessica Staddon, Rosanna Bellini</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148177">Link</a></p>
<h3>Stranger Danger? Investor Behavior and Incentives on Cryptocurrency Copy-Trading Platforms</h3>
<p>Authors: Daisuke Kawai, Kyle Soska, Bryan Routledge, Ariel Zetlin-Jones, Nicolas Christin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148232">Link</a></p>
<h3>Supportive Fintech for Individuals with Bipolar Disorder: Financial Data Sharing Preferences for Longitudinal Care Management</h3>
<p>Authors: Jeff Brozena, Johnna Blair, Thomas Richardson, Mark Matthews, Dahlia Mukherjee, Erika F. H. Saunders, Saeed Abdullah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147609">Link</a></p>
<h3>Trading as Gambling: Social Investing and Financial Risks on the r/WallStreetBets subreddit</h3>
<p>Authors: Yubo Kou, Sam Moradzadeh, Xinning Gui</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147259">Link</a></p>
<h3>"Don't put all your eggs in one basket": How Cryptocurrency Users Choose and Secure Their Wallets</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yaman Yu, Tanusree Sharma, Sauvik Das, Yang Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148179">Link</a></p>
<h2>Hand Interaction</h2>
<h3>EITPose: Wearable and Practical Electrical Impedance Tomography for Continuous Hand Pose Estimation</h3>
<p>Authors: Alexander Kyu, Hongyu Mao, Junyi Zhu, Mayank Goel, Karan Ahuja</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147181">Link</a></p>
<h3>EchoWrist: Continuous Hand Pose Tracking and Hand-Object Interaction Recognition Using Low-Power Active Acoustic Sensing On a Wristband</h3>
<p>Authors: Chi-Jung Lee, Ruidong Zhang, Devansh Agarwal, Tianhong Yu, Vipin Gunda, Oliver Lopez, James Kim, Sicheng Yin, Boao Dong, Ke Li, Mose Sakashita, Francois Guimbretiere, Cheng Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147046">Link</a></p>
<h3>Single-handed Folding Interactions with a Modified Clamshell Flip Phone</h3>
<p>Authors: Yen-Ting Yeh, Antony Albert Raj Irudayaraj, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147358">Link</a></p>
<h3>Emotion Embodied: Unveiling the Expressive Potential of Single-Hand Gestures</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yuhan Luo, Junnan Yu, Minhui Liang, Yichen Wan, Kening Zhu, Shannon Santosa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146626">Link</a></p>
<h3>Hand Gesture Recognition for Blind Users by Tracking 3D Gesture Trajectory</h3>
<p>Authors: Prerna Khanna, IV Ramakrishnan, Shubham Jain, Xiaojun Bi, Aruna Balasubramanian</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148204">Link</a></p>
<h2>Health and AI A</h2>
<h3>``It Is a Moving Process'': Understanding the Evolution of Explainability Needs of Clinicians in Pulmonary Medicine</h3>
<p>Authors: Lorenzo Corti, Rembrandt Oltmans, Jiwon Jung, Agathe Balayn, Marlies Wijsenbeek, Jie Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147566">Link</a></p>
<p>Abstract: Clinicians increasingly pay attention to Artificial Intelligence (AI) to improve the quality and timeliness of their services. There are converging opinions on the need for Explainable AI (XAI) in healthcare. However, prior work considers explanations as stationary entities with no account for the temporal dynamics of patient care. In this work, we involve 16 Idiopathic Pulmonary Fibrosis (IPF) clinicians from a European university medical centre and investigate their evolving uses and purposes for explainability throughout patient care. By applying a patient journey map for IPF, we elucidate clinicians' informational needs, how human agency and patient-specific conditions can influence the interaction with XAI systems, and the content, delivery, and relevance of explanations over time. We discuss implications for integrating XAI in clinical contexts and more broadly how explainability is defined and evaluated. Furthermore, we reflect on the role of medical education in addressing epistemic challenges related to AI literacy.</p>
<h3>Understanding the Impact of Long-Term Memory on Self-Disclosure with Large Language Model-Driven Chatbots for Public Health Intervention</h3>
<p>Authors: Eunkyung Jo, Yuin Jeong, SoHyun Park, Daniel Epstein, Young-Ho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148244">Link</a></p>
<p>Abstract: Recent large language models (LLMs) offer the potential to support public health monitoring by facilitating health disclosure through open-ended conversations but rarely preserve the knowledge gained about individuals across repeated interactions. Augmenting LLMs with long-term memory (LTM) presents an opportunity to improve engagement and self-disclosure, but we lack an understanding of how LTM impacts people's interaction with LLM-driven chatbots in public health interventions. We examine the case of CareCall—an LLM-driven voice chatbot with LTM—through the analysis of 1,252 call logs and interviews with nine users. We found that LTM enhanced health disclosure and fostered positive perceptions of the chatbot by offering familiarity. However, we also observed challenges in promoting self-disclosure through LTM, particularly around addressing chronic health conditions and privacy concerns. We discuss considerations for LTM integration in LLM-driven chatbots for public health monitoring, including carefully deciding what topics need to be remembered in light of public health goals.  </p>
<h3>Advancing Patient-Centered Shared Decision-Making with AI Systems for Older Adult Cancer Patients</h3>
<p>Authors: Yuexing Hao, Zeyu Liu, Robert Riter, Saleh Kalantari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148222">Link</a></p>
<p>Abstract: Shared decision making (SDM) plays a vital role in clinical practice guidelines, fostering enduring therapeutic communication and patient-clinician relationships. Previous research indicates that active patient participation in decision-making improves satisfaction and treatment outcomes. However, medical decision-making can be intricate and multifaceted. To help make SDM more accessible, we designed a patient-centered Artificial Intelligence (AI) SDM system for older adult cancer patients who lack high health literacy to become more involved in the clinical decision-making process and to improve comprehension toward treatment outcomes. We conducted a pilot feasibility study through 12 preliminary interviews followed by 25 usability testing interviews after the system development, with older adult cancer survivors and clinicians. Results indicated promise in the AI system's ability to enhance SDM, providing personalized healthcare experiences and education for cancer patients. Clinician responses also provided useful suggestions for SDM’s new design and research opportunities in mitigating medical errors and improving clinical efficiency.</p>
<h3>Beyond the Waiting Room: Patient's Perspectives on the Conversational Nuances of Pre-Consultation Chatbots</h3>
<p>Authors: Brenna Li, Ofek Gross, Noah Crampton, Mamta Kapoor, Saba Tauseef, Mohit Jain, Khai Truong, Alex Mariakakis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147742">Link</a></p>
<p>Abstract: Pre-consultation serves as a critical information exchange between healthcare providers and patients, streamlining visits and supporting patient-centered care. Human-led pre-consultations offer many benefits, yet they require significant time and energy from clinical staff. In this work, we identify design goals for pre-consultation chatbots given their potential to carry out human-like conversations and autonomously adapt their line of questioning. We conducted a study with 33 walk-in clinic patients to elicit design considerations for pre-consultation chatbots. Participants were exposed to one of two study conditions: an LLM-powered AI agent and a Wizard-of-Oz agent simulated by medical professionals. Our study found that both conditions were equally well-received and demonstrated comparable conversational capabilities. However, the extent of the follow-up questions and the amount of empathy impacted the chatbot's perceived thoroughness and sincerity. Patients also highlighted the importance of setting expectations for the chatbot before and after the pre-consultation experience.</p>
<h3>How Much Decision Power Should (A)I Have?: Investigating Patients’ Preferences Towards AI Autonomy in Healthcare Decision Making</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Dajung Kim, Niko Vegt, Valentijn Visch, Marina Bos-de Vos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146903">Link</a></p>
<p>Abstract: Despite the growing potential of artificial intelligence (AI) in improving clinical decision making, patients' perspectives on the use of AI for their care decision making are underexplored. In this paper, we investigate patients’ preferences towards the autonomy of AI in assisting healthcare decision making. We conducted interviews and an online survey using an interactive narrative and speculative AI prototypes to elicit participants’ preferred choices of using AI in a pregnancy care context. The analysis of the interviews and in-story responses reveals that patients’ preferences for AI autonomy vary per person and context, and may change over time. This finding suggests the need for involving patients in defining and reassessing the appropriate level of AI assistance for healthcare decision making. Departing from these varied preferences for AI autonomy, we discuss implications for incorporating patient-centeredness in designing AI-powered healthcare decision making.</p>
<h2>Health and AI B</h2>
<h3>The Illusion of Empathy? Notes on Displays of Emotion in Human-Computer Interaction</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Andrea Cuadra, Maria Wang, Lynn Stein, Malte Jung, Nicola Dell, Deborah Estrin, James Landay</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147950">Link</a></p>
<p>Abstract: From ELIZA to Alexa, Conversational Agents (CAs) have been deliberately designed to elicit or project empathy. Although empathy can help technology better serve human needs, it can also be deceptive and potentially exploitative. In this work, we characterize empathy in interactions with CAs, highlighting the importance of distinguishing evocations of empathy between two humans from ones between a human and a CA. To this end, we systematically prompt CAs backed by large language models (LLMs) to display empathy while conversing with, or about, 65 distinct human identities, and also compare how different LLMs display or model empathy. We find that CAs make value judgments about certain identities, and can be encouraging of identities related to harmful ideologies (e.g., Nazism and xenophobia). Moreover, a computational approach to understanding empathy reveals that despite their ability to display empathy, CAs do poorly when interpreting and exploring a user's experience, contrasting with their human counterparts.</p>
<h3>Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis</h3>
<p>Authors: Shao Zhang, Jianing Yu, Xuhai "Orson" Xu, Changchang Yin, Yuxuan Lu, Bingsheng Yao, Melanie Tory, Lace Padilla, Jeffrey Caterino, Ping Zhang, Dakuo Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147992">Link</a></p>
<p>Abstract: Today's AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that \system enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.</p>
<h3>Leveraging Prompt-Based Large Language Models: Predicting Pandemic Health Decisions and Outcomes Through Social Media Language</h3>
<p>Authors: Xiaohan Ding, Buse Carik, Uma Sushmitha Gunturi, Valerie Reyna, Eugenia Rho</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147157">Link</a></p>
<p>Abstract: We introduce a multi-step reasoning framework using prompt-based LLMs to examine the relationship between social media language patterns and trends in national health outcomes. Grounded in fuzzy-trace theory, which emphasizes the importance of “gists” of causal coherence in effective health communication, we introduce Role-Based Incremental Coaching (RBIC), a prompt-based LLM framework, to identify gists at-scale. Using RBIC, we systematically extract gists from subreddit discussions opposing COVID-19 health measures (Study 1). We then track how these gists evolve across key events (Study 2) and assess their influence on online engagement (Study 3). Finally, we investigate how the volume of gists is associated with national health trends like vaccine uptake and hospitalizations (Study 4). Our work is the first to empirically link social media linguistic patterns to real-world public health trends, highlighting the potential of prompt-based LLMs in identifying critical online discussion patterns that can form the basis of public health communication strategies.</p>
<h3>Multimodal Healthcare AI: Identifying and Designing Clinically Relevant Vision-Language Applications for Radiology</h3>
<p>Authors: Nur Yildirim, Hannah Richardson, Maria Teodora Wetscherek, Junaid Bajwa, Joseph Jacob, Mark Pinnock, Stephen Harris, Daniel Coelho de Castro, Shruthi Bannur, Stephanie Hyland, Pratik Ghosh, Mercy Ranjit, Kenza Bouzid, Anton Schwaighofer, Fernando Pérez-García, Harshita Sharma, Ozan Oktay, Matthew Lungren, Javier Alvarez-Valle, Aditya Nori, Anja Thieme</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146624">Link</a></p>
<p>Abstract: Recent advances in AI combine large language models (LLMs) with vision encoders that bring forward unprecedented technical capabilities to leverage for a wide range of healthcare applications. Focusing on the domain of radiology, vision-language models (VLMs) achieve good performance results for tasks such as generating radiology findings based on a patient's medical image, or answering visual questions (e.g., ``Where are the nodules in this chest X-ray?''). However, the clinical utility of potential applications of these capabilities is currently underexplored. We engaged in an iterative, multidisciplinary design process to envision clinically relevant VLM interactions, and co-designed four VLM use concepts: Draft Report Generation, Augmented Report Review, Visual Search and Querying, and Patient Imaging History Highlights. We studied these concepts with 13 radiologists and clinicians who assessed the VLM concepts as valuable, yet articulated many design considerations. Reflecting on our findings, we discuss implications for integrating VLM capabilities in radiology, and for healthcare AI more generally.</p>
<h3>Human-Algorithmic Interaction Using a Large Language Model-Augmented Artificial Intelligence Clinical Decision Support System</h3>
<p>Authors: Niroop Rajashekar, Yeo Eun Shin, Yuan Pu, Sunny Chung, Kisung You, Mauro Giuffre, Colleen Chan, Theo Saarinen, Allen Hsiao, Jasjeet Sekhon, Ambrose Wong, Leigh Evans, Rene Kizilcec, Loren Laine, Terika McCall, Dennis Shung</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147431">Link</a></p>
<p>Abstract: Integration of artificial intelligence (AI) into clinical decision support systems (CDSS) poses a socio-technological challenge that is impacted by usability, trust, and human-computer interaction (HCI). AI-CDSS interventions have shown limited benefit in clinical outcomes, which may be due to insufficient understanding of how health-care providers interact with AI systems. Large language models (LLMs) have the potential to enhance AI-CDSS, but haven't been studied in either simulated or real-world clinical scenarios. We present findings from a randomized controlled trial deploying AI-CDSS for the management of upper gastrointestinal bleeding (UGIB) with and without an LLM interface within realistic clinical simulations for physician and medical student participants. We find evidence that LLM augmentation improves ease-of-use, that LLM-generated responses with citations improve trust, and HCI varies based on clinical expertise. Qualitative themes from interviews suggest the perception of LLM-augmented AI-CDSS as a team-member used to confirm initial clinical intuitions and help evaluate borderline decisions. </p>
<h2>Health and Care Practices</h2>
<h3>Designing Communication Feedback Systems To Reduce Healthcare Providers’ Implicit Biases In Patient Encounters</h3>
<p>Authors: Emily Bascom, Reggie Casanova-Perez, Kelly Tobar, Manas Satish Bedmutha, Harshini Ramaswamy, Wanda Pratt, Janice Sabin, Brian Wood, Nadir Weibel, Andrea Hartzler</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147797">Link</a></p>
<h3>Perceived Empathy of Technology Scale (PETS): Measuring Empathy of Systems Toward the User</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Matthias Schmidmaier, Jonathan Rupp, Darina Cvetanova, Sven Mayer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146760">Link</a></p>
<h3>Designing for Caregiver-facing Values Elicitation Tools</h3>
<p>BEST_PAPER</p>
<p>Authors: Pin Sym Foong, Natasha Ureyang, Charisse Foo, Sajeban Antonyrex, Gerald Huat Choon Koh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146676">Link</a></p>
<h3>Hospital Employee Experiences Caring for Patients in Smart Patient Rooms</h3>
<p>Authors: Joshua Dawson, Eden Fisher, Jason Wiese</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147343">Link</a></p>
<h3>Investigating Why Clinicians Deviate from Standards of Care: Liberating Patients from Mechanical Ventilation in the ICU</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Nur Yildirim, Susanna Zlotnikov, Aradhana Venkat, Gursimran Chawla, Jennifer Kim, Leigh Bukowski, Jeremy Kahn, James McCann, John Zimmerman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147846">Link</a></p>
<h2>Healthcare Training</h2>
<h3>Looking Together ≠ Seeing the Same Thing: Understanding Surgeons' Visual Needs During Intra-operative Coordination and Instruction</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Vitaliy Popov, Xinyue Chen, Jingying Wang, Michael Kemp, Gurjit Sandhu, Taylor Kantor, Natalie Mateju, Xu Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146738">Link</a></p>
<h3>Surgment: Segmentation-enabled Semantic Search and Creation of Visual Question and Feedback to Support Video-Based Surgery Learning</h3>
<p>Authors: Jingying Wang, Haoran Tang, Taylor Kantor, Tandis Soltani, Vitaliy Popov, Xu Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147894">Link</a></p>
<h3>MR Microsurgical Suture Training System with Level-Appropriate Support</h3>
<p>Authors: Yuka Tashiro, Shio Miyafuji, Yusuke Kojima, Satoshi Kiyofuji, Taichi Kin, Takeo Igarashi, Hideki Koike</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147989">Link</a></p>
<h3>Facilitating Virtual Reality Integration in Medical Education: A Case Study of Acceptability and Learning Impact in Childbirth Delivery Training</h3>
<p>Authors: Chang Liu, Felicia Tan, Shengdong Zhao, Abhiram Kanneganti, Gosavi Arundhati Tushar, Eng Tat Khoo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147754">Link</a></p>
<h3>"I'd be watching him contour till 10 o'clock at night'': Understanding Tensions between Teaching Methods and Learning Needs in Healthcare Apprenticeship</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Matin Yarmand, Chen Chen, Kexin Cheng, James D. Murphy, Nadir Weibel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147449">Link</a></p>
<h2>Human-Robot Interaction A</h2>
<h3>A Robot Jumping the Queue: Expectations About Politeness and Power During Conflicts in Everyday Human-Robot Encounters</h3>
<p>Authors: Franziska Babel, Robin Welsch, Linda Miller, Philipp Hock, Sam Thellman, Tom Ziemke</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147417">Link</a></p>
<h3>I feel being there, they feel being together: Exploring How Telepresence Robots Facilitate Long-Distance Family Communication</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jiyeon Seo, Hajin Lim, Bongwon Suh, Joonhwan Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147312">Link</a></p>
<h3>PepperPose: Full-Body Pose Estimation with a Companion Robot</h3>
<p>Authors: Chongyang Wang, Siqi Zheng, Lingxiao Zhong, Chun Yu, Chen Liang, Yuntao Wang, Yuan Gao, Tin Lun Lam, Yuanchun Shi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146730">Link</a></p>
<h3>Giving Robots a Voice: Human-in-the-Loop Voice Creation and open-ended Labeling</h3>
<p>Authors: Pol van Rijn, Silvan Mertes, Kathrin Janowski, Katharina Weitz, Nori Jacoby, Elisabeth André</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147115">Link</a></p>
<h2>Human-Robot Interaction B</h2>
<h3>Robot-Assisted Decision-Making: Unveiling the Role of Uncertainty Visualisation and Embodiment</h3>
<p>Authors: Sarah Schömbs, Saumya Pareek, Jorge Goncalves, Wafa Johal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146811">Link</a></p>
<h3>Trash in Motion: Emergent Interactions with a Robotic Trashcan</h3>
<p>Authors: Barry Brown, Fanjun Bu, Ilan Mandel, Wendy Ju</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146631">Link</a></p>
<h3>Investigating Effect of Altered Auditory Feedback on Self-Representation, Subjective Operator Experience, and Task Performance in Teleoperation of a Social Robot</h3>
<p>Authors: Nami Ogawa, Jun Baba, Junya Nakanishi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147866">Link</a></p>
<h3>The Adaptive Architectural Layout: How the Control of a Semi-Autonomous Mobile Robotic Partition was Shared to Mediate the Environmental Demands and Resources of an Open-Plan Office</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Alex Binh Vinh Duc Nguyen, Andrew Vande Moere</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146791">Link</a></p>
<h3>From Agent Autonomy to Casual Collaboration: A Design Investigation on Help-Seeking Urban Robots</h3>
<p>Authors: Xinyan Yu, Marius Hoggenmüller, Martin Tomitsch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148163">Link</a></p>
<h2>Human-Robot Interaction C</h2>
<h3>Impact of Multi-Robot Presence and Anthropomorphism on Human Cognition and Emotion</h3>
<p>Authors: Jiadi Luo, Veronika Domova, Lawrence Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147559">Link</a></p>
<h3>Join Me Here if You Will: Investigating Embodiment and Politeness Behaviors When Joining Small Groups of Humans, Robots, and Virtual Characters</h3>
<p>Authors: Sahba Zojaji, Andrii Matviienko, Iolanda Leite, Christopher Peters</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147171">Link</a></p>
<h3>Designing Multispecies Worlds for Robots, Cats, and Humans</h3>
<p>BEST_PAPER</p>
<p>Authors: Eike Schneiders, Steven Benford, Alan Chamberlain, Clara Mancini, Simon Castle-Green, Victor Ngo, Ju Row Farr, Matt Adams, Nick Tandavanitj, Joel Fischer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147577">Link</a></p>
<h3>Towards Robotic Companions: Understanding Handler-Guide Dog Interactions for Informed Guide Dog Robot Design</h3>
<p>BEST_PAPER</p>
<p>Authors: Hochul Hwang, Hee-Tae Jung, Nicholas Giudice, Joydeep Biswas, Sunghoon Lee, Donghyun Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147890">Link</a></p>
<h2>Inter- and Cross-Species Interactions</h2>
<h3>No More Angry Birds: Investigating Touchscreen Ergonomics to Improve Tablet-Based Enrichment for Parrots</h3>
<p>Authors: Rebecca Kleinberger, Jennifer Cunha, Megan McMahon, Ilyena Hirskyj-Douglas</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148084">Link</a></p>
<h3>Ellie Talks About the Weather: Toward Evaluating the Expressive and Enrichment Potential of a Tablet-Based Speech Board in a single Goffin’s Cockatoo</h3>
<p>Authors: Jennifer Cunha, Corinne Renguette, Nikhil Singh, Lily Stella, Megan McMahon, Hao Jin, Rebecca Kleinberger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147963">Link</a></p>
<h3>Call of the Wild Web: Comparing Parrot Engagement in Live vs. Pre-Recorded Video Calls</h3>
<p>Authors: Ilyena Hirskyj-Douglas, Jennifer Cunha, Rebecca Kleinberger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147943">Link</a></p>
<h3>Uncovering Lemur Cross-Species Usage of an Interactive Audio Device In Zoos</h3>
<p>Authors: Vilma Kankaanpää, Fay Clark, Ilyena Hirskyj-Douglas</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147810">Link</a></p>
<h3>Charting Ethical Tensions in Multispecies Technology Research through Beneficiary-Epistemology Space</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Steven Benford, Clara Mancini, Alan Chamberlain, Eike Schneiders, Simon Castle-Green, Joel Fischer, Ayse Kucukyilmaz, Guido Salimbeni, Victor Ngo, Pepita Barnard Stringer, Matt Adams, Nick Tandavanitj, Ju Row Farr</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147025">Link</a></p>
<h2>Perception and Input in Immersive Environments</h2>
<h3>Big or Small, It’s All in Your Head: Visuo-Haptic Illusion of Size-Change Using Finger-Repositioning</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Myung Jin Kim, Eyal Ofek, Michel Pahud, Mike Sinclair, Andrea Bianchi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147073">Link</a></p>
<p>Abstract: Haptic perception of physical sizes increases the realism and immersion in Virtual Reality (VR). Prior work rendered sizes by exerting pressure on the user’s fingertips or employing tangible, shape-changing devices. These interfaces are constrained by the physical shapes they can assume, making it challenging to simulate objects growing larger or smaller than the perceived size of the interface. Motivated by literature on pseudo-haptics describing the strong influence of visuals over haptic perception, this work investigates modulating the perception of size beyond this range. We developed a fixed-sized VR controller leveraging finger-repositioning to create a visuo-haptic illusion of dynamic size-change of handheld virtual objects. Through two user studies, we found that with an accompanying size-changing visual context, users can perceive virtual object sizes up to 44.2% smaller to 160.4%larger than the perceived size of the device. Without the accompanying visuals, a constant size (141.4% of device size) was perceived.</p>
<h3>STMG: A Machine Learning Microgesture Recognition System for Supporting Thumb-Based VR/AR Input</h3>
<p>Authors: Kenrick Kin, Chengde Wan, Ken Koh, Andrei Marin, Necati Cihan Camgöz, Yubo Zhang, Yujun Cai, Fedor Kovalev, Moshe Ben-Zacharia, Shannon Hoople, Marcos Nunes-Ueno, Mariel Sanchez-Rodriguez, Ayush Bhargava, Robert Wang, Eric Sauser, Shugao Ma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146737">Link</a></p>
<p>Abstract: AR/VR devices have started to adopt hand tracking, in lieu of controllers, to support user interaction. However, today's hand input rely primarily on one gesture: pinch. Moreover, current mappings of hand motion to use cases like VR locomotion and content scrolling involve more complex and larger arm motions than joystick or trackpad usage. STMG increases the gesture space by recognizing additional small thumb-based microgestures from skeletal tracking running on a headset. We take a machine learning approach and achieve a 95.1% recognition accuracy across seven thumb gestures performed on the index finger surface: four directional thumb swipes (left, right, forward, backward), thumb tap, and fingertip pinch start and pinch end. We detail the components to our machine learning pipeline and highlight our design decisions and lessons learned in producing a well generalized model. We then demonstrate how these microgestures simplify and reduce arm motions for hand-based locomotion and scrolling interactions.</p>
<h3>Beyond the Blink: Investigating Combined Saccadic &amp; Blink-Suppressed Hand Redirection in Virtual Reality</h3>
<p>Authors: André Zenner, Chiara Karr, Martin Feick, Oscar Ariza, Antonio Krüger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147392">Link</a></p>
<p>Abstract: In pursuit of hand redirection techniques that are ever more tailored to human perception, we propose the first algorithm for hand redirection in virtual reality that makes use of saccades, i.e., fast ballistic eye movements that are accompanied by the perceptual phenomenon of change blindness. Our technique combines the previously proposed approaches of gradual hand warping and blink-suppressed hand redirection with the novel approach of saccadic redirection in one unified yet simple algorithm. We compare three variants of the proposed Saccadic &amp; Blink-Suppressed Hand Redirection (SBHR) technique with the conventional approach to redirection in a psychophysical study (N=25). Our results highlight the great potential of our proposed technique for comfortable redirection by showing that SBHR allows for significantly greater magnitudes of unnoticeable redirection while being perceived as significantly less intrusive and less noticeable than commonly employed techniques that only use gradual hand warping.</p>
<h3>TriPad: Touch Input in AR on Ordinary Surfaces with Hand Tracking Only</h3>
<p>Authors: Camille Dupré, Caroline Appert, Stéphanie Rey, Houssem Saidi, Emmanuel Pietriga</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147490">Link</a></p>
<p>Abstract: TriPad enables opportunistic touch interaction in Augmented Reality using hand tracking only. Users declare the surface they want to appropriate with a simple hand tap gesture. They can then use this surface at will for direct and indirect touch input. TriPad only involves analyzing hand movements and postures, without the need for additional instrumentation, scene understanding or machine learning. TriPad thus works on a variety of flat surfaces, including glass. It also ensures low computational overhead on devices that typically have a limited power budget. We describe the approach, and report on two user studies. The first study demonstrates the robustness of TriPad's hand movement interpreter on different surface materials. The second study compares TriPad against direct mid-air AR input techniques on both discrete and continuous tasks and with different surface orientations. TriPad achieves a better speed-accuracy trade-off overall, improves comfort and minimizes fatigue.</p>
<h3>Flicker Augmentations: Rapid Brightness Modulation for Real-World Visual Guidance using Augmented Reality</h3>
<p>Authors: Jonathan Sutton, Tobias Langlotz, Alexander Plopski, Kasper Hornbæk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147292">Link</a></p>
<p>Abstract: Providing attention guidance, such as assisting in search tasks, is a prominent use for Augmented Reality.  Typically, this is achieved by graphically overlaying geometrical shapes such as arrows. However, providing visual guidance can cause side effects such as attention tunnelling or scene occlusions, and introduce additional visual clutter. Alternatively, visual guidance can adjust saliency but this comes with different challenges such as hardware requirements and environment dependent parameters. In this work we advocate for using flicker as an alternative for real-world guidance using Augmented Reality. We provide evidence for the effectiveness of flicker from two user studies. The first compared flicker against alternative approaches in a highly controlled setting, demonstrating efficacy (N = 28). The second investigated flicker in a practical task, demonstrating feasibility with higher ecological validity (N = 20). Finally, our discussion highlights the opportunities and challenges when using flicker to provide real-world visual guidance using Augmented Reality.</p>
<h2>Learning with AI</h2>
<h3>The Metacognitive Demands and Opportunities of Generative AI</h3>
<p>BEST_PAPER</p>
<p>Authors: Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Scott, Advait Sarkar, Abigail Sellen, Sean Rintel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147504">Link</a></p>
<p>Abstract: Generative AI (GenAI) systems offer unprecedented opportunities for transforming professional and personal work, yet present challenges around prompting, evaluating and relying on outputs, and optimizing workflows. We argue that metacognition—the psychological ability to monitor and control one’s thoughts and behavior—offers a valuable lens to understand and design for these usability challenges. Drawing on research in psychology and cognitive science, and recent GenAI user studies, we illustrate how GenAI systems impose metacognitive demands on users, requiring a high degree of metacognitive monitoring and control. We propose these demands could be addressed by integrating metacognitive support strategies into GenAI systems, and by designing GenAI systems to reduce their metacognitive demand by targeting explainability and customizability. Metacognition offers a coherent framework for understanding the usability challenges posed by GenAI, and provides novel research and design directions to advance human-AI interaction.</p>
<h3>BIDTrainer: An LLMs-driven Education Tool for Enhancing the Understanding and Reasoning in Bio-inspired Design</h3>
<p>Authors: Liuqing Chen, Zhaojun Jiang, Duowei Xia, Zebin Cai, Lingyun Sun, Peter Childs, Haoyu Zuo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147876">Link</a></p>
<p>Abstract: Bio-inspired design (BID) fosters innovative solutions in engineering by drawing inspiration from biology. Learning BID is crucial for developing multidisciplinary innovation skills of designers and engineers. While current BID education has attempted to enhance learners' understanding and analogical reasoning skills in BID, it often relies much on teachers' expertise. When learners turn to learn independently through some educational tools, there are challenges in understanding and reasoning practice in such complex multidisciplinary environment, as well as evaluating learning outcomes comprehensively. Addressing these challenges, we introduce a Large Language Models (LLMs)-driven BID education method based on a structured ontology, as well as three strategies: enhancing understanding through LLMs-enpowered "learning by asking", assisting reasoning by providing hints and feedback, and assessing learning outcomes through benchmarking against existing BID knowledge. Implementing the method, we developed BIDTrainer, an interactive BID education tool. User studies indicate that learners using BIDTrainer understood BID cases better, reason faster with higher interactivity than the baseline, and BIDTrainer assessed the learning outcomes consistent with experts.</p>
<h3>Teachers, Parents, and Students' perspectives on Integrating Generative AI into Elementary Literacy Education</h3>
<p>Authors: Ariel Han, Xiaofei Zhou, Zhenyao Cai, Shenshen Han, Richard Ko, Seth Corrigan, Kylie Peppler</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147607">Link</a></p>
<p>Abstract: The viral launch of new generative AI (GAI) systems, such as ChatGPT and Text-to-Image (TTL) generators, sparked questions about how they can be effectively incorporated into writing education. However, it is still unclear how teachers, parents, and students perceive and suspect GAI systems in elementary school settings. We conducted a workshop with twelve families (parent-child dyads) with children ages 8-12 and interviewed sixteen teachers in order to understand each stakeholder's perspectives and opinions on GAI systems for learning and teaching writing. We found that the GAI systems could be beneficial in generating adaptable teaching materials for teachers, enhancing ideation, and providing students with personalized, timely feedback. However, there are concerns over authorship, students’ agency in learning, and uncertainty concerning bias and misinformation. In this article, we discuss design strategies to mitigate these constraints by implementing an adults-oversight system, balancing AI-role allocation, and facilitating customization to enhance students’ agency over writing projects.</p>
<h3>Teaching Middle Schoolers about the Privacy Threats of Tracking and Pervasive Personalization: A Classroom Intervention Using Design-Based Research</h3>
<p>Authors: Sushmita Khan, Mehtab Iqbal, Oluwafemi Osho, Khushbu Singh, Kyra Derrick, Philip Nelson, Lingyuan Li, Emily Sidnam-Mauch, Nicole Bannister, Kelly Caine, Bart Knijnenburg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146762">Link</a></p>
<p>Abstract: With the pervasive and evolving use of tracking and AI to make inferences about online platform users, it has become imperative for adolescents---a key demographic using such platforms---to develop a deep understanding of these practices to protect their privacy. Traditionally, K-12 cybersecurity education has largely been confined to extracurricular activities, limiting underrepresented students' access. To resolve this shortcoming, we partnered with a rural-identifying middle school to deliver AI-related privacy education in classrooms. Using Design-Based Research methodology, we identified students' AI-related privacy learning needs and developed six education modules. This paper focuses on the design, classroom implementation, and evaluation of module #2, covering the privacy threats of Tracking and Pervasive Personalization (TaPP). Student assessment outcomes show they developed transferable foundational knowledge of the privacy implications of tracking and personalization after participating in the TaPP module. Our findings demonstrate the benefits of integrating AI-related privacy education into existing K-12 curricula.</p>
<h3>Putting Things into Context: Generative AI-Enabled Context Personalization for Vocabulary Learning Improves Learning Motivation</h3>
<p>Authors: Joanne Leong, Pat Pataranutaporn, Valdemar Danry, Florian Perteneder, Yaoli Mao, Pattie Maes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147682">Link</a></p>
<p>Abstract: Fostering students' interests in learning is considered to have many positive downstream effects. Large language models have opened up new horizons for generating content tuned to one's interests, yet it is unclear in what ways and to what extent this customization could have positive effects on learning. To explore this novel dimension, we conducted a between-subjects online study (n=272) featuring different variations of a generative AI vocabulary learning app that enables users to personalize their learning examples. Participants were randomly assigned to control (sentence sourced from pre-existing text) or experimental conditions (generated sentence or short story based on users’ text input). While we did not observe a difference in learning performance between the conditions, the analysis revealed that generative AI-driven context personalization positively affected learning motivation. We discuss how these results relate to previous findings and underscore their significance for the emerging field of using generative AI for personalized learning.  </p>
<h2>Menstrual Tracking and Health</h2>
<h3>Understanding Cultural and Religious Values Relating to Awareness of Women’s Intimate Health among Arab Muslims</h3>
<p>Authors: Latifa Al Naimi, Mirela Alistar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147619">Link</a></p>
<h3>"Islamically, I am not on my period": A Study of Menstrual Tracking in Muslim Women in the US</h3>
<p>Authors: Zaidat Ibrahim, Pallavi Panchpor, Novia Nurain, James Clawson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147294">Link</a></p>
<h3>Tracking During Ramadan: Examining the Intersection of Menstrual and Religious Tracking Practices Among Muslim Women in the United States</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zaidat Ibrahim, Novia Nurain, James Clawson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147054">Link</a></p>
<h3>Functional Design Requirements to Facilitate Menstrual Health Data Exploration</h3>
<p>Authors: Georgianna Lin, Pierre-William Lessard, Minh Le, Brenna Li, Fanny Chevalier, Khai Truong, Alex Mariakakis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147625">Link</a></p>
<h3>My Data, My Choice, My Insights: Women's Requirements when Collecting, Interpreting and Sharing their Personal Health Data</h3>
<p>Authors: Sophie Grimme, Susanna Spoerl, Susanne Boll, Marion Koelle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148283">Link</a></p>
<h2>Mental Health A</h2>
<h3>Supporting Cognitive Reappraisal With Digital Technology: A Content Analysis and Scoping Review of Challenges, Interventions, and Future Directions</h3>
<p>Authors: Alexandra Kitson, Petr Slovak, Alissa Antle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148296">Link</a></p>
<h3>Multi-stakeholder Perspectives on Mental Health Screening Tools for Children</h3>
<p>Authors: Manasa Kalanadhabhatta, Adrelys Mateo Santana, Lynnea Mayorga, Tauhidur Rahman, Deepak Ganesan, Adam Grabell</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147792">Link</a></p>
<h3>HCI Contributions in Mental Health: A Modular Framework to Guide Psychosocial Intervention Design</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Petr Slovak, Sean Munson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148036">Link</a></p>
<h3>“Can you be with that feeling?”: Extending Design Strategies for Interoceptive Awareness for the Context of Mental Health</h3>
<p>Authors: Phoebe Staab, A. Jess Williams, MacKenzie D. A. Robertson, Petr Slovak</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146761">Link</a></p>
<h3>''I Call Upon a Friend'': Virtual Reality-Based Supports for Cognitive Reappraisal Identified through Co-designing with Adolescents</h3>
<p>Authors: Alexandra Kitson, Alissa Antle, Sadhbh Kenny, Ashu Adhikari, Kenneth Karthik, Artun Cimensel, Melissa Chan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147702">Link</a></p>
<h2>Mental Health and AI</h2>
<h3>Patient Perspectives on AI-Driven Predictions of Schizophrenia Relapses: Understanding Concerns and Opportunities for Self-Care and Treatment</h3>
<p>Authors: Dong Whi Yoo, Hayoung Woo, Viet Cuong Nguyen, Michael L. Birnbaum, Kaylee Kruzan, Jennifer Kim, Gregory Abowd, Munmun De Choudhury</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147243">Link</a></p>
<p>Abstract: Early detection and intervention for relapse is important in the treatment of schizophrenia spectrum disorders. Researchers have developed AI models to predict relapse from patient-contributed data like social media. However, these models face challenges, including misalignment with practice and ethical issues related to transparency, accountability, and potential harm. Furthermore, how patients who have recovered from schizophrenia view these AI models has been underexplored. To address this gap, we first conducted semi-structured interviews with 28 patients and reflexive thematic analysis, which revealed a disconnect between AI predictions and patient experience, and the importance of the social aspect of relapse detection. In response, we developed a prototype that used patients' Facebook data to predict relapse. Feedback from seven patients highlighted the potential for AI to foster collaboration between patients and their support systems, and to encourage self-reflection. Our work provides insights into human-AI interaction and suggests ways to empower people with schizophrenia.</p>
<h3>Understanding Human-AI Collaboration in Music Therapy Through Co-Design with Therapists</h3>
<p>Authors: Jingjing Sun, Jingyi Yang, Guyue Zhou, Yucheng Jin, Jiangtao Gong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146901">Link</a></p>
<p>Abstract: The rapid development of musical AI technologies has expanded the creative potential of various musical activities, ranging from music style transformation to music generation. However, little research has investigated how musical AIs can support music therapists, who urgently need new technology support. This study used a mixed method, including semi-structured interviews and a participatory design approach. By collaborating with music therapists, we explored design opportunities for musical AIs in music therapy. We presented the co-design outcomes involving the integration of musical AIs into a music therapy process, which was developed from a theoretical framework rooted in emotion-focused therapy. After that, we concluded the benefits and concerns surrounding music AIs from the perspective of music therapists. Based on our findings, we discussed the opportunities and design implications for applying musical AIs to music therapy. Our work offers valuable insights for developing human-AI collaborative music systems in therapy involving complex procedures and specific requirements.</p>
<h3>Simulating Emotions With an Integrated Computational Model of Appraisal and Reinforcement Learning</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jiayi Zhang, Bernhard Hilpert, Joost Broekens, Jussi Jokinen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147014">Link</a></p>
<p>Abstract: Predicting users' emotional states during interaction is a long-standing goal of affective computing. However, traditional methods based on sensory data alone fall short due to the interplay between users' latent cognitive states and emotional responses. To address this, we introduce a computational cognitive model that simulates emotion as a continuous process, rather than a static state, during interactive episodes. This model integrates cognitive-emotional appraisal mechanisms with computational rationality, utilizing value predictions from reinforcement learning. Experiments with human participants demonstrate the model's ability to predict and explain the emergence of emotions such as happiness, boredom, and irritation during interactions. Our approach opens the possibility of designing interactive systems that adapt to users' emotional states, thereby improving user experience and engagement. This work also deepens our understanding of the potential of modeling the relationship between reward processing, reinforcement learning, goal-directed behavior, and appraisal.</p>
<h3>Facilitating Self-Guided Mental Health Interventions Through Human-Language Model Interaction: A Case Study of Cognitive Restructuring</h3>
<p>Authors: Ashish Sharma, Kevin Rushton, Inna Lin, Theresa Nguyen, Tim Althoff</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147699">Link</a></p>
<p>Abstract: Self-guided mental health interventions, such as "do-it-yourself" tools to learn and practice coping strategies, show great promise to improve access to mental health care. However, these interventions are often cognitively demanding and emotionally triggering, creating accessibility barriers that limit their wide-scale implementation and adoption. In this paper, we study how human-language model interaction can support self-guided mental health interventions. We take cognitive restructuring, an evidence-based therapeutic technique to overcome negative thinking, as a case study. In an IRB-approved randomized field study on a large mental health website with 15,531 participants, we design and evaluate a system that uses language models to support people through various steps of cognitive restructuring. Our findings reveal that our system positively impacts emotional intensity for 67% of participants and helps 65% overcome negative thoughts. Although adolescents report relatively worse outcomes, we find that tailored interventions that simplify language model generations improve overall effectiveness and equity.</p>
<h3>Seeking in Cycles: How Users Leverage Personal Information Ecosystems to Find Mental Health Information</h3>
<p>Authors: Ashlee Milton, Juan Maestre, Abhishek Roy, Rebecca Umbach, Stevie Chancellor</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146836">Link</a></p>
<p>Abstract: Information is crucial to how people understand their mental health and well-being, and many turn to online sources found through search engines and social media. We present an interview study (n = 17) of participants who use online platforms to seek information about their mental illnesses. Participants use their personal information ecosystems in a cyclical process to find information. This cycle is driven by the adoption of new information and questioning the credibility of information. Privacy concerns fueled by perceptions of stigma and platform design also influence their information-seeking decisions. Our work proposes theoretical implications for social computing and information retrieval on information seeking in users' personal information ecosystems. We offer design implications to support users in navigating personal information ecosystems to find mental health information.</p>
<h2>Mindfulness and Goals</h2>
<h3>Fragmented Moments, Balanced Choices: How Do People Make Use of Their Waiting Time?</h3>
<p>Authors: Jian Zheng, Ge Gao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147136">Link</a></p>
<h3>Mindful Scroll: An Infinite Scroll Abstract Colouring App for Mindfulness</h3>
<p>Authors: Saralin Zassman, Craig Kaplan, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147867">Link</a></p>
<h3>My Voice as a Daily Reminder: Self-Voice Alarm for Daily Goal Achievement</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jieun Kim, Hayeon Song</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146620">Link</a></p>
<h3>Leveraging Idle Games to Incentivize Intermittent and Frequent Practice of Deep Breathing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Book Sadprasid, Anne Mei, Alex Mariakakis, Scott Bateman, Fanny Chevalier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147724">Link</a></p>
<h3>Stairway to Heaven: A Gamified VR Journey for Breath Awareness</h3>
<p>Authors: Nathan Miner, Amir Abdollahi, Caleb Myers, Mehmet Kosa, Hamid Ghaednia, Joseph Schwab, Casper Harteveld, Giovanni Troiano</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147670">Link</a></p>
<h2>Participatory AI</h2>
<h3>How Do Analysts Understand and Verify AI-Assisted Data Analyses?</h3>
<p>Authors: Ken Gu, Ruoxi Shang, Tim Althoff, Chenglong Wang, Steven Drucker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148040">Link</a></p>
<p>Abstract: Data analysis is challenging as it requires synthesizing domain knowledge, statistical expertise, and programming skills. Assistants powered by large language models (LLMs), such as ChatGPT, can assist analysts by translating natural language instructions into code. However, AI-assistant responses and analysis code can be misaligned with the analyst's intent or be seemingly correct but lead to incorrect conclusions. Therefore, validating AI assistance is crucial and challenging. Here, we explore how analysts understand and verify the correctness of AI-generated analyses. To observe analysts in diverse verification approaches, we develop a design probe equipped with natural language explanations, code, visualizations, and interactive data tables with common data operations. Through a qualitative user study (n=22) using this probe, we uncover common behaviors within verification workflows and how analysts' programming, analysis, and tool backgrounds reflect these behaviors. Additionally, we provide recommendations for analysts and highlight opportunities for designers to improve future AI-assistant experiences.</p>
<h3>From Fitting Participation to Forging Relationships: The Art of Participatory ML</h3>
<p>Authors: Ned Cooper, Alexandra Zafiroglu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148266">Link</a></p>
<p>Abstract: Participatory machine learning (ML) encourages the inclusion of end users and people affected by ML systems in design and development processes. We interviewed 18 participation brokers—individuals who facilitate such inclusion and transform the products of participants' labour into inputs for an ML artefact or system—across a range of organisational settings and project locations. Our findings demonstrate the inherent challenges of integrating messy contextual information generated through participation with the structured data formats required by ML workflows and the uneven power dynamics in project contexts. We advocate for evolution in the role of brokers to more equitably balance value generated in Participatory ML projects for design and development teams with value created for participants. To move beyond 'fitting' participation to existing processes and empower participants to envision alternative futures through ML, brokers must become educators and advocates for end users, while attending to frustration and dissent from indirect stakeholders.</p>
<h3>Explaining It Your Way - Findings from a Co-Creative Design Workshop on Designing XAI Applications with AI End-Users from the Public Sector</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Katharina Weitz, Ruben Schlagowski, Elisabeth André, Maris Männiste, Ceenu George</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148130">Link</a></p>
<p>Abstract: Human-Centered AI prioritizes end-users' needs like transparency and usability. This is vital for applications that affect people's everyday lives, such as social assessment tasks in the public sector. This paper discusses our pioneering effort to involve public sector AI users in XAI application design through a co-creative workshop with unemployment consultants from Estonia. The workshop's objectives were identifying user needs and creating novel XAI interfaces for the used AI system. As a result of our user-centered design approach, consultants were able to develop AI interface prototypes that would support them in creating success stories for their clients by getting detailed feedback and suggestions. We present a discussion on the value of co-creative design methods with end-users working in the public sector to improve AI application design and provide a summary of recommendations for practitioners and researchers working on AI systems in the public sector. </p>
<h3>Generative AI in the Wild: Prospects, Challenges, and Strategies</h3>
<p>Authors: Yuan Sun, Eunchae Jang, Fenglong Ma, Ting Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146627">Link</a></p>
<p>Abstract: Propelled by their remarkable capabilities to generate novel and engaging content, Generative Artificial Intelligence (GenAI) technologies are disrupting traditional workflows in many industries. While prior research has examined GenAI from a techno-centric perspective, there is still a lack of understanding about how users perceive and utilize GenAI in real-world scenarios. To bridge this gap, we conducted semi-structured interviews with (N = 18) GenAI users in creative industries, investigating the human-GenAI co-creation process within a holistic LUA (Learning, Using and Assessing) framework. Our study uncovered an intriguingly complex landscape: Prospects -- GenAI greatly fosters the co-creation between human expertise and GenAI capabilities, profoundly transforming creative workflows; Challenges -- Meanwhile, users face substantial uncertainties and complexities arising from resource availability, tool usability, and regulatory compliance; Strategies -- In response, users actively devise various strategies to overcome many of such challenges. Our study reveals key implications for the design of future GenAI tools. </p>
<h3>The Situate AI Guidebook: Co-Designing a Toolkit to Support Multi-Stakeholder, Early-stage Deliberations Around Public Sector AI Proposals</h3>
<p>Authors: Anna Kawakami, Amanda Coston, Haiyi Zhu, Hoda Heidari, Kenneth Holstein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147906">Link</a></p>
<p>Abstract: Public sector agencies are rapidly deploying AI systems to augment or automate critical decisions in real-world contexts like child welfare, criminal justice, and public health. 
A growing body of work documents how these AI systems often fail to improve services in practice. These failures can often be traced to decisions made during the early stages of AI ideation and design, such as problem formulation. However, today, we lack systematic processes to support effective, early-stage decision-making about whether and under what conditions to move forward with a proposed AI project. To understand how to scaffold such processes in real-world settings, we worked with public sector agency leaders, AI developers, frontline workers, and community advocates across four public sector agencies and three community advocacy groups in the United States. Through an iterative co-design process, we created the Situate AI Guidebook: a structured process centered around a set of deliberation questions to scaffold conversations around (1) goals and intended use or a proposed AI system, (2) societal and legal considerations, (3) data and modeling constraints, and (4) organizational governance factors. We discuss how the guidebook's design is informed by participants’ challenges, needs, and desires for improved deliberation processes. We further elaborate on implications for designing responsible AI toolkits in collaboration with public sector agency stakeholders and opportunities for future work to expand upon the guidebook. This design approach can be more broadly adopted to support the co-creation of responsible AI toolkits that scaffold key decision-making processes surrounding the use of AI in the public sector and beyond.</p>
<h2>Privacy &amp; Boundaries</h2>
<h3>Under the (neighbor)hood: Hyperlocal Surveillance on Nextdoor</h3>
<p>Authors: Madiha Zahrah Choksi, Marianne Aubin Le Quere, Travis Lloyd, Ruojia Tao, James Grimmelmann, Mor Naaman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147901">Link</a></p>
<h3>What You Experience is What We Collect: User Experience Based Fine-Grained Permissions for Everyday Augmented Reality</h3>
<p>Authors: Melvin Abraham, Mark McGill, Mohamed Khamis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146684">Link</a></p>
<h3>“I Don’t Want to Become a Number’’: Examining Different Stakeholder Perspectives on a Video-Based Monitoring System for Senior Care with Inherent Privacy Protection (by Design).</h3>
<p>Authors: Tamara Mujirishvili, Anton Fedosov, Kooshan Hashemifard, Pau Climent-Pérez, Francisco Florez-Revuelta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146872">Link</a></p>
<h3>Bring Privacy To The Table: Interactive Negotiation for Privacy Settings of Shared Sensing Devices</h3>
<p>Authors: Haozhe Zhou, Mayank Goel, Yuvraj Agarwal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147351">Link</a></p>
<h3>What to the Muslim is Internet search: Digital Borders as Barriers to Information</h3>
<p>Authors: Lubna Razaq, Sucheta Ghoshal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147363">Link</a></p>
<h2>Privacy for Safer Web and Apps</h2>
<h3>“That’s Kind of Sus(picious)”: The Comprehensiveness of Mental Health Application Users’ Privacy and Security Concerns</h3>
<p>Authors: Yi Xuan Khoo, Rachael Kang, Tera L. Reynolds, Helena M. Mentis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146698">Link</a></p>
<h3>Websites Need Your Permission Too -- User Sentiment and Decision-Making on Web Permission Prompts in Desktop Chrome</h3>
<p>Authors: Marian Harbach</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147321">Link</a></p>
<h3>PriviAware: Exploring Data Visualization and Dynamic Privacy Control Support for Data Collection in Mobile Sensing Research</h3>
<p>Authors: Hyunsoo Lee, Yugyeong Jung, Hei Yiu Law, Seolyeong Bae, Uichin Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148313">Link</a></p>
<h3>Privacy of Default Apps in Apple’s Mobile Ecosystem</h3>
<p>Authors: Amel Bourdoucen, Janne Lindqvist</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147013">Link</a></p>
<h3>Measuring Compliance with the California Consumer Privacy Act Over Space and Time</h3>
<p>Authors: Van Tran, Aarushi Mehrotra, Marshini Chetty, Nick Feamster, Jens Frankenreiter, Lior Strahilevitz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147035">Link</a></p>
<h2>Privacy and Deepfake</h2>
<h3>Non-Consensual Synthetic Intimate Imagery: Prevalence, Attitudes, and Knowledge in 10 Countries</h3>
<p>Authors: Rebecca Umbach, Nicola Henry, Gemma Beard, Colleen Berryessa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148314">Link</a></p>
<h3>It's Trying Too Hard To Look Real: Deepfake Moderation Mistakes and Identity-Based Bias</h3>
<p>Authors: Jaron Mink, Miranda Wei, Collins Munyendo, Kurt Hugenberg, Tadayoshi Kohno, Elissa Redmiles, Gang Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147959">Link</a></p>
<h3>Examining Human Perception of Generative Content Replacement in Image Privacy Protection</h3>
<p>Authors: Anran Xu, Shitao Fang, Huan Yang, Simo Hosio, Koji Yatani</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148241">Link</a></p>
<h3>Dungeons &amp; Deepfakes: Using scenario-based role-play to study journalists' behavior towards using AI-based verification tools for video content</h3>
<p>Authors: Saniat Sohrawardi, Matthew Wright, Yijing Kelly Wu, Andrea Hickerson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146663">Link</a></p>
<h3>Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks</h3>
<p>BEST_PAPER</p>
<p>Authors: Hao-Ping (Hank) Lee, Yu-Ju Yang, Thomas Serban von Davier, Jodi Forlizzi, Sauvik Das</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146930">Link</a></p>
<h2>Reflection and Regulation for Wellbeing</h2>
<h3>“I feel like he’s looking in the computer world to be social, but I can’t trust his judgement”: Reimagining Parental Control for Children with ASD</h3>
<p>Authors: Prakriti Dumaru, Bryson Hackler, Audrey Flood, Mahdi Nasrullah Al-Ameen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147979">Link</a></p>
<h3>Supporting Experiential Learning in People with Gestational Diabetes Mellitus</h3>
<p>Authors: Zaidat Ibrahim, Clara Caldeira, Chia-Fang Chung</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147011">Link</a></p>
<h3>Momentary Stressor Logging and Reflective Visualizations: Implications for Stress Management with Wearables</h3>
<p>Authors: Sameer Neupane, Mithun Saha, Nasir Ali, Timothy Hnat, Shahin Samiei, Anandatirtha Nandugudi, David M. Almeida, Santosh Kumar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148091">Link</a></p>
<h3>From Disorientation to Harmony: Autoethnographic Insights into Transformative Videogame Experiences</h3>
<p>BEST_PAPER</p>
<p>Authors: Jaakko Väkevä, Elisa Mekler, Janne Lindqvist</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147641">Link</a></p>
<h3>New Understandings of Loss: Examining the Role of Reflective Technology Within Bereavement and Meaning-Making</h3>
<p>Authors: Colin LeFevre, Chia-Fang Chung</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147535">Link</a></p>
<h2>Research Methods and Tools B</h2>
<h3>"To Click or not to Click": Back to Basic for Experience Sampling for Office Well-being in Shared Office Spaces</h3>
<p>Authors: Hans Brombacher, Dimitra Dritsa, Steven Vos, Steven Houben</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147147">Link</a></p>
<h3>Who is "I"?: Subjectivity and  Ethnography in HCI</h3>
<p>Authors: Tejaswini Joshi, Heidi Biggs, Jeffrey Bardzell, Shaowen Bardzell</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147561">Link</a></p>
<h3>Understanding fraudulence in online qualitative studies: From the researcher's perspective</h3>
<p>Authors: Aswati Panicker, Novia Nurain, Zaidat Ibrahim, Chun-Han Ariel Wang, Seung Wan Ha, Yuxing Wu, Kay Connelly, Katie Siek, Chia-Fang Chung</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147323">Link</a></p>
<h3>Did You Misclick? Reversing 5-Point Satisfaction Scales Causes Unintended Responses</h3>
<p>Authors: Martin Pielot</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147691">Link</a></p>
<h3>Towards Estimating Missing Emotion Self-reports Leveraging User Similarity: A Multi-task Learning Approach</h3>
<p>Authors: Surjya Ghosh, Salma Mandi, Sougata Sen, Bivas Mitra, Pradipta De</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148276">Link</a></p>
<h2>Security Systems</h2>
<h3>Is a Trustmark and QR Code Enough? The Effect of IoT Security and Privacy Label Information Complexity on Consumer Comprehension and Behavior</h3>
<p>Authors: Claire Chen, Dillon Shu, Hamsini Ravishankar, Xinran Li, Yuvraj Agarwal, Lorrie Cranor</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146756">Link</a></p>
<h3>I see an IC: A Mixed-Methods Approach to Study Human Problem-Solving Processes in Hardware Reverse Engineering</h3>
<p>Authors: René Walendy, Markus Weber, Jingjie Li, Steffen Becker, Carina Wiesen, Malte Elson, Younghyun Kim, Kassem Fawaz, Nikol Rummel, Christof Paar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146998">Link</a></p>
<h3>Mental Models, Expectations and Implications of Client-Side Scanning: An Interview Study with Experts</h3>
<p>Authors: Divyanshu Bhardwaj, Carolyn Guthoff, Adrian Dabrowski, Sascha Fahl, Katharina Krombholz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147543">Link</a></p>
<h3>VeriSMS: A Message Verification System for Inclusive Patient Outreach against Phishing Attacks</h3>
<p>Authors: Chenkai Wang, Zhuofan Jia, Hadjer Benkraouda, Cody Zevnik, Nicholas Heuermann, Roopa Foulger, Jonathan Handler, Gang Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148268">Link</a></p>
<h3>SkullID: Through-Skull Sound Conduction based Authentication for Smartglasses</h3>
<p>Authors: Hyejin Shin, Jun Ho Huh, Bum Jun Kwon, Iljoo Kim, Eunyong Cheon, HongMin Kim, Choong-Hoon Lee, Ian Oakley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146810">Link</a></p>
<h2>Social Support for Wellbeing</h2>
<h3>Saharaline: A Collective Social Support Intervention for Teachers in Low-Income Indian Schools</h3>
<p>Authors: Rama Adithya Varanasi, Nicola Dell, Aditya Vashistha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147521">Link</a></p>
<h3>Machine and Human Understanding of Empathy in Online Peer Support: A Cognitive Behavioral Approach</h3>
<p>Authors: Sara Syed, Zainab Iftikhar, Amy Xiao, Jeff Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146964">Link</a></p>
<h3>"Butt call me once you get a chance to chat &#128578;" : Designing Persuasive Reminders for Veterans to Facilitate Peer-Mentor Support</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Md Romael Haque, Zeno Franco, Praveen Madiraju, Natalie Baker, SHEIKH AHAMED, OTIS WINSTEAD, Robert Curry, Sabirat Rubya</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146845">Link</a></p>
<h3>Transitioning Towards a Proactive Practice: A Longitudinal Field Study on the Implementation of a ML System in Adult Social Care</h3>
<p>Authors: Tyler Reinmund, Lars Kunze, Marina Jirotka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147484">Link</a></p>
<h3>The Sound of Support: Gendered Voice Agent as Support to Minority Teammates in Gender-Imbalanced Team</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Angel Hsing-Chi Hwang, Andrea Stevenson Won</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148275">Link</a></p>
<h2>Universal Accessibility A</h2>
<h3>Exploring Mobile Device Accessibility: Challenges, Insights, and Recommendations for Evaluation Methodologies</h3>
<p>Authors: Letícia Seixas Pereira, Maria Matos, Carlos Duarte</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146754">Link</a></p>
<h3>Human I/O: Towards a Unified Approach to Detecting Situational Impairments</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Xingyu Liu, Jiahao Li, David Kim, Xiang 'Anthony' Chen, Ruofei Du</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148270">Link</a></p>
<h3>AXNav: Replaying Accessibility Tests from Natural Language</h3>
<p>Authors: Maryam Taeb, Amanda Swearngin, Eldon Schoop, Ruijia Cheng, Yue Jiang, Jeffrey Nichols</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147260">Link</a></p>
<h3>AccessLens: Auto-detecting Inaccessibility of Everyday Objects</h3>
<p>Authors: Nahyun Kwon, Qian Lu, Muhammad Hasham Qazi, Joanne Liu, Changhoon Oh, Shu Kong, Jeeeun Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147903">Link</a></p>
<h3>A Systematic Review of Ability-diverse Collaboration through Ability-based Lens in HCI</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Lan Xiao, Maryam Bandukda, Katrin Angerbauer, Weiyue Lin, Tigmanshu Bhatnagar, Michael Sedlmair, Catherine Holloway</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147798">Link</a></p>
<h2>User Studies on Large Language Models</h2>
<h3>The Effects of Perceived AI Use On Content Perceptions</h3>
<p>Authors: Irene Rae</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147441">Link</a></p>
<p>Abstract: There is a potential future where the content created by a human and an AI are indistinguishable. In this future, if you can't tell the difference, does it matter?  We conducted a 3 (Assigned creator: human, human with AI assistance, AI) by 4 (Context: news, travel, health, and jokes) mixed-design experiment where participants evaluated human-written content that was presented as created by a human, a human with AI assistance, or an AI.  We found that participants felt more negatively about the content creator and were less satisfied when they thought AI was used, but assigned creator had no effect on content judgments.  We also identified five interpretations for how participants thought AI use affected the content creation process.  Our work suggests that informing users about AI use may not have the intended effect of helping consumers make content judgments and may instead damage the relationship between creators and followers.</p>
<h3>DirectGPT: A Direct Manipulation Interface to Interact with Large Language Models</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Damien Masson, Sylvain Malacria, Géry Casiez, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146635">Link</a></p>
<p>Abstract: We characterize and demonstrate how the principles of direct manipulation can improve interaction with large language models. This includes: continuous representation of generated objects of interest; reuse of prompt syntax in a toolbar of commands; manipulable outputs to compose or control the effect of prompts; and undo mechanisms. This idea is exemplified in DirectGPT, a user interface layer on top of ChatGPT that works by transforming direct manipulation actions to engineered prompts. A study shows participants were 50% faster and relied on 50% fewer and 72% shorter prompts to edit text, code, and vector images compared to baseline ChatGPT. Our work contributes a validated approach to integrate LLMs into traditional software using direct manipulation. Data, code, and demo available at https://osf.io/3wt6s.</p>
<h3>From Text to Self: Users’ Perception of AIMC Tools on Interpersonal Communication and Self</h3>
<p>BEST_PAPER</p>
<p>Authors: Yue Fu, Sami Foell, Xuhai "Orson" Xu, Alexis Hiniker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146970">Link</a></p>
<p>Abstract: In the rapidly evolving landscape of AI-mediated communication (AIMC), tools powered by Large Language Models (LLMs) are becoming integral to interpersonal communication. Employing a mixed-methods approach, we conducted a one-week diary and interview study to explore users’ perceptions of these tools’ ability to: 1) support interpersonal communication in the short-term, and 2) lead to potential long-term effects. Our findings indicate that participants view AIMC support favorably, citing benefits such as increased communication confidence, finding precise language to express their thoughts, and navigating linguistic and cultural barriers. However, our findings also show current limitations of AIMC tools, including verbosity, unnatural responses, and excessive emotional intensity. These shortcomings are further exacerbated by user concerns about inauthenticity and potential overreliance on the technology. We identify four key communication spaces delineated by communication stakes (high or low) and relationship dynamics (formal or informal) that differentially predict users’ attitudes toward AIMC tools. Specifically, participants report that these tools are more suitable for communicating in formal relationships than informal ones and more beneficial in high-stakes than low-stakes communication.</p>
<h3>Farsight: Fostering Responsible AI Awareness During AI Application Prototyping</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zijie Wang, Chinmay Kulkarni, Lauren Wilcox, Michael Terry, Michael Madaio</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146993">Link</a></p>
<p>Abstract: Prompt-based interfaces for Large Language Models (LLMs) have made prototyping and building AI-powered applications easier than ever before. However, identifying potential harms that may arise from AI applications remains a challenge, particularly during prompt-based prototyping. To address this, we present Farsight, a novel in situ interactive tool that helps people identify potential harms from the AI applications they are prototyping. Based on a user's prompt, Farsight highlights news articles about relevant AI incidents and allows users to explore and edit LLM-generated use cases, stakeholders, and harms. We report design insights from a co-design study with 10 AI prototypers and findings from a user study with 42 AI prototypers. After using Farsight, AI prototypers in our user study are better able to independently identify potential harms associated with a prompt and find our tool more useful and usable than existing resources. Their qualitative feedback also highlights that Farsight encourages them to focus on end-users and think beyond immediate harms. We discuss these findings and reflect on their implications for designing AI prototyping experiences that meaningfully engage with AI harms. Farsight is publicly accessible at: https://pair-code.github.io/farsight.</p>
<h3>“As an AI language model, I cannot”: Investigating LLM Denials of User Requests</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Joel Wester, Tim Schrills, Henning Pohl, Niels van Berkel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148063">Link</a></p>
<p>Abstract: Users ask large language models (LLMs) to help with their homework, for lifestyle advice, or for support in making challenging decisions. Yet LLMs are often unable to fulfil these requests, either as a result of their technical inabilities or policies restricting their responses. To investigate the effect of LLMs denying user requests, we evaluate participants' perceptions of different denial styles. We compare specific denial styles (baseline, factual, diverting, and opinionated) across two studies, respectively focusing on LLM's technical limitations and their social policy restrictions. Our results indicate significant differences in users' perceptions of the denials between the denial styles. The baseline denial, which provided participants with brief denials without any motivation, was rated significantly higher on frustration and significantly lower on usefulness, appropriateness, and relevance. In contrast, we found that participants generally appreciated the diverting denial style. We provide design recommendations for LLM denials that better meet peoples' denial expectations.</p>
<h2>Visualization and Sonification</h2>
<h3>Glanceable Data Visualizations for Older Adults: Establishing Thresholds and Examining Disparities Between Age Groups</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zack While, Tanja Blascheck, Yujie Gong, Petra Isenberg, Ali Sarvghad</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148143">Link</a></p>
<h3>DynaVis: Dynamically Synthesized UI Widgets for Visualization Editing</h3>
<p>BEST_PAPER</p>
<p>Authors: Priyan Vaithilingam, Elena Glassman, Jeevana Priya Inala, Chenglong Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148267">Link</a></p>
<h3>Graph4GUI: Graph Neural Networks for Representing Graphical User Interfaces</h3>
<p>Authors: Yue Jiang, Changkong Zhou, Vikas Garg, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146736">Link</a></p>
<h3>Erie: A Declarative Grammar for Data Sonification</h3>
<p>Authors: Hyeok Kim, Yea-Seul Kim, Jessica Hullman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148059">Link</a></p>
<h3>“It is hard to remove from my eye”: Design Makeup Residue Visualization System for Chinese Traditional Opera (Xiqu) Performers</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zeyu Xiong, Shihan Fu, Yanying Zhu, Chenqing Zhu, Xiaojuan Ma, Mingming Fan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146861">Link</a></p>
<h2>Wellbeing and Eating: Nutrition and Weight</h2>
<h3>FoodCensor: Promoting Mindful Digital Food Content Consumption for People with Eating Disorders</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ryuhaerang Choi, Subin Park, Sujin Han, Sung-Ju Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146779">Link</a></p>
<h3>Integrating Expertise in LLMs: Crafting a Customized Nutrition Assistant with Refined Template Instructions</h3>
<p>Authors: Annalisa Szymanski, Brianna Wimer, Oghenemaro Anuyah, Heather Eicher-Miller, Ronald Metoyer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147537">Link</a></p>
<h3>Beyond Static Labels: Unpacking Nutrition Comprehension in the Digital Age</h3>
<p>Authors: Brianna Wimer, Annalisa Szymanski, Ronald Metoyer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148140">Link</a></p>
<h3>Investigating Contextual Notifications to Drive Self-Monitoring in mHealth Apps for Weight Maintenance</h3>
<p>Authors: Yu-Peng Chen, Julia Woodward, Dinank Bista, Xuanpu Zhang, Ishvina Singh, Oluwatomisin Obajemu, Meena Shankar, Kathryn Ross, Jaime Ruiz, Lisa Anthony</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148173">Link</a></p>
<h3>Predicting early user churn in a public digital weight loss intervention</h3>
<p>Authors: Robert Jakob, Nils Lepper, Elgar Fleisch, Tobias Kowatsch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148260">Link</a></p>
<h2>Wellbeing and Mental Health B</h2>
<h3>DeepStress: Supporting Stressful Context Sensemaking in Personal Informatics Systems Using a Quasi-experimental Approach</h3>
<p>Authors: Gyuwon Jung, Sangjun Park, Uichin Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147710">Link</a></p>
<h3>Maintaining Continuing Bonds in Bereavement: A Participatory Design Process of Be.side</h3>
<p>Authors: Jieun Kim, Daisuke Uriu, Giulia Barbareschi, Youichi Kamiyama, Kouta Minamizawa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146846">Link</a></p>
<h3>"I'm gonna KMS": From Imminent Risk to Youth Joking about Suicide and Self-Harm via Social Media</h3>
<p>Authors: Naima Samreen Ali, Sarvech Qadir, Ashwaq Alsoubai, Munmun De Choudhury, Afsaneh Razi, Pamela Wisniewski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147067">Link</a></p>
<h3>EmoEden: Applying Generative Artificial Intelligence to Emotional Learning for Children with High-Function Autism</h3>
<p>Authors: Yilin Tang, Liuqing Chen, Ziyu Chen, Wenkai Chen, Yu Cai, Yao Du, Fan Yang, Lingyun Sun</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146914">Link</a></p>
<h3>“This app said I had severe depression, and now I don’t know what to do”: the unintentional harms of mental health applications</h3>
<p>BEST_PAPER</p>
<p>Authors: Rachael Kang, Tera L. Reynolds</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147719">Link</a></p>
<h2>Writing and AI A</h2>
<h3>MindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients' Journaling</h3>
<p>Authors: Taewan Kim, Seolyeong Bae, Hyun AH Kim, Su-woo Lee, Hwajung Hong, Chanmo Yang, Young-Ho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147830">Link</a></p>
<p>Abstract: Large Language Models (LLMs) offer promising opportunities in mental health domains, although their inherent complexity and low controllability elicit concern regarding their applicability in clinical settings. We present MindfulDiary, an LLM-driven journaling app that helps psychiatric patients document daily experiences through conversation. Designed in collaboration with mental health professionals, MindfulDiary takes a state-based approach to safely comply with the experts' guidelines while carrying on free-form conversations. Through a four-week field study involving 28 patients with major depressive disorder and five psychiatrists, we examined how MindfulDiary facilitates patients' journaling practice and clinical care. The study revealed that MindfulDiary supported patients in consistently enriching their daily records and helped clinicians better empathize with their patients through an understanding of their thoughts and daily contexts. Drawing on these findings, we discuss the implications of leveraging LLMs in the mental health domain, bridging the technical feasibility and their integration into clinical settings.</p>
<h3>Shaping Human-AI Collaboration: Varied Scaffolding Levels in Co-writing with Language Models</h3>
<p>Authors: Paramveer Dhillon, Somayeh Molaei, Jiaqi Li, Maximilian Golub, Shaochun Zheng, Lionel Robert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147385">Link</a></p>
<p>Abstract: Advances in language modeling have paved the way for novel human-AI co-writing experiences. This paper explores how varying levels of scaffolding from large language models (LLMs) shape the co-writing process. Employing a within-subjects field experiment with a Latin square design, we asked participants (N=131) to respond to argumentative writing prompts under three randomly sequenced conditions: no AI assistance (control), next-sentence suggestions (low scaffolding), and next-paragraph suggestions (high scaffolding). Our findings reveal a U-shaped impact of scaffolding on writing quality and productivity (words/time). While low scaffolding did not significantly improve writing quality or productivity, high scaffolding led to significant improvements, especially benefiting non-regular writers and less tech-savvy users. No significant cognitive burden was observed while using the scaffolded writing tools, but a moderate decrease in text ownership and satisfaction was noted. Our results have broad implications for the design of AI-powered writing tools, including the need for personalized scaffolding mechanisms.</p>
<h3>The HaLLMark Effect: Supporting Provenance and Transparent Use of Large Language Models in Writing with Interactive Visualization</h3>
<p>Authors: Md Naimul Hoque, Tasfia Mashiat, Bhavya Ghai, Cecilia Shelton, Fanny Chevalier, Kari Kraus, Niklas Elmqvist</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147129">Link</a></p>
<p>Abstract: The use of Large Language Models (LLMs) for writing has sparked controversy both among readers and writers. On one hand, writers are concerned that LLMs will deprive them of agency and ownership, and readers are concerned about spending their time on text generated by soulless machines. On the other hand, AI-assistance can improve writing as long as writers can conform to publisher policies, and as long as readers can be assured that a text has been verified by a human. We argue that a system that captures the provenance of interaction with an LLM can help writers retain their agency, conform to policies, and communicate their use of AI to publishers and readers transparently. Thus we propose HaLLMark, a tool for visualizing the writer's interaction with the LLM. We evaluated HaLLMark with 13 creative writers, and found that it helped them retain a sense of control and ownership of the text.</p>
<h3>ABScribe: Rapid Exploration &amp; Organization of Multiple Writing Variations in Human-AI Co-Writing Tasks using Large Language Models</h3>
<p>Authors: Mohi Reza, Nathan Laundry, Ilya Musabirov, Peter Dushniku, Zhi Yuan "Michael" Yu, Kashish Mittal, Tovi Grossman, Michael Liut, Anastasia Kuzminykh, Joseph Williams</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148096">Link</a></p>
<p>Abstract: Exploring alternative ideas by rewriting text is integral to the writing process. State-of-the-art Large Language Models (LLMs) can simplify writing variation generation. However, current interfaces pose challenges for simultaneous consideration of multiple variations: creating new variations without overwriting text can be difficult, and pasting them sequentially can clutter documents, increasing workload and disrupting writers' flow. To tackle this, we present ABScribe, an interface that supports rapid, yet visually structured, exploration and organization of writing variations in human-AI co-writing tasks. With ABScribe, users can swiftly modify variations using LLM prompts, which are auto-converted into reusable buttons. Variations are stored adjacently within text fields for rapid in-place comparisons using mouse-over interactions on a popup toolbar. Our user study with 12 writers shows that ABScribe significantly reduces task workload (d = 1.20, p &lt; 0.001), enhances user perceptions of the revision process (d = 2.41, p &lt; 0.001) compared to a popular baseline workflow, and provides insights into how writers explore variations using LLMs.</p>
<h2>Writing and AI B</h2>
<h3>Writer-Defined AI Personas for On-Demand Feedback Generation</h3>
<p>Authors: Karim Benharrak, Tim Zindulka, Florian Lehmann, Hendrik Heuer, Daniel Buschek</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147111">Link</a></p>
<p>Abstract: Compelling writing is tailored to its audience. This is challenging, as writers may struggle to empathize with readers, get feedback in time, or gain access to the target group. We propose a concept that generates on-demand feedback, based on writer-defined AI personas of any target audience. We explore this concept with a prototype (using GPT-3.5) in two user studies (N=5 and N=11): Writers appreciated the concept and strategically used personas for getting different perspectives. The feedback was seen as helpful and inspired revisions of text and personas, although it was often verbose and unspecific. We discuss the impact of on-demand feedback, the limited representativity of contemporary AI systems, and further ideas for defining AI personas. This work contributes to the vision of supporting writers with AI by expanding the socio-technical perspective in AI tool design: To empower creators, we also need to keep in mind their relationship to an audience.</p>
<h3>Intelligent Support Engages Writers Through Relevant Cognitive Processes</h3>
<p>Authors: Andreas Göldi, Thiemo Wambsganss, Seyed Parsa Neshaei, Roman Rietsche</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147114">Link</a></p>
<p>Abstract: Student peer review writing is prevalent and important in education for fostering critical thinking and learning motivation. However, it often entails challenges such as high effort and writer's block. Leaving students unsupported may thus diminish the efficacy of the process. Large Language Models (LLMs) offer a potential remedy, but their utility hinges on user-centered design. Guided by design-determining constructs from the Cognitive Process Theory of Writing, we developed an intelligent writing support tool to alleviate these challenges, aiding 1) ideation and 2) evaluation. A randomized experiment (n=120) confirmed users were less inclined to utilize the tool's intelligent features when offered pre-supplied ideas or evaluations, validating our approach. Moreover, students engaged not less but more with their writing if support was available, indicating an enhanced experience. Our research illuminates design choices for enhancing LLM-based tools' usability and user experience, specifically optimizing intelligent writing support tools to facilitate student peer review.</p>
<h3>The Value, Benefits, and Concerns of Generative AI-Powered Assistance in Writing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zhuoyan Li, Chen Liang, Jing Peng, Ming Yin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147288">Link</a></p>
<p>Abstract: Recent advances in generative AI technologies like large language models raise both excitement and concerns about the future of human-AI co-creation in writing. To unpack people’s attitude towards and experience with generative AI-powered writing assistants, in this paper, we conduct an experiment to understand whether and how much value people attach to AI assistance, and how the incorporation of AI assistance in writing workflows changes people’s writing perceptions and performance. Our results suggest that people are willing to forgo financial payments to receive writing assistance from AI, especially if AI can provide direct content generation assistance and the writing task is highly creative. Generative AI-powered assistance is found to offer benefits in increasing people’s productivity and confidence in writing. However, direct content generation assistance offered by AI also comes with risks, including decreasing people’s sense of accountability and diversity in writing. We conclude by discussing the implications of our findings.</p>
<h3>Rambler: Supporting Writing With Speech via LLM-Assisted Gist Manipulation</h3>
<p>Authors: Susan Lin, Jeremy Warner, J.D. Zamfirescu-Pereira, Matthew Lee, Sauhard Jain, Shanqing Cai, Piyawat Lertvittayakumjorn, Michael Xuelin Huang, Shumin Zhai, Bjoern Hartmann, Can Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147240">Link</a></p>
<p>Abstract: Dictation enables efficient text input on mobile devices. However, writing with speech can produce disfluent, wordy, and incoherent text and thus requires heavy post-processing. This paper presents Rambler, an LLM-powered graphical user interface that supports gist-level manipulation of dictated text with two main sets of functions: gist extraction and macro revision. Gist extraction generates keywords and summaries as anchors to support the review and interaction with spoken text. LLM-assisted macro revisions allow users to respeak, split, merge, and transform dictated text without specifying precise editing locations. Together they pave the way for interactive dictation and revision that help close gaps between spontaneously spoken words and well-structured writing. In a comparative study with 12 participants performing verbal composition tasks, \tool outperformed the baseline of a speech-to-text editor + ChatGPT, as it better facilitates iterative revisions with enhanced user control over the content while supporting surprisingly diverse user strategies.</p>
<h2>Writing, Sketching and AI</h2>
<h3>Neural Canvas: Supporting Scenic Design Prototyping by Integrating 3D Sketching and Generative AI</h3>
<p>Authors: Yulin Shen, Yifei Shen, Jiawen Cheng, Chutian Jiang, Mingming Fan, Zeyu Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147583">Link</a></p>
<p>Abstract: We propose Neural Canvas, a lightweight 3D platform that integrates sketching and a collection of generative AI models to facilitate scenic design prototyping. Compared with traditional 3D tools, sketching in a 3D environment helps designers quickly express spatial ideas, but it does not facilitate the rapid prototyping of scene appearance or atmosphere. Neural Canvas integrates generative AI models into a 3D sketching interface and incorporates four types of projection operations to facilitate 2D-to-3D content creation. Our user study shows that Neural Canvas is an effective creativity support tool, enabling users to rapidly explore visual ideas and iterate 3D scenic designs. It also expedites the creative process for both novices and artists who wish to leverage generative AI technology, resulting in attractive and detailed 3D designs created more efficiently than using traditional modeling tools or individual generative AI platforms.</p>
<h3>A Design Space for Intelligent and Interactive Writing Assistants</h3>
<p>Authors: Mina Lee, Katy Gero, John Chung, Simon Buckingham Shum, Vipul Raheja, Hua Shen, Subhashini Venugopalan, Thiemo Wambsganss, David Zhou, Emad Alghamdi, Tal August, Avinash Bhat, Madiha Zahrah Choksi, Senjuti Dutta, Jin L.C. Guo, Md Naimul Hoque, Yewon Kim, Simon Knight, Seyed Parsa Neshaei, Antonette Shibani, Disha Shrivastava, Lila Shroff, Agnia Sergeyuk, Jessi Stark, Sarah Sterman, Sitong Wang, Antoine Bosselut, Daniel Buschek, Joseph Chee Chang, Sherol Chen, Max Kreminski, Joonsuk Park, Roy Pea, Eugenia Rho, Zejiang Shen, Pao Siangliulue</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146994">Link</a></p>
<p>Abstract: In our era of rapid technological advancement, the research landscape for writing assistants has become increasingly fragmented across various research communities. We seek to address this challenge by proposing a design space as a structured way to examine and explore the multidimensional space of intelligent and interactive writing assistants. Through community collaboration, we explore five aspects of writing assistants: task, user, technology, interaction, and ecosystem. Within each aspect, we define dimensions and codes by systematically reviewing 115 papers while leveraging the expertise of researchers in various disciplines. Our design space aims to offer researchers and designers a practical tool to navigate, comprehend, and compare the various possibilities of writing assistants, and aid in the design of new writing assistants.</p>
<h3>The Impact of Sketch-guided vs. Prompt-guided 3D Generative AIs on the Design Exploration Process</h3>
<p>Authors: Seung Won Lee, Tae Hee Jo, Semin Jin, Jiin Choi, Kyungwon Yun, Sergio Bromberg, Seonghoon Ban, Kyung Hoon Hyun</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148240">Link</a></p>
<p>Abstract: Various modalities have emerged in the field of 3D generative AI (GenAI) to enhance design outcomes.  While some designers find inspiration in prompts to guide their design options, others prefer sketching to embody creative visions. Nonetheless, the impact of the different modalities of 3D GenAI on the design process remains largely unexplored. This study examines the utilization of prompt- and sketch-guided modalities within the design process by conducting linkography and workflow analyses with 12 designers. The results revealed that prompts played a pivotal role in stimulating initial ideation, whereas sketches played a crucial role in embodying design ideas. This investigation highlights the distinct contributions of these modalities at different phases of the design process, suggesting the potential for a more refined and synergistic collaboration between humans and AI. By elucidating the diverse functions of sketches and prompts, we propose prospective directions for the UX framework of the 3D GenAI.</p>
<h3>CreativeConnect: Supporting Reference Recombination for Graphic Design Ideation with Generative AI</h3>
<p>Authors: DaEun Choi, Sumin Hong, Jeongeon Park, John Chung, Juho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147936">Link</a></p>
<p>Abstract: Graphic designers often get inspiration through the recombination of references. Our formative study (N=6) reveals that graphic designers focus on conceptual keywords during this process, and want support for discovering the keywords, expanding them, and exploring diverse recombination options of them, while still having room for designers' creativity. We propose CreativeConnect, a system with generative AI pipelines that helps users discover useful elements from the reference image using keywords, recommends relevant keywords, generates diverse recombination options with user-selected keywords, and shows recombinations as sketches with text descriptions. Our user study (N=16) showed that CreativeConnect helped users discover keywords from the reference and generate multiple ideas based on them, ultimately helping users produce more design ideas with higher self-reported creativity compared to the baseline system without generative pipelines. While CreativeConnect was shown effective in ideation, we discussed how CreativeConnect can be extended to support other types of tasks in creativity support.</p>
<h2>Children and Adults Online Safety</h2>
<h3>"Pikachu would electrocute people who are misbehaving": Expert, Guardian and Child Perspectives on Automated Embodied Moderators for Safeguarding Children in Social Virtual Reality</h3>
<p>Authors: Cristina Fiani, Robin Bretin, Shaun Macdonald, Mohamed Khamis, Mark McGill</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147166">Link</a></p>
<h3>Tricky vs. Transparent: Towards an Ecologically Valid and Safe Approach for Evaluating Online Safety Nudges for Teens</h3>
<p>Authors: Zainab Agha, Jinkyung Park, Ruyuan Wan, Naima Samreen Ali, Yiwei Wang, Dominic DiFranzo, Karla Badillo-Urquiola, Pamela Wisniewski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147274">Link</a></p>
<h3>Systemization of Knowledge (SoK): Creating a Research Agenda for Human-Centered Real-Time Risk Detection on Social Media Platforms</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ashwaq Alsoubai, Jinkyung Park, Sarvech Qadir, Gianluca Stringhini, Afsaneh Razi, Pamela Wisniewski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147468">Link</a></p>
<h3>"I Know I'm Being Observed:" Video Interventions to Educate Users about Targeted Advertising on Facebook</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Garrett Smith, Sarah Carson, Rhea Vengurlekar, Stephanie Morales, Yun-Chieh Tsai, Rachel George, Josh Bedwell, Trevor Jones, Mainack Mondal, Brian Smith, Norman Su, Bart Knijnenburg, Xinru Page</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147986">Link</a></p>
<h3>Sharenting on TikTok: Exploring Parental Sharing Behaviors and the Discourse Around Children's Online Privacy</h3>
<p>Authors: Sophie Stephenson, Christopher Page, Miranda Wei, Apu Kapadia, Franziska Roesner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147746">Link</a></p>
<h2>Creativity Tools</h2>
<h3>EyeGuide &amp; EyeConGuide: Gaze-based Visual Guides to Improve 3D Sketching Systems</h3>
<p>Authors: Rumeysa Turkmen, Zeynep Ecem Gelmez, Anil Ufuk Batmaz, Wolfgang Stuerzlinger, Paul Asente, Mine Sarac, Ken Pfeuffer, Mayra Barrera Machuca</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147653">Link</a></p>
<h3>Formulating or Fixating: Effects of Examples on Problem Solving Vary as a Function of Example Presentation Interface Design</h3>
<p>Authors: Joel Chan, Zijian Ding, Eesh Kamrah, Mark Fuge</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147454">Link</a></p>
<h3>GenQuery: Supporting Expressive Visual Search with Generative Models</h3>
<p>Authors: Kihoon Son, DaEun Choi, Tae Soo Kim, Young-Ho Kim, Juho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148274">Link</a></p>
<h3>Inkeraction: An Interaction Modality Powered by Ink Recognition and Synthesis</h3>
<p>Authors: Lei Shi, Rachel Campbell, Peggy Chi, Maria Cirimele, Mike Cleron, Kirsten Climer, Chelsey Fleming, Ashwin Ganti, Philippe Gervais, Pedro Gonnet, Tayeb Karim, Andrii Maksai, Chris Melancon, Rob Mickle, Claudiu Musat, Palash Nandy, Xiaoyu Iris Qu, David Robishaw, Angad Singh, Mathangi Venkatesan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147672">Link</a></p>
<h3>Personalizing Products with Stylized Head Portraits for Self-Expression</h3>
<p>Authors: Yang Shi, Yechun Peng, Shengqi Dang, Nanxuan Zhao, Nan Cao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147814">Link</a></p>
<h2>Ethics of Digital Technologies B</h2>
<h3>Fighting Malicious Designs: Towards Visual Countermeasures Against Dark Patterns</h3>
<p>Authors: René Schäfer, Paul Preuschoff, René Röpke, Sarah Sahabi, Jan Borchers</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147553">Link</a></p>
<h3>A Scoping Study of Evaluation Practices for Responsible AI Tools: Steps Towards Effectiveness Evaluations</h3>
<p>Authors: Glen Berman, Nitesh Goyal, Michael Madaio</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147656">Link</a></p>
<h3>Searching for the Non-Consequential: Dialectical Activities in HCI and the Limits of Computers</h3>
<p>Authors: Haoqi Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147571">Link</a></p>
<h3>Building an Ethics-Focused Action Plan: Roles, Process Moves, and Trajectories</h3>
<p>Authors: Colin Gray, Ike Obi, Shruthi Sai Chivukula, Ziqing Li, Thomas Carlock, Matthew Will, Anne Pivonka, Janna Johns, Brookley Rigsbee, Ambika R Menon, Aayushi Bharadwaj</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147804">Link</a></p>
<h3>Staying at the Roach Motel: Cross-Country Analysis of Manipulative Subscription and Cancellation Flows</h3>
<p>Authors: Ashley Sheil, Gunes Acar, Hanna Schraffenberger, Raphael Gellert, David Malone</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147230">Link</a></p>
<h2>Supporting Children and Teens Socialization</h2>
<h3>From Adolescents' Eyes: Assessing an Indicator-Based Intervention to Combat Misinformation on TikTok</h3>
<p>Authors: Katrin Hartwig, Tom Biselli, Franziska Schneider, Christian Reuter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147187">Link</a></p>
<h3>For Me or Not for Me? The Ease With Which Teens Navigate Accurate and Inaccurate Personalized Social Media Content</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Nora McDonald, John Seberger, Afsaneh Razi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146940">Link</a></p>
<h3>Wrist-bound Guanxi, Jiazu, and Kuolie: Unpacking Chinese Adolescent Smartwatch-Mediated Socialization</h3>
<p>Authors: Lanjing Liu, Chao Zhang, Zhicong Lu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148286">Link</a></p>
<h3>ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events</h3>
<p>Authors: Woosuk Seo, Chanmo Yang, Young-Ho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148027">Link</a></p>
<h3>‘A Teaspoon of Authenticity’: Exploring How Young Adults BeReal on Social Media</h3>
<p>Authors: Ananya Reddy, Priya Kumar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148046">Link</a></p>
<h2>Online Communities: Engagement A</h2>
<h3>Message in a Bottle: Investigating Bioart Installations as a Transdisciplinary Means of Community Engagement</h3>
<p>Authors: Lydia Stamato, Hasan Mahmud Prottoy, Erin Higgins, Lisa Scheifele, Foad Hamidi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147439">Link</a></p>
<h3>Analyzing User Engagement with TikTok's Short Format Video Recommendations using Data Donations</h3>
<p>Authors: Savvas Zannettou, Olivia Nemes-Nemeth, Oshrat Ayalon, Angelica Goetzen, Krishna P. Gummadi, Elissa Redmiles, Franziska Roesner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147650">Link</a></p>
<h3>Mapping the Design Space of Teachable Social Media Feed Experiences</h3>
<p>Authors: K. J. Kevin Feng, Xander Koo, Lawrence Tan, Amy Bruckman, David McDonald, Amy Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147899">Link</a></p>
<h3>How Founder Motivations, Goals, and Actions Influence Early Trajectories of Online Communities</h3>
<p>Authors: Sanjay Kairam, Jeremy Foote</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147364">Link</a></p>
<h3>“I Prefer Regular Visitors to Answer My Questions”: Users’ Desired Experiential Background of Contributors for Location-based Crowdsourcing Platform</h3>
<p>Authors: Fang-Yu Lin, Pei-Hua Tsai, Chia-Yi Lee, Yi-Ting Ho, Yao-Kuang Chen, Grace Yu-Chun Yen, Yung-Ju Chang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147015">Link</a></p>
<h2>Evaluating AI Technologies B</h2>
<h3>Listening to the Voices: Describing Ethical Caveats of Conversational User Interfaces According to Experts and Frequent Users</h3>
<p>Authors: Thomas Mildner, Orla Cooney, Anna-Maria Meck, Marion Bartl, Gian-Luca Savino, Philip Doyle, Diego Garaialde, Leigh Clark, John Sloan, Nina Wenig, Rainer Malaka, Jasmin Niess</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147969">Link</a></p>
<p>Abstract: Advances in natural language processing and understanding have led to a rapid growth in the popularity of conversational user interfaces (CUIs). While CUIs introduce novel benefits, they also yield risks that may exploit people's trust. Although research looking at unethical design deployed through graphical user interfaces (GUIs) established a thorough taxonomy of so-called dark patterns, there is a need for an equally in-depth understanding in the context of CUIs. Addressing this gap, we interviewed 27 participants from three cohorts: researchers, practitioners, and frequent users of CUIs. Applying thematic analysis, we develop five themes reflecting each cohort's insights about ethical design challenges and introduce the CUI Expectation Cycle, bridging system capabilities and user expectations while respecting each theme's ethical caveats. This research aims to inform future work to consider ethical constraints while adopting a human-centred approach.</p>
<h3>EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria</h3>
<p>Authors: Tae Soo Kim, Yoonjoo Lee, Jamin Shin, Young-Ho Kim, Juho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147201">Link</a></p>
<p>Abstract: By simply composing prompts, developers can prototype novel generative applications with Large Language Models (LLMs). To refine prototypes into products, however, developers must iteratively revise prompts by evaluating outputs to diagnose weaknesses. Formative interviews (N=8) revealed that developers invest significant effort in manually evaluating outputs as they assess context-specific and subjective criteria. We present EvalLM, an interactive system for iteratively refining prompts by evaluating multiple outputs on user-defined criteria. By describing criteria in natural language, users can employ the system's LLM-based evaluator to get an overview of where prompts excel or fail, and improve these based on the evaluator's feedback. A comparative study (N=12) showed that EvalLM, when compared to manual evaluation, helped participants compose more diverse criteria, examine twice as many outputs, and reach satisfactory prompts with 59% fewer revisions. Beyond prompts, our work can be extended to augment model evaluation and alignment in specific application contexts.</p>
<h3>Understanding Choice Independence and Error Types in Human-AI Collaboration</h3>
<p>Authors: Alexander Erlei, Abhinav Sharma, Ujwal Gadiraju</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147055">Link</a></p>
<p>Abstract: The ability to make appropriate delegation decisions is an important prerequisite of effective human-AI collaboration. Recent work, however, has shown that people struggle to evaluate AI systems in the presence of forecasting errors, falling well short of relying on AI systems appropriately. We use a pre-registered crowdsourcing study ($N=611$) to extend this literature by two underexplored crucial features of human AI decision-making: \textit{choice independence} and \textit{error type}. Subjects in our study repeatedly complete two prediction tasks and choose which predictions they want to delegate to an AI system. For one task, subjects receive a decision heuristic that allows them to make informed and relatively accurate predictions. The second task is substantially harder to solve, and subjects must come up with their own decision rule. We systematically vary the AI system's performance such that it either provides the best possible prediction for both tasks or only for one of the two. Our results demonstrate that people systematically violate choice independence by taking the AI's performance in an unrelated second task into account. Humans who delegate predictions to a superior AI in their own expertise domain significantly reduce appropriate reliance when the model makes systematic errors in a complementary expertise domain. In contrast, humans who delegate predictions to a superior AI in a complementary expertise domain significantly increase appropriate reliance when the model systematically errs in the human expertise domain. Furthermore, we show that humans differentiate between error types and that this effect is conditional on the considered expertise domain. This is the first empirical exploration of choice independence and error types in the context of human-AI collaboration. Our results have broad and important implications for the future design, deployment, and appropriate application of AI systems.  </p>
<h3>ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ian Arawjo, Chelse Swoopes, Priyan Vaithilingam, Martin Wattenberg, Elena Glassman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147701">Link</a></p>
<p>Abstract: Evaluating outputs of large language models (LLMs) is challenging, requiring making—and making sense of—many responses. Yet tools that go beyond basic prompting tend to require knowledge of programming APIs, focus on narrow domains, or are closed-source. We present ChainForge, an open-source visual toolkit for prompt engineering and on-demand hypothesis testing of text generation LLMs. ChainForge provides a graphical interface for comparison of responses across models and prompt variations. Our system was designed to support three tasks: model selection, prompt template design, and hypothesis testing (e.g., auditing). We released ChainForge early in its development and iterated on its design with academics and online users. Through in-lab and interview studies, we find that a range of people could use ChainForge to investigate hypotheses that matter to them, including in real-world settings. We identify three modes of prompt engineering and LLM hypothesis testing: opportunistic exploration, limited evaluation, and iterative refinement.</p>
<h3>CloChat: Understanding How People Customize, Interact, and Experience Personas in Large Language Models</h3>
<p>Authors: Juhye Ha, Hyeon Jeon, DaEun Han, Jinwook Seo, Changhoon Oh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147362">Link</a></p>
<p>Abstract: Large language models (LLMs) have facilitated significant strides in generating conversational agents, enabling seamless, contextually relevant dialogues across diverse topics. However, the existing LLM-driven conversational agents have fixed personalities and functionalities, limiting their adaptability to individual user needs. Creating personalized agent personas with distinct expertise or traits can address this issue. Nonetheless, we lack knowledge of how people customize and interact with agent personas. In this research, we investigated how users customize agent personas and their impact on interaction quality, diversity, and dynamics. To this end, we developed CloChat, an interface supporting easy and accurate customization of agent personas in LLMs. We conducted a study comparing how participants interact with CloChat and ChatGPT. The results indicate that participants formed emotional bonds with the customized agents, engaged in more dynamic dialogues, and showed interest in sustaining interactions. These findings contribute to design implications for future systems with conversational agents using LLMs.</p>
<h2>Politics of Datasets</h2>
<h3>The Cadaver in the Machine: The Social Practices of Measurement and Validation in Motion Capture Technology</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Emma Harvey, Hauke Sandhaus, Abigail Jacobs, Emanuel Moss, Mona Sloane</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147039">Link</a></p>
<h3>Aligning Data with the Goals of an Organization and Its Workers: Designing Data Labeling for Social Service Case Notes</h3>
<p>Authors: Apoorva Gondimalla, Varshinee Sreekanth, Govind Joshi, Whitney Nelson, Eunsol Choi, Stephen Slota, Sherri Greenberg, Kenneth Fleischmann, Min Kyung Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148090">Link</a></p>
<h3>The ``Colonial Impulse" of Natural Language Processing: An Audit of Bengali Sentiment Analysis Tools and Their Identity-based Biases</h3>
<p>Authors: Dipto Das, Shion Guha, Jed Brubaker, Bryan Semaan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146683">Link</a></p>
<h3>Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM</h3>
<p>Authors: Michelle Lam, Janice Teoh, James Landay, Jeffrey Heer, Michael Bernstein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147161">Link</a></p>
<h3>Situating Datasets: Making Public Eviction Data Actionable for Housing Justice</h3>
<p>Authors: Anh-Ton Tran, Grace Guo, Jordan Taylor, Katsuki Chan, Elora Raymond, Carl DiSalvo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148020">Link</a></p>
<h2>Touch, Gesture and Posture</h2>
<h3>CRTypist: Simulating Touchscreen Typing Behavior via Computational Rationality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Danqing Shi, Yujun Zhu, Jussi Jokinen, Aditya Acharya, Aini Putkonen, Shumin Zhai, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147836">Link</a></p>
<h3>WheelPose: Data Synthesis Techniques to Improve Pose Estimation Performance on Wheelchair Users</h3>
<p>Authors: William Huang, Sam Ghahremani, Siyou Pei, Yang Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148072">Link</a></p>
<h3>Sitting Posture Recognition and Feedback: A Literature Review</h3>
<p>Authors: Christian Krauter, Katrin Angerbauer, Aimée Sousa Calepso, Alexander Achberger, Sven Mayer, Michael Sedlmair</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147428">Link</a></p>
<h3>iPose: Interactive Human Pose Reconstruction from Video</h3>
<p>Authors: Jingyuan Liu, Li-Yi Wei, Ariel Shamir, Takeo Igarashi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146911">Link</a></p>
<h2>Governance and Public Policies</h2>
<h3>Data Probes as Boundary Objects for Technology Policy Design: Demystifying Technology for Policymakers and Aligning Stakeholder Objectives in Rideshare Gig Work</h3>
<p>Authors: Angie Zhang, Rocita Rana, Alexander Boltz, Veena Dubal, Min Kyung Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146997">Link</a></p>
<h3>In Dice We Trust: Uncertainty Displays for Maintaining Trust in Election Forecasts Over Time</h3>
<p>BEST_PAPER</p>
<p>Authors: Fumeng Yang, Chloe Mortenson, Erik Nisbet, Nicholas Diakopoulos, Matthew Kay</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147247">Link</a></p>
<h3>V-FRAMER: Visualization Framework for Mitigating Reasoning Errors in Public Policy</h3>
<p>Authors: Lily Ge, Matthew Easterday, Matthew Kay, Evanthia Dimara, Peter Cheng, Steven Franconeri</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147167">Link</a></p>
<h3>Affective Design: The Influence of Facebook Reactions on the Emotional Expression of the 114th US Congress</h3>
<p>Authors: Jacob Erickson, Bei Yan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147668">Link</a></p>
<h3>Watching the Election Sausage Get Made: How Data Journalists Visualize the Vote Counting Process in U.S. Elections</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mandi Cai, Matthew Kay</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146972">Link</a></p>
<h2>Supporting Communities</h2>
<h3>Pika: Empowering Non-Programmers to Author Executable Governance Policies in Online Communities</h3>
<p>Authors: Leijie Wang, Nicholas Vincent, Julija Rukanskaitė, Amy Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146949">Link</a></p>
<h3>Do We Run How We Say We Run? Formalization and Practice of Governance in OSS Communities</h3>
<p>Authors: Mahasweta Chakraborti, Curtis Atkisson, Ştefan Stănciulescu, Vladimir Filkov, Seth Frey</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147289">Link</a></p>
<h3>Third-Party Developers and Tool Development For Community Management on Live Streaming Platform Twitch</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jie Cai, Ya-Fang Lin, He Zhang, John Carroll</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147232">Link</a></p>
<h3>“I was able to give her the confidence”: Reciprocal Capacity Building in a Community-based Program for Digital Engagement</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Julie Hui, Kristin Seefeldt, Lutalo Sanifu, Christie Baer, Jeanette Szomstein, Tawanna Dillahunt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146613">Link</a></p>
<h3>In Between Users and Developers: Serendipitous Connections and Intermediaries in Volunteer-Driven Open-Source Software Development</h3>
<p>Authors: Leonie Jahn, Philip Engelbutzeder, Dave Randall, Yannick Bollmann, Vasilis Ntouros, Lea Katharina Michel, Volker Wulf</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148224">Link</a></p>
<h2>AI and Interaction Design</h2>
<h3>(Un)making AI Magic: A Design Taxonomy</h3>
<p>Authors: Maria Luce Lupetti, Dave Murray-Rust</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147268">Link</a></p>
<p>Abstract: This paper examines the role that enchantment plays in the design of AI things by constructing a taxonomy of design approaches that increase or decrease the perception of magic and enchantment. We start from the design discourse surrounding recent developments in AI technologies, highlighting specific interaction qualities such as algorithmic uncertainties and errors and articulating relations to the rhetoric of magic and supernatural thinking. Through analyzing and reflecting upon 52 students' design projects from two editions of a Master course in design and AI, we identify seven design principles and unpack the effects of each in terms of enchantment and disenchantment. We conclude by articulating ways in which this taxonomy can be approached and appropriated by design/HCI practitioners, especially to support exploration and reflexivity.</p>
<h3>AI-Assisted Causal Pathway Diagram for Human-Centered Design</h3>
<p>Authors: Ruican Zhong, Donghoon Shin, Rosemary Meza, Predrag Klasnja, Lucas Colusso, Gary Hsieh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147483">Link</a></p>
<p>Abstract: This paper explores the integration of causal pathway diagrams (CPD) into human-centered design (HCD), investigating how these diagrams can enhance the early stages of the design process. A dedicated CPD plugin for the online collaborative whiteboard platform Miro was developed to streamline diagram creation and offer real-time AI-driven guidance. Through a user study with designers ($N=20$), we found that CPD's branching and its emphasis on causal connections supported both divergent and convergent processes during design. CPD can also facilitate communication among stakeholders. Additionally, we found our plugin significantly reduces designers' cognitive workload and increases their creativity during brainstorming, highlighting the implications of AI-assisted tools in supporting creative work and evidence-based designs.</p>
<h3>VAL: Interactive Task Learning with GPT Dialog Parsing</h3>
<p>Authors: Lane Lawley, Christopher MacLellan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148061">Link</a></p>
<p>Abstract: Machine learning often requires millions of examples to produce static, black-box models. In contrast, interactive task learning (ITL) emphasizes incremental knowledge acquisition from limited instruction provided by humans in modalities such as natural language. However, ITL systems often suffer from brittle, error-prone language parsing, which limits their usability. Large language models (LLMs) are resistant to brittleness but are not interpretable and cannot learn incrementally. We present VAL, an ITL system with a new philosophy for LLM/symbolic integration. By using LLMs only for specific tasks—such as predicate and argument selection—within an algorithmic framework, VAL reaps the benefits of LLMs to support interactive learning of hierarchical task knowledge from natural language. Acquired knowledge is human interpretable and generalizes to support execution of novel tasks without additional training. We studied users' interactions with VAL in a video game setting, finding that most users could successfully teach VAL using language they felt was natural.</p>
<h3>Jigsaw: Supporting Designers to Prototype Multimodal Applications by Chaining AI Foundation Models</h3>
<p>Authors: David Chuan-En Lin, Nikolas Martelaro</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147352">Link</a></p>
<p>Abstract: Recent advancements in AI foundation models have made it possible for them to be utilized off-the-shelf for creative tasks, including ideating design concepts or generating visual prototypes. However, integrating these models into the creative process can be challenging as they often exist as standalone applications tailored to specific tasks. To address this challenge, we introduce Jigsaw, a prototype system that employs puzzle pieces as metaphors to represent foundation models. Jigsaw allows designers to combine different foundation model capabilities across various modalities by assembling compatible puzzle pieces. To inform the design of Jigsaw, we interviewed ten designers and distilled design goals. In a user study, we showed that Jigsaw enhanced designers' understanding of available foundation model capabilities, provided guidance on combining capabilities across different modalities and tasks, and served as a canvas to support design exploration, prototyping, and documentation.</p>
<h3>Enhancing UX Evaluation Through Collaboration with Conversational AI Assistants: Effects of Proactive Dialogue and Timing</h3>
<p>Authors: Emily Kuang, Minghao Li, Mingming Fan, Kristen Shinohara</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147731">Link</a></p>
<p>Abstract: Usability testing is vital for enhancing the user experience (UX) of interactive systems. However, analyzing test videos is complex and resource-intensive. Recent AI advancements have spurred exploration into human-AI collaboration for UX analysis, particularly through natural language. Unlike user-initiated dialogue, our study investigated the potential of proactive conversational assistants to aid UX evaluators through automatic suggestions at three distinct times: before, in sync with, and after potential usability problems. We conducted a hybrid Wizard-of-Oz study involving 24 UX evaluators, using ChatGPT to generate automatic problem suggestions and a human actor to respond to impromptu questions. While timing did not significantly impact analytic performance, suggestions appearing after potential problems were preferred, enhancing trust and efficiency. Participants found the automatic suggestions useful, but they collectively identified more than twice as many problems, underscoring the irreplaceable role of human expertise. Our findings also offer insights into future human-AI collaborative tools for UX evaluation.</p>
<h2>AI and UI Design</h2>
<h3>SimUser: Generating Usability Feedback by Simulating Various Users Interacting with Mobile Applications</h3>
<p>Authors: Wei Xiang, Hanfei Zhu, Suqi Lou, Xinli Chen, Zhenghua Pan, Yuping Jin, Shi Chen, Lingyun Sun</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148321">Link</a></p>
<p>Abstract: The conflict between the rapid iteration demand of prototyping and the time-consuming nature of user tests has led researchers to adopt AI methods to identify usability issues. However, these AI-driven methods concentrate on evaluating the feasibility of a system, while often overlooking the influence of specified user characteristics and usage contexts. Our work proposes a tool named SimUser based on large language models (LLMs) with the Chain-of-Thought structure and user modeling method. It generates usability feedback by simulating the interaction between users and applications, which is influenced by user characteristics and contextual factors. The empirical study (48 human users and 21 designers) validated that in the context of a simple smartwatch interface, SimUser could generate heuristic usability feedback with the similarity varying from 35.7% to 100% according to the user groups and usability category. Our work provides insights into simulating users by LLM to improve future design activities.</p>
<h3>Generating Automatic Feedback on UI Mockups with Large Language Models</h3>
<p>Authors: Peitong Duan, Jeremy Warner, Yang Li, Bjoern Hartmann</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146712">Link</a></p>
<p>Abstract: Feedback on user interface (UI) mockups is crucial in design. However, human feedback is not always readily available. We explore the potential of using large language models for automatic feedback. Specifically, we focus on \changes{applying GPT-4 to automate heuristic evaluation}, which currently entails a human expert assessing a UI’s compliance with a set of design guidelines. We implemented a Figma plugin that takes in a UI design and a set of written heuristics, and renders automatically-generated feedback as constructive suggestions. We assessed performance on 51 UIs using three sets of guidelines, compared GPT-4-generated design suggestions with those from human experts, and conducted a study with 12 expert designers to understand fit with existing practice. We found that GPT-4-based feedback is useful for catching subtle errors, improving text, and considering UI semantics, but feedback also decreased in utility over iterations. Participants described several uses for this plugin despite its imperfect suggestions.</p>
<h3>MUD: Towards a Large-Scale and Noise-Filtered UI Dataset for Modern Style UI Modeling</h3>
<p>Authors: Sidong Feng, Suyu Ma, Han Wang, David Kong, Chunyang Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147307">Link</a></p>
<p>Abstract: The importance of computational modeling of mobile user interfaces (UIs) is undeniable. However, these require a high-quality UI dataset. Existing datasets are often outdated, collected years ago, and are frequently noisy with mismatches in their visual representation. This presents challenges in modeling UI understanding in the wild. This paper introduces a novel approach to automatically mine UI data from Android apps, leveraging Large Language Models (LLMs) to mimic human-like exploration. To ensure dataset quality, we employ the best practices in UI noise filtering and incorporate human annotation as a final validation step. Our results demonstrate the effectiveness of LLMs-enhanced app exploration in mining more meaningful UIs, resulting in a large dataset MUD of 18k human-annotated UIs from 3.3k apps. We highlight the usefulness of MUD in two common UI modeling tasks: element detection and UI retrieval, showcasing its potential to establish a foundation for future research into high-quality, modern UIs.</p>
<h3>Surveyor: Facilitating Discovery Within Video Games for Blind and Low Vision Players</h3>
<p>Authors: Vishnu Nair, Hanxiu 'Hazel' Zhu, Peize Song, Jizhong Wang, Brian Smith</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147935">Link</a></p>
<p>Abstract: Video games are increasingly accessible to blind and low vision (BLV) players, yet many aspects remain inaccessible. One aspect is the joy players feel when they explore environments and make new discoveries, which is integral to many games. Sighted players experience discovery by surveying environments and identifying unexplored areas. Current accessibility tools, however, guide BLV players directly to items and places, robbing them of that experience. Thus, a crucial challenge is to develop navigation assistance tools that also foster exploration and discovery. To address this challenge, we propose the concept of exploration assistance in games and design Surveyor, an in-game exploration assistance tool that enhances discovery by tracking where BLV players look and highlighting unexplored areas. We designed Surveyor using insights from a formative study and compared Surveyor's effectiveness to approaches found in existing accessible games. Our findings reveal implications for facilitating richer play experiences for BLV users within games.</p>
<h3>OmniActions: Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs</h3>
<p>Authors: Jiahao Li, Yan Xu, Tovi Grossman, Stephanie Santosa, Michelle Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147206">Link</a></p>
<p>Abstract: The progression to "Pervasive Augmented Reality" envisions easy access to multimodal information continuously. However, in many everyday scenarios, users are occupied physically, cognitively or socially. This may increase the friction to act upon the multimodal information that users encounter in the world. To reduce such friction, future interactive interfaces should intelligently provide quick access to digital actions based on users' context. To explore the range of possible digital actions, we conducted a diary study that required participants to capture and share the media that they intended to perform actions on (e.g., images or audio), along with their desired actions and other contextual information. Using this data, we generated a holistic design space of digital follow-up actions that could be performed in response to different types of multimodal sensory inputs. We then designed \codename, a pipeline powered by large language models (LLMs) that processes multimodal sensory inputs and predicts follow-up actions on the target information grounded in the derived design space. Using the empirical data collected in the diary study, we performed quantitative evaluations on three variations of LLM techniques (intent classification, in-context learning and finetuning) and identified the most effective technique for our task. Additionally, as an instantiation of the pipeline, we developed an interactive prototype and reported preliminary user feedback about how people perceive and react to the action predictions and its errors. </p>
<h2>AI for Researchers</h2>
<h3>Know Your Audience: The benefits and pitfalls of generating plain language summaries beyond the "general" audience</h3>
<p>Authors: Tal August, Kyle Lo, Noah A. Smith, Katharina Reinecke</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147146">Link</a></p>
<p>Abstract: Language models (LMs) show promise as tools for communicating science to the general public by simplifying and summarizing complex language. Because models can be prompted to generate text for a specific audience (e.g., college-educated adults), LMs might be used to create multiple versions of plain language summaries for people with different familiarities of scientific topics. However, it is not clear what the benefits and pitfalls of adaptive plain language are. When is simplifying necessary, what are the costs in doing so, and do these costs differ for readers with different background knowledge? Through three within-subjects studies in which we surface summaries for different envisioned audiences to participants of different backgrounds, we found that while simpler text led to the best reading experience for readers with little to no familiarity in a topic, high familiarity readers tended to ignore certain details in overly plain summaries (e.g., study limitations). Our work provides methods and guidance on ways of adapting plain language summaries beyond the single "general" audience. </p>
<h3>Evaluating Large Language Models on Academic Literature Understanding and Review: An Empirical Study among Early-stage Scholars</h3>
<p>Authors: Jiyao Wang, Haolong Hu, Zuyuan Wang, Song Yan, Youyu Sheng, Dengbo He</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147471">Link</a></p>
<p>Abstract: The rapid advancement of large language models (LLMs) such as ChatGPT makes LLM-based academic tools possible. However, little research has empirically evaluated how scholars perform different types of academic tasks with LLMs. Through an empirical study followed by a semi-structured interview, we assessed 48 early-stage scholars’ performance in conducting core academic activities (i.e., paper reading and literature reviews) under different levels of time pressure. Before conducting the tasks, participants received different training programs regarding the limitations and capabilities of the LLMs. After completing the tasks, participants completed an interview. Quantitative data regarding the influence of time pressure, task type, and training program on participants' performance in academic tasks was analyzed. Semi-structured interviews provided additional information on the influential factors of task performance, participants' perceptions of LLMs, and concerns about integrating LLMs into academic workflows. The findings can guide more appropriate usage and design of LLM-based tools in assisting academic work.</p>
<h3>Understanding the Role of Large Language Models in Personalizing and Scaffolding Strategies to Combat Academic Procrastination</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ananya Bhattacharjee, Yuchen Zeng, Sarah Yi Xu, Dana Kulzhabayeva, Minyi Ma, Rachel Kornfield, Syed Ishtiaque Ahmed, Alex Mariakakis, Mary Czerwinski, Anastasia Kuzminykh, Michael Liut, Joseph Williams</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148128">Link</a></p>
<p>Abstract: Traditional interventions for academic procrastination often fail to capture the nuanced, individual-specific factors that underlie them. Large language models (LLMs) hold immense potential for addressing this gap by permitting open-ended inputs, including the ability to customize interventions to individuals' unique needs. However, user expectations and potential limitations of LLMs in this context remain underexplored. To address this, we conducted interviews and focus group discussions with 15 university students and 6 experts, during which a technology probe for generating personalized advice for managing procrastination was presented. Our results highlight the necessity for LLMs to provide structured, deadline-oriented steps and enhanced user support mechanisms. Additionally, our results surface the need for an adaptive approach to questioning based on factors like busyness. These findings offer crucial design implications for the development of LLM-based tools for managing procrastination while cautioning the use of LLMs for therapeutic guidance.</p>
<h3>From Paper to Card: Transforming Design Implications with Generative AI</h3>
<p>Authors: Donghoon Shin, Lucy Wang, Gary Hsieh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147713">Link</a></p>
<p>Abstract: Communicating design implications is common within the HCI community when publishing academic papers, yet these papers are rarely read and used by designers. One solution is to use design cards as a form of translational resource that communicates valuable insights from papers in a more digestible and accessible format to assist in design processes. However, creating design cards can be time-consuming, and authors may lack the resources/know-how to produce cards. Through an iterative design process, we built a system that helps create design cards from academic papers using an LLM and text-to-image model. Our evaluation with designers (N=21) and authors of selected papers (N=12) revealed that designers perceived the design implications from our design cards as more inspiring and generative, compared to reading original paper texts, and the authors viewed our system as an effective way of communicating their design implications. We also propose future enhancements for AI-generated design cards.</p>
<h3>CollabCoder: A Lower-barrier, Rigorous Workflow for Inductive Collaborative Qualitative Analysis with Large Language Models</h3>
<p>Authors: Jie Gao, Yuchen Guo, Gionnieve Lim, Tianqin Zhang, Zheng Zhang, Toby Li, Simon Perrault</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147401">Link</a></p>
<p>Abstract: Collaborative Qualitative Analysis (CQA) can enhance qualitative analysis rigor and depth by incorporating varied viewpoints. Nevertheless, ensuring a rigorous CQA procedure itself can be both complex and costly. To lower this bar, we take a theoretical perspective to design a one-stop, end-to-end workflow, CollabCoder, that integrates Large Language Models (LLMs) into key inductive CQA stages. In the independent open coding phase, CollabCoder offers AI-generated code suggestions and records decision-making data. During the iterative discussion phase, it promotes mutual understanding by sharing this data within the coding team and using quantitative metrics to identify coding (dis)agreements, aiding in consensus-building. In the codebook development phase, CollabCoder provides primary code group suggestions, lightening the workload of developing a codebook from scratch. A 16-user evaluation confirmed the effectiveness of CollabCoder, demonstrating its advantages over the existing CQA platform. All related materials of CollabCoder, including code and further extensions, will be included in: https://gaojie058.github.io/CollabCoder/.</p>
<h2>Assistive Technologies for Neurodiversity</h2>
<h3>Designing Scaffolding Strategies for Conversational Agents in Dialog Task of Neurocognitive Disorders Screening</h3>
<p>Authors: Jiaxiong Hu, Junze Li, YUHANG ZENG, Dongjie Yang, Danxuan LIANG, Helen Meng, Xiaojuan Ma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147967">Link</a></p>
<h3>Unlock Life with a Chat(GPT): Integrating Conversational AI with Large Language Models into Everyday Lives of Autistic Individuals</h3>
<p>Authors: Dasom Choi, Sunok Lee, Sung-In Kim, Kyungah Lee, Hee Jeong Yoo, Sangsu Lee, Hwajung Hong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146853">Link</a></p>
<h3>An Emotion Translator: Speculative Design By Neurodiverse Dyads</h3>
<p>Authors: Annuska Zolyomi, Jaime Snyder</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148281">Link</a></p>
<h3>From Letterboards to Holograms: Advancing Assistive Technology for Nonspeaking Autistic Individuals with the HoloBoard</h3>
<p>Authors: Lorans Alabood, Travis Dow, Kaylyn Feeley, Vikram Jaswal, Diwakar Krishnamurthy</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147346">Link</a></p>
<h3>Are Robots Ready to Deliver Autism Inclusion?: A Critical Review</h3>
<p>Authors: Naba Rizvi, William Wu, Mya Bolds, Raunak Mondal, Andrew Begel, Imani Munyaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147238">Link</a></p>
<h2>Body, Avatars, and Interaction in Immersive Realities</h2>
<h3>Your Avatar Seems Hesitant to Share About Yourself: How People Perceive Others' Avatars in the Transparent System</h3>
<p>Authors: Yeonju Jang, Taenyun Kim, Huisung Kwon, Hyemin Park, Ki Joon Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146653">Link</a></p>
<p>Abstract: In avatar-mediated communications, users often cannot identify how others' avatars are created, which is one of the important information they need to evaluate others. Thus, we tested a social virtual world that is transparent about others' avatar-creation methods and investigated how knowing about others' avatar-creation methods shapes users' perceptions of others and their self-disclosure. We conducted a 2x2 mixed-design experiment with system design (nontransparent vs. transparent system) as a between-subjects and avatar-creation method (customized vs. personalized avatar) as a within-subjects variable with 60 participants. The results revealed that personalized avatars in the transparent system were viewed less positively than customized avatars in the transparent system or avatars in the nontransparent system. These avatars appeared less comfortable and honest in their self-disclosure and less competent. Interestingly, avatars in the nontransparent system attracted more followers. Our results suggest being cautious when creating a social virtual world that discloses the avatar-creation process.</p>
<h3>CamTroller: An Auxiliary Tool for Controlling Your Avatar in PC Games Using Natural Motion Mapping</h3>
<p>Authors: Junjian CHEN, Yuqian Wang, Yan Luximon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147378">Link</a></p>
<p>Abstract: Natural motion mapping enhances the gaming experience by reducing the cognitive burden and increasing immersion. However, many players still use the keyboard and mouse in recent commercial PC games. To solve the conflict between complex avatar motion and the limited interaction system, we introduced CamTroller, an auxiliary tool for commercial one-to-one avatar mapping PC games following the concept of a natural user interface. To validate this concept, we selected PUBG  as the application scenario and developed a proof-of-concept system to help players achieve a better experience by naturally mapping selected human motions to the avatars in games through an RGB webcam. A within-subject study with 18 non-professional players practiced common operation (Basic), professional player’s operation (Pro), and CamTroller. Results showed that the performance of CamTroller was as good as the Pro and significantly higher than Basic. Also, the subjective evaluation showed that CamTroller achieved significantly higher intuitiveness than Basic and Pro.</p>
<h3>Stretch your reach: Studying Self-Avatar and Controller Misalignment in Virtual Reality Interaction</h3>
<p>Authors: Jose Luis Ponton, Reza Keshavarz, Alejandro Beacco, Nuria Pelechano</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147486">Link</a></p>
<p>Abstract: Immersive Virtual Reality typically requires a head-mounted display (HMD) to visualize the environment and hand-held controllers to interact with the virtual objects. Recently, many applications display full-body avatars to represent the user and animate the arms to follow the controllers. Embodiment is higher when the self-avatar movements align correctly with the user. However, having a full-body self-avatar following the user's movements can be challenging due to the disparities between the virtual body and the user's body. This can lead to misalignments in the hand position that can be noticeable when interacting with virtual objects. In this work, we propose five different interaction modes to allow the user to interact with virtual objects despite the self-avatar and controller misalignment and study their influence on embodiment, proprioception, preference, and task performance. We modify aspects such as whether the virtual controllers are rendered, whether controllers are rendered in their real physical location or attached to the user's hand, and whether stretching the avatar arms to always reach the real controllers. We evaluate the interaction modes both quantitatively (performance metrics) and qualitatively (embodiment, proprioception, and user preference questionnaires). Our results show that the stretching arms solution, which provides body continuity and guarantees that the virtual hands or controllers are in the correct location, offers the best results in embodiment, user preference, proprioception, and performance. Also, rendering the controller does not have an effect on either embodiment or user preference. </p>
<h3>Virtual Body Swapping: A VR-Based Approach to Embodied Third-Person Self-Processing in Mind-Body Therapy</h3>
<p>Authors: Nina Döllinger, David Mal, Sebastian Keppler, Erik Wolf, Mario Botsch, Johann Habakuk Israel, Marc Latoschik, Carolin Wienrich</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146675">Link</a></p>
<p>Abstract: Virtual reality (VR) offers various opportunities for innovative therapeutic approaches, especially regarding self-related mind-body interventions.
We introduce a VR body swap system enabling multiple users to swap their perspectives and appearances and evaluate its effects on virtual sense of embodiment (SoE) and perception- and cognition-based self-related processes.
In a self-compassion-framed scenario, twenty participants embodied their personalized, photorealistic avatar, swapped bodies with an unfamiliar peer, and reported their SoE, interoceptive awareness (perception), and self-compassion (cognition). Participants' experiences differed between bottom-up and top-down processes. Regarding SoE, their agency and self-location shifted to the swap avatar, while their top-down self-identification remained with their personalized avatar. Further, the experience positively affected interoceptive awareness but not self-compassion. Our outcomes offer novel insights into the SoE in a multiple-embodiment scenario and highlight the need to differentiate between the different processes in intervention design. They raise concerns and requirements for future research on avatar-based mind-body interventions.</p>
<h3>"I Shot the Interviewer!": The Effects of In-VR Interviews on Participant Feedback and Rapport</h3>
<p>Authors: Jacob Young, Jennifer Ferreira, Nadia Pantidi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146913">Link</a></p>
<p>Abstract: The integration of questionnaires into virtual reality experiences has recently been proposed as a way to reduce the potential biases introduced through the negative effects of leaving VR, however there has been little attention paid to how qualitative interviews could similarly be integrated into the virtual world for the purposes of user evaluation. In this paper we explore how conducting interviews within the virtual environment may affect the outcome of the evaluation and the relationship between participant and interviewer, and how this may differ with and without visual representation of the interviewer through use of an avatar. We conclude that in-VR interviews are a valid and promising method of data collection for user evaluation with similar data quality to in-person interviews, but that the interviewer should have a visual presence in the environment to maintain their relationship with the participant and the perceived realism of the environment.</p>
<h2>Children and Family A</h2>
<h3>LegacySphere: Facilitating Intergenerational Communication Through Perspective-Taking and Storytelling in Embodied VR</h3>
<p>Authors: Chenxinran Shen, Joanna McGrenere, Dongwook Yoon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147857">Link</a></p>
<h3>Open Sesame? Open Salami! Personalizing Vocabulary Assessment-Intervention for Children via Pervasive Profiling and Bespoke Storybook Generation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jungeun Lee, Suwon Yoon, Kyoosik Lee, Eunae Jeong, Jae-Eun Cho, Wonjeong Park, Dongsun Yim, Inseok Hwang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147041">Link</a></p>
<h3>Parent-Child Joint Media Engagement within HCI: A Scoping Analysis of the Research Landscape</h3>
<p>Authors: Junnan Yu, Xiang QI, Siqi Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147467">Link</a></p>
<h3>"When He Feels Cold, He Goes to the Seahorse"—Blending Generative AI into Multimaterial Storymaking for Family Expressive Arts Therapy</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Di Liu, Hanqing Zhou, Pengcheng An</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147056">Link</a></p>
<h3>"I want it to talk like Darth Vader": Helping Children Construct Creative Self-Efficacy with Generative AI</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Michele Newman, Kaiwen Sun, Ilena Dalla Gasperina, Grace Shin, Matthew Pedraja, Ritesh Kanchi, Maia B. Song, Rannie Li, Jin Ha Lee, Jason Yip</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147049">Link</a></p>
<h2>Creative Practices, Arts and AI</h2>
<h3>CollageVis: Rapid Previsualization Tool for Indie Filmmaking using Video Collages</h3>
<p>Authors: Hye-Young Jo, Ryo Suzuki, Yoonji Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147599">Link</a></p>
<p>Abstract: Previsualization, previs, is essential for film production, allowing cinematographic experiments and effective collaboration. However, traditional previs methods like 2D storyboarding and 3D animation require substantial time, cost, and technical expertise, posing challenges for indie filmmakers. We introduce CollageVis, a rapid previsualization tool using video collages. CollageVis enables filmmakers to create previs through two main user interfaces. First, it automatically segments actors from videos and assigns roles using name tags, color filters, and face swaps. Second, it positions video layers on a virtual stage and allows users to record shots using mobile as a proxy for a virtual camera. These features were developed based on formative interviews by reflecting indie filmmakers’ needs and working methods. We demonstrate the system’s capability by replicating seven film scenes and evaluate the system’s usability with six indie filmmakers. The findings indicate that CollageVis allows more flexible yet expressive previs creation for idea development and collaboration.</p>
<h3>Machine Learning Processes As Sources of Ambiguity: Insights from AI Art</h3>
<p>Authors: Christian Sivertsen, Guido Salimbeni, Anders Løvlie, Steven Benford, Jichen Zhu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148345">Link</a></p>
<p>Abstract: Ongoing efforts to turn Machine Learning (ML) into a design material have encountered limited success. 
This paper examines the burgeoning area of AI art to understand how artists incorporate ML in their creative work. Drawing upon related HCI theories, we investigate how artists create ambiguity by analyzing nine AI artworks that use computer vision and image synthesis.
Our analysis shows that, in addition to the established types of ambiguity, artists worked closely with the ML process (dataset curation, model training, and application) and developed various techniques to evoke the ambiguity of processes. Our finding indicates that the current conceptualization of ML as a design material needs to reframe the ML process as design elements, instead of technical details. Finally, this paper offers reflections on commonly held assumptions in HCI about ML uncertainty, dependability, and explainability, and advocates to supplement the artifact-centered design perspective of ML with a process-centered one.</p>
<h3>Metamorpheus: Interactive, Affective, and Creative Dream Narration Through Metaphorical Visual Storytelling</h3>
<p>Authors: Qian Wan, Xin Feng, Yining Bei, Zhiqi Gao, Zhicong Lu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148065">Link</a></p>
<p>Abstract: Human emotions are essentially molded by lived experiences, from which we construct personalised meaning. The engagement in such meaning-making process has been practiced as an intervention in various psychotherapies to promote wellness. Nevertheless, to support recollecting and recounting lived experiences in everyday life remains under explored in HCI. It also remains unknown how technologies such as generative AI models can facilitate the meaning making process, and ultimately support affective mindfulness. In this paper we present Metamorpheus, an affective interface that engages users in a creative visual storytelling of emotional experiences during dreams. Metamorpheus arranges the storyline based on a dream's emotional arc, and provokes self-reflection through the creation of metaphorical images and text depictions. The system provides metaphor suggestions, and generates visual metaphors and text depictions using generative AI models, while users can apply generations to recolour and re-arrange the interface to be visually affective. Our experience-centred evaluation manifests that, by interacting with Metamorpheus, users can recall their dreams in vivid detail, through which they relive and reflect upon their experiences in a meaningful way.</p>
<h3>An Artists' Perspectives on Natural Interactions for Virtual Reality 3D Sketching</h3>
<p>Authors: Richard Rodriguez, Brian Sullivan, Mayra Barrera Machuca, Anil Ufuk Batmaz, Cyane Tornatzky, Francisco Ortega</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147688">Link</a></p>
<p>Abstract: Virtual Reality (VR) applications like OpenBrush offer artists access to 3D sketching tools within the digital 3D virtual space. These 3D sketching tools allow users to ``paint'' using virtual digital strokes that emulate real-world mark-making. Yet, users paint these strokes through (unimodal) VR controllers. Given that sketching in VR is a relatively nascent field, this paper investigates ways to expand our understanding of sketching in virtual space, taking full advantage of what an immersive digital canvas offers. Through a study conducted with the participation of artists, we identify potential methods for natural multimodal and unimodal interaction techniques in 3D sketching. These methods demonstrate ways to incrementally improve existing interaction techniques and incorporate artistic feedback into the design.</p>
<h3>#PoetsOfInstagram: Navigating The Practices And Challenges Of Novice Poets On Instagram</h3>
<p>Authors: Ankolika De, Zhicong Lu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148301">Link</a></p>
<p>Abstract: Commencing as a photo-sharing platform, Instagram has since become multifaceted, accommodating diverse art forms, with poetry emerging as a prominent one. However, the academic understanding of Instagram's poetry community is limited, yet its significance emerges from its distinctive utilization of a primarily visual social media platform guided by recommendation algorithms for disseminating poetry, further characterized by a predominantly novice creative population. We employ qualitative analysis to explore motivations, experiences, and algorithmic influence within Instagram's poetry community. We demonstrate that participants prioritize conforming to algorithmic constraints for visibility, yet maintain their community's values of integrity and originality, illustrating the tension between algorithmic growth and participant authenticity. We introduce the concept of Algorithmically Mediated Creative Labor, a phenomenon specific to non-monetizing creative users who are impacted by the prioritization of professional creators and continually adapt their creative endeavours to align with platform logic, thereby affecting their motivation and creative outputs.</p>
<h2>Creativity: Visualizations and AI</h2>
<h3>IntentTuner: An Interactive Framework for Integrating Human Intentions in Fine-tuning Text-to-Image Generative Models</h3>
<p>Authors: Xingchen Zeng, Ziyao Gao, Yilin Ye, Wei Zeng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147372">Link</a></p>
<p>Abstract: Fine-tuning facilitates the adaptation of text-to-image generative models to novel concepts (e.g., styles and portraits), empowering users to forge creatively customized content. Recent efforts on fine-tuning focus on reducing training data and lightening computation overload but neglect alignment with user intentions, particularly in manual curation of multi-modal training data and intent-oriented evaluation. Informed by a formative study with fine-tuning practitioners for comprehending user intentions, we propose IntentTuner, an interactive framework that intelligently incorporates human intentions throughout each phase of the fine-tuning workflow. IntentTuner enables users to articulate training intentions with imagery exemplars and textual descriptions, automatically converting them into effective data augmentation strategies. Furthermore, IntentTuner introduces novel metrics to measure user intent alignment, allowing intent-aware monitoring and evaluation of model training. Application exemplars and user studies demonstrate that IntentTuner streamlines fine-tuning, reducing cognitive effort and yielding superior models compared to the common baseline tool.</p>
<h3>Table Illustrator: Puzzle-based interactive authoring of plain tables</h3>
<p>Authors: Yanwei Huang, Yurun Yang, Xinhuan Shu, Ran Chen, Di Weng, Yingcai Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147780">Link</a></p>
<p>Abstract: Plain tables excel at displaying data details and are widely used in data presentation, often polished to an elaborate appearance for readability in many scenarios. However, existing authoring tools fail to provide both flexible and efficient support for altering the table layout and styles, motivating us to develop an intuitive and swift tool for table prototyping. To this end, we contribute Table Illustrator, a table authoring system taking a novel visual metaphor, puzzle, as the primary interaction unit. Through combinations and configurations on puzzles, the system enables rapid table construction and supports a diverse range of table layouts and styles. The tool design is informed by practical challenges and requirements from interviews with 10 table practitioners and a structured design space based on an analysis of over 2,500 real-world tables. User studies showed that Table Illustrator achieved comparable performance to Microsoft Excel while reducing users' completion time and perceived workload.</p>
<h3>Is It AI or Is It Me? Understanding Users’ Prompt Journey with Text-to-Image Generative AI Tools</h3>
<p>Authors: Atefeh Mahdavi Goloujeh, Anne Sullivan, Brian Magerko</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146973">Link</a></p>
<p>Abstract: Generative Artificial Intelligence (AI) has witnessed unprecedented growth in text-to-image AI tools. Yet, much remains unknown about users' prompt journey with such tools in the wild. In this paper, we posit that designing human-centered text-to-image AI tools requires a clear understanding of how individuals intuitively approach crafting prompts, and what challenges they may encounter. To address this, we conducted semi-structured interviews with 19 existing users of a text-to-image AI tool. Our findings (1) offer insights into users’ prompt journey including structures and processes for writing, evaluating, and refining prompts in text-to-image AI tools and (2) indicate that users must overcome barriers to aligning AI to their intents, and mastering prompt crafting knowledge. From the findings, we discuss the prompt journey as an individual yet a social experience and highlight opportunities for aligning text-to-image AI tools and users’ intents.</p>
<h3>PromptCharm: Text-to-Image Generation through Multi-modal Prompting and Refinement</h3>
<p>Authors: Zhijie Wang, Yuheng Huang, Da Song, Lei Ma, Tianyi Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148288">Link</a></p>
<p>Abstract: The recent advancements in Generative AI have significantly advanced the field of text-to-image generation. The state-of-the-art text-to-image model, Stable Diffusion, is now capable of synthesizing high-quality images with a strong sense of aesthetics. Crafting text prompts that align with the model's interpretation and the user's intent thus becomes crucial. However, prompting remains challenging for novice users due to the complexity of the stable diffusion model and the non-trivial efforts required for iteratively editing and refining the text prompts. To address these challenges, we propose PromptCharm, a mixed-initiative system that facilitates text-to-image creation through multi-modal prompt engineering and refinement. To assist novice users in prompting, PromptCharm first automatically refines and optimizes the user's initial prompt. Furthermore, PromptCharm supports the user in exploring and selecting different image styles within a large database. To assist users in effectively refining their prompts and images, PromptCharm renders model explanations by visualizing the model's attention values. If the user notices any unsatisfactory areas in the generated images, they can further refine the images through model attention adjustment or image inpainting within the rich feedback loop of PromptCharm. To evaluate the effectiveness and usability of PromptCharm, we conducted a controlled user study with 12 participants and an exploratory user study with another 12 participants. These two studies show that participants using PromptCharm were able to create images with higher quality and better aligned with the user's expectations compared with using two variants of PromptCharm that lacked interaction or visualization support.</p>
<h3>An Accessible, Three-Axis Plotter for Enhancing Calligraphy Learning through Generated Motion</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Cathy Mengying Fang, Lingdong Huang, Quincy Kuang, Zach Lieberman, Pattie Maes, Hiroshi Ishii</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147202">Link</a></p>
<p>Abstract: An Accessible, Three-Axis Plotter for Enhancing Calligraphy Learning through Generated Motion</p>
<h2>Data Visualization and Literacy</h2>
<h3>Data Storytelling in Data Visualisation: Does it Enhance the Efficiency and Effectiveness of Information Retrieval and Insights Comprehension?</h3>
<p>Authors: Hongbo Shao, Roberto Martinez-Maldonado, Vanessa Echeverria, Lixiang Yan, Dragan Gasevic</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146892">Link</a></p>
<h3>Make Interaction Situated: Designing User Acceptable Interaction for Situated Visualization in Public Environments</h3>
<p>Authors: Qian Zhu, Zhuo Wang, Wei Zeng, Wai Tong, Weiyue Lin, Xiaojuan Ma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147605">Link</a></p>
<h3>A Human Information Processing Theory of the Interpretation of Visualizations: Demonstrating Its Utility</h3>
<p>Authors: Peter Cheng, Grecia Garcia Garcia, Daniel Raggi, Mateja Jamnik</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147576">Link</a></p>
<h3>VAID: Indexing View Designs in Visual Analytics System</h3>
<p>Authors: Lu Ying, Aoyu Wu, Haotian Li, Zikun Deng, Ji Lan, Jiang Wu, Yong Wang, Huamin Qu, Dazhen Deng, Yingcai Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148123">Link</a></p>
<h3>Reading Between the Pixels: Investigating the Barriers to Visualization Literacy</h3>
<p>Authors: Carolina Nobre, Kehang Zhu, Eric Mörth, Hanspeter Pfister, Johanna Beyer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147374">Link</a></p>
<h2>Data Visualization and Physicalization</h2>
<h3>StableLev: Data-Driven Stability Enhancement for Multi-Particle Acoustic Levitation</h3>
<p>Authors: Lei Gao, Giorgos Christopoulos, Prateek Mittal, Ryuji Hirayama, Sriram Subramanian</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148311">Link</a></p>
<h3>"Yeah, this graph doesn't show that": Analysis of Online Engagement with Misleading Data Visualizations</h3>
<p>Authors: Maxim Lisnic, Alexander Lex, Marina Kogan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147712">Link</a></p>
<h3>Epigraphics: Message-Driven Infographics Authoring</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Tongyu Zhou, Jeff Huang, Gromit Yeuk-Yin Chan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148344">Link</a></p>
<h3>From Exploration to End of Life: Unpacking Sustainability in Physicalization Practices</h3>
<p>BEST_PAPER</p>
<p>Authors: Luiz Morais, Georgia Panagiotidou, Sarah Hayes, Tatiana Losev, Rebecca Noonan, Uta Hinrichs</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147627">Link</a></p>
<h3>That's Rough! Encoding Data into Roughness for Physicalization</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Xiaojiao Du, Kadek Ananta Satriadi, Adam Drogemuller, Brandon Matthews, Ross Smith, James A. Walsh, Andrew Cunningham</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147680">Link</a></p>
<h2>Design Methods</h2>
<h3>Demystifying Tacit Knowledge in Graphic Design: Characteristics, Instances, Approaches, and Guidelines</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Kihoon Son, DaEun Choi, Tae Soo Kim, Juho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147058">Link</a></p>
<h3>A Living Framework for Understanding Cooperative Games</h3>
<p>Authors: Pedro Pais, David Gonçalves, Daniel Reis, João Godinho, João Morais, Manuel Piçarra, Pedro Trindade, Dmitry Alexandrovsky, Kathrin Gerling, João Guerreiro, André Rodrigues</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148293">Link</a></p>
<h3>"I Am So Overwhelmed I Don't Know Where to Begin!" Towards Developing Relationship-Based and Values-Based End-of-Life Data Planning Approaches</h3>
<p>Authors: Dylan Doyle, Jed Brubaker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148141">Link</a></p>
<h3>Embodied Tentacle: Mapping Design to Control of Non-Analogous Body Parts with the Human Body</h3>
<p>Authors: Shuto Takashita, Ken Arai, Hiroto Saito, Michiteru Kitazaki, Masahiko Inami</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147057">Link</a></p>
<h3>Imagining Sustainable Energy Communities: Design Narratives of Future Digital Technologies, Sites, and Participation</h3>
<p>Authors: Victor Jensen, Kristina Laursen, Rikke Hagensby Jensen, Rachel Smith</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147766">Link</a></p>
<h2>Design Tools A</h2>
<h3>KOALA Hero Toolkit: A New Approach to Inform Families of Mobile Datafication Risks</h3>
<p>Authors: Ge Wang, Jun Zhao, Konrad Kollnig, Adrien Zier, Blanche Duron, Zhilin Zhang, Max Van Kleek, Nigel Shadbolt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148198">Link</a></p>
<h3>Rapid Prototyping with VideoClipper: In-camera Storyboarding and Video Capture</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Wendy Mackay, Alexandre Battut, Germán Leiva, Michel Beaudouin-Lafon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147150">Link</a></p>
<h3>Grand challenges in WaterHCI</h3>
<p>Authors: Florian Mueller, Maria Montoya, Sarah Jane Pell, Leif Oppermann, Mark Blythe, Paul Dietz, Joe Marshall, Scott Bateman, Ian Smith, Swamy Ananthanarayan, Ali Mazalek, Alexander Verni, Alexander Bakogeorge, Mathieu Simonnet, Kirsten Ellis, Nathan Semertzidis, Winslow Burleson, John Quarles, Steve Mann, Chris Hill, Christal Clashing, Don Samitha Elvitigala</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147744">Link</a></p>
<h3>A temporal vocabulary of Design Events for Research through Design</h3>
<p>Authors: Doenja Oogjes, Audrey Desjardins</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148024">Link</a></p>
<h3>Strategies of Product Managers: Negotiating Social Values in Digital Product Design</h3>
<p>Authors: Eilat Lev Ari, Maayan Roichman, Eran Toch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147477">Link</a></p>
<h2>Design Tools B</h2>
<h3>Griffith: A Storyboarding Tool Designed with Japanese Animation Professionals</h3>
<p>Authors: Jun Kato, Kenta Hara, Nao Hirasawa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147403">Link</a></p>
<h3>From Concept to Community: Unpacking the Work of Designing Educational and Activist Toolkits</h3>
<p>Authors: Tamar Wilner, Krishna Akhil Kumar Adavi, Sreehana Mandava, Ayesha Bhimdiwala, Hana Frluckaj, Jennifer Turns, Ahmer Arif</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147784">Link</a></p>
<h3>AdapTics: A Toolkit for Creative Design and Integration of Real-Time Adaptive Mid-Air Ultrasound Tactons</h3>
<p>Authors: Kevin John, Yinan Li, Hasti Seifi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148147">Link</a></p>
<h3>Bitacora: A Toolkit for Supporting  NonProfits to Critically Reflect on Social Media Data Use</h3>
<p>Authors: Adriana Alvarado Garcia, Marisol Wong-Villacres, Benjamín Hernández, Christopher Le Dantec</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146866">Link</a></p>
<h3>Design Patterns for Data-Driven News Articles</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Shan Hao, Zezhong Wang, Benjamin Bach, Larissa Pschetz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146944">Link</a></p>
<h2>Drivers and Pedestrians A</h2>
<h3>Inter-regional Lens on the Privacy Preferences of Drivers for ITS and Future VANETs</h3>
<p>Authors: Lejla Islami, Agnieszka Kitkowska, Simone Fischer-Hübner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146934">Link</a></p>
<h3>AdaptiveVoice: Cognitively Adaptive Voice Interface for Driving Assistance</h3>
<p>Authors: Shaoyue Wen, Songming Ping, Jialin Wang, Hai-Ning Liang, Xuhai "Orson" Xu, Yukang Yan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147590">Link</a></p>
<h3>Portobello: Extending Driving Simulation from the Lab to the Road</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Fanjun Bu, Stacey Li, David Goedicke, Mark Colley, Gyanendra Sharma, Wendy Ju</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146873">Link</a></p>
<h3>SYNC-VR: Synchronizing Your Senses to Conquer Motion Sickness for Enriching In-Vehicle Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ahmed Elsharkawy, Aya Ataya, Dohyeon Yeo, Eunsol An, Seokhyun Hwang, SeungJun Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147287">Link</a></p>
<h3>Can You Hazard a Guess?: Evaluating the Effect of Augmented Reality Cues on Driver Hazard Prediction</h3>
<p>Authors: Thomas Goodge, Frank Pollick, Stephen Brewster</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146912">Link</a></p>
<h2>Drivers and Pedestrians B</h2>
<h3>Investigating the Effects of External Communication and Platoon Behavior on Manual Drivers at Highway Access</h3>
<p>Authors: Mark Colley, Omid Rajabi, Enrico Rukzio</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147216">Link</a></p>
<h3>Understanding Human-machine Cooperation in Game-theoretical Driving Scenarios amid Mixed Traffic</h3>
<p>Authors: Yutong Zhang, Edmond Awad, Morgan Frank, Peng Liu, Na Du</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147435">Link</a></p>
<h3>An Eye Gaze Heatmap Analysis of Uncertainty Head-Up Display Designs for Conditional Automated Driving</h3>
<p>Authors: Michael Gerber, Ronald Schroeter, Daniel Johnson, Christian Janssen, Andry Rakotonirainy, Jonny Kuo, Mike Lenné</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147765">Link</a></p>
<h3>From Slow-Mo to Ludicrous Speed: Comfortably Manipulating the Perception of Linear In-Car VR Motion Through Vehicular Translational Gain and Attenuation</h3>
<p>Authors: Katharina Pöhlmann, Graham Wilson, Gang Li, Mark McGill, Stephen Brewster</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148305">Link</a></p>
<h3>Understanding Pedestrians’ Perception of Safety and Safe Mobility Practices</h3>
<p>Authors: Min Zhang, Arosha Bandara</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146652">Link</a></p>
<h2>Drone Interaction</h2>
<h3>Swarm Body: Embodied Swarm Robots</h3>
<p>Authors: Sosuke Ichihashi, So Kuroki, Mai Nishimura, Kazumi Kasaura, Takefumi Hiraki, Kazutoshi Tanaka, Shigeo Yoshida</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146948">Link</a></p>
<h3>Exploring Intended Functions of Indoor Flying Robots Interacting With Humans in Proximity</h3>
<p>Authors: Ziming Wang, Yiqian Wu, Shiwei Yang, Xiaowei Chen, Björn Rohles, Morten Fjeld</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147793">Link</a></p>
<h3>Firefighters' Perceptions on Collaboration and Interaction with Autonomous Drones: Results of a Field Trial</h3>
<p>Authors: Moyi Li, Dzmitry Katsiuba, Mateusz Dolata, Gerhard Schwabe</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147198">Link</a></p>
<h3>HIFuzz: Human Interaction Fuzzing for Small Unmanned Aerial Vehicles</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Theodore Chambers, Michael Vierhauser, Ankit Agrawal, Michael Murphy, Jason Matthew Brauer, Salil Purandare, Myra Cohen, Jane Cleland-Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147755">Link</a></p>
<h3>Dances with Drones: Spatial Matching and Perceived Agency in Improvised Movements with Drone and Human Partners</h3>
<p>Authors: Kaixu Dong, Zhiyuan Zhang, Xiaoyu CHANG, Pakpong Chirarattananon, RAY LC</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147482">Link</a></p>
<h2>Fabrication and Tangible Interaction A</h2>
<h3>MoiréWidgets: High-Precision, Passive Tangible Interfaces via Moiré Effect</h3>
<p>Authors: Daniel Campos Zamora, Mustafa Doga Dogan, Alexa Siu, Eunyee Koh, Chang Xiao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147630">Link</a></p>
<h3>DungeonMaker: Embedding Tangible Creation and Destruction in Hybrid Board Games through Personal Fabrication Technology</h3>
<p>Authors: Evgeny Stemasov, Tobias Wagner, Ali Askari, Jessica Janek, Omid Rajabi, Anja Schikorr, Julian Frommel, Jan Gugenheimer, Enrico Rukzio</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146888">Link</a></p>
<h3>Squishy, Yet Satisfying: Exploring Deformable Shapes' Cross-Modal Correspondences with Colours and Emotions</h3>
<p>Authors: Cameron Steer, Kim Sauvé, Anika Jain, Omosunmisola Lawal, Michael Proulx, Crescent Jicol, Jason Alexander</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148261">Link</a></p>
<h3>PaperTouch: Tangible Interfaces through Paper Craft and Touchscreen Devices</h3>
<p>Authors: Qian Ye, Zhen Zhou Yong, Bo Han, Ching Chiuan Yen, Clement Zheng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146860">Link</a></p>
<h3>WooDowel: Electrode Isolation for Electromagnetic Shielding in Triboelectric Plywood Sensors</h3>
<p>Authors: Yonghao Shi, Chenzheng Li, Yuning Su, Xing-Dong Yang, Te-Yen Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147211">Link</a></p>
<h2>Fabrication and Tangible Interaction B</h2>
<h3>Tandem: Reproducible Digital Fabrication Workflows as Multimodal Programs</h3>
<p>Authors: Jasper Tran O'Leary, Thrisha Ramesh, Octi Zhang, Nadya Peek</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146800">Link</a></p>
<h3>ecSkin: Low-Cost Fabrication of Epidermal Electrochemical Sensors for Detecting Biomarkers in Sweat</h3>
<p>Authors: Sai Nandan Panigrahy, Chang Lee, Vrahant Nagoria, Mohammad Janghorban, Richa Pandey, Aditya Shekhar Nittala</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147205">Link</a></p>
<h3>VabricBeads : Variable Stiffness Structured Fabric using Artificial Muscle in Woven Beads</h3>
<p>Authors: Jefferson Pardomuan, Shio Miyafuji, Nobuhiro Takahashi, Hideki Koike</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147426">Link</a></p>
<h3>DisplayFab: The State of the Art and a Roadmap in the Personal Fabrication of Free-Form Displays Using Active Materials and Additive Manufacturing.</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ollie Hanton, Mike Fraser, Anne Roudaut</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147502">Link</a></p>
<h3>pARam: Leveraging Parametric Design in Extended Reality to Support the Personalization of Artifacts for Personal Fabrication</h3>
<p>Authors: Evgeny Stemasov, Simon Demharter, Max Rädler, Jan Gugenheimer, Enrico Rukzio</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147551">Link</a></p>
<h2>Game Design A</h2>
<h3>Not All the Same: Understanding and Informing Similarity Estimation in Tile-Based Video Games</h3>
<p>Authors: Sebastian Berns, Vanessa Volz, Laurissa Tokarchuk, Sam Snodgrass, Christian Guckelsberger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147878">Link</a></p>
<h3>Find the Bot!: Gamifying Facial Emotion Recognition for Both Human Training and Machine Learning Data Collection</h3>
<p>Authors: Yeonsun Yang, Ahyeon Shin, Nayoung Kim, Huidam Woo, John Chung, Jean Song</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148164">Link</a></p>
<h3>Cheat Codes as External Support for Players Navigating Fear of Failure and Self-Regulation Challenges In Digital Games</h3>
<p>Authors: Karla Waldenmeier, Susanne Poeller, Martin Dechant, Nicola Baumann, Regan Mandryk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147333">Link</a></p>
<h3>How does Juicy Game Feedback Motivate? Testing Curiosity, Competence, and Effectance</h3>
<p>Authors: Dominic Kao, Nick Ballou, Kathrin Gerling, Heiko Breitsohl, Sebastian Deterding</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148171">Link</a></p>
<h3>"Ah! I see'' - Facilitating Process Reflection in Gameplay through a Novel Spatio-Temporal Visualization System</h3>
<p>Authors: Sai Siddartha Maram, Erica Kleinman, Jennifer Villareale, Jichen Zhu, Magy Seif El-Nasr</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147359">Link</a></p>
<h2>Game Design B</h2>
<h3>A Game of Love for Women: Social Support in Otome Game Mr. Love: Queen’s Choice in China</h3>
<p>Authors: Qinyuan Lei, Ran Tang, Hiu Man Ho, Han Zhou, Jingyi Guo, Zilu Tang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147914">Link</a></p>
<h3>Independent Validation of the Player Experience Inventory: Findings from a Large Set of Video Game Players</h3>
<p>Authors: Sebastian Perrig, Nicolas Scharowski, Florian Brühlmann, Nick von Felten, Klaus Opwis, Lena Aeschbach</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147606">Link</a></p>
<h3>Effects of a Gaze-Based 2D Platform Game on User Enjoyment, Perceived Competence, and Digital Eye Strain</h3>
<p>Authors: Mark Colley, Beate Wanner, Max Rädler, Marcel Rötzer, Julian Frommel, Teresa Hirzle, Pascal Jansen, Enrico Rukzio</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148322">Link</a></p>
<h3>Damage Optimization in Video Games: A Player-Driven Co-Creative Approach</h3>
<p>Authors: Johannes Pfau, Manik Charan, Erica Kleinman, Magy Seif El-Nasr</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147749">Link</a></p>
<h3>The Trick is to Stay Behind?: Defining and Exploring the Design Space of Player Balancing Mechanics</h3>
<p>Authors: David Gonçalves, Daniel Barros, Pedro Pais, João Guerreiro, Tiago Guerreiro, André Rodrigues</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147203">Link</a></p>
<h2>Generative AI for Design</h2>
<h3>The Effects of Generative AI on Design Fixation and Divergent Thinking</h3>
<p>Authors: Samangi Wadinambiarachchi, Ryan Kelly, Saumya Pareek, Qiushi Zhou, Eduardo Velloso</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147562">Link</a></p>
<p>Abstract: Generative AI systems have been heralded as tools for augmenting human creativity and inspiring divergent thinking, though with little empirical evidence for these claims. This paper explores the effects of exposure to AI-generated images on measures of design fixation and divergent thinking in a visual ideation task. Through a between-participants experiment (N=60), we found that support from an AI image generator during ideation leads to higher fixation on an initial example. Participants who used AI produced fewer ideas, with less variety and lower originality compared to a baseline. Our qualitative analysis suggests that the effectiveness of co-ideation with AI rests on participants' chosen approach to prompt creation and on the strategies used by participants to generate ideas in response to the AI's suggestions. We discuss opportunities for designing generative AI systems for ideation support and incorporating these AI tools into ideation workflows.</p>
<h3>Beyond Numbers: Creating Analogies to Enhance Data Comprehension and Communication with Generative AI</h3>
<p>Authors: Qing Chen, Wei Shuai, Jiyao Zhang, Zhida Sun, Nan Cao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146906">Link</a></p>
<p>Abstract: Unfamiliar measurements usually hinder readers from grasping the scale of the numerical data, understanding the content, and feeling engaged with the context. To enhance data comprehension and communication, we leverage analogies to bridge the gap between abstract data and familiar measurements. In this work, we first conduct semi-structured interviews with design experts to identify design problems and summarize design considerations. Then, we collect an analogy dataset of 138 cases from various online sources. Based on the collected dataset, we characterize a design space for creating data analogies. Next, we build a prototype system, AnalogyMate, that automatically suggests data analogies, their corresponding design solutions, and generated visual representations powered by generative AI. The study results show the usefulness of AnalogyMate in aiding the creation process of data analogies and the effectiveness of data analogy in enhancing data comprehension and communication. </p>
<h3>RoomDreaming: Generative-AI Approach to Facilitating Iterative, Preliminary Interior Design Exploration</h3>
<p>Authors: Shun-Yu Wang, Wei-Chung Su, Serena Chen, Marta Misztal, Katherine Cheng, Alwena Lin, Yu Chen, Ching-Yi Tsai, Mike Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147375">Link</a></p>
<p>Abstract: Interior design aims to create aesthetically pleasing and functional environments within an architectural space. For a simple room, the preliminary design exploration currently takes multiple meetings and days of work for interior designers to incorporate homeowners' personal preferences through layout, furnishings, form, colors, and materials.
We present RoomDreaming, a generative AI-based approach designed to facilitate preliminary interior design exploration. It empowers owners and designers to rapidly and efficiently iterate through a broad range of AI-generated, photo-realistic design alternatives, each uniquely tailored to fit actual space layouts and individual design preferences.
We conducted a series of formative and summative studies with a total of 18 homeowners and 20 interior designers to help design, improve, and evaluate RoomDreaming.
Owners reported that RoomDreaming effectively increased the breadth and depth of design exploration with higher efficiency and satisfaction. Designers reported that one hour of collaborative designing with RoomDreaming yielded results comparable to several days of traditional owner-designer meetings, plus days to weeks worth of designer work to develop and refine designs.</p>
<h3>Design Principles for Generative AI Applications</h3>
<p>Authors: Justin Weisz, Jessica He, Michael Muller, Gabriela Hoefer, Rachel Miles, Werner Geyer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147832">Link</a></p>
<p>Abstract: Generative AI applications present unique design challenges. As generative AI technologies are increasingly being incorporated into mainstream applications, there is an urgent need for guidance on how to design user experiences that foster effective and safe use. We present six principles for the design of generative AI applications that address unique characteristics of generative AI UX and offer new interpretations and extensions of known issues in the design of AI applications. Each principle is coupled with a set of design strategies for implementing that principle via UX capabilities or through the design process. The principles and strategies were developed through an iterative process involving literature review, feedback from design practitioners, validation against real-world generative AI applications, and incorporation into the design process of two generative AI applications. We anticipate the principles to usefully inform the design of generative AI applications by driving actionable design recommendations.</p>
<h3>User Experience Design Professionals’ Perceptions of Generative Artificial Intelligence</h3>
<p>Authors: Jie Li, Hancheng Cao, Laura Lin, Youyang Hou, Ruihao Zhu, Abdallah El Ali</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148101">Link</a></p>
<p>Abstract: Among creative professionals, Generative Artificial Intelligence (GenAI) has sparked excitement over its capabilities and fear over unanticipated consequences. How does GenAI impact User Experience Design (UXD) practice, and are fears warranted? We interviewed 20 UX Designers, with diverse experience and across companies (startups to large enterprises). We probed them to characterize their practices, and sample their attitudes, concerns, and expectations. We found that experienced designers are confident in their originality, creativity, and empathic skills, and find GenAI’s role as assistive. They emphasized the unique human factors of “enjoyment” and “agency”, where humans remain the arbiters of “AI alignment”. However, skill degradation, job replacement, and creativity exhaustion can adversely impact junior designers. We discuss implications for human-GenAI collaboration, specifically copyright and ownership, human creativity and agency, and AI literacy and access. Through the lens of responsible and participatory AI, we contribute a deeper understanding of GenAI fears and opportunities for UXD.</p>
<h2>Haptics and Embodied Interaction A</h2>
<h3>Touching the Moon: Leveraging Passive Haptics, Embodiment and Presence for Operational Assessments in Virtual Reality</h3>
<p>BEST_PAPER</p>
<p>Authors: Florian Dufresne, Tommy Nilsson, Geoffrey Gorisse, Enrico Guerra, André Zenner, Olivier Christmann, Leonie Bensch, Nikolai Callus, Aidan Cowley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147838">Link</a></p>
<h3>A Meta-Bayesian Approach for Rapid Online Parametric Optimization for Wrist-based Interactions</h3>
<p>Authors: Yi-Chi Liao, Ruta Desai, Alec Pierce, Krista Taylor, Hrvoje Benko, Tanya Jonker, Aakar Gupta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146812">Link</a></p>
<h3>vARitouch: Back of the Finger Device for Adding Variable Compliance to Rigid Objects</h3>
<p>Authors: Gabriela Vega, Valentin Martinez-Missir, Dennis Wittchen, Nihar Sabnis, Audrey Girouard, Karen Cochrane, Paul Strohmeier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147275">Link</a></p>
<h3>Haptic Source-effector: Full-body Haptics via Non-invasive Brain Stimulation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yudai Tanaka, Jacob Serfaty, Pedro Lopes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147704">Link</a></p>
<h3>MouseRing: Always-available Touchpad Interaction with IMU Rings</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Xiyuan Shen, Chun Yu, Xutong Wang, Chen Liang, Haozhan Chen, Yuanchun Shi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148332">Link</a></p>
<h2>Haptics and Embodied Interaction B</h2>
<h3>Thermal Masking: When the Illusion Takes Over the Real</h3>
<p>Authors: Haokun Wang, Yatharth Singhal, Hyunjae Gil, Jin Ryong Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147304">Link</a></p>
<h3>Haptic Permeability: Adding Holes to Tactile Devices Improves Dexterity</h3>
<p>Authors: Shan-Yuan Teng, Aryan Gupta, Pedro Lopes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146851">Link</a></p>
<h3>Don’t Look Now: Audio/Haptic Guidance for 3D Scanning of Landmarks</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jessica Van Brummelen, Liv Urwin, Oliver Johnston, Mohamed Sayed, Gabriel Brostow</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147615">Link</a></p>
<h3>ErgoPulse: Electrifying Your Lower Body With Biomechanical Simulation-based Electrical Muscle Stimulation Haptic System in Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Seokhyun Hwang, Jeongseok Oh, Seongjun Kang, Minwoo Seong, Ahmed Elsharkawy, SeungJun Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147568">Link</a></p>
<h3>Motionless Movement: Towards Vibrotactile Kinesthetic Displays</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yuran Ding, Nihar Sabnis, Paul Strohmeier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147366">Link</a></p>
<h2>HCI for Development A</h2>
<h3>Enhancing Communication Equity: Evaluation of an Automated Speech Recognition Application in Ghana</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Gifty Ayoka, Giulia Barbareschi, Richard Cave, Catherine Holloway</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147191">Link</a></p>
<h3>Hearing Community Voices in HCI4D: Establishing Safe Places to Co-Create Counter-Collective Narratives with Women Farmers in Bangladesh</h3>
<p>Authors: Manika Saha, Stephen Lindsay, Jessica Watterson, Tom Bartindale, Delvin Varghese, Ms Mallika Saha, Gillian Oliver, Syed Ishtiaque Ahmed, Patrick Olivier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147578">Link</a></p>
<h3>Digital Repression in Palestine</h3>
<p>Authors: Ghadeer Awwad, Kentaro Toyama</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146966">Link</a></p>
<h3>"Unrest and trauma stays with you!": Navigating mental health and professional service-seeking in Kashmir</h3>
<p>Authors: Asra Wani, Ishika Joshi, Nadia Nahvi, Pushpendra Singh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147671">Link</a></p>
<h3>“I know I have this till my Last Breath”: Unmasking the Gaps in Chronic Obstructive Pulmonary Disease (COPD) Care in India</h3>
<p>BEST_PAPER</p>
<p>Authors: Gautami Tripathi, Medhavi Sabherwal, Pushpendra Singh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147082">Link</a></p>
<h2>HCI for Development B</h2>
<h3>Challenges to Online Disability Rights Advocacy in India</h3>
<p>Authors: Sukhnidh Kaur, Manohar Swaminathan, Kalika Bali, Aditya Vashistha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147020">Link</a></p>
<h3>Expanding Concepts of Non-Consensual Image-Disclosure Abuse: A Study of NCIDA in Pakistan</h3>
<p>Authors: Amna Batool, Mustafa Naseem, Kentaro Toyama</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146885">Link</a></p>
<h3>Viewer2Explorer: Designing a Map Interface for Spatial Navigation in Linear 360 Museum Exhibition Video</h3>
<p>Authors: Chaeeun Lee, Jinwook Kim, HyeonBeom Yi, Woohun Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147613">Link</a></p>
<h3>Explorable Explainable AI: Improving AI Understanding for Community Health Workers in India</h3>
<p>Authors: Ian Solano-Kamaiko, Dibyendu Mishra, Nicola Dell, Aditya Vashistha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147612">Link</a></p>
<h2>Healthy Aging</h2>
<h3>Redefining Activity Tracking Through Older Adults' Reflections on Meaningful Activities</h3>
<p>Authors: Yiwen Wang, Mengying Li, Young-Ho Kim, Bongshin Lee, Margaret Danilovich, Amanda Lazar, David E Conroy, Hernisa Kacorri, Eun Kyoung Choe</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148041">Link</a></p>
<h3>“X-Ray Vision” as a Compensatory Augmentation for Slowing Cognitive Map Decay in Older Adults</h3>
<p>Authors: Christopher Bennett, Paul Fink, Nicholas Giudice</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147822">Link</a></p>
<h3>Mentorable Interfaces for Automated Vehicles: A New Paradigm for Designing Learnable Technology for Older Adults</h3>
<p>Authors: Togtokhtur Batbold, Alessandro Soro, Ronald Schroeter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147087">Link</a></p>
<h3>Navigating the Maze of Routine Disruption: Exploring How Older Adults Living Alone Navigate Barriers to Establishing and Maintaining Physical Activity Habits</h3>
<p>Authors: Muhe Yang, Karyn Moffatt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147390">Link</a></p>
<h3>LightSword: A Customized Virtual Reality Exergame for Long-Term Cognitive Inhibition Training in Older Adults</h3>
<p>Authors: Qiuxin Du, Zhen Song, Haiyan Jiang, Xiaoying Wei, Dongdong Weng, Mingming Fan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147594">Link</a></p>
<h2>Interaction and Input in Immersive Environments</h2>
<h3>Spatial Gaze Markers: Supporting Effective Task Switching in Augmented Reality</h3>
<p>Authors: Mathias Lystbæk, Ken Pfeuffer, Tobias Langlotz, Jens Emil Grønbæk, Hans Gellersen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147964">Link</a></p>
<p>Abstract: Task switching can occur frequently in daily routines with physical activity. In this paper, we introduce Spatial Gaze Markers, an augmented reality tool to support users in immediately returning to the last point of interest after an attention shift. The tool is task-agnostic, using only eye-tracking information to infer distinct points of visual attention and to mark the corresponding area in the physical environment. We present a user study that evaluates the effectiveness of Spatial Gaze Markers in simulated physical repair and inspection tasks against a no-marker baseline. The results give insights into how Spatial Gaze Markers affect user performance, task load, and experience of users with varying levels of task type and distractions. Our work is relevant to assist physical workers with simple AR techniques and render task switching faster with less effort.</p>
<h3>The RayHand Navigation: A Virtual Navigation Method with Relative Position between Hand and Gaze-Ray</h3>
<p>Authors: Sei Kang, Jaejoon Jeong, Gun Lee, Soo-Hyung Kim, Hyung-Jeong Yang, Seungwon Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148284">Link</a></p>
<p>Abstract: In this paper, we introduce a novel Virtual Reality (VR) navigation method using gaze ray and hand, named RayHand navigation. It supports controlling navigation speed and direction by quickly indicating the initial direction using gaze and then using dexterous hand movement for controlling the speed and direction based on the relative position between the gaze ray and user’s hand. We conducted a user study comparing our approach to the head-hand and torso-leaning-based navigation methods, and also evaluated their learning effect. The results showed that the RayHand and head-hand navigations were less physically demanding than the torso-leaning navigation, and the RayHand supported rich navigation experience with high hedonic quality and solved the issue of the user unintentionally stepping out from the designated interaction area. In addition, our approach showed a significant improvement over time with a learning effect.</p>
<h3>Effects of Device Environment and Information Layout on Spatial Memory and Performance in VR Selection Tasks</h3>
<p>Authors: Kim Kargut, Carl Gutwin, Andy Cockburn</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147581">Link</a></p>
<p>Abstract: Virtual Reality systems are increasingly proposed as a platform for everyday interactive software. Many applications are dependent on actions such as navigation and selection, but it is not clear how well immersive environments support these basic activities. Previous studies have suggested advantages for spatial learning in VR, so we carried out a study that investigated two aspects of immersion on spatial memory and selection: the degree to which the user is immersed in the data, and whether the system uses immersive input and output. The study showed that more-immersive conditions had substantially worse selection performance, and did not improve spatial learning. However, most participants believed that the immersive conditions were better for learning object locations, and most people preferred the immersive layout and the HMD. Our study suggests that designers should be cautious about assuming that everyday software applications will benefit from being deployed in an immersive VR environment.</p>
<h3>Rowing Beyond: Investigating Steering Methods for Rowing-based Locomotion in Virtual Environments</h3>
<p>Authors: Martin Hedlund, Cristian Bogdan, Gerrit Meixner, Andrii Matviienko</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147740">Link</a></p>
<p>Abstract: Rowing has great potential in Virtual Reality (VR) exergames as it requires physical effort and uses physical motion to map the locomotion in a virtual space. However, rowing in VR is currently restricted to locomotion along one axis, leaving 2D and 3D locomotion out of the scope. To facilitate rowing-based locomotion, we implemented three steering techniques based on head, hands, and feet movements for 2D and 3D VR environments. To investigate these methods, we conducted a controlled experiment (N = 24) to assess the user performance, experience and VR sickness. We found that head steering leads to fast and precise steering in 2D and 3D, and hand steering is the most realistic. Feet steering had the largest performance difference between 2D and 3D but comparable precision to hands in 2D. Lastly, head steering is the least mentally demanding, and all methods had comparable VR sickness. </p>
<h3>Sicknificant Steps: A Systematic Review and Meta-analysis of VR Sickness in Walking-based Locomotion for Virtual Reality</h3>
<p>Authors: Thomas van Gemert, Niels Christian Nilsson, Teresa Hirzle, Joanna Bergström</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147138">Link</a></p>
<p>Abstract: Walking-based locomotion techniques in virtual reality (VR) can use redirection to enable walking in a virtual environment larger than the physical one. This results in a mismatch between the perceived virtual and physical movement, which is known to cause VR sickness. However, it is unclear if different types of walking techniques (e.g., resetting, reorientation, or self-overlapping spaces) affect VR sickness differently. To address this, we conducted a systematic review and meta-analysis of 96 papers published in 2016–2022 that measure VR sickness in walking-based locomotion. We find different VR sickness effects between types of redirection and between normal walking and redirection. However, we also identified several problems with the use and reporting of VR sickness measures. We discuss the challenges in understanding VR sickness differences between walking techniques and present guidelines for measuring VR sickness in locomotion studies.</p>
<h2>Reality and Un-Reality in Immersive Interactions</h2>
<h3>The Effects of False but Stable Heart Rate Feedback on Cybersickness and User Experience in Virtual Reality</h3>
<p>Authors: DongYun Joo, Hanseob Kim, Gerard Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148245">Link</a></p>
<p>Abstract: Virtual reality (VR) offers a compelling and immersive experience; however, cybersickness (or VR sickness) stands as a significant obstacle to its widespread adoption. 
When a user experiences cybersickness, one's physical condition deteriorates with various symptoms, often accompanied by an increased and destabilized heart rate and even altered perception of one's state. In this paper, we propose to provide ``False but Stable Heart rate (FSH)'' feedback through auditory and vibrotactile stimulation to reversely induce a stably perceived heart rate and, thereby, alleviate cybersickness while navigating a sickness-inducing VR content. 
The validation of the human experiment confirmed the intended effect in a statistically significant way. Furthermore, it was found that the lesser compatible FSH feedback had a more substantial sickness reduction effect but distracted the user with the reduced immersive experience. 
The compatible FSH feedback still showed moderate sickness reduction with the maintained sense of presence and immersion. </p>
<h3>Was it Real or Virtual? Confirming the Occurrence and Explaining Causes of Memory Source Confusion between Reality and Virtual Reality</h3>
<p>Authors: Elise Bonnail, Julian Frommel, Eric Lecolinet, Samuel Huron, Jan Gugenheimer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147768">Link</a></p>
<p>Abstract: Source confusion occurs when individuals attribute a memory to the wrong source (e.g., confusing a picture with an experienced event). Virtual Reality (VR) represents a new source of memories particularly prone to being confused with reality. While previous research identified causes of source confusion between reality and other sources (e.g., imagination, pictures), there is currently no understanding of what characteristics specific to VR (e.g., immersion, presence) could influence source confusion. Through a laboratory study (n=29), we 1) confirm the existence of VR source confusion with current technology, and 2) present a quantitative and qualitative exploration of factors influencing VR source confusion. Building on the Source Monitoring Framework, we identify VR characteristics and assumptions about VR capabilities (e.g., poor rendering) that are used to distinguish virtual from real memories. From these insights, we reflect on how the increasing realism of VR could leave users vulnerable to memory errors and perceptual manipulations.</p>
<h3>Socially Late, Virtually Present: The Effects of Transforming Asynchronous Social Interactions in Virtual Reality</h3>
<p>Authors: Portia Wang, Mark Miller, Anna Queiroz, Jeremy Bailenson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148136">Link</a></p>
<p>Abstract: Social Virtual Reality (VR) typically entails users interacting in real time. However, asynchronous Social VR presents the possibility of combining the convenience of asynchronous communication with the high presence of VR. Because the tools to easily record and replay VR social interactions are fairly new, scholars have not yet examined how users perceive asynchronous VR social interactions, and how nonverbal transformations of recorded interactions influence user behavior. In this work, we study nonverbal transformations of group interactions around proxemics and gaze and present results from an exploratory user study (N=128) investigating their effects. We found that the combination of spatial accommodation and added gaze increases social presence, perceived attention, and mutual gaze. Results also showed an inverse relationship between interpersonal distance and perceived levels of dominance and threat of the recorded group. Finally, we outline implications for educators and virtual meeting organizers to incorporate these transformations into real-world scenarios.</p>
<h3>“I’d rather drink in VRChat”: Understanding Drinking in Social Virtual Reality</h3>
<p>Authors: Qijia Chen, Andrea Bellucci, Giulio Jacucci</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147852">Link</a></p>
<p>Abstract: Drinking in social VR has become popular, yet little is known about how users perceive and experience alcohol consumption while immersed in virtual spaces with others, as well as its potential harm and negative effects on their offline and online lives. To better understand this emerging phenomenon from the perspective of both drinkers and non-drinkers, we analyzed public discussions from the r/VRchat online community on users' perceptions, and experiences with alcohol consumption in social VR. Heavy drinking is prevalent. We find that VR drinkers feel less intoxicated, which makes them drink more without being aware of it. Anti-cybersickness designs may affect users' perception of vertigo, even if the vertigo is not caused by VR. We discuss how affordances that support meaningful activities (i.e., sense of presence, embodiment, and social interactions) exacerbate alcohol abuse. We propose implications for the design of safer social VR experiences for both drinkers and non-drinkers.</p>
<h3>Using Feedforward to Reveal Interaction Possibilities in Virtual Reality</h3>
<p>Authors: Andreea Muresan, Jess McIntosh, Kasper Hornbæk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150634">Link</a></p>
<p>Abstract: In virtual reality (VR), interactions may fail when users encounter new, unknown, or unexpected objects. We propose using feedforward in VR to help users interact with objects by revealing how such objects work. Feedforward lets users know what to do and how to do it by showing the available actions and outcomes before an interaction. In this article, we first chart the design space of feedforward in VR and illustrate how to design feedforward for specific VR interactions. We discuss starting the feedforward, previewing actions and outcomes, and returning the virtual world to its state before the feedforward. Second, we implement three real-world VR applications to show how feedforward can be applied to multistep interactions, perceived interactivity, and discoverability. Third, we conduct an evaluation of the design space with 14 VR experts to understand its usefulness. Finally, we summarize the findings of our work on VR feedforward in 15 guidelines.</p>
<h2>Large Language Models</h2>
<h3>Model Compression in Practice: Lessons Learned from Practitioners Creating On-device Machine Learning Experiences</h3>
<p>Authors: Fred Hohman, Mary Beth Kery, Donghao Ren, Dominik Moritz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147982">Link</a></p>
<p>Abstract: On-device machine learning (ML) promises to improve the privacy, responsiveness, and proliferation of new, intelligent user experiences by moving ML computation onto everyday personal devices. However, today's large ML models must be drastically compressed to run efficiently on-device, a hurtle that requires deep, yet currently niche expertise. To engage the broader human-centered ML community in on-device ML experiences, we present the results from an interview study with 30 experts at Apple that specialize in producing efficient models. We compile tacit knowledge that experts have developed through practical experience with model compression across different hardware platforms. Our findings offer pragmatic considerations missing from prior work, covering the design process, trade-offs, and technical strategies that go into creating efficient models. Finally, we distill design recommendations for tooling to help ease the difficulty of this work and bring on-device ML into to more widespread practice.</p>
<h3>Talaria: Interactively Optimizing Machine Learning Models for Efficient Inference</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Fred Hohman, Chaoqun Wang, Jinmook Lee, Jochen Görtler, Dominik Moritz, Jeffrey Bigham, Zhile Ren, Cecile Foret, Qi Shan, Xiaoyi Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146741">Link</a></p>
<p>Abstract: On-device machine learning (ML) moves computation from the cloud to personal devices, protecting user privacy and enabling intelligent user experiences. However, fitting models on devices with limited resources presents a major technical challenge: practitioners need to optimize models and balance hardware metrics such as model size, latency, and power. To help practitioners create efficient ML models, we designed and developed Talaria: a model visualization and optimization system. Talaria enables practitioners to compile models to hardware, interactively visualize model statistics, and simulate optimizations to test the impact on inference metrics. Since its internal deployment two years ago, we have evaluated Talaria using three methodologies: (1) a log analysis highlighting its growth of 800+ practitioners submitting 3,600+ models; (2) a usability survey with 26 users assessing the utility of 20 Talaria features; and (3) a qualitative interview with the 7 most active users about their experience using Talaria.</p>
<h3>Luminate: Structured Generation and Exploration of Design Space with Large Language Models for Human-AI Co-Creation</h3>
<p>Authors: Sangho Suh, Meng Chen, Bryan Min, Toby Li, Haijun Xia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147623">Link</a></p>
<p>Abstract: Thanks to their generative capabilities, large language models (LLMs) have become an invaluable tool for creative processes. These models have the capacity to produce hundreds and thousands of visual and textual outputs, offering abundant inspiration for creative endeavors. But are we harnessing their full potential? We argue that current interaction paradigms fall short, guiding users towards rapid convergence on a limited set of ideas, rather than empowering them to explore the vast latent design space in generative models. To address this limitation, we propose a framework that facilitates the structured generation of design space in which users can seamlessly explore, evaluate, and synthesize a multitude of responses. We demonstrate the feasibility and usefulness of this framework through the design and development of an interactive system, Luminate, and a user study with 14 professional writers. Our work advances how we interact with LLMs for creative tasks, introducing a way to harness the creative potential of LLMs.</p>
<h3>Narrating Fitness: Leveraging Large Language Models for Reflective Fitness Tracker Data Interpretation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Konstantin Strömel, Stanislas Henry, Tim Johansson, Jasmin Niess, Paweł W. Woźniak</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147608">Link</a></p>
<p>Abstract: While fitness trackers generate and present quantitative data, past research suggests that users often conceptualise their wellbeing in qualitative terms. This discrepancy between numeric data and personal wellbeing perception may limit the effectiveness of personal informatics tools in encouraging meaningful engagement with one’s wellbeing. In this work, we aim to bridge the gap between raw numeric metrics and users’ qualitative perceptions of wellbeing. In an online survey with $n=273$ participants, we used step data from fitness trackers and compared three presentation formats: standard charts, qualitative descriptions generated by an LLM (Large Language Model), and a combination of both. Our findings reveal that users experienced more reflection, focused attention and reward when presented with the generated qualitative data compared to the standard charts alone. Our work demonstrates how automatically generated data descriptions can effectively complement numeric fitness data, fostering a richer, more reflective engagement with personal wellbeing information.</p>
<h3>RELIC: Investigating Large Language Model Responses using Self-Consistency</h3>
<p>Authors: Furui Cheng, Vilém Zouhar, Simran Arora, Mrinmaya Sachan, Hendrik Strobelt, Mennatallah El-Assady</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147472">Link</a></p>
<p>Abstract: Large Language Models (LLMs) are notorious for blending fact with fiction and generating non-factual content, known as hallucinations. To address this challenge, we propose an interactive system that helps users gain insight into the reliability of the generated text. Our approach is based on the idea that the self-consistency of multiple samples generated by the same LLM relates to its confidence in individual claims in the generated texts. Using this idea, we design RELIC, an interactive system that enables users to investigate and verify semantic-level variations in multiple long-form responses. This allows users to recognize potentially inaccurate information in the generated text and make necessary corrections. From a user study with ten participants, we demonstrate that our approach helps users better verify the reliability of the generated text. We further summarize the design implications and lessons learned from this research for future studies of reliable human-LLM interactions.</p>
<h2>Learning and Teaching CS and STEAM</h2>
<h3>EXPLORA: A teacher-apprentice methodology for eliciting natural child-computer interactions</h3>
<p>Authors: Vanessa Figueiredo, Catherine Ann Cameron</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148216">Link</a></p>
<h3>Interactive Murals: New Opportunities for Collaborative STEAM Learning</h3>
<p>Authors: Alyshia Bustos, Mia Shaw, Nanibah Chacon, Fiona Bell, Leah Buechley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147930">Link</a></p>
<h3>From Prisons to Programming: Fostering Self-Efficacy via Virtual Web Design Curricula in Prisons and Jails</h3>
<p>Authors: Martin Nisser, Marisa Gaetz, Andrew Fishberg, Raechel Soicher, Faraz Faruqi, Joshua Long</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147558">Link</a></p>
<h3>Mapping Accessibility Assignments into Core Computer Science Topics: An Empirical Study with Interviews and Surveys of Instructors and Students</h3>
<p>Authors: Emily Kuang, Selah Bellscheidt, Di Pham, Kristen Shinohara, Catherine Baker, Yasmine Elglaly</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147853">Link</a></p>
<h3>The Matchmaker Inclusive Design Curriculum: A Faculty-Enabling Curriculum to Teach Inclusive Design Throughout Undergraduate CS</h3>
<p>Authors: Rosalinda Garcia, Patricia Morreale, Gail Verdi, Heather Garcia, Geraldine Jimena Noa, Spencer Madsen, Maria Jesus Alzugaray-Orellana, Elizabeth Li, Margaret Burnett</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147021">Link</a></p>
<h2>Learning and Teaching Technologies A</h2>
<h3>Investigating the Effects of Real-time Student Monitoring Interface on Instructors’ Monitoring Practices in Online Teaching</h3>
<p>Authors: Ha Yeon Lee, Seora Park, Esther Hehsun Kim, Jiyeon Seo, Hajin Lim, Joonhwan Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146670">Link</a></p>
<h3>Bridging the Literacy Gap for Adults: Streaming and Engaging in Adult Literacy Education through Livestreaming</h3>
<p>Authors: Shihan Fu, Jianhao Chen, Emily Kuang, Mingming Fan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148074">Link</a></p>
<h3>ClassMeta: Designing Interactive Virtual Classmate to Promote VR Classroom Participation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ziyi Liu, Zhengzhe Zhu, Lijun Zhu, Enze Jiang, Xiyun Hu, Kylie Peppler, Karthik Ramani</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147941">Link</a></p>
<h3>Simulator-based Mixed Reality eVTOL Pilot Training: The Instructor Operator Station</h3>
<p>Authors: Sharina Kimura, Michael Zintl, Claudius Hammann, Florian Holzapfel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146971">Link</a></p>
<h3>Privacy Concerns of Student Data Shared with Instructors in an Online Learning Management System</h3>
<p>Authors: Monika Kwapisz, Avanya Kohli, Prashanth Rajivan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146719">Link</a></p>
<h2>Learning and Teaching Technologies B</h2>
<h3>“Oh My God! It’s Recreating Our Room!” Understanding Children’s Experiences with A Room-Scale Augmented Reality Authoring Toolkit</h3>
<p>Authors: John Chen, Lexie Zhao, Yinmiao Li, Zhennian Xie, Uri Wilensky, Mike Horn</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147001">Link</a></p>
<h3>ClassInSight: Designing Conversation Support Tools to Visualize Classroom Discussion for Personalized Teacher Professional Development</h3>
<p>Authors: Tricia Ngoon, S Sushil, Angela Stewart, Ung-Sang Lee, Saranya Venkatraman, Neil Thawani, Prasenjit Mitra, Sherice Clarke, John Zimmerman, Amy Ogan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146615">Link</a></p>
<h3>Virtual Reality, Real Pedagogy: A Contextual Inquiry of Instructor Practices with VR Video</h3>
<p>Authors: Qiao Jin, Yu Liu, Ye Yuan, Bo Han, Feng Qian, Svetlana Yarosh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146868">Link</a></p>
<h3>Investigating Demographics and Motivation in Engineering Education Using Radio and Phone-Based Educational Technologies</h3>
<p>Authors: Christine Kwon, Darren Butler, Judith Uchidiuno, John Stamper, Amy Ogan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147291">Link</a></p>
<h3>Xylocode: A Novel Approach to Fostering Interest in Computer Science via an Embodied Music Simulation</h3>
<p>Authors: Duri Long, Jiaxi Yang, Cassandra Naomi, Brian Magerko</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146705">Link</a></p>
<h2>Music</h2>
<h3>A Way for Deaf and Hard of Hearing People to Enjoy Music by Exploring and Customizing Cross-modal Music Concepts</h3>
<p>Authors: Youjin Choi, Junryeol Jeon, ChungHa Lee, Yeo-Gyeong Noh, Jin-Hyuk Hong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147004">Link</a></p>
<h3>Capturing Cancer as Music: Cancer Mechanisms Expressed through Musification</h3>
<p>Authors: Rostyslav Hnatyshyn, Jiayi Hong, Ross Maciejewski, Christopher Norby, Carlo C. Maley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146927">Link</a></p>
<h3>MARingBA: Music-Adaptive Ringtones for Blended Audio Notification Delivery</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Alexander Wang, Yi Fei Cheng, David Lindlbauer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147470">Link</a></p>
<h3>Challenges of Music Score Writing and the Potentials of Interactive Surfaces</h3>
<p>Authors: Vincent Cavez, Catherine Letondal, Emmanuel Pietriga, Caroline Appert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148089">Link</a></p>
<h3>Sound Designer-Generative AI Interactions: Towards Designing Creative Support Tools for Professional Sound Designers</h3>
<p>Authors: Purnima Kamath, Fabio Morreale, Priambudi Lintang Bagaskara, Yize Wei, Suranga Nanayakkara</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148093">Link</a></p>
<h2>Players and Game Experiences</h2>
<h3>Sweating the Details: Emotion Recognition and the Influence of Physical Exertion in Virtual Reality Exergaming</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Dominic Potts, Zoe Broad, Tarini Sehgal, Joseph Hartley, Eamonn O'Neill, Crescent Jicol, Christopher Clarke, Christof Lutteroth</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148111">Link</a></p>
<h3>Exploring the association between engagement with location-based game features and getting inspired about environmental issues and nature</h3>
<p>Authors: Bastian Kordyaka, Samuli Laato, Sebastian Weber, Juho Hamari, Bjoern Niehaves</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147451">Link</a></p>
<h3>``Backseat Gaming" A Study of Co-Regulated Learning within a Collegiate Male Esports Community</h3>
<p>Authors: Erica Kleinman, Reza Habibi, Garrett Powell, Brent Reeves, James Prather, Magy Seif El-Nasr</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147778">Link</a></p>
<h3>Quantifying Wrist-Aiming Habits with A Dual-Sensor Mouse: Implications for Player Performance and Workload</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Donghyeon Kang, Namsub Kim, Daekaun Kang, June-Seop Yoon, Sunjun Kim, Byungjoo Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146862">Link</a></p>
<h3>Traumatizing or Just Annoying? Unveiling the Spectrum of Gamer Toxicity in the StarCraft II Community</h3>
<p>Authors: Samuli Laato, Bastian Kordyaka, Juho Hamari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148033">Link</a></p>
<h2>Understanding Player Experiences</h2>
<h3>Tunnel Runner: a Proof-of-principle for the Feasibility and Benefits of Facilitating Players' Sense of Control in Cognitive Assessment Games</h3>
<p>Authors: Benny Markovitch, Panos Markopoulos, Max Birk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147125">Link</a></p>
<h3>"I Know What You Mean": Context-Aware Recognition to Enhance Speech-Based Games</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Nima Zargham, Mohamed Lamine Fetni, Laura Spillner, Thomas Muender, Rainer Malaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147848">Link</a></p>
<h3>Screenless Interactive Tabletop Gaming with Capacitive Surface Sensing</h3>
<p>Authors: Krzysztof Adamkiewicz, Julia Dominiak, Anna Walczak, Andrzej Romanowski, Paweł W. Woźniak</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147873">Link</a></p>
<h3>Characterizing and Quantifying Expert Input Behavior in League of Legends</h3>
<p>Authors: Hanbyeol Lee, Seyeon Lee, Rohan Nallapati, Youngjung Uh, Byungjoo Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148156">Link</a></p>
<h3>Toxicity in Online Games: The Prevalence and Efficacy of Coping Strategies</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Julian Frommel, Regan Mandryk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147177">Link</a></p>
<h2>Reflecting on Online Content</h2>
<h3>Help Me Reflect: Leveraging Self-Reflection Interface Nudges to Enhance Deliberativeness on Online Deliberation Platforms</h3>
<p>Authors: ShunYi Yeo, Gionnieve Lim, Jie Gao, Weiyu Zhang, Simon Perrault</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147640">Link</a></p>
<h3>Capra: Making Use of Multiple Perspectives for Capturing, Noticing and Revisiting Hiking Experiences Over Time</h3>
<p>Authors: William Odom, Jordan White, Samuel Barnett, Nico Brand, Henry Lin, MinYoung Yoo, Tal Amram</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148073">Link</a></p>
<h3>AI-Driven Mediation Strategies for Audience Depolarisation in Online Debates</h3>
<p>Authors: Jarod Govers, Eduardo Velloso, Vassilis Kostakos, Jorge Goncalves</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147072">Link</a></p>
<h3>Debate Chatbots to Facilitate Critical Thinking on YouTube: Social Identity and Conversational Style Make A Difference</h3>
<p>BEST_PAPER</p>
<p>Authors: Thitaree Tanprasert, Sidney Fels, Luanne Sinnamon, Dongwook Yoon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147628">Link</a></p>
<h3>Viblio: Introducing Credibility Signals and Citations to Video-Sharing Platforms</h3>
<p>Authors: Emelia Hughes, Renee Wang, Prerna Juneja, Tony Li, Tanushree Mitra, Amy Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148085">Link</a></p>
<h2>Security</h2>
<h3>Comparing the Use and Usefulness of Four IoT Security Labels</h3>
<p>Authors: Peter Caven, Zitao Zhang, Jacob Abbott, Xinyao Ma, LJean Camp</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147913">Link</a></p>
<h3>Better Together: The Interplay Between a Phishing Awareness Video and a Link-centric Phishing Support Tool</h3>
<p>Authors: Benjamin Berens, Florian Schaub, Mattia Mossano, Melanie Volkamer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147585">Link</a></p>
<h3>The Effects of Group Discussion and Role-playing Training on Self-efficacy, Support-seeking, and Reporting Phishing Emails: Evidence from a Mixed-design Experiment</h3>
<p>Authors: Xiaowei Chen, Margault Sacré, Gabriele Lenzini, Samuel Greiff, Verena Distler, Anastasia Sergeeva</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146688">Link</a></p>
<h3>Usable News Authentication: How the Presentation and Location of Cryptographic Information Impacts the Usability of Provenance Information and Perceptions of News Articles</h3>
<p>Authors: Errol Francis II, Catherine Barwulor, Ayana Monroe, Kediel Morales, Samya Potlapalli, Kimberly Brown, Julia Jose, Emily Sidnam-Mauch, Susan McGregor, Kelly Caine</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147602">Link</a></p>
<h3>Interdisciplinary Approaches to Cybervulnerability Impact Assessment for Energy Critical Infrastructure</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Andrea Gallardo, Robert Erbes, Katya Le Blanc, Lujo Bauer, Lorrie Cranor</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147155">Link</a></p>
<h2>Sensemaking with AI A</h2>
<h3>Selenite: Scaffolding Online Sensemaking with Comprehensive Overviews Elicited from Large Language Models</h3>
<p>Authors: Michael Xieyang Liu, Tongshuang Wu, Tianying Chen, Franklin Mingzhe Li, Aniket Kittur, Brad Myers</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148071">Link</a></p>
<p>Abstract: Sensemaking in unfamiliar domains can be challenging, demanding considerable user effort to compare different options with respect to various criteria. Prior research and our formative study found that people would benefit from reading an overview of an information space upfront, including the criteria others previously found useful. However, existing sensemaking tools struggle with the "cold-start" problem -- not only requiring significant input from previous users to generate and share these overviews, but also that such overviews may turn out to be biased and incomplete. In this work, we introduce a novel system, Selenite, which leverages Large Language Models (LLMs) as reasoning machines and knowledge retrievers to automatically produce a comprehensive overview of options and criteria to jumpstart users' sensemaking processes. Subsequently, Selenite also adapts as people use it, helping users find, read, and navigate unfamiliar information in a systematic yet personalized manner. Through three studies, we found that Selenite produced accurate and high-quality overviews reliably, significantly accelerated users' information processing, and effectively improved their overall comprehension and sensemaking experience.</p>
<h3>Supporting Sensemaking of Large Language Model Outputs at Scale</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Katy Gero, Chelse Swoopes, Ziwei Gu, Jonathan Kummerfeld, Elena Glassman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146937">Link</a></p>
<p>Abstract: Large language models (LLMs) are capable of generating multiple responses to a single prompt, yet little effort has been expended to help end-users or system designers make use of this capability. In this paper, we explore how to present many LLM responses at once. We design five features, which include both pre-existing and novel methods for computing similarities and differences across textual documents, as well as how to render their outputs. We report on a controlled user study (n=24) and eight case studies evaluating these features and how they support users in different tasks. We find that the features support a wide variety of sensemaking tasks and even make tasks tractable that our participants previously considered to be too difficult to attempt. Finally, we present design guidelines to inform future explorations of new LLM interfaces.</p>
<h3>Explanations, Fairness, and Appropriate Reliance in Human-AI Decision-Making</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jakob Schoeffer, Maria De-Arteaga, Niklas Kühl</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147316">Link</a></p>
<p>Abstract: In this work, we study the effects of feature-based explanations on distributive fairness of AI-assisted decisions, specifically focusing on the task of predicting occupations from short textual bios. We also investigate how any effects are mediated by humans' fairness perceptions and their reliance on AI recommendations. Our findings show that explanations influence fairness perceptions, which, in turn, relate to humans' tendency to adhere to AI recommendations. However, we see that such explanations do not enable humans to discern correct and incorrect AI recommendations. Instead, we show that they may affect reliance irrespective of the correctness of AI recommendations. Depending on which features an explanation highlights, this can foster or hinder distributive fairness: when explanations highlight features that are task-irrelevant and evidently associated with the sensitive attribute, this prompts overrides that counter AI recommendations that align with gender stereotypes. Meanwhile, if explanations appear task-relevant, this induces reliance behavior that reinforces stereotype-aligned errors. These results imply that feature-based explanations are not a reliable mechanism to improve distributive fairness.</p>
<h3>Unraveling the Dilemma of AI Errors: Exploring the Effectiveness of Human and Machine Explanations for Large Language Models</h3>
<p>Authors: Marvin Pafla, Kate Larson, Mark Hancock</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147603">Link</a></p>
<p>Abstract: The field of eXplainable artificial intelligence (XAI) has produced a plethora of methods (e.g., saliency-maps) to gain insight into artificial intelligence (AI) models, and has exploded with the rise of deep learning (DL). However, human-participant studies question the efficacy of these methods, particularly when the AI output is wrong. In this study, we collected and analyzed 156 human-generated text and saliency-based explanations collected in a question-answering task (N=40) and compared them empirically to state-of-the-art XAI explanations (integrated gradients, conservative LRP, and ChatGPT) in a human-participant study (N=136). Our findings show that participants found human saliency maps to be more helpful in explaining AI answers than machine saliency maps, but performance negatively correlated with trust in the AI model and explanations. This finding hints at the dilemma of AI errors in explanation, where helpful explanations can lead to lower task performance when they support wrong AI predictions. </p>
<h3>"Are You Really Sure?'' Understanding the Effects of Human Self-Confidence Calibration in AI-Assisted Decision Making</h3>
<p>Authors: Shuai Ma, Xinru Wang, Ying Lei, Chuhan Shi, Ming Yin, Xiaojuan Ma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147034">Link</a></p>
<p>Abstract: In AI-assisted decision-making, it is crucial but challenging for humans to achieve appropriate reliance on AI. This paper approaches this problem from a human-centered perspective, "human self-confidence calibration". We begin by proposing an analytical framework to highlight the importance of calibrated human self-confidence. In our first study, we explore the relationship between human self-confidence appropriateness and reliance appropriateness. Then in our second study, We propose three calibration mechanisms and compare their effects on humans' self-confidence and user experience. Subsequently, our third study investigates the effects of self-confidence calibration on AI-assisted decision-making. Results show that calibrating human self-confidence enhances human-AI team performance and encourages more rational reliance on AI (in some aspects) compared to uncalibrated baselines. Finally, we discuss our main findings and provide implications for designing future AI-assisted decision-making interfaces.</p>
<h2>Sensemaking with AI B</h2>
<h3>Towards a Diffractive Analysis of Prompt-Based Generative AI</h3>
<p>Authors: Nina Rajcic, Maria Teresa Llano Rodriguez, Jon McCormack</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148226">Link</a></p>
<p>Abstract: Recent developments in prompt-based generative AI has given rise to discourse surrounding the perceived ethical concerns, economic implications, and consequences for the future of cultural production. As generative imagery becomes pervasive in mainstream society, dominated primarily by emerging industry leaders, we encourage that the role of the CHI community be one of inquiry; to investigate the numerous ways in which generative AI has the potential to, and already is, augmenting human creativity. In this paper, we conducted a diffractive analysis exploring the potential role of prompt-based interfaces in artists' creative practice. Over a two week period, seven visual artists were given access to a personalised instance of Stable Diffusion, fine-tuned on a dataset of their work. In the following diffractive analysis, we identified two dominant modes adopted by participants, AI for ideation, and AI for production. We furthermore present a number of ethical design considerations for the future development of generative AI interfaces.</p>
<h3>Where Are We So Far? Understanding Data Storytelling Tools from the Perspective of Human-AI Collaboration</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Haotian Li, Yun Wang, Huamin Qu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146630">Link</a></p>
<p>Abstract: Data storytelling is powerful for communicating data insights, but it requires diverse skills and considerable effort from human creators. Recent research has widely explored the potential for artificial intelligence (AI) to support and augment humans in data storytelling. However, there lacks a systematic review to understand data storytelling tools from the perspective of human-AI collaboration, which hinders researchers from reflecting on the existing collaborative tool designs that promote humans' and AI's advantages and mitigate their shortcomings. This paper investigated existing tools with a framework from two perspectives: the stages in the storytelling workflow where a tool serves, including analysis, planning, implementation, and communication, and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers. Through our analysis, we recognize the common collaboration patterns in existing tools, summarize lessons learned from these patterns, and further illustrate research opportunities for human-AI collaboration in data storytelling.</p>
<h3>Dissecting users' needs for search result explanations</h3>
<p>Authors: Prerna Juneja, Wenjuan Zhang, Alison Smith-Renner, Hemank Lamba, Joel Tetreault, Alex Jaimes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148160">Link</a></p>
<p>Abstract: There is a growing demand for transparency in search engines to understand how search results are curated and to enhance users' trust. Prior research has introduced search result explanations with a focus on "how" to explain, assuming explanations are beneficial. Our study takes a step back to examine "if" search explanations are needed and "when" they are likely to provide benefits. Additionally, we summarize key characteristics of helpful explanations and share users' perspectives on explanation features provided by Google and Bing. Interviews with non-technical individuals reveal that users do not always seek or understand search explanations and mostly desire them for complex and critical tasks. They find Google's search explanations too obvious but appreciate the ability to contest search results. Based on our findings, we offer design recommendations for search engines and explanations to help users better evaluate search results and enhance their search experience.</p>
<h3>Natural Language Dataset Generation Framework for Visualizations Powered by Large Language Models</h3>
<p>Authors: Kwon Ko, Hyeon Jeon, Gwanmo Park, Dae Hyun Kim, Nam Wook Kim, Juho Kim, Jinwook Seo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147000">Link</a></p>
<p>Abstract: We introduce VL2NL, a Large Language Model (LLM) framework that generates rich and diverse NL datasets using Vega-Lite specifications as input, thereby streamlining the development of Natural Language Interfaces (NLIs) for data visualization. To synthesize relevant chart semantics accurately and enhance syntactic diversity in each NL dataset, we leverage 1) a guided discovery incorporated into prompting so that LLMs can steer themselves to create faithful NL datasets in a self-directed manner; 2) a score-based paraphrasing to augment NL syntax along with four language axes. We also present a new collection of 1,981 real-world Vega-Lite specifications that have increased diversity and complexity than existing chart collections. When tested on our chart collection, VL2NL extracted chart semantics and generated L1/L2 captions with 89.4% and 76.0% accuracy, respectively. It also demonstrated generating and paraphrasing utterances and questions with greater diversity compared to the benchmarks. Last, we discuss how our NL datasets and framework can be utilized in real-world scenarios. The codes and chart collection are available at https://github.com/hyungkwonko/chart-llm.</p>
<h3>Marco: Supporting Business Document Workflows via Collection-Centric Information Foraging with Large Language Models</h3>
<p>Authors: Raymond Fok, Nedim Lipka, Tong Sun, Alexa Siu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147634">Link</a></p>
<p>Abstract: Knowledge workers often need to extract and analyze information from a collection of documents to solve complex information tasks in the workplace, e.g., hiring managers reviewing resumes or analysts assessing risk in contracts. However, foraging for relevant information can become tedious and repetitive over many documents and criteria of interest. We introduce Marco, a mixed-initiative workspace supporting sensemaking over diverse business document collections. Through collection-centric assistance, Marco reduces the cognitive costs of extracting and structuring information, allowing users to prioritize comparative synthesis and decision making processes. Users interactively communicate their information needs to an AI assistant using natural language and compose schemas that provide an overview of a document collection. Findings from a usability study (n=16) demonstrate that when using Marco, users complete sensemaking tasks 16% more quickly, with less effort, and without diminishing accuracy. A design probe with seven domain experts identifies how Marco can benefit various real-world workflows.</p>
<h2>Smart Homes and Environments</h2>
<h3>Decide Yourself or Delegate - User Preferences Regarding the Autonomy of Personal Privacy Assistants in Private IoT-Equipped Environments</h3>
<p>Authors: Karola Marky, Alina Stöver, Sarah Prange, Kira Bleck, Paul Gerber, Verena Zimmermann, Florian Müller, Florian Alt, Max Mühlhäuser</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146932">Link</a></p>
<h3>“You can’t write down the logic”: Bringing smart technology into the water infrastructure control room</h3>
<p>Authors: Jacquelyn Schmidt, Ariel Roy, Branko Kerkez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147334">Link</a></p>
<h3>Tagnoo: Enabling Smart Room-Scale Environments with RFID-Augmented Plywood</h3>
<p>Authors: Yuning Su, Tingyu Zhang, Jiuen Feng, Yonghao Shi, Xing-Dong Yang, Te-Yen Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148075">Link</a></p>
<h3>Who Should Hold Control? Rethinking Empowerment in Home Automation among Cohabitants through the Lens of Co-Design</h3>
<p>Authors: Xiao XUE, Xinyang Li, Boyang Jia, Jiachen Du, Xinyi Fu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147601">Link</a></p>
<h3>Understanding Users' Interaction with Login Notifications</h3>
<p>Authors: Philipp Markert, Leona Lassak, Maximilian Golla, Markus Dürmuth</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147051">Link</a></p>
<h2>Smart Textiles and Changing Displays</h2>
<h3>MagneSwift: Low-Cost, Interactive Shape Display Leveraging Magnetic Materials</h3>
<p>Authors: Kentaro Yasu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146985">Link</a></p>
<h3>Shape-Changing Clay-Dough: Taking a Material-Oriented Approach to 3D Printing Ceramic Forms</h3>
<p>Authors: Fiona Bell, Erin McClure, Camila Friedman-Gerlicz, Ruby Ta, Leah Buechley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146926">Link</a></p>
<h3>Waxpaper Actuator: Sequentially and Conditionally Programmable Wax Paper for Morphing Interfaces</h3>
<p>Authors: Di Wu, Emily Guan, Yunjia Zhang, Hsuanju Lai, Qiuyu Lu, Lining Yao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148150">Link</a></p>
<h3>Loopsense: low-scale, unobtrusive, and minimally invasive knitted force sensors for multi-modal input, enabled by selective loop-meshing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Roland Aigner, Mira Haberfellner, Michael Haller</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147384">Link</a></p>
<h3>Cymatics Cup: Shape-Changing Drinks by Leveraging Cymatics</h3>
<p>Authors: Weijen Chen, Yang Yang, Kao-Hua Liu, Yun Suen Pai, Junichi Yamaoka, Kouta Minamizawa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147592">Link</a></p>
<h2>Social and Political Activism</h2>
<h3>Keyboard Fighters: The Use of ICTs by Activists in Times of Military Coup in Myanmar</h3>
<p>Authors: Laura Guntrum</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147122">Link</a></p>
<h3>Designing for Harm Reduction: Communication Repair for Multicultural Users' Voice Interactions</h3>
<p>BEST_PAPER</p>
<p>Authors: Kimi Wenzel, Geoff Kaufman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147425">Link</a></p>
<h3>Persuasion or Insulting? Unpacking Discursive Strategies of Gender Debate in Everyday Feminism in China</h3>
<p>Authors: Yue DENG, Zheng Chen, Changyang He, Zhicong Lu, Bo Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147170">Link</a></p>
<h3>Starting a New Life after Crossing the Tumen River: How North Korean Defectors Use Digital Technology in Transition</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Hayoun Noh, Soohyun Yoon, Hyunah Jo, Max Van Kleek, Younah Kang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147753">Link</a></p>
<h2>Sound, Rhythm, Movement</h2>
<h3>FabSound: Audio-Tactile and Affective Fabric Experiences Through Mid-air Haptics</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jing Xue, Roberto Montano Murillo, Christopher Dawes, William Frier, Patricia Cornelio, Marianna Obrist</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147299">Link</a></p>
<h3>Exploring Collaborative Movement Improvisation Towards the Design of LuminAI—a Co-Creative AI Dance Partner</h3>
<p>Authors: Milka Trajkova, Duri Long, Manoj Deshpande, Andrea Knowlton, Brian Magerko</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147151">Link</a></p>
<h3>Understanding Feedback in Rhythmic Gymnastics Training: An Ethnographic-Informed Study of a Competition Class</h3>
<p>BEST_PAPER</p>
<p>Authors: Leonor Portugal da Fonseca, Francisco Nunes, Paula Alexandra Silva</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148223">Link</a></p>
<h3>Designing and Evaluating an Advanced Dance Video Comprehension Tool with In-situ Move Identification Capabilities</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Saad Hassan, Caluã de Lacerda Pataca, Laleh Nourian, Garreth Tigwell, Briana Davis, Will Silver Wagman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147258">Link</a></p>
<h3>DoodleTunes: Interactive Visual Analysis of Music-Inspired Children Doodles with Automated Feature Annotation</h3>
<p>Authors: Shuqi Liu, Jia Bu, Huayuan Ye, Juntong Chen, Shiqi Jiang, Mingtian Tao, Liping Guo, Changbo Wang, Chenhui Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147267">Link</a></p>
<h2>Supporting Accessibility of Text, Image and Video A</h2>
<h3>“It’s Kind of Context Dependent”: Understanding Blind and Low Vision People’s Video Accessibility Preferences Across Viewing Scenarios</h3>
<p>Authors: Lucy Jiang, Crescentia Jung, Mahika Phutane, Abigale Stangl, Shiri Azenkot</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146788">Link</a></p>
<h3>GazePrompt: Enhancing Low Vision People's Reading Experience with Gaze-Aware Augmentations</h3>
<p>Authors: Ru Wang, Zach Potter, Yun Ho, Daniel Killough, Linxiu Zeng, Sanbrita Mondal, Yuhang Zhao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147371">Link</a></p>
<h3>Constrained Highlighting in a Document Reader can Improve Reading Comprehension</h3>
<p>BEST_PAPER</p>
<p>Authors: Nikhita Joshi, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147932">Link</a></p>
<h3>Making Short-Form Videos Accessible with Hierarchical Video Summaries</h3>
<p>Authors: Tess Van Daele, Akhil Iyer, Yuning Zhang, Jalyn Derry, Mina Huh, Amy Pavel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148297">Link</a></p>
<h2>Supporting Accessibility of Text, Image and Video B</h2>
<h3>Caption Royale: Exploring the Design Space of Affective Captions from the Perspective of Deaf and Hard-of-Hearing Individuals</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Caluã de Lacerda Pataca, Saad Hassan, Nathan Tinker, Roshan Peiris, Matt Huenerfauth</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148008">Link</a></p>
<h3>SPICA: Interactive Video Content Exploration through Augmented Audio Descriptions for Blind or Low-Vision Viewers</h3>
<p>Authors: Zheng Ning, Brianna Wimer, Kaiwen Jiang, Keyi Chen, Jerrick Ban, Yapeng Tian, Yuhang Zhao, Toby Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147481">Link</a></p>
<h3>An AI-Resilient Text Rendering Technique for Reading and Skimming Documents</h3>
<p>Authors: Ziwei Gu, Ian Arawjo, Kenneth Li, Jonathan Kummerfeld, Elena Glassman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147987">Link</a></p>
<h3>Investigating Use Cases of AI-Powered Scene Description Applications for Blind and Low Vision People</h3>
<p>Authors: Ricardo Gonzalez Penuela, Jazmin Collins, Cynthia Bennett, Shiri Azenkot</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147196">Link</a></p>
<h3>From Provenance to Aberrations: Image Creator and Screen Reader User Perspectives on Alt Text for AI-Generated Images</h3>
<p>Authors: Maitraye Das, Alexander Fiannaca, Meredith Morris, Shaun Kane, Cynthia Bennett</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148306">Link</a></p>
<h2>Supporting Communication Needs A</h2>
<h3>Lights, Camera, Access: A Closeup on Audiovisual Media Accessibility and Aphasia</h3>
<p>Authors: Alexandre Nevsky, Timothy Neate, Elena Simperl, Madeline Cruice</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147404">Link</a></p>
<p>Abstract: The presence of audiovisual media is a mainstay in the lives of many, increasingly so with technological progress. Accessing video and audio content, however, can be challenging for people with diverse needs. Existing research has explored a wide range of accessibility challenges and worked with disabled communities to design technologies that help bridge the access gap. Despite this work, our understanding of the challenges faced by communities with complex communication needs (CCNs) remains poor. To address this shortcoming, we present the first study that investigates the viewing experience of people with the communication impairment aphasia through an online survey (N=41) and two focus group sessions (N=10), with the aim of understanding their specific access challenges. We find that aphasia significantly impact viewing experience and present a taxonomy of access barriers and facilitators, with suggestions for future research.</p>
<h3>Co-Designing QuickPic: Automated Topic-Specific Communication Boards from Photographs for AAC-Based Language Instruction</h3>
<p>Authors: Mauricio Fontana de Vargas, Christina Yu, Howard C. Shane, Karyn Moffatt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147269">Link</a></p>
<p>Abstract:  Traditional topic-specific communication boards for Augmentative and Alternative Communication (AAC)  require  manual programming of relevant symbolic vocabulary, which is time-consuming and often impractical even for experienced Speech-Language Pathologists (SLPs). While recent research has demonstrated the potential to automatically generate these boards from photographs using artificial intelligence, there has been no exploration on how to design such tools to support the specific needs of AAC-based language instruction. This paper introduces QuickPic, a mobile AAC application co-designed with SLPs and special educators, aimed at enhancing language learning for non-speaking individuals, such as autistic children. Through a 17-month design process, we uncover the unique design features required to provide timely language support in therapy and special education contexts. We present emerging evidence on the overall satisfaction of SLPs using QuickPic, and on the advantages of large language model-based generation compared to the existing technique for automated vocabulary from photographs for AAC.</p>
<h3>Empowering Independence Through Design: Investigating Standard Digital Design Patterns For Easy-to-Read Users.</h3>
<p>Authors: Sabina Sieghart, Björn Rohles, Ann Bessemans</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148221">Link</a></p>
<p>Abstract: As designers and researchers, it is our duty to ensure information accessibility for all, irrespective of cognitive abilities. Currently, Easy-to-Read (ETR) is commonly used to simplify text for individuals with cognitive impairments. Although design aspects of text
comprehensibility have recently gained attention, digital design patterns remain relatively unexplored. Our understanding of how ETR users interact with digital media, and how to design specifically for their needs, is still limited. Our study involved observing 20 German
ETR users engaging with a digital PDF and a website designed in a participatory process. We collected data on their access to digital media, personal use and workarounds, and their interaction with digital design patterns. Tasks on the smartphone were completed mostly successfully, while only 50% could navigate a digital PDF. In both cases, visual cues played a significant role. Our findings contribute recommendations for beneficial digital design patterns and future research.</p>
<h3>ChatDirector: Enhancing Video Conferencing with Space-Aware Scene Rendering and Speech-Driven Layout Transition</h3>
<p>Authors: Xun Qian, Feitong Tan, Yinda Zhang, Brian Collins, David Kim, Alex Olwal, Karthik Ramani, Ruofei Du</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148295">Link</a></p>
<p>Abstract: Remote video conferencing systems (RVCS) are widely adopted in personal and professional communication. However, they often lack the co-presence experience of in-person meetings. This is largely due to the absence of intuitive visual cues and clear spatial relationships among remote participants, which can lead to speech interruptions and loss of attention. This paper presents ChatDirector, a novel RVCS that overcomes these limitations by incorporating space-aware visual presence and speech-aware attention transition assistance. ChatDirector employs a real-time pipeline that converts participants' RGB video streams into 3D portrait avatars and renders them in a virtual 3D scene. We also contribute a decision tree algorithm that directs the avatar layouts and behaviors based on participants' speech states. We report on results from a user study (N=16) where we evaluated ChatDirector. The satisfactory algorithm performance and complimentary subject user feedback imply that ChatDirector significantly enhances communication efficacy and user engagement.</p>
<h3>COR Themes for Readability from Iterative Feedback</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Tianyuan Cai, Aleena Niklaus, Bernard Kerr, Michael Kraley, Zoya Bylinskii</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148158">Link</a></p>
<p>Abstract: Digital reading applications give readers the ability to customize fonts, sizes, and spacings, all of which have been shown to improve the reading experience for readers from different demographics. However, tweaking these text features can be challenging, especially given their interactions on the final look and feel of the text. Our solution is to offer readers preset combinations of font, character, word and line spacing, which we bundle together into reading themes. We identify a recommended set of reading themes through data-driven design iterations with the crowd and experts. We show that after four design iterations, we converge on a set of three COR themes (Compact, Open, and Relaxed) that meet diverse readers' preferences, when evaluating the reading speeds, comprehension scores, and preferences of hundreds of readers with and without dyslexia, using crowdsourced experiments.</p>
<h2>Supporting Communication Needs B</h2>
<h3>COMPA: Using Conversation Context to Achieve Common Ground in AAC</h3>
<p>Authors: Stephanie Valencia, Jessica Huynh, Emma Jiang, Yufei Wu, Teresa Wan, Zixuan Zheng, Henny Admoni, Jeffrey Bigham, Amy Pavel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146686">Link</a></p>
<p>Abstract: Group conversations often shift quickly from topic to topic, leaving a small window of time for participants to contribute. AAC users often miss this window due to the speed asymmetry between using speech and using AAC devices. AAC users may take over a minute longer to contribute, and this speed difference can cause mismatches between the ongoing conversation and the AAC user's response. This results in misunderstandings and missed opportunities to participate. We present COMPA, an add-on tool for online group conversations that seeks to support conversation partners in achieving common ground. COMPA uses a conversation's live transcription to enable AAC users to mark conversation segments they intend to address (Context Marking) and generate contextual starter phrases related to the marked conversation segment (Phrase Assistance) and a selected user intent. We study COMPA in 5 different triadic group conversations, each composed by a researcher, an AAC user and a conversation partner (n=10) and share findings on how conversational context supports conversation partners in achieving common ground.</p>
<h3>Finding My Voice over Zoom: An Autoethnography of Videoconferencing Experience for a Person Who Stutters</h3>
<p>Authors: Shaomei Wu, Jingjin Li, Gilly Leshed</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146953">Link</a></p>
<p>Abstract: Existing videoconferencing (VC) technologies are often optimized for productivity and efficiency, with little support for the "soft side" of VC meetings such as empathy, authenticity, belonging, and emotional connections. This paper presents findings from a 15-month long autoethnographic study of VC experiences by the first author, a person who stutters (PWS). Our research shed light on the hidden costs of VC for PWS, uncovering the substantial emotional and cognitive efforts that other meeting attendants are often unaware of. Recognizing the disproportionate burden on PWS to be heard in VC, we propose a set of design implications for a more inclusive communication environment, advocating for shared responsibility among all, including communication technologies, to ensure the inclusion and respect of every voice.</p>
<h3>Breaking Badge: Augmenting Communication with Wearable AAC Smartbadges and Displays</h3>
<p>Authors: Humphrey Curtis, Duncan Lau, Timothy Neate</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147567">Link</a></p>
<p>Abstract: People living with complex communication needs employ multimodal pathways to communicate including: limited speech, paralinguistics, non-verbal communication and leveraging low-tech devices. However, most augmentative and alternative communication (AAC) interventions undermine end-users' agency by obstructing these intuitive communication pathways. In this paper, we collaborate with 19 people living with the language impairment aphasia exploring contextual communication challenges, before low-fidelity prototyping and wireframing wearable AAC displays. These activities culminated in two low-input wearable AAC prototypes that instead, scaffold users' pre-existing communication abilities. Firstly, the InkTalker is a low-power and affordable eInk AAC smartbadge designed to discreetly reveal invisible disabilities and usable as a communication prop. Secondly, WalkieTalkie is a scalable AAC app that converts smartphones into a feature-rich public display operable via multimodal input/outputs. We offer results from communication interactions with both devices, discussions and feedback responses. Participants used both AAC devices to interdependently socialise with others and augment pre-existing communication abilities.</p>
<h3>"It Is Easy Using My Apps:" Understanding Technology Use and Needs of Adults with Down Syndrome</h3>
<p>Authors: Hailey Johnson, Audra Sterling, Bilge Mutlu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147214">Link</a></p>
<p>Abstract: Assistive technologies for adults with Down syndrome (DS) need designs tailored to their specific technology requirements. While prior research has explored technology design for individuals with intellectual disabilities, little is understood about the needs and expectations of adults with DS. Assistive technologies should leverage the abilities and interests of the population, while incorporating age- and context-considerate content. In this work, we interviewed six adults with DS, seven parents of adults with DS, and three experts in speech-language pathology, special education, and occupational therapy to determine how technology could support adults with DS. In our thematic analysis, four main themes emerged, including (1) community vs. home social involvement; (2) misalignment of skill expectations between adults with DS and parents; (3) family limitations in technology support; and (4) considerations for technology development. Our findings extend prior literature by including the voices of adults with DS in how and when they use technology.</p>
<h3>Voice Assistive Technology for Activities of Daily Living: Developing an Alexa Telehealth Training for Adults with Cognitive-Communication Disorders</h3>
<p>Authors: Yao Du, Claire O'Connor, Ginna Byun, Lauren Kim, Siona Amrgousian, Priyal Vora</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147679">Link</a></p>
<p>Abstract: Individuals with cognitive-communication disorders (CCDs) due to neurological conditions, such as traumatic brain injury and aphasia, experience difficulties in communication and cognition that impact their ability to perform activities of daily living, or ADLs (e.g., self-care, meal preparation, scheduling). Voice assistive technology (VAT) can support the independent performance of ADLs; however, there are limited VAT training programs that teach individuals with CCDs how to properly implement and use VAT for ADLs. The present study examined the implementation of an online training program using Alexa voice commands for five ADL domains (scheduling, entertainment, self-care, news &amp; facts, and meal preparation). Using video analysis with seven adults with CCDs between ages 25 and 82 and interviews with five participants and three caregivers, we synthesized five weeks of training performance, analyzed participants' perceived benefits and challenges, and discussed challenges and opportunities for implementing VAT training for ADLs skills for adults with CCDs. </p>
<h2>Supporting Programmers and Learners A</h2>
<h3>Understanding the Needs of Novice Developers in Creating Self-Powered IoT</h3>
<p>Authors: Chengshuo Xia, Tian Min, Daxing Zhang, Congsi Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147080">Link</a></p>
<h3>AQuA: Automated Question-Answering in Software Tutorial Videos with Visual Anchors</h3>
<p>Authors: Saelyne Yang, Jo Vermeulen, George Fitzmaurice, Justin Matejka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148273">Link</a></p>
<h3>Meta-Manager: A Tool for Collecting and Exploring Meta Information about Code</h3>
<p>Authors: Amber Horvath, Andrew Macvean, Brad Myers</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147791">Link</a></p>
<h3>SQL Puzzles: Evaluating Micro Parsons Problems With Different Feedbacks as Practice for Novices</h3>
<p>Authors: Zihan Wu, Barbara Ericson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148131">Link</a></p>
<h3>Taking ASCII Drawings Seriously: How Programmers Diagram Code</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Devamardeep Hayatpur, Brian Hempel, Kathy Chen, William Duan, Philip Guo, Haijun Xia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147729">Link</a></p>
<h2>Supporting Programmers and Learners B</h2>
<h3>"Do You Want Me to Participate or Not?": Investigating the Accessibility of Software Development Meetings for Blind and Low Vision Professionals</h3>
<p>Authors: Yoonha Cha, Isabela Figueira, Jessy Ayala, Emory Edwards, Joshua Garcia, André van der Hoek, Stacy Branham</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147835">Link</a></p>
<h3>MµSE: Supporting Exploration of Software-Hardware Interactions Through Examples</h3>
<p>Authors: Paul Methfessel, Tom Beckmann, Patrick Rein, Stefan Ramson, Robert Hirschfeld</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148162">Link</a></p>
<h3>Is Stack Overflow Obsolete? An Empirical Study of the Characteristics of ChatGPT Answers to Stack Overflow Questions</h3>
<p>Authors: Samia Kabir, David N. Udo-Imeh, Bonan Kou, Tianyi Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146667">Link</a></p>
<h3>CoPrompt: Supporting Prompt Sharing and Referring in Collaborative Natural Language Programming</h3>
<p>Authors: Li Feng, Ryan Yen, Yuzhe You, Mingming Fan, Jian Zhao, Zhicong Lu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147317">Link</a></p>
<h3>Understanding Documentation Use Through Log Analysis: A Case Study of Four Cloud Services</h3>
<p>Authors: Daye Nam, Andrew Macvean, Brad Myers, Bogdan Vasilescu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147074">Link</a></p>
<h2>Trust in Social Media</h2>
<h3>Uncovering Human Traits in Determining Real and Spoofed Audio: Insights from Blind and Sighted Individuals</h3>
<p>Authors: Chaeeun Han, Prasenjit Mitra, Syed Masum Billah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146813">Link</a></p>
<h3>Understanding Underground Incentivized Review Services</h3>
<p>Authors: Rajvardhan Oak, Zubair Shafiq</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147503">Link</a></p>
<h3>Trust, Privacy, and Safety Factors Associated with Decision Making in P2P Markets Based on Social Networks: A Case Study of Facebook Marketplace in USA and Canada</h3>
<p>Authors: Azadeh Mokhberi, Yue Huang, Guillaume Humbert, Masoud Mehrabi Koushki, Borke Obada-Obieh, Konstantin (Kosta) Beznosov</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148310">Link</a></p>
<h3>Profiling the Dynamics of Trust &amp; Distrust in Social Media: A Survey Study</h3>
<p>Authors: Yixuan Zhang, Yimeng Wang, Nutchanon Yongsatianchot, Joseph Gaggiano, Nurul Suhaimi, Anne Okrah, Jacqueline Griffin, Miso Kim, Andrea Parker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148331">Link</a></p>
<h3>A Browser Extension for in-place Signaling and Assessment of Misinformation</h3>
<p>Authors: Farnaz Jahanbakhsh, David Karger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148142">Link</a></p>
<h2>Wellbeing in Aging</h2>
<h3>An Iterative Participatory Design Approach to Develop Collaborative Augmented Reality Activities for Older Adults in Long-Term Care Facilities</h3>
<p>Authors: Akshith Ullal, Mahrukh Tauseef, Alexandra Watkins, Lisa Juckett, Cathy Maxwell, JUDITH TATE, Lorraine Mion, Nilanjan Sarkar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147541">Link</a></p>
<h3>Understanding Socio-technical Opportunities for Enhancing Communication Between Older Adults and their Remote Family</h3>
<p>Authors: Baihui Chen, Xueliang Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146735">Link</a></p>
<h3>Designing for Inclusive Experiences: Investigating Opportunities for Supporting Older Adults in Community-based Social Programs</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yushan Xing, Ryan Kelly, Melissa Rogerson, Jenny Waycott, Kashifa Aslam</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147962">Link</a></p>
<h3>Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults</h3>
<p>Authors: Yucheng Jin, Wanling Cai, Li Chen, Yizhe Zhang, Gavin Doherty, Tonglin Jiang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147408">Link</a></p>
<h3>Dancing with the Roles: Towards Designing Technology that Supports the Multifaceted Roles of Caregivers for Older Adults</h3>
<p>Authors: Long-Jing Hsu, Chia-Fang Chung</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147745">Link</a></p>
<h2>Working Practices and Tools B</h2>
<h3>The Impact of Social Norms on Hybrid Workers’ Well-Being: A Cross-Cultural Comparison of Japan and the United States</h3>
<p>Authors: Wataru Akahori, Naomi Yamashita, Jack Jamieson, Momoko Nakatani, Ryo Hashimoto, Masahiro Watanabe</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146875">Link</a></p>
<h3>Mental Models of Meeting Goals: Supporting Intentionality in Meeting Technologies</h3>
<p>Authors: Ava Scott, Lev Tankelevitch, Sean Rintel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146999">Link</a></p>
<h3>Circle Back Next Week: The Effect of Meeting-Free Weeks on Distributed Workers’ Unstructured Time and Attention Negotiation</h3>
<p>Authors: Sharon Ferguson, Michael Massimi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147336">Link</a></p>
<h3>Exploring the Diminishing Allure of Paper and Low-Fidelity Prototyping Among Designers in the Software Industry: Impacts of Hybrid Work, Digital Tools, and Corporate Culture</h3>
<p>Authors: Jonathan Chen, Dongwook Yoon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146922">Link</a></p>
<h3>Reinforcing and Reclaiming The Home: Co-speculating Future Technologies to Support Remote and Hybrid Work</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Janghee Cho, Dasom Choi, Junnan Yu, Stephen Voida</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146980">Link</a></p>
<h2>Working Practices and Tools C</h2>
<h3>Practice-informed Patterns for Organising Large Groups in Distributed Mixed Reality Collaboration</h3>
<p>Authors: Emily Wong, Juan Sánchez Esquivel, Germán Leiva, Jens Emil Grønbæk, Eduardo Velloso</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147880">Link</a></p>
<h3>Whispering Through Walls: Towards Inclusive Backchannel Communication in Hybrid Meetings</h3>
<p>Authors: Qianqian Mu, Marcel Borowski, Jens Emil Grønbæk, Susanne Bødker, Eve Hoggan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148087">Link</a></p>
<h3>DISCERN: Designing Decision Support Interfaces to Investigate the Complexities of Workplace Social Decision-Making With Line Managers</h3>
<p>Authors: Pranav Khadpe, Lindy Le, Kate Nowak, Shamsi Iqbal, Jina Suh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147698">Link</a></p>
<h3>The Effects of Update Interval and Reveal Method on Writer Comfort in Synchronized Shared-Editors</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yen-Ting Yeh, Nikhita Joshi, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148285">Link</a></p>
<h3>Exploring the Effectiveness of Time-lapse Screen Recording for Self-Reflection in Work Context</h3>
<p>Authors: Donghan Hu, Sang Won Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148168">Link</a></p>
<h2>Working with Data A</h2>
<h3>Generative Echo Chamber? Effect of LLM-Powered Search Systems on Diverse Information Seeking</h3>
<p>BEST_PAPER</p>
<p>Authors: Nikhil Sharma, Q. Vera Liao, Ziang Xiao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147446">Link</a></p>
<h3>SwapVid: Integrating Video Viewing and Document Exploration with Direct Manipulation</h3>
<p>Authors: Taichi Murakami, Kazuyuki Fujita, Kotaro Hara, Kazuki Takashima, Yoshifumi Kitamura</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147489">Link</a></p>
<h3>rTisane: Externalizing conceptual models for data analysis increases engagement with domain knowledge and improves statistical model quality</h3>
<p>BEST_PAPER</p>
<p>Authors: Eunice Jun, Edward Misback, Jeffrey Heer, Rene Just</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147809">Link</a></p>
<h3>Odds and Insights: Decision Quality in Exploratory Data Analysis Under Uncertainty</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Abhraneel Sarma, Xiaoying Pu, Yuan Cui, Eli Brown, Michael Correll, Matthew Kay</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146941">Link</a></p>
<h3>Using Open Data to Automatically Generate Localized Analogies</h3>
<p>Authors: Sofia Eleni Spatharioti, Daniel Goldstein, Jake Hofman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147137">Link</a></p>
<h2>Immersive Experiences: Design and Evaluation</h2>
<h3>Milliways: Taming Multiverses through Principled Evaluation of Data Analysis Paths</h3>
<p>Authors: Abhraneel Sarma, Kyle Hwang, Jessica Hullman, Matthew Kay</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146939">Link</a></p>
<p>Abstract: Multiverse analyses involve conducting all combinations of reasonable choices in a data analysis process. A reader of a study containing a multiverse analysis might question—are all the choices included in the multiverse reasonable and equally justifiable? How much do results vary if we make different choices in the analysis process? In this work, we identify principles for validating the composition of, and interpreting the uncertainty in, the results of a multiverse analysis. We present Milliways, a novel interactive visualisation system to support principled evaluation of multiverse analyses. Milliways provides interlinked panels presenting result distributions, individual analysis composition, multiverse code specification, and data summaries. Milliways supports interactions to sort, filter and aggregate results based on the analysis specification to identify decisions in the analysis process to which the results are sensitive. To represent the two qualitatively different types of uncertainty that arise in multiverse analyses—probabilistic uncertainty from estimating unknown quantities of interest such as regression coefficients, and possibilistic uncertainty from choices in the data analysis—Milliways uses consonance curves and probability boxes. Through an evaluative study with five users familiar with multiverse analysis, we demonstrate how Milliways can support multiverse analysis tasks, including a principled assessment of the results of a multiverse analysis.</p>
<h3>Development and Validation of the Collision Anxiety Questionnaire for VR Applications</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Patrizia Ring, Julius Tietenberg, Katharina Emmerich, Maic Masuch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147339">Link</a></p>
<p>Abstract: The high degree of sensory immersion is a distinctive feature of head-mounted virtual reality (VR) systems. While the visual detachment from the real world enables unique immersive experiences, users risk collisions due to their inability to perceive physical obstacles in their environment. Even the mere anticipation of a collision can adversely affect the overall experience and erode user confidence in the VR system. However, there are currently no valid tools for assessing collision anxiety. We present the iterative development and validation of the Collision Anxiety Questionnaire (CAQ), involving an exploratory and a confirmatory factor analysis with a total of 159 participants. The results provide evidence for both discriminant and convergent validity and a good model fit for the final CAQ with three subscales: general collision anxiety, orientation, and interpersonal collision anxiety. By utilizing the CAQ, researchers can examine potential confounding effects of collision anxiety and evaluate methods for its mitigation.</p>
<h3>Assessing User Apprehensions About Mixed Reality Artifacts and Applications: The Mixed Reality Concerns (MRC) Questionnaire</h3>
<p>Authors: Christopher Katins, Paweł W. Woźniak, Aodi Chen, Ihsan Tumay, Luu Viet Trinh Le, John Uschold, Thomas Kosch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146992">Link</a></p>
<p>Abstract: Current research in Mixed Reality (MR) presents a wide range of novel use cases for blending virtual elements with the real world. This yet-to-be-ubiquitous technology challenges how users currently work and interact with digital content. While offering many potential advantages, MR technologies introduce new security, safety, and privacy challenges. Thus, it is relevant to understand users' apprehensions towards MR technologies, ranging from security concerns to social acceptance. To address this challenge, we present the Mixed Reality Concerns (MRC) Questionnaire, designed to assess users' concerns towards MR artifacts and applications systematically. The development followed a structured process considering previous work, expert interviews, iterative refinements, and confirmatory tests to analytically validate the questionnaire. The MRC Questionnaire offers a new method of assessing users' critical opinions to compare and assess novel MR artifacts and applications regarding security, privacy, social implications, and trust.</p>
<h3>Virtual Unreality: Augmentation-Oriented Ideation Through Design Cards</h3>
<p>Authors: Robin Neuhaus, Ronda Ringfort-Felner, Daniel Courtney, Madlen Kneile, Marc Hassenzahl</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148278">Link</a></p>
<p>Abstract: While realism is a common design goal for virtual reality (VR), VR also offers opportunities that are impossible in the real world (e.g., telekinesis). So far, there is no design support to exploit the potential of such “impossible” augmentations, especially for serious applications. We developed a card set and a workshop format, which features 15 opportunities to facilitate the ideation of augmentation-oriented VR. We piloted the method in five workshops with people in the early stages of developing a VR application (N=35). Participants found the cards easy to use and to inspire viable new concepts that differed from earlier ideas. Analysis of the concepts with interaction criticism identified two strategies: (1) augmentations that are only loosely related to the purpose of the application, simply to increase “fun”, and (2) augmentations that are closely related to the core purpose and thereby subtly facilitate its fulfillment. The latter has the greater potential.</p>
<h3>Evaluating Navigation and Comparison Performance of Computational Notebooks on Desktop and in Virtual Reality</h3>
<p>Authors: Sungwon In, Eric Krokos, Kirsten Whitley, Chris North, Yalong Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146704">Link</a></p>
<p>Abstract: The computational notebook serves as a versatile tool for data analysis. However, its conventional user interface falls short of keeping pace with the ever-growing data-related tasks, signaling the need for novel approaches. With the rapid development of interaction techniques and computing environments, there is a growing interest in integrating emerging technologies in data-driven workflows. Virtual reality, in particular, has demonstrated its potential in interactive data visualizations. In this work, we aimed to experiment with adapting computational notebooks into VR and verify the potential benefits VR can bring. We focus on the navigation and comparison aspects as they are primitive components in analysts' workflow. To further improve comparison, we have designed and implemented a Branching&amp;Merging functionality. We tested computational notebooks on the desktop and in VR, both with and without the added Branching&amp;Merging capability. We found VR significantly facilitated navigation compared to desktop, and the ability to create branches enhanced comparison.</p>
<h2>Understanding Immersive Experiences</h2>
<h3>Fast-Forward Reality: Authoring Error-Free Context-Aware Policies with Real-Time Unit Tests in Extended Reality</h3>
<p>Authors: Xun Qian, Tianyi Wang, Xuhai "Orson" Xu, Tanya Jonker, Kashyap Todi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147548">Link</a></p>
<p>Abstract: Advances in ubiquitous computing have enabled end-user authoring of context-aware policies (CAPs) that control smart devices based on specific contexts of the user and environment. However, authoring CAPs accurately and avoiding run-time errors is challenging for end-users as it is difficult to foresee CAP behaviors under complex real-world conditions. We propose Fast-Forward Reality, an Extended Reality (XR) based authoring workflow that enables end-users to iteratively author and refine CAPs by validating their behaviors via simulated unit test cases. We develop a computational approach to automatically generate test cases based on the authored CAP and the user's context history. Our system delivers each test case with immersive visualizations in XR, facilitating users to verify the CAP behavior and identify necessary refinements. We evaluated Fast-Forward Reality in a user study (N=12). Our authoring and validation process improved the accuracy of CAPs and the users provided positive feedback on the system usability.</p>
<h3>Towards Building Condition-Based Cross-Modality Intention-Aware Human-AI Cooperation under VR Environment</h3>
<p>Authors: Ziyao He, Shiyuan Li, Yunpeng Song, Zhongmin Cai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147782">Link</a></p>
<p>Abstract: To address critical challenges in effectively identifying user intent and forming relevant information presentations and recommendations in VR environments, we propose an innovative condition-based multi-modal human-AI cooperation framework. It highlights the intent tuples (intent, condition, intent prompt, action prompt) and 2-Large-Language-Models (2-LLMs) architecture. This design, utilizes ``condition'' as the core to describe tasks, dynamically match user interactions with intentions, and empower generations of various tailored multi-modal AI responses. The architecture of 2-LLMs separates the roles of intent detection and action generation, decreasing the prompt length and helping with generating appropriate responses. We implemented a VR-based intelligent furniture purchasing system based on the proposed framework and conducted a three-phase comparative user study. The results conclusively demonstrate the system's superiority in time efficiency and accuracy, intention conveyance improvements, effective product acquisitions, and user satisfaction and cooperation preference. Our framework provides a promising approach towards personalized and efficient user experiences in VR.</p>
<h3>Predicting the Noticeability of Dynamic Virtual Elements in Virtual Reality</h3>
<p>Authors: Zhipeng Li, Yi Fei Cheng, Yukang Yan, David Lindlbauer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148043">Link</a></p>
<p>Abstract: While Virtual Reality (VR) systems can present virtual elements such as notifications anywhere, designing them so they are not missed by or distracting to users is highly challenging for content creators. To address this challenge, we introduce a novel approach to predict the noticeability of virtual elements. It computes the visual saliency distribution of what users see, and analyzes the temporal changes of the distribution with respect to the dynamic virtual elements that are animated. The computed features serve as input for a long short-term memory (LSTM) model that predicts whether a virtual element will be noticed. Our approach is based on data collected from 24 users in different VR environments performing tasks such as watching a video or typing. We evaluate our approach (n = 12), and show that it can predict the timing of when users notice a change to a virtual element within 2.56 sec compared to a ground truth, and demonstrate the versatility of our approach with a set of applications. We believe that our predictive approach opens the path for computational design tools that assist VR content creators in creating interfaces that automatically adapt virtual elements based on noticeability.</p>
<h3>Just Undo It: Exploring Undo Mechanics in Multi-User Virtual Reality</h3>
<p>Authors: Julian Rasch, Florian Perzl, Yannick Weiss, Florian Müller</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147280">Link</a></p>
<p>Abstract: With the proliferation of VR and a metaverse on the horizon, many multi-user activities are migrating to the VR world, calling for effective collaboration support. As one key feature, traditional collaborative systems provide users with undo mechanics to reverse errors and other unwanted changes. While undo has been extensively researched in this domain and is now considered industry standard, it is strikingly absent for VR systems in research and industry.
This work addresses this research gap by exploring different undo techniques for basic object manipulation in different collaboration modes in VR. We conducted a study involving 32 participants organized in teams of two. Here, we studied users' performance and preferences in a tower stacking task, varying the available undo techniques and their mode of collaboration. The results suggest that users desire and use undo in VR and that the choice of the undo technique impacts users' performance and social connection.</p>
<h2>Immersive Experiences: UIs and Personalisation</h2>
<h3>UI Mobility Control in XR: Switching UI Positionings between Static, Dynamic, and Self Entities</h3>
<p>Authors: Siyou Pei, David Kim, Alex Olwal, Yang Zhang, Ruofei Du</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147970">Link</a></p>
<p>Abstract: Extended reality (XR) has the potential for seamless user interface (UI) transitions across people, objects, and environments. However, the design space, applications, and common practices of 3D UI transitions remain underexplored. To address this gap, we conducted a need-finding study with 11 participants, identifying and distilling a taxonomy based on three types of UI placements --- affixed to static, dynamic, or self entities. We further surveyed 113 commercial applications to understand the common practices of 3D UI mobility control, where only 6.2% of these applications allowed users to transition UI between entities. In response, we built interaction prototypes to facilitate UI transitions between entities. We report on results from a qualitative user study (N=14) on 3D UI mobility control using our FingerSwitches technique, which suggests that perceived usefulness is affected by types of entities and environments. We aspire to tackle a vital need in UI mobility within XR.</p>
<h3>ProInterAR: A Visual Programming Platform for Creating Immersive AR Interactions</h3>
<p>Authors: Hui Ye, Jiaye Leng, Pengfei Xu, Karan Singh, Hongbo Fu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148242">Link</a></p>
<p>Abstract: AR applications commonly contain diverse interactions among different AR contents. Creating such applications requires creators to have advanced programming skills for scripting interactive behaviors of AR contents, repeated transferring and adjustment of virtual contents from virtual to physical scenes, testing by traversing between desktop interfaces and target AR scenes, and digitalizing AR contents. Existing immersive tools for prototyping/authoring such interactions are tailored for domain-specific applications. To support programming general interactive behaviors of real object(s)/environment(s) and virtual object(s)/environment(s) for novice AR creators, we propose ProInterAR, an integrated visual programming platform to create immersive AR applications with a tablet and an AR-HMD. Users can construct interaction scenes by creating virtual contents and augmenting real contents from the view of an AR-HMD, script interactive behaviors by stacking blocks from a tablet UI, and then execute and control the interactions in the AR scene. We showcase a wide range of AR application scenarios enabled by ProInterAR, including AR game, AR teaching, sequential animation, AR information visualization, etc. Two usability studies validate that novice AR creators can easily program various desired AR applications using ProInterAR.</p>
<h3>MineXR: Mining Personalized Extended Reality Interfaces</h3>
<p>Authors: Hyunsung Cho, Yukang Yan, Kashyap Todi, Mark Parent, Missie Smith, Tanya Jonker, Hrvoje Benko, David Lindlbauer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147924">Link</a></p>
<p>Abstract: Extended Reality (XR) interfaces offer engaging user experiences, but their effective design requires a nuanced understanding of user behavior and preferences. This knowledge is challenging to obtain without the widespread adoption of XR devices. We introduce MineXR, a design mining workflow and data analysis platform for collecting and analyzing personalized XR user interaction and experience data. MineXR enables elicitation of personalized interfaces from participants of a data collection: for any particular context, participants create interface elements using application screenshots from their own smartphone, place them in the environment, and simultaneously preview the resulting XR layout on a headset. Using MineXR, we contribute a dataset of personalized XR interfaces collected from 31 participants, consisting of 695 XR widgets created from 178 unique applications. We provide insights for XR widget functionalities, categories, clusters, UI element types, and placement. Our open-source tools and data support researchers and designers in developing future XR interfaces.</p>
<h3>VirtuWander: Enhancing Multi-modal Interaction for Virtual Tour Guidance through Large Language Models</h3>
<p>Authors: Zhan Wang, Linping Yuan, Liangwei Wang, Bingchuan Jiang, Wei Zeng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148243">Link</a></p>
<p>Abstract: Tour guidance in virtual museums encourages multi-modal interactions to boost user experiences, concerning engagement, immersion, and spatial awareness. Nevertheless, achieving the goal is challenging due to the complexity of comprehending diverse user needs and accommodating personalized user preferences. Informed by a formative study that characterizes guidance-seeking contexts, we establish a multi-modal interaction design framework for virtual tour guidance. We then design VirtuWander, a two-stage innovative system using domain-oriented large language models to transform user inquiries into diverse guidance-seeking contexts and facilitate multi-modal interactions. The feasibility and versatility of VirtuWander are demonstrated with virtual guiding examples that encompass various touring scenarios and cater to personalized preferences. We further evaluate VirtuWander through a user study within an immersive simulated museum. The results suggest that our system enhances engaging virtual tour experiences through personalized communication and knowledgeable assistance, indicating its potential for expanding into real-world scenarios.</p>
<h2>Immersive Experiences: Creating and Communicating</h2>
<h3>Elastica: Adaptive Live Augmented Presentations with Elastic Mappings Across Modalities</h3>
<p>Authors: Yining Cao, Rubaiat Habib Kazi, Li-Yi Wei, Deepali Aneja, Haijun Xia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147635">Link</a></p>
<p>Abstract: Augmented presentations offer compelling storytelling by combining speech content, gestural performance, and animated graphics in a congruent manner. The expressiveness of these presentations stems from the harmonious coordination of spoken words and graphic elements, complemented by smooth animations aligned with the presenter's gestures. However, achieving such desired congruence in a live presentation poses significant challenges due to the unpredictability and imprecision inherent in presenters' real-time actions. Existing methods either leveraged rigid mapping without predefined states or required the presenters to conform to predefined animations. We introduce adaptive presentations that dynamically adjust predefined graphic animations to real-time speech and gestures. Our approach leverages script following and motion warping to establish elastic mappings that generate runtime graphic parameters coordinating speech, gesture, and predefined animation state. Our evaluation demonstrated that the proposed adaptive presentation can effectively mitigate undesired visual artifacts caused by performance deviations and enhance the expressiveness of resulting presentations.</p>
<h3>Unlocking Understanding: An Investigation of Multimodal Communication in Virtual Reality Collaboration</h3>
<p>Authors: Ryan Ghamandi, Ravi Kiran Kattoju, Yahya Hmaiti, Mykola Maslych, Eugene Taranta, Ryan P. McMahan, Joseph LaViola</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146938">Link</a></p>
<p>Abstract: Communication in collaboration, especially synchronous, remote communication, is crucial to the success of task-specific goals. Insufficient or excessive forms of communication may lead to detrimental effects on task performance while increasing mental fatigue. However, identifying which combinations of communication modalities provide the most efficient transfer of information in collaborative settings will greatly improve collaboration. To investigate this, we developed a remote, synchronous, asymmetric VR collaborative assembly task application, where users play the role of either mentor or mentee, and were exposed to different combinations of three communication modalities: voice, gestures, and gaze. Through task-based experiments with 25 pairs of participants (50 individuals), we evaluated quantitative and qualitative data and found that gaze did not differ significantly from multiple combinations of communication modalities. Our qualitative results indicate that mentees experienced more difficulty and frustration in completing tasks than mentors, with both types of users preferring all three modalities to be present.</p>
<h3>Meaning Follows Purpose: Unravelling the Architectural Design Conventions in the Contemporary Metaverse</h3>
<p>Authors: Jihae Han, Andrew Vande Moere, Adalberto Simeone</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147826">Link</a></p>
<p>Abstract: Thousands of people regularly meet, work and play in the architectural spaces that the metaverse offers today. Yet despite the creative potential to disrupt how the built environment is represented, there exists a prevalent belief that the architectural design of the metaverse is rather conventional and reliant on simulating physical reality. We investigated this claim by conducting a design critique study of the most apparent architectural design conventions within the current most popular metaverse platforms, as determined by a scoping review and Google Trends analysis. Based on the opinions of 21 architectural experts on the design of interiors, buildings, and plazas within these platforms, we elicited three overarching design conventions that capture the representation, engagement, and purpose of metaverse architecture. By discussing the impact of these conventions on architectural quality, we inform the future design of metaverse spaces to more purposefully, and perhaps less frequently, use realism to convey meaning. </p>
<h3>LLMR: Real-time Prompting of Interactive Worlds using Large Language Models</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Fernanda De La Torre, Cathy Mengying Fang, Han Huang, Andrzej Banburski-Fahey, Judith Amores, Jaron Lanier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146847">Link</a></p>
<p>Abstract: We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR's cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.</p>
<h3>Using the Visual Language of Comics to Alter Sensations in Augmented Reality</h3>
<p>Authors: Arpit Bhatia, Henning Pohl, Teresa Hirzle, Hasti Seifi, Kasper Hornbæk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147047">Link</a></p>
<p>Abstract: Augmented Reality (AR) excels at altering what we see but non-visual sensations are difficult to augment. To augment non-visual sensations in AR, we draw on the visual language of comic books. Synthesizing comic studies, we create a design space describing how to use comic elements (e.g., onomatopoeia) to depict non-visual sensations (e.g., hearing). To demonstrate this design space, we built eight demos, such as speed lines to make a user think they are faster and smell lines to make a scent seem stronger. We evaluate these elements in a qualitative user study (N=20) where participants performed everyday tasks with comic elements added as augmentations. All participants stated feeling a change in perception for at least one sensation, with perceived changes detected by between four participants (touch) and 15 participants (hearing). The elements also had positive effects on emotion and user experience, even when participants did not feel changes in perception.</p>
<h2>Highlight on Health</h2>
<h3>Shared Responsibility in Collaborative Tracking for Children with Type 1 Diabetes and their Parents</h3>
<p>Authors: Yoon Jeong Cha, Yasemin Gunal, Alice Wou, Joyce Lee, Mark Newman, Sun Young Park</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147031">Link</a></p>
<h3>Learning About Social Context From Smartphone Data: Generalization Across Countries and Daily Life Moments</h3>
<p>Authors: Aurel Ruben Mäder, Lakmal Meegahapola, Daniel Gatica-Perez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148104">Link</a></p>
<h3>Somaesthetic Meditation Wearable: Exploring the Effect of Targeted Warmth Technology on Meditators' Experiences</h3>
<p>Authors: Talia Ezer, Jonathan Giron, Hadas Erel, Oren Zuckerman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148124">Link</a></p>
<h3>Using and Appropriating Technology to Support The Menopause Journey in the UK</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Emily Lopez Burst, Marianela Ciolfi Felice, Aisling Ann O'Kane</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147124">Link</a></p>
<h3>"It's Sink or Swim": Exploring Patients' Challenges and Tool Needs for Self-Management of Postoperative Acute Pain</h3>
<p>Authors: Souleima Zghab, M. Gabrielle Pagé, Mélanie Lussier, Sylvain Bédard, Jinghui Cheng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146987">Link</a></p>
<h3>Individual Differences and Technology Affordances Combine to Predict Mobile Social Media Distraction Behaviors and Consequences</h3>
<p>Authors: Emily Sidnam-Mauch, Peter Monge</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147042">Link</a></p>
<h3>"Speech is Silver, Silence is Golden " Analyzing Micro-communication Strategies between Visually Impaired Runners and their Guides</h3>
<p>Authors: Giulia Barbareschi, Tarika Kumar, Christopher Kim, George Chernyshov, Kai Kunze</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147500">Link</a></p>
<h3>"If This Person is Suicidal, What Do I Do?": Designing Computational Approaches to Help Online Volunteers Respond to Suicidality</h3>
<p>Authors: Logan Stapleton, Sunniva Liu, Cindy Liu, Irene Hong, Stevie Chancellor, Robert Kraut, Haiyi Zhu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147747">Link</a></p>
<h3>Mindfulness-based Embodied Tangible Interactions for Stroke Rehabilitation at Home</h3>
<p>BEST_PAPER</p>
<p>Authors: Preetham Nagaraj, Wen Mo, Catherine Holloway</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146728">Link</a></p>
<h3>Quantifying the Pollan Effect: Investigating the Impact of Emerging Psychiatric Interventions on Online Mental Health Discourse</h3>
<p>Authors: Sachin Pendse, Neha Kumar, Munmun De Choudhury</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146755">Link</a></p>
<h3>Holding AI to Account: Challenges for the Delivery of Trustworthy AI in Healthcare</h3>
<p>Authors: Rob Procter, Peter Tolmie, Mark Rouncefield</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150872">Link</a></p>
<h3>“If Someone Walks In On Us Talking, Pretend to be My Friend, Not My Therapist": Challenges and Opportunities for Digital Mental Health Support in Saudi Arabia</h3>
<p>Authors: Sarah Aldaweesh, Deemah Alateeq, Max Van Kleek, Nigel Shadbolt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147711">Link</a></p>
<h2>Highlight on Interaction and Cultures</h2>
<h3>Commoning as a Strategy for HCI Research and Design in South Asia</h3>
<p>Authors: Aarjav Chauhan, Robert Soden</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147596">Link</a></p>
<h3>Better Little People Pictures: Generative Creation of Demographically Diverse Anthropographics</h3>
<p>Authors: Priya Dhawka, Lauren Perera, Wesley Willett</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147622">Link</a></p>
<h3>Design With Rural-To-Urban Migrant Women: Opportunities and Challenges in Designing within a Precarious Marriage Context in South China</h3>
<p>Authors: Yuchao Zhao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147663">Link</a></p>
<h3>Justice-oriented Design Listening: Participatory Ecoacoustics with a Ghanaian Forest Community</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Joycelyn Longdon, Michelle Westerlaken, Alan Blackwell, Jennifer Gabrys, Benjamin Ossom, Adham Ashton-Butt, Emmanuel Acheampong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147917">Link</a></p>
<h3>Politics of the Past: Understanding the Role of Memory, Postmemory, and Remembrance in Navigating the History of Migrant Families</h3>
<p>Authors: Nabila Chowdhury, Natasha Shokri, Cibeles Valera, Azhagu Meena SP, Carolina Reyes Marquez, Mohammad Rashidujjaman Rifat, Marisol Wong-Villacres, Cosmin Munteanu, Negin Dahya, Syed Ishtiaque Ahmed</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146983">Link</a></p>
<h3>Migrant Farmworkers' Experiences of Agricultural Technologies: Implications for Worker Sociality and Desired Change</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Olivia Doggett, Matt Ratto, Priyank Chandra</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147193">Link</a></p>
<h3>Play Across Boundaries: Exploring Cross-Cultural Maldaimonic Game Experiences</h3>
<p>Authors: Katie Seaborn, Satoru Iseya, Shun Hidaka, Sota Kobuki, Shruti Chandra</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147448">Link</a></p>
<h3>Air/time Travel: Rethinking Appropriation in Global HCI and Futures of Electronic Exchange</h3>
<p>Authors: Daniel Mwesigwa, Christopher Csikszentmihalyi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148174">Link</a></p>
<h3>Low-Resourced Languages and Online Knowledge Repositories: A Need-Finding Study.</h3>
<p>Authors: Hellina Hailu Nigatu, John Canny, Sarah Chasins</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147539">Link</a></p>
<h2>Highlight on Fabrication</h2>
<h3>Towards More Sustainable Interactive Textiles: A Literature Review on The Use of Biomaterials for eTextiles.</h3>
<p>Authors: Sofía Guridi, Matteo Iannacchero, Emmi Pouta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147272">Link</a></p>
<h3>ExCell: High Expansion Ratio Moisture-Responsive Wooden Actuators for DIY Shape-Changing and Deployable Structures</h3>
<p>Authors: Tucker Rae-Grant, Shuhong Wang, Lining Yao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147588">Link</a></p>
<h3>Flextiles: Designing Customisable Shape-Change in Textiles with SMA-Actuated Smocking Patterns</h3>
<p>Authors: Alice Haynes, Jürgen Steimle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147340">Link</a></p>
<h3>Evaluating ActuAir: Building Occupants' Experiences of a Shape-Changing Air Quality Display</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Eleni Margariti, Vasilis Vlachokyriakos, Abigail Durrant, David Kirk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146904">Link</a></p>
<h2>Highlight on Immersive Interactions</h2>
<h3>ARCADIA: A Gamified Mixed Reality System for Emotional Regulation and Self-Compassion</h3>
<p>Authors: José Luis Soler-Domínguez, Samuel Navas-Medrano, Patricia Pons</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147990">Link</a></p>
<p>Abstract: Mental health and wellbeing have become one of the significant challenges in global society, for which emotional regulation strategies hold the potential to offer a transversal approach to addressing them. However, the persistently declining adherence of patients to therapeutic interventions, coupled with the limited applicability of current technological interventions across diverse individuals and diagnoses, underscores the need for innovative solutions. We present ARCADIA, a Mixed-Reality platform strategically co-designed with therapists to enhance emotional regulation and self-compassion. ARCADIA comprises several gamified therapeutic activities, with a strong emphasis on fostering patient motivation. Through a dual study involving therapists and mental health patients, we validate the fully functional prototype of ARCADIA. Encouraging results are observed in terms of system usability, user engagement, and therapeutic potential. These findings lead us to believe that the combination of Mixed Reality and gamified therapeutic activities could be a significant tool in the future of mental health.</p>
<h3>Implementation of Virtual Reality Motivated Physical Activity via Omnidirectional Treadmill in a Supported Living Facility for Older Adults: A Mixed-Methods Evaluation.</h3>
<p>Authors: Hannah Bradwell, Leonie Cooper, Rory Baxter, Simone Tomaz, Katie Jane Edwards, Anna Whittaker, Ray Jones</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148214">Link</a></p>
<p>Abstract: Virtual reality (VR) can support healthy ageing, but few devices have been trialed with frail older adults to increase physical activity. We conducted a preliminary mixed-methods implementation evaluation of an omnidirectional VR treadmill and a static VR experience with seven older adults over a six-week period in a supported living facility. Frequency of use and pre-post physical functioning measures were collected, mainly to establish technology suitability based on person characteristics. Diary entries following technology use, resident focus group and staff interview revealed technology acceptance and perceived potential for increasing physical activity, health and wellbeing through accessing virtual environments, which motivated continued activity. Results demonstrated technology suitability for a range of older adults with various mobility and physical impairments. However, residents noted interest in a seated treadmill for physical activity without perceived risks of falls with standing treadmills. Staff raised considerations around care home implementations including usability, cost and space.</p>
<h3>MobileGravity: Mobile Simulation of a High Range of Weight in Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Alexander Kalus, Johannes Klein, Tien-Julian Ho, Lee-Ann Seegets, Niels Henze</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147373">Link</a></p>
<p>Abstract: Simulating accurate weight forces in Virtual Reality (VR) is an unsolved challenge. Therefore, providing real weight sensations by transferring liquid mass has emerged as a promising approach. However, key objectives conceptually interfere with each other. In particular, previous designs that support a high range of weight or high flow rate lack mobility. In this work, we present MobileGravity, a system, that decouples the weight-changing object from the liquid supply and the pump. It enables weight changes of up to 1 kg at a rate of 235 g/s and allows the user to walk around freely. Through a study with 30 participants, we show that the system enables users to perceive the weight of different virtual objects and enhances realism, as well as enjoyment.</p>
<h3>Behind the Scenes: Adapting Cinematography and Editing Concepts to Navigation in Virtual Reality</h3>
<p>Authors: Alan Medlar, Mari Lehtikari, Dorota Glowacka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147397">Link</a></p>
<p>Abstract: Teleportation is a popular method of navigation in virtual reality (VR) because it does not induce symptoms of VR sickness, such as nausea and disorientation. However, teleportation may reduce spatial awareness, causing users to miss important aspects of their surroundings. We present ACTIVE, a novel approach to teleportation that uses techniques from cinematography to enhance the user experience of navigation in VR. ACTIVE adapts heuristics from continuity editing to dynamically reposition and reorient the camera after teleportation. This approach aims to improve the aesthetic quality of entities and environmental features while respecting users' intended trajectory through the virtual environment. In a user study, we found that even though ACTIVE did not improve users' recall of which entities were present in the environment, it increased engagement by significantly improving aesthetic appeal. Lastly, despite removing some agency from users, ACTIVE had no impact on presence or VR sickness compared to teleportation.</p>
<h3>The Impact of Avatar Completeness on Embodiment and the Detectability of Hand Redirection in Virtual Reality</h3>
<p>Authors: Martin Feick, André Zenner, Simon Seibert, Anthony Tang, Antonio Krüger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147279">Link</a></p>
<p>Abstract: To enhance interactions in VR, many techniques introduce offsets between the virtual and real-world position of users’ hands. Nevertheless, such hand redirection (HR) techniques are only effective as long as they go unnoticed by users—not disrupting the VR experience. While several studies consider how much unnoticeable redirection can be applied, these focus on mid-air floating hands that are disconnected from users’ bodies. Increasingly, VR avatars are embodied as being directly connected with the user’s body, which provide more visual cue anchoring, and may therefore reduce the unnoticeable redirection threshold. In this work, we studied more complete avatars and their effect on the sense of embodiment and the detectability of HR. We found that higher avatar completeness increases embodiment, and we provide evidence for the absence of practically relevant effects on the detectability of HR.</p>
<h3>A Survey On Measuring Presence in Mixed Reality</h3>
<p>Authors: Tanh Tran, Tobias Langlotz, Holger Regenbrecht</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148206">Link</a></p>
<p>Abstract: Presence is a defining element of virtual reality (VR), but it is also increasingly used when assessing mixed reality (MR) experiences. The increased interest in measuring presence in MR and recent works underpinning the specific nature of presence in MR raise the question of the current state and practice of assessing presence in MR. To address this question, we present an analysis of more than 320 studies that report on presence measurements in MR. Our analysis showed that questionnaires are the dominant measurement but also identify problematic trends that stem from the lack of a generally agreed-upon concept or measurement for presence in MR. More specifically, we show that using measurements that are not validated in MR or custom questionnaires limiting the comparability of results is commonplace and could contribute to a looming replication crisis in an increasingly relevant field.</p>
<h3>On the Benefits of Image-Schematic Metaphors when Designing Mixed Reality Systems</h3>
<p>Authors: Jingyi Li, Per Ola Kristensson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146697">Link</a></p>
<p>Abstract: A Mixed Reality (MR) system encompasses various aspects, such as visualization and spatial registration of user interface elements, user interactions and interaction feedback. Image-schematic metaphors (ISMs) are universal knowledge structures shared by a wide range of users. They hold a theoretical promise of facilitating greater ease of learning and use for interactive systems without costly adaptations. This paper investigates whether image-schematic metaphors (ISMs) can improve user learning, by comparing an existing MR instruction authoring system with or without ISM enhancements. In a user study with 32 participants, we found that the ISM-enhanced system significantly improved task performance, learnability and mental efficiency compared to the baseline. Participants also rated the ISM-enhanced system significantly higher in terms of perspicuity, efficiency, and novelty. These results empirically demonstrate multiple benefits of ISMs when integrated into the design of this MR system and encourage further studies to explore the wider applicability of ISMs in user interface design.</p>
<h2>Highlight on AI</h2>
<h3>Mind The Gap: Designers and Standards on Algorithmic System Transparency for Users</h3>
<p>Authors: bianca schor, Chris Norval, Ellen Charlesworth, Jat Singh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147422">Link</a></p>
<p>Abstract: Many call for algorithmic systems to be more transparent, yet it is often unclear for designers how to do so in practice. Standards are emerging that aim to support designers in building transparent systems, e.g by setting testable transparency levels, but their efficacy in this regard is not yet understood. In this paper, we use the <code>Standard for Transparency of Autonomous Systems' (IEEE 7001) to explore designers' understanding of algorithmic system transparency, and the degree to which their perspectives align with the standard's recommendations. Our mixed-method study reveals participants consider transparency important, difficult to implement, and welcome support. However, despite IEEE 7001's potential, many did not find its recommendations particularly appropriate. Given the importance and increased attention on transparency, and because standards like this purport to guide system design, our findings reveal the need for</code>bridging the gap,' through (i) raising designers’ awareness about the importance of algorithmic system transparency, alongside (ii) better engagement between stakeholders (i.e. standards bodies, designers, users). We further identify opportunities towards developing transparency best practices, as means to help drive more responsible systems going forward.</p>
<h3>I lose vs. I earn: Consumer perceived price fairness toward algorithmic (vs. human) price discrimination</h3>
<p>Authors: Xiaoping Zhang, Xusen Cheng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147741">Link</a></p>
<p>Abstract: Many companies are turning to algorithms to determine prices. However, little research has been done to investigate consumers’ perceived price fairness when price discrimination is implemented by either a human or an algorithm. The results of two experiments with 2 (price-setting agent: algorithm vs. human) × 2 (price discrimination: advantaged vs. disadvantaged) between-subjects design reveal that consumers perceive disadvantaged price discrimination as being more unfair when it is implemented by a human (vs. algorithm). Conversely, they perceive advantaged price discrimination as being more unfair when it is implemented by an algorithm (vs. human). This difference is caused by distinct attribution processes. Consumers are more likely to externalize disadvantaged price discrimination implemented by a human than an algorithm (i.e., attributing it to the unintentionality of price-setting agents), while they are more likely to internalize advantaged price discrimination implemented by a human than an algorithm (i.e., attributing it to perceived personal luck). Based on these findings, we discuss how designers and managers can design and utilize algorithms to implement price discrimination that reduces consumer perception of price unfairness. We believe that reasonable disclosure of algorithmic clues to consumers can maximize the benefits of price discrimination strategies.</p>
<h3>Towards a Non-Ideal Methodological Framework for Responsible ML</h3>
<p>Authors: Ramaravind Kommiya Mothilal, Shion Guha, Syed Ishtiaque Ahmed</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148062">Link</a></p>
<p>Abstract: Though ML practitioners increasingly employ various Responsible ML (RML) strategies, their methodological approach in practice is still unclear. In particular, the constraints, assumptions, and choices of practitioners with technical duties--such as developers, engineers, and data scientists---are often implicit, subtle, and under-scrutinized in HCI and related fields. We interviewed 22 technically oriented ML practitioners across seven domains to understand the characteristics of their methodological approaches to RML through the lens of ideal and non-ideal theorizing of fairness. We find that practitioners’ methodological approaches fall along a spectrum of idealization. While they structured their approaches through ideal theorizing, such as by abstracting RML workflow from the inquiry of applicability of ML, they did not systematically document nor pay deliberate attention to their non-ideal approaches, such as diagnosing imperfect conditions. We end our paper with a discussion of a new methodological approach, inspired by elements of non-ideal theory, to structure technical practitioners’ RML process and facilitate collaboration with other stakeholders.</p>
<h3>(Beyond) Reasonable Doubt: Challenges that Public Defenders Face in Scrutinizing AI in Court</h3>
<p>Authors: Angela Jin, Niloufar Salehi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146685">Link</a></p>
<p>Abstract: Accountable use of AI systems in high-stakes settings relies on making systems contestable. In this paper we study efforts to contest AI systems in practice by studying how public defenders scrutinize AI in court. We present findings from interviews with 17 people in the U.S. public defense community to understand their perceptions of and experiences scrutinizing computational forensic software (CFS) --- automated decision systems that the government uses to convict and incarcerate, such as facial recognition, gunshot detection, and probabilistic genotyping tools. We find that our participants faced challenges assessing and contesting CFS reliability due to difficulties (a) navigating how CFS is developed and used, (b) overcoming judges and jurors’ non-critical perceptions of CFS, and (c) gathering CFS expertise. To conclude, we provide recommendations that center the technical, social, and institutional context to better position interventions such as performance evaluations to support contestability in practice. </p>
<h3>“The bus is nothing without us”: Making Visible the Labor of Bus Operators amid the Ongoing Push Towards Transit Automation</h3>
<p>Authors: Hunter Akridge, Bonnie Fan, Alice Xiaodi Tang, Chinar Mehta, Nikolas Martelaro, Sarah Fox</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147433">Link</a></p>
<p>Abstract:  This paper describes how the complexity of circumstances bus operators manage presents unique challenges to the feasibility of high-level automation in public transit. Avoiding an overly rationalized view of bus operators' labor is critical to ensure the introduction of automation technologies does not compromise public wellbeing, the dignity of transit workers, or the integrity of critical public infrastructure. Our findings from a group interview study show that bus operators take on work — undervalued by those advancing automation technologies — to ensure the well-being of passengers and community members. Notably, bus operators are positioned to function as shock absorbers during social crises in their communities and in moments of technological breakdown as new systems come on board. These roles present a critical argument against the rapid push toward driverless automation in public transit. We conclude by identifying opportunities for participatory design and collaborative human-machine teaming for a more just future of transit.</p>
<h3>Care-Based Eco-Feedback Augmented with Generative AI: Fostering Pro-Environmental Behavior through Emotional Attachment</h3>
<p>Authors: Manon Berney, Abdessalam Ouaazki, Vladimir Macko, Bruno Kocher, Adrian Holzer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147985">Link</a></p>
<p>Abstract: Lights out! With the escalating climate crisis, eco-feedback has gained prominence over the last decade. However, traditional approaches could be underperforming as they often use data-driven strategies and assume that people only need additional information about their consumption to change behavior. A proposed path to overcome this issue is to design eco-feedback to foster emotional connections with users. However, not much is known about the effectiveness of such designs. In this paper, we propose a novel care-based eco-feedback system. Central to the system is a Tamagotchi-inspired digital character named INFI who gets its life force from the user's energy savings. Additionally, we harness the latest advancements in generative artificial intelligence to enhance emotional attachment through conversational interactions that users can have with INFI. The results of a randomized controlled experiment (N=420) convey the fact that this design increases emotional attachment, which in turn increases energy-saving behavior.</p>
<h3>DeepTreeSketch: Neural Graph Prediction for Faithful 3D Tree Modeling from Sketches</h3>
<p>Authors: Zhihao Liu, Yu LI, Fangyuan Tu, Ruiyuan Zhang, Zhanglin Cheng, Naoto Yokoya</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147555">Link</a></p>
<p>Abstract: We present DeepTreeSketch, a novel AI-assisted sketching system that enables users to create realistic 3D tree models from 2D freehand sketches. Our system leverages a tree graph prediction network, TGP-Net, to learn the underlying structural patterns of trees from a large collection of 3D tree models. The TGP-Net simulates the iterative growth of botanical trees and progressively constructs the 3D tree structures in a bottom-up manner. Furthermore, our system supports a flexible sketching mode for both precise and coarse control of the tree shapes by drawing branch strokes and foliage strokes, respectively. Combined with a procedural generation strategy, users can freely control the foliage propagation with diverse and fine details. We demonstrate the expressiveness, efficiency, and usability of our system through various experiments and user studies. Our system offers a practical tool for 3D tree creation, especially for natural scenes in games, movies, and landscape applications.</p>
<h3>Amplifying Human Capabilities in Prostate Cancer Diagnosis: An Empirical Study of Current Practices and AI Potentials in Radiology</h3>
<p>Authors: Sheree May Saßmannshausen, Nazmun Ontika, Aparecido Fabiano Pinatti de Carvalho, Mark Rouncefield, Volkmar Pipek</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147429">Link</a></p>
<p>Abstract: This paper examines the potential of Human-Centered AI (HCAI) solutions to support radiologists in diagnosing prostate cancer. Prostate cancer is one of the most prevalent and increasing cancers among men. The scarcity of radiologists raises concerns about their ability to address the growing demand for prostate cancer diagnosis, leading to a significant surge in the workload of radiologists. Drawing on an HCAI approach, we sought to understand the current practices concerning radiologists' work on detecting and diagnosing prostate cancer, as well as the challenges they face. The findings from our empirical studies point toward the potential that AI has to expedite informed decision-making and enhance accuracy, efficiency, and consistency. This is particularly beneficial for collaborative prostate cancer diagnosis processes. We discuss these results and introduce design recommendations and HCAI concepts for the domain of prostate cancer diagnosis, with the aim of amplifying the professional capabilities of radiologists.</p>
<h3>Data Ethics Emergency Drill: A Toolbox for Discussing Responsible AI for Industry Teams</h3>
<p>Authors: Vanessa Aisyahsari Hanschke, Dylan Rees, Merve Alanyali, David Hopkinson, Paul Marshall</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147218">Link</a></p>
<p>Abstract: Researchers urge technology practitioners such as data scientists to consider the impacts and ethical implications of algorithmic decisions. However, unlike programming, statistics, and data management, discussion of ethical implications is rarely included in standard data science training. To begin to address this gap, we designed and tested a toolbox called the data ethics emergency drill (DEED) to help data science teams discuss and reflect on the ethical implications of their work. The DEED is a roleplay of a fictional ethical emergency scenario that is contextually situated in the team’s specific workplace and applications. This paper outlines the DEED toolbox and describes three studies carried out with two different data science teams that iteratively shaped its design. Our findings show that practitioners can apply lessons learnt from the roleplay to real-life situations, and how the DEED opened up conversations around ethics and values.</p>
<h3>JupyterLab in Retrograde: Contextual Notifications That Highlight Fairness and Bias Issues for Data Scientists</h3>
<p>BEST_PAPER</p>
<p>Authors: Galen Harrison, Kevin Bryson, Ahmad Bamba, Luca Dovichi, Aleksander Binion, Arthur Borem, Blase Ur</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147904">Link</a></p>
<p>Abstract: Current algorithmic fairness tools focus on auditing completed models, neglecting the potential downstream impacts of iterative decisions about cleaning data and training machine learning models. In response, we developed Retrograde, a JupyterLab environment extension for Python that generates real-time, contextual notifications for data scientists about decisions they are making regarding protected classes, proxy variables, missing data, and demographic differences in model performance. Our novel framework uses automated code analysis to trace data provenance in JupyterLab, enabling these notifications. In a between-subjects online experiment, 51 data scientists constructed loan-decision models with Retrograde providing notifications continuously throughout the process, only at the end, or never. Retrograde's notifications successfully nudged participants to account for missing data, avoid using protected classes as predictors, minimize demographic differences in model performance, and exhibit healthy skepticism about their models.</p>
<h3>Understanding Contestability on the Margins: Implications for the Design of Algorithmic Decision-making in Public Services</h3>
<p>Authors: Naveena Karusala, Sohini Upadhyay, Rajesh Veeraraghavan, Krzysztof Gajos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148034">Link</a></p>
<p>Abstract: Policymakers have established that the ability to contest decisions made by or with algorithms is core to responsible artificial intelligence (AI). However, there has been a disconnect between research on contestability of algorithms, and what the situated practice of contestation looks like in contexts across the world, especially amongst communities on the margins. We address this gap through a qualitative study of follow-up and contestation in accessing public services for land ownership in rural India and affordable housing in the urban United States. We find there are significant barriers to exercising rights and contesting decisions, which intermediaries like NGO workers or lawyers work with communities to address. We draw on the notion of accompaniment in global health to highlight the open-ended work required to support people in navigating violent social systems. We discuss the implications of our findings for key aspects of contestability, including building capacity for contestation, human review, and the role of explanations. We also discuss how sociotechnical systems of algorithmic decision-making can embody accompaniment by taking on a higher burden of preventing denials and enabling contestation.</p>
<h3>In-Between Visuals and Visible: The Impacts of Text-to-Image Generative AI Tools on Digital Image-making Practices in the Global South</h3>
<p>Authors: Nusrat Jahan Mim, Dipannita Nandi, Sadaf Khan, Arundhuti Dey, Syed Ishtiaque Ahmed</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147687">Link</a></p>
<p>Abstract: This paper joins the growing body of HCI work on critical AI studies and focuses on the impact of Generative Artificial Intelligence (GAI) tools in Bangladesh. While the West has started to examine the limitations and risks associated with these tools, their impacts on the Global South have remained understudied. Based on our interviews, focus group discussions (FGD), and social media-based qualitative study, this paper reports how popular text-to-image GAI tools (ex., DALL-E, Midjourney,  Stable Diffusion, Firefly) are affecting various image-related local creative fields. We report how these tools limit the creative explorations of marginal artists, struggle to understand linguistic nuances, fail to generate local forms of art and architecture, and misrepresent the diversity among citizens in the image production process. Drawing from a rich body of work on critical image theory, postcolonial computing, and design politics, we explain how our findings are pertinent to HCI's broader interest in social justice, decolonization, and global development.</p>
<h2>Highlight on Learning and Education</h2>
<h3>Emergency Remote Education in Nigeria: Challenges and Design Opportunities</h3>
<p>Authors: Rebecca Nicholson, Rebecca Strachan, Opeyemi Dele-Ajayi, Kemi Fasae</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147787">Link</a></p>
<h3>Establishing Heuristics for Improving the Usability of GUI Machine Learning Tools for Novice Users</h3>
<p>Authors: Asma Yamani, Haifa Al-Shammare, Malak Baslyman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148181">Link</a></p>
<h3>Envisioning Support-Centered Technologies for Language Practice and Use: Needs and Design Opportunities for Immigrant English Language Learners (ELLs)</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Adinawa Adjagbodjou, Geoff Kaufman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146672">Link</a></p>
<h3>Understanding Takeovers and Telestration in Laparoscopic Surgery to Inform Telementoring System Design</h3>
<p>Authors: Solène Lambert, Sandrine Voros, Geoffroy Canlorbe, Jocelyne Troccaz, Ignacio Avellino</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147383">Link</a></p>
<h3>WriteUpRight: Regulating Children’s Handwriting Body Posture by Unobstrusively Error Amplification via Slow Visual Stimuli on Tablets</h3>
<p>Authors: Chenyang Wang, Daniel Tozadore, Barbara Bruno, Pierre Dillenbourg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146950">Link</a></p>
<h3>Interrupting for Microlearning: Understanding Perceptions and Interruptibility of Proactive Conversational Microlearning Services</h3>
<p>Authors: Minyeong Kim, Jiwook Lee, Youngji Koh, Chanhee Lee, Uichin Lee, Auk Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148333">Link</a></p>
<h3>The Realities of Evaluating Educational Technology in School Settings</h3>
<p>Authors: Megan Venn-Wycherley, Ahmed Kharrufa, Susan Lechelt, Rebecca Nicholson, Kate Howland, Abrar Almjally, Anthony Trory, Vidya Sarangapani</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150648">Link</a></p>
<h2>Highlight on Input and Control Techniques</h2>
<h3>Ultrasonic Mid-Air Haptics on the Face: Effects of Lateral Modulation Frequency and Amplitude on Users’ Responses</h3>
<p>Authors: Ruiheng Lan, Xu Sun, Qingfeng Wang, Bingjian Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148049">Link</a></p>
<h3>Model-based Evaluation of Recall-based Interaction Techniques</h3>
<p>Authors: Julien Gori, Bruno Fruchard, Gilles Bailly</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147569">Link</a></p>
<h3>Behavioral Differences between Tap and Swipe: Observations on Time, Error, Touch-point Distribution, and Trajectory for Tap-and-swipe Enabled Targets</h3>
<p>Authors: Shota Yamanaka, Hiroki Usuba, Junichi Sato</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147678">Link</a></p>
<h3>Impact of Fingernails Length on Mobile Tactile Interaction</h3>
<p>Authors: Céline Coutrix, Camélia Prost</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147406">Link</a></p>
<h3>Controlling the Rooms: How People Prefer Using Gestures to Control Their Smart Homes</h3>
<p>Authors: Masoumehsadat Hosseini, Heiko Mueller, Susanne Boll</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147598">Link</a></p>
<h3>Grip-Reach-Touch-Repeat: A Refined Model of Grasp to Encompass One-Handed Interaction with Arbitrary Form Factor Devices</h3>
<p>Authors: Kaixing Zhao, Chaoyi Wu, Tao Xu, Liang He, Marcos Serrano, Anne Roudaut</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146671">Link</a></p>
<h3>Take a Seat, Make a Gesture: Charting User Preferences for On-Chair and From-Chair Gesture Input</h3>
<p>Authors: Alexandru-Tudor Andrei, Laura-Bianca Bilius, Radu-Daniel Vatavu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147142">Link</a></p>
<h3>Simulating Interaction Movements via Model Predictive Control</h3>
<p>Authors: Markus Klar, Florian Fischer, Arthur Fleig, Miroslav Bachinski, Jörg Müller</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150926">Link</a></p>
<h2>Highlight on Security and Privacy</h2>
<h3>Exploring Privacy Practices of Female mHealth Apps in a Post-Roe World</h3>
<p>Authors: Lisa Malki, Ina Kaleva, Dilisha Patel, Mark Warner, Ruba Abu-Salma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147278">Link</a></p>
<h3>Counting Carrds: Investigating Personal Disclosure and Boundary Management in Transformative Fandom</h3>
<p>Authors: Kelly Wang, Dan Bially Levy, Kien Nguyen, Ada Lerner, Abigail Marsh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147455">Link</a></p>
<h3>Stochastic Machine Witnesses at Work: Today's Critiques of Taylorism are Inadequate for Workplace Surveillance Epistemologies of the Future</h3>
<p>Authors: Sandy Gould</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147223">Link</a></p>
<h3>‘We Do Not Have the Capacity to Monitor All Media’: A Design Case Study on Cyber Situational Awareness in Computer Emergency Response Teams</h3>
<p>BEST_PAPER</p>
<p>Authors: Marc-André Kaufhold, Thea Riebe, Markus Bayer, Christian Reuter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146975">Link</a></p>
<h3>Analyzing Security and Privacy Advice During the 2022 Russian Invasion of Ukraine on Twitter</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Juliane Schmüser, Harshini Sri Ramulu, Noah Wöhler, Christian Stransky, Felix Bensmann, Dimitar Dimitrov, Sebastian Schellhammer, Dominik Wermke, Stefan Dietze, Yasemin Acar, Sascha Fahl</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147984">Link</a></p>
<h3>In Focus, Out of Privacy: The Wearer's Perspective on the Privacy Dilemma of Camera Glasses</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Divyanshu Bhardwaj, Alexander Ponticello, Shreya Tomar, Adrian Dabrowski, Katharina Krombholz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147215">Link</a></p>
<h3>The Impact of Risk Appeal Approaches on Users’ Sharing Confidential Information</h3>
<p>Authors: Elham Al Qahtani, Peter Story, Mohamed Shehab</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148170">Link</a></p>
<h2>Highlight on Games and Play</h2>
<h3>Comic-making to Study Game-making: Using Comics in Qualitative Longitudinal Research on Game Development</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Solip Park, Perttu Hämäläinen, Annakaisa Kultima</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147421">Link</a></p>
<h3>Understanding Neurodiverse Social Play Between Autistic and Non-Autistic Children</h3>
<p>Authors: Brooke Morris, Hayati Havlucu, Alison Oldfield, Oussama Metatla</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147697">Link</a></p>
<h3>Ecological In/Congruence: Becoming Sensitised to Nature in Video Games through Humanistic First-Person Research</h3>
<p>Authors: Velvet Spors, Oğuz 'Oz' Buruk, Juho Hamari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147799">Link</a></p>
<h3>Community, Storytelling, and Play: Making and Breaking Rituals in Destiny 2</h3>
<p>Authors: Bjarke Larsen, Elin Carstensdottir</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147767">Link</a></p>
<h3>A Design Framework for Reflective Play</h3>
<p>Authors: Josh Aaron Miller, Kutub Gandhi, Matthew Whitby, Mehmet Kosa, Seth Cooper, Elisa Mekler, Ioanna Iacovides</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146677">Link</a></p>
<h3>Playing on Hard Mode: Accessibility, Difficulty and Joy in Video Game Adoption for Gamers with Disabilities</h3>
<p>Authors: Jesse Martinez, Jon Froehlich, James Fogarty</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146616">Link</a></p>
<h3>Outplay Your Weaker Self: A Mixed-Methods Study on Gamification to Overcome Procrastination in Academia</h3>
<p>Authors: Jeanine Kirchner-Krath, Manuel Schmidt-Kraepelin, Sofia Schöbel, Mathias Ullrich, Ali Sunyaev, Harald von Korflesch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147416">Link</a></p>
<h2>Highlight on Diversity In HCI</h2>
<h3>A Playbook to be Proud of: Making the Case for LGBTQ+ Inclusive User Account Design</h3>
<p>Authors: Beatrice Fadrigon, Princess Gordon, Jane Lupica, Morgan Ames</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148092">Link</a></p>
<h3>Unpacking Norms, Narratives, and Nourishment: A Feminist HCI Critique on Food Tracking Technologies</h3>
<p>Authors: Daisy O'Neill, Max Birk, Regan Mandryk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148303">Link</a></p>
<h3>Cruising Queer HCI on the DL: A Literature Review of LGBTQ+ People in HCI</h3>
<p>Authors: Jordan Taylor, Ellen Simpson, Anh-Ton Tran, Jed Brubaker, Sarah Fox, Haiyi Zhu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147332">Link</a></p>
<h3>Silver-Tongued and Sundry: Exploring Intersectional Pronouns with ChatGPT</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Takao Fujii, Katie Seaborn, Madeleine Steeds</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148287">Link</a></p>
<h3>Deus Ex Machina and Personas from Large Language Models: Investigating the Composition of AI-Generated Persona Descriptions</h3>
<p>Authors: Joni Salminen, Chang Liu, Wenjing Pian, Jianxing Chi, Essi Häyhänen, Bernard Jansen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148256">Link</a></p>
<h3>Designing an Archive of Feelings: Queering Tangible Interaction with Button Portraits</h3>
<p>Authors: Alexandra Teixeira Riggs, Sylvia Janicki, Noura Howell, Anne Sullivan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147424">Link</a></p>
<h3>Designing Diverse Pathways for Participation</h3>
<p>Authors: Jeanette Falk, Anna Blumenkranz, Moritz Kubesch, Ralf Vetter, Lisa Hofer, Christopher Frauenberger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146734">Link</a></p>
<h3>SustAInable: How Values in the Form of Individual Motivation Shape Algorithms’ Outcomes. An Example Promoting Ecological and Social Sustainability</h3>
<p>Authors: Sarah Zabel, Siegmar Otto</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147851">Link</a></p>
<h3>Conceptualising Fatness within HCI: A Call for Fat Liberation</h3>
<p>Authors: Aisha Sobey</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147550">Link</a></p>
<h3>Blueprints: Systematizing Behavior Change Designs - The Case of Social Comparison Theory</h3>
<p>Authors: Roelof de Vries, Mailin Lemke, Geke Ludden</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150871">Link</a></p>
<h2>Highlight on Communities and Online Platforms</h2>
<h3>Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool</h3>
<p>Authors: Liudmila Zavolokina, Kilian Sprenkamp, Zoya Katashinskaya, Daniel Gordon Jones, Gerhard Schwabe</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147239">Link</a></p>
<h3>"Caption it in an Accessible Way That is Also Enjoyable": Characterizing User-Driven Captioning Practices on TikTok</h3>
<p>Authors: Emma McDonnell, Tessa Eagle, Pitch Sinlapanuntakul, Soo Hyun Moon, Jon Froehlich, Kathryn Ringland, Leah Findlater</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147777">Link</a></p>
<h3>SolarClub: Supporting Renewable Energy Communities through an Interactive Coordination System</h3>
<p>Authors: Georgia Panagiotidou, Enrico Costanza, Kyrill Potapov, Sonia Nkatha, Michael Fell, Farhan Samanani, Hannah Knox</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146855">Link</a></p>
<h3>Examining the Role of Peer Acknowledgements on Social Annotations: Unraveling the Psychological Underpinnings</h3>
<p>Authors: Xiaoshan Huang, Haolun Wu, Xue Liu, Susanne Lajoie</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147427">Link</a></p>
<h3>"Community Guidelines Make this the Best Party on the Internet": An In-Depth Study of Online Platforms' Content Moderation Policies</h3>
<p>Authors: Brennan Schaffner, Arjun Nitin Bhagoji, Siyuan Cheng, Jacqueline Mei, Jay Shen, Grace Wang, Marshini Chetty, Nick Feamster, Genevieve Lakier, Chenhao Tan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148026">Link</a></p>
<h3>A Quantitative Approach to Identifying Emergent Editor Roles in Open Street Map</h3>
<p>Authors: Bowen Zhang, Jennings Anderson, Dipto Sarkar, Robert Soden</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147183">Link</a></p>
<h3>Insights Into Legacy: Issues of Handover from a Partner-Initiated Project</h3>
<p>Authors: Emily Thorn, Jocelyn Spence, Boriana Koleva, Steven Benford</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146665">Link</a></p>
<h2>Highlight on Creative HCI</h2>
<h3>Thinking with Sound: Exploring the Experience of Listening to an Ultrasonic Art Installation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Nicole Robson, Andrew McPherson, Nick Bryan-Kinns</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147210">Link</a></p>
<h3>What Counts as ‘Creative’ Work? Articulating Four Epistemic Positions in Creativity-Oriented HCI Research</h3>
<p>BEST_PAPER</p>
<p>Authors: Stacy Hsueh, Marianela Ciolfi Felice, Sarah Fdili Alaoui, Wendy Mackay</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148122">Link</a></p>
<h3>The Illusion of Increased Customization: Framing Choices as a Creative Process Increases Perceived Customization</h3>
<p>Authors: Alice Moon, Maarten Bos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146702">Link</a></p>
<h3>Heart and Soul: The Ethics of Biometric Capture in Immersive Artistic Performance</h3>
<p>Authors: Lucy Sparrow, Caiti Galwey, Ben Loveridge, Solange Glasser, Margaret Osborne, Ryan Kelly</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147399">Link</a></p>
<h3>Entangling Entanglement: A Diffractive Dialogue on HCI and Musical Interactions</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Andrew McPherson, Landon Morrison</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147415">Link</a></p>
<h3>Living with Cyanobacteria: Exploring Materiality in Caring for Microbes in Everyday Life</h3>
<p>Authors: Jiwei Zhou, Zjenja Doubrovski, Elisa Giaccardi, Elvin Karana</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147186">Link</a></p>
<h3>PhotoScout: Synthesis-Powered Multi-Modal Image Search</h3>
<p>Authors: Celeste Barnaby, Qiaochu Chen, Chenglong Wang, Isil Dillig</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147573">Link</a></p>
<h3>"Please Be Nice": Robot Responses to User Bullying - Measuring Performance Across Aggression Levels</h3>
<p>Authors: Yiming Luo, Shihao Liu, Di Wu, Hao Wang, Yushan Pan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147077">Link</a></p>
<h3>GustosonicSense: Towards understanding the design of playful gustosonic eating experiences</h3>
<p>Authors: Yan Wang, Humphrey Obie, Zhuying Li, Flora Salim, John Grundy, Florian Mueller</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148023">Link</a></p>
<h3>A Design Framework for Ingestible Play</h3>
<p>Authors: Zhuying Li, Yan Wang, Josh Andres, Nathan Semertzidis, Stefan Greuter, Florian Mueller</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150650">Link</a></p>
<h3>Algorithmic Ways of Seeing: Using Object Detection to Facilitate Art Exploration</h3>
<p>Authors: Louie Meyer, Johanne Engel Aaen, Anitamalina Regitse Tranberg, Peter Kun, Matthias Freiberger, Sebastian Risi, Anders Løvlie</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147105">Link</a></p>
<h2>Highlight on Design and Design Methods</h2>
<h3>What's the Rush?: Alternative Values in Navigation Technologies for Urban Placemaking</h3>
<p>Authors: Taneea Agrawaal, Aarjav Chauhan, Carolina Nobre, Robert Soden</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147044">Link</a></p>
<h3>Input Visualization: Collecting and Modifying Data with Visual Representations</h3>
<p>Authors: Nathalie Bressa, Jordan Louis, Wesley Willett, Samuel Huron</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147820">Link</a></p>
<h3>Multimedia-Enabled 911: Exploring 911 Callers’ Experience of Call Taker Controlled Video Calling in Simulated Emergencies</h3>
<p>Authors: Punyashlok Dash, Benett Axtell, Denise Y. Geiskkovitch, Carman Neustaedter, Wolfgang Stuerzlinger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148116">Link</a></p>
<h3>eKichabi v2: Designing and Scaling a Dual-Platform Technology in Rural Tanzania</h3>
<p>Authors: Ananditha Raghunath, Alexander Metzger, Hans Easton, XunMei Liu, Fanchong Wang, Yunqi Wang, Yunwei Zhao, Hosea Mpogole, Richard Anderson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147861">Link</a></p>
<h3>Designing a Data-Driven Survey System: Leveraging Participants' Online Data to Personalize Surveys</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Lev Velykoivanenko, Kavous Salehzadeh Niksirat, Stefan Teofanovic, Bertil Chapuis, Michelle Mazurek, Kévin Huguenin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147705">Link</a></p>
<h3>“Is Text-Based Music Search Enough to Satisfy Your Needs?” A New Way to Discover Music with Images</h3>
<p>Authors: Jeongeun Park, Hyorim Shin, Changhoon Oh, Ha Young Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148282">Link</a></p>
<h3>Writing out the Storm: Designing and Evaluating Tools for Weather Risk Messaging</h3>
<p>Authors: Sophia Jit, Jennifer Spinney, Priyank Chandra, Lydia Chilton, Robert Soden</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147048">Link</a></p>
<h3>“What’s Your Name Again?”: How Race and Gender Dynamics Impact Codesign Processes and Output</h3>
<p>Authors: Judith Uchidiuno, Jaemarie Solyst, Jonaya Kemper, Erik Harpstead, Ross Higashi, Jessica Hammer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150848">Link</a></p>
<h2>Highlight on HCI For Caring</h2>
<h3>CareJournal: A Voice-Based Conversational Agent for Supporting Care Communications</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: John Rudnik, Sharadhi Raghuraj, Mingyi Li, Robin Brewer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147253">Link</a></p>
<h3>Let’s Talk About Death: Existential Conversations with Chatbots</h3>
<p>Authors: Ruben Albers, Marc Hassenzahl</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147858">Link</a></p>
<h3>Unpacking ICT-supported Social Connections and Support of Late-life Migration: From the Lens of Social Convoys</h3>
<p>Authors: Ying Lei, Shuai Ma, Yuling Sun</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147033">Link</a></p>
<h3>Networks of care in digital domestic labour economies</h3>
<p>Authors: Adrian Petterson, Isabella Jaimes Rodriguez, Olivia Doggett, Priyank Chandra</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147318">Link</a></p>
<h3>Hostile Systems: A Taxonomy of Harms Articulated by Citizens Living with Socio-Economic Deprivation</h3>
<p>Authors: Colin Watson, Clara Crivellaro, Adam Parnaby, Ahmed Kharrufa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148328">Link</a></p>
<h3>Digital Comprehensibility Assessment of Simplified Texts among Persons with Intellectual Disabilities</h3>
<p>Authors: Andreas Säuberli, Franz Holzknecht, Patrick Haller, Silvana Deilen, Laura Schiffl, Silvia Hansen-Schirra, Sarah Ebling</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147152">Link</a></p>
<h3>Understanding Antenatal Care Needs through Co-Creation with Roma Women to Inform the Design of mHealth Technologies</h3>
<p>Authors: Caroline Claisse, Abigail Durrant, Mabel Lie</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146924">Link</a></p>
<h2>Highlight on Chatbots and LLMs</h2>
<h3>AI is Entering Regulated Territory: Understanding the Supervisors' Perspective for Model Justifiability in Financial Crime Detection</h3>
<p>Authors: Astrid Bertrand, James Eagan, Winston Maxwell, Joshua Brand</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147023">Link</a></p>
<p>Abstract: Artificial intelligence (AI) has the potential to bring significant benefits to highly regulated industries such as healthcare or banking. Adoption, however, remains low. AI's entry into complex socio-techno-legal systems raises issues of transparency, specifically for regulators. However, the perspective of supervisors, regulators who monitor compliance with applicable financial regulations, has rarely been studied. This paper focuses on understanding the needs of supervisors in anti-money laundering (AML) to better inform the design of AI justifications and explanations in highly regulated fields. Through scenario-based workshops with 13 supervisors and 6 banking professionals, we outline the auditing practices and socio-technical context of the supervisor. By combining the workshops’ insights with an analysis of compliance requirements, we identify the AML obligations that conflict with AI opacity. We then formulate seven needs that supervisors have for model justifiability. We discuss the role of explanations as reliable evidence on which to base justifications.</p>
<h3>HILL: A Hallucination Identifier for Large Language Models</h3>
<p>Authors: Florian Leiser, Sven Eckhardt, Valentin Leuthe, Merlin Knaeble, Alexander Mädche, Gerhard Schwabe, Ali Sunyaev</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147556">Link</a></p>
<p>Abstract: Large language models (LLMs) are prone to hallucinations, i.e., nonsensical, unfaithful, and undesirable text. Users tend to overrely on LLMs and corresponding hallucinations which can lead to misinterpretations and errors. To tackle the problem of overreliance, we propose HILL, the Hallucination Identifier for Large Language Models. First, we identified design features for HILL with a Wizard of Oz approach with nine participants. Subsequently, we implemented HILL based on the identified design features and evaluated HILL's interface design by surveying 17 participants. Further, we investigated HILL's functionality to identify hallucinations based on an existing question-answering dataset and five user interviews. We find that HILL can correctly identify and highlight hallucinations in LLM responses which enables users to handle LLM responses with more caution. With that, we propose an easy-to-implement adaptation to existing LLMs and demonstrate the relevance of user-centered designs of AI artifacts.</p>
<h3>Synlogue with Aizuchi-bot: Investigating the Co-Adaptive and Open-Ended Interaction Paradigm</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Kazumi Yoshimura, Dominique Chen, Olaf Witkowski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147480">Link</a></p>
<p>Abstract: In contrast to dialogue, wherein the exchange of completed messages occurs through turn-taking, synlogue is a mode of conversation characterized by co-creative processes, such as mutually complementing incomplete utterances and cooperative overlaps of backchannelings. Such co-creative conversations have the potential to alleviate social divisions in contemporary information environments. This study proposed the design concept of a synlogue based on literature in linguistics and anthropology and explored features that facilitate synlogic interactions in computer-mediated interfaces. Through an experiment, we focused on aizuchi, an important backchanneling element that drives synlogic conversation, and compared the speech and perceptual changes of participants when a bot dynamically uttered aizuchi or otherwise silent in a situation simulating an online video call. Consequently, we discussed the implications for interaction design based on our qualitative and quantitative analysis of the experiment. The synlogic perspective presented in this study is expected to facilitate HCI researchers to achieve more convivial forms of communication.</p>
<h3>Empowering Calibrated (Dis-)Trust in Conversational Agents: A User Study on the Persuasive Power of Limitation Disclaimers vs. Authoritative Style</h3>
<p>Authors: Luise Metzger, Linda Miller, Martin Baumann, Johannes Kraus</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148239">Link</a></p>
<p>Abstract: While conversational agents based on Large Language Models (LLMs) can drive progress in many domains, they are prone to generating faulty information. To ensure an efficient, safe, and satisfactory user experience maximizing benefits of these systems, users must be empowered to judge the reliability of system outputs. In this, both disclaimers and agents' communicative style are pivotal design instances. 
In an online study with 594 participants, we investigated how these affect users' trust and a mock-up agent's persuasiveness, based on an established framework from social psychology. While prior information on potential inaccuracies or faulty information did not affect trust, an authoritative communicative style elicited more trust. Also, a trusted agent was more persuasive resulting in more positive attitudes regarding the subject of the conversation. Results imply that disclaimers on agents' limitations fail to effectively alter users' trust but can be supported by appropriate communicative style during interaction.</p>
<h3>DiaryMate: Understanding User Perceptions and Experience in Human-AI Collaboration for Personal Journaling</h3>
<p>Authors: Taewan Kim, Donghoon Shin, Young-Ho Kim, Hwajung Hong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148343">Link</a></p>
<p>Abstract: With their generative capabilities, large language models (LLMs) have transformed the role of technological writing assistants from simple editors to writing collaborators. Such a transition emphasizes the need for understanding user perception and experience, such as balancing user intent and the involvement of LLMs across various writing domains in designing writing assistants. In this study, we delve into the less explored domain of personal writing, focusing on the use of LLMs in introspective activities. Specifically, we designed DiaryMate, a system that assists users in journal writing with LLM. Through a 10-day field study (N=24), we observed that participants used the diverse sentences generated by the LLM to reflect on their past experiences from multiple perspectives. However, we also observed that they are over-relying on the LLM, often prioritizing its emotional expressions over their own. Drawing from these findings, we discuss design considerations when leveraging LLMs in a personal writing practice.</p>
<h2>Text Entry Techniques</h2>
<h3>PonDeFlick: A Japanese Text Entry on Smartwatch Commonalizing Flick Operation with Smartphone Interface</h3>
<p>Authors: Kai Akamine, Ryotaro Tsuchida, Tsuneo Kato, Akihiro Tamura</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147586">Link</a></p>
<h3>ARTiST: Automated Text Simplification for Task Guidance in Augmented Reality</h3>
<p>Authors: Guande Wu, Jing Qian, Sonia Castelo Quispe, Shaoyu Chen, João Rulff, Claudio Silva</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147808">Link</a></p>
<h3>Exploration of Foot-based Text Entry Techniques for Virtual Reality Environments</h3>
<p>Authors: Tingjie Wan, Liangyuting Zhang, Hongyu Yang, Pourang Irani, Lingyun Yu, Hai-Ning Liang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146722">Link</a></p>
<h3>A Tool for Capturing Smartphone Screen Text</h3>
<p>Authors: Songyan Teng, Simon D'Alfonso, Vassilis Kostakos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147910">Link</a></p>
<h2>Writing and AI C</h2>
<h3>CharacterMeet: Supporting Creative Writers' Entire Story Character Construction Processes Through Conversation with LLM-Powered Chatbot Avatars</h3>
<p>Authors: Hua Xuan Qin, Shan Jin, Ze Gao, Mingming Fan, Pan Hui</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146770">Link</a></p>
<p>Abstract: Support for story character construction is as essential as characters are for stories. Building upon past research on early character construction stages, we explore how conversation with chatbot avatars embodying characters powered by more recent technologies could support the entire character construction process for creative writing. Through a user study (N=14) with creative writers, we examine thinking and usage patterns of CharacterMeet, a prototype system allowing writers to progressively manifest characters through conversation while customizing context, character appearance, voice, and background image. We discover that CharacterMeet facilitates iterative character construction. Specifically, participants, including those with more linear usual approaches, alternated between writing and personalized exploration through visualization of ideas on CharacterMeet while visuals and audio enhanced immersion. Our findings support research on iterative creative processes and the growing potential of personalizable generative AI creativity support tools. We present design implications for leveraging chatbot avatars in the creative writing process.</p>
<h3>PANDALens: Towards AI-Assisted In-Context Writing on OHMD During Travels</h3>
<p>Authors: Runze Cai, Nuwan Janaka, Yang Chen, Lucia Wang, Shengdong Zhao, Can Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146640">Link</a></p>
<p>Abstract: While effective for recording and sharing experiences, traditional in-context writing tools are relatively passive and unintelligent, serving more like instruments rather than companions. This reduces primary task (e.g., travel) enjoyment and hinders high-quality writing. Through formative study and iterative development, we introduce PANDALens, a Proactive AI Narrative Documentation Assistant built on an Optical See-Through Head Mounted Display that supports personalized documentation in everyday activities. PANDALens observes multimodal contextual information from user behaviors and environment to confirm interests and elicit contemplation, and employs Large Language Models to transform such multimodal information into coherent narratives with significantly reduced user effort. A real-world travel scenario comparing PANDALens with a smartphone alternative confirmed its effectiveness in improving writing quality and travel enjoyment while minimizing user effort. Accordingly, we propose design guidelines for AI-assisted in-context writing, highlighting the potential of transforming them from tools to intelligent companions.</p>
<h3>AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation</h3>
<p>Authors: Orit Shaer, Angelora Cooper, Osnat Mokryn, Andrew Kun, Hagit Ben Shoshan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147572">Link</a></p>
<p>Abstract: The growing availability of generative AI technologies such as large language models (LLMs) has significant implications for creative work. This paper explores twofold aspects of integrating LLMs into the creative process – the divergence stage of idea generation, and the convergence stage of evaluation and selection of ideas. We devised a collaborative group-AI Brainwriting ideation framework,  which incorporated  an LLM as an enhancement into the group ideation process, and evaluated the idea generation process and the resulted solution space. To assess the potential of using LLMs in the idea evaluation process, we design an evaluation engine and compared it to idea ratings assigned by three expert and six novice evaluators. Our findings suggest that integrating LLM in Brainwriting could enhance both the ideation process and its outcome. We also provide evidence that LLMs can support idea evaluation.  We conclude by discussing implications for HCI education and practice.</p>
<h3>LegalWriter: An Intelligent Writing Support System for Structured and Persuasive Legal Case Writing for Novice Law Students</h3>
<p>Authors: Florian Weber, Thiemo Wambsganss, Seyed Parsa Neshaei, Matthias Soellner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147647">Link</a></p>
<p>Abstract: Novice students in law courses or students who encounter legal education face the challenge of acquiring specialized and highly concept-oriented knowledge. Structured and persuasive writing combined with the necessary domain knowledge is challenging for many learners. Recent advances in machine learning (ML) have shown the potential to support learners in complex writing tasks. To test the effects of ML-based support on students' legal writing skills, we developed the intelligent writing support system \textit{LegalWriter}. We evaluated the system's effectiveness with 62 students. We showed that students who received intelligent writing support based on their errors wrote more structured and persuasive case solutions with a better quality of legal writing than the current benchmark. At the same time, our results demonstrated the positive effects on the students' writing processes.</p>
<h2>Social Activism C</h2>
<h3>Social Justice in HCI: A Systematic Literature Review</h3>
<p>Authors: Ishita Chordia, Leya Breanna Baltaxe-Admony, Ashley Boone, Alyssa Sheehan, Lynn Dombrowski, Christopher Le Dantec, Kathryn Ringland, Angela D. R. Smith</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148051">Link</a></p>
<h3>Seam Work and Simulacra of Societal Impact in Networking Research: A Critical Technical Practice Approach</h3>
<p>Authors: Gloire Rubambiza, Phoebe Sengers, Hakim Weatherspoon, Jen Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146610">Link</a></p>
<h3>Addressing Interpersonal Harm in Online Gaming Communities: The Opportunities and Challenges for a Restorative Justice Approach</h3>
<p>Authors: Sijia Xiao, Shagun Jhaver, Niloufar Salehi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150929">Link</a></p>
<h3>A Human-Centered Review of Algorithms in Homelessness Research</h3>
<p>Authors: Erina Seh-Young Moon, Shion Guha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147715">Link</a></p>
<h2>Designing with Users</h2>
<h3>Older Adults Imagining Future Technologies in Participatory Design Workshops: Supporting Continuity in the Pursuit of Meaningful Activities</h3>
<p>Authors: Wei Zhao, Ryan Kelly, Melissa Rogerson, Jenny Waycott</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147953">Link</a></p>
<h3>Co-design Partners as Transformative Learners: Imagining Ideal Technology for Schools by Centering Speculative Relationships</h3>
<p>Authors: Michael Chang, Richmond Wong, Thomas Breideband, Thomas M Philip, Ashieda McKoy, Arturo Cortez, Sidney D'Mello</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147225">Link</a></p>
<h3>Co-Designing Situated Displays for Family Co-Regulation with ADHD Children</h3>
<p>Authors: Lucas Silva, Franceli Cibrian, Clarisse Bonang, Arpita Bhattacharya, Aehong Min, Elissa Monteiro, Jesus Beltran, Sabrina Schuck, Kimberley Lakes, Gillian Hayes, Daniel Epstein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148144">Link</a></p>
<h3>Guidelines for Integrating Value Sensitive Design in Responsible AI Toolkits</h3>
<p>Authors: Malak Sadek, Marios Constantinides, Daniele Quercia, Celine Mougenot</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148342">Link</a></p>
<h3>Co-design Accessible Public Robots: Insights from People with Mobility Disability, Robotic Practitioners and Their Collaborations</h3>
<p>Authors: Howard Han, Franklin Mingzhe Li, Alesandra Baca Vazquez, Daragh Byrne, Nikolas Martelaro, Sarah Fox</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147032">Link</a></p>