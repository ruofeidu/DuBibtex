<h2>Behavior Change</h2>
<h3>SoniWeight Shoes: Investigating Effects and Personalization of a Wearable Sound Device for Altering Body Perception, Behavior and Emotion</h3>
<p>Authors: Amar D'Adamo, Ana Tajadura-Jiménez, Marte Roel Lesur, Luis Antonio Azpicueta-Ruiz, Mohammad Mahdi Dehshibi, Aleksander Väljamäe, Joaquin Diaz Duran, Daniel De La Prida, Laia Turmo Vidal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148202">Link</a></p>
<p>Abstract: Changes in body perception influence behavior and emotion and can be induced through multisensory feedback. Auditory feedback to one's actions can trigger such alterations; however, it is unclear which individual factors modulate these effects. We employ and evaluate SoniWeight Shoes, a wearable device based on literature for altering one's weight perception through manipulated footstep sounds. In a healthy population sample across a spectrum of individuals (n=84) with varying degrees of eating disorder symptomatology, physical activity levels, body concerns, and mental imagery capacities, we explore the effects of three sound conditions (low-frequency, high-frequency and control) on extensive body perception measures (demographic, behavioral, physiological, psychological, and subjective). Analyses revealed an impact of individual differences in each of these dimensions. Besides replicating previous findings, we reveal and highlight the role of individual differences in body perception, offering avenues for personalized sonification strategies. Datasets, technical refinements, and novel body map quantification tools are provided.</p>
<h3>EcoSanté Lifestyle Intervention: Encourage Reflections on the Connections between Health and Environment</h3>
<p>Authors: Mike Horn, Pei-Yi (Patricia) Kuo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150654">Link</a></p>
<p>Abstract: EcoSantéis a mobile lifestyle intervention that encourages individual behavior change while also helping participants understand the deep connections between daily lifestyle choices and our collective impact on the planet. Informed by research on “small” intervention approaches, we sent participants daily behavioral challenges that demonstrated connections between personal health and environmental impact at large. Through a 20-day mobile intervention study, 139 participants uploaded 1,920 submissions documenting their attempts to engage in these challenges. We found that participants’ self-reported healthy eating behavior and general self-efficacy improved significantly immediately after the intervention. Moreover, 30 days after the intervention, participants’ self-reported eating, exercise, and general self-efficacy all significantly improved compared to the beginning of the study. Participants had a more negative reaction when being asked to come up with their own challenges. Based on quantitative and qualitative findings, we provide implications for future researcher on mobile behavior intervention research.</p>
<h3>Exploring the Lived Experience of Behavior Change Technologies: Towards an Existential Model of Behavior Change for HCI</h3>
<p>Authors: Amon Rapp, Arianna Boldi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150910">Link</a></p>
<p>Abstract: The majority of behavior change and persuasive technologies are exclusively addressed to modify a specific behavior. However, the focus on behavior may cloud the “existential aspects” of the process of change. To explore the lived and meaning-laden experience of behavior change, we interviewed 23 individuals who have used behavior change technology in their everyday life. The study findings highlight that behavior change is tied to meanings that point to existential matters, relates to a nexus of life circumstances, and unfolds over long periods of time. By contrast, the technology used by the participants appears mostly to focus on the present target behavior, ignoring its links to the participants’ life “context” and “time,” also providing scarce help for sense-making. Based on these findings, we surface a preliminary “existential model of behavior change,” identify several barriers that may prevent the modification of behavior and propose some design suggestions to overcome them.</p>
<h3>Me, My Health, and My Watch: How Children with ADHD Understand Smartwatch Health Data</h3>
<p>Authors: Kimberley Lakes, Jesus Beltran, Lucas Silva, Gillian Hayes, Franceli Cibrian, Sabrina Schuck, Arya Tavakoulnia, Elizabeth Ankrah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150927">Link</a></p>
<p>Abstract: Children with ADHD can experience a wide variety of challenges related to self-regulation, which can lead to poor educational, health, and wellness outcomes. Technological interventions, such as mobile and wearable health systems, can support data collection and reflection about health status. However, little is known about how ADHD children interpret such data. We conducted a deployment study with 10 children, aged 10 to 15, for six weeks, during which they used a smartwatch in their homes. Results from observations and interviews during this study indicate that children with ADHD can interpret their own health data, particularly at the moment. However, as ADHD children develop more autonomy, smartwatch systems may require alternatives for data reflection that are interpretable and actionable for them. This work contributes to the scholarly discourse around health data visualization, particularly in considering implications for the design of health technologies for children with ADHD.</p>
<h2>Hand and Gaze</h2>
<h3>GazePointAR: A Context-Aware Multimodal Voice Assistant for Pronoun Disambiguation in Wearable Augmented Reality</h3>
<p>Authors: Sebastian Rodriguez, Liam Chu, Jon Froehlich, Jun Wang, Jaewook Lee, Elizabeth Brown</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147184">Link</a></p>
<p>Abstract: Voice assistants (VAs) like Siri and Alexa are transforming human-computer interaction; however, they lack awareness of users' spatiotemporal context, resulting in limited performance and unnatural dialogue. We introduce GazePointAR, a fully-functional context-aware VA for wearable augmented reality that leverages eye gaze, pointing gestures, and conversation history to disambiguate speech queries. With GazePointAR, users can ask "what's over there?" or "how do I solve this math problem?" simply by looking and/or pointing. We evaluated GazePointAR in a three-part lab study (N=12): (1) comparing GazePointAR to two commercial systems, (2) examining GazePointAR's pronoun disambiguation across three tasks; (3) and an open-ended phase where participants could suggest and try their own context-sensitive queries. Participants appreciated the naturalness and human-like nature of pronoun-driven queries, although sometimes pronoun use was counter-intuitive. We then iterated on GazePointAR and conducted a first-person diary study examining how GazePointAR performs in-the-wild. We conclude by enumerating limitations and design considerations for future context-aware VAs.</p>
<h3>QuadStretcher: A Forearm-Worn Skin Stretch Display for Bare-Hand Interaction in AR/VR</h3>
<p>Authors: Sunbum Kim, Taejun Kim, Geehyuk Lee, Jaeyeon Lee, YoungIn Kim, Youngbo Shim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148253">Link</a></p>
<p>Abstract: The paradigm of bare-hand interaction has become increasingly prevalent in Augmented Reality (AR) and Virtual Reality (VR) environments, propelled by advancements in hand tracking technology. However, a significant challenge arises in delivering haptic feedback to users’ hands, due to the necessity for the hands to remain bare. In response to this challenge, recent research has proposed an indirect solution of providing haptic feedback to the forearm. In this work, we present QuadStretcher, a skin stretch display featuring four independently controlled stretching units surrounding the forearm. While achieving rich haptic expression, our device also eliminates the need for a grounding base on the forearm by using a pair of counteracting tactors, thereby reducing bulkiness. To assess the effectiveness of QuadStretcher in facilitating immersive barehand experiences, we conducted a comparative user evaluation (n = 20) with a baseline solution, Squeezer. The results confirmed that QuadStretcher outperformed Squeezer in terms of expressing force direction and heightening the sense of realism, particularly in 3-DoF VR interactions such as pulling a rubber band, hooking a fishing rod, and swinging a tennis racket. We further discuss the design insights gained from qualitative user interviews, presenting key takeaways for future forearm-haptic systems aimed at advancing AR/VR bare-hand experiences.</p>
<h3>ArmDeformation: Inducing the Sensation of Arm Deformation in Virtual Reality Using Skin-Stretching</h3>
<p>Authors: Yilong Lin, Peng Zhang, Eyal Ofek, Seungwoo Je</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147750">Link</a></p>
<p>Abstract: With the development of virtual reality (VR) technology, research is being actively conducted on how incorporating multisensory feedback can create the illusion that virtual avatars are perceived as an extension of the body in VR. In line with this research direction, we introduce ArmDeformation, a wearable device employing skin-stretching to enhance virtual forearm ownership during arm deformation illusion. We conducted five user studies with 98 participants. Using a developed tabletop device, we confirmed the optimal number of actuators and the ideal skin-stretching design effectively increases the user's body ownership. Additionally, we explored the maximum visual threshold for forearm bending and the minimum detectable bending direction angle when using skin-stretching in VR. Finally, our study demonstrates that using ArmDeformation in VR applications enhances user realism and enjoyment compared to relying on visual feedback alone.</p>
<h3>CLERA: A Unified Model for Joint Cognitive Load and Eye Region Analysis in the Wild</h3>
<p>Authors: Meng Wang, Bryan Reimer, Jack Terwilliger, Aishni Parab, Li Ding, Lex Fridman, Bruce Mehler</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150827">Link</a></p>
<p>Abstract: Non-intrusive, real-time analysis of the dynamics of the eye region allows us to monitor humans’ visual attention allocation and estimate their mental state during the performance of real-world tasks, which can potentially benefit a wide range of human-computer interaction (HCI) applications. While commercial eye-tracking devices have been frequently employed, the difficulty of customizing these devices places unnecessary constraints on the exploration of more efficient, end-to-end models of eye dynamics. In this work, we propose CLERA, a unified model for Cognitive Load and Eye Region Analysis, which achieves precise keypoint detection and spatiotemporal tracking in a joint-learning framework. Our method demonstrates significant efficiency and outperforms prior work on tasks including cognitive load estimation, eye landmark detection, and blink estimation. We also introduce a large-scale dataset of 30k human faces with joint pupil, eye-openness, and landmark annotation, which aims to support future HCI research on human factors and eye-related analysis.</p>
<h3>How Gaze Visualization Facilitates Initiation of Informal Communication in 3D Virtual Spaces</h3>
<p>Authors: Takehito Yoshiki, Junko Ichino, daisuke okabe, Masahiro Ide, Hirotoshi Asano, Hideo Miyachi, Hitomi Yokoyama</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150879">Link</a></p>
<p>Abstract: This study explores how gaze visualization in virtual spaces facilitates the initiation of informal communication. Three styles of gaze cue visualization (arrow, bubbles, and miniature avatar) with two types of gaze behavior (one-sided gaze and joint gaze) were evaluated. 96 participants used either a non-visualized gaze cue or one of the three visualized gaze cues. The results showed that all visualized gaze cues facilitated the initiation of informal communication more effectively than the non-visualized gaze cue. For one-sided gaze, overall, bubbles had more positive effects on the gaze receiver’s behaviors and experiences than the other two visualized gaze cues, although the only statistically significant difference was in the verbal reaction rates. For joint gaze, all three visualized gaze cues had positive effects on the receiver’s behaviors and experiences. The design implications of the gaze visualization and the confederate-based evaluation method contribute to research on informal communication and social virtual reality.</p>
<h2>Privacy for Immersive Tracking</h2>
<h3>Privacy in Immersive Extended Reality: Exploring User Perceptions, Concerns, and Coping Strategies</h3>
<p>Authors: Derrick Wang, Lennart Nacke, Leah Zhang-Kennedy, Hilda Hadan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147162">Link</a></p>
<p>Abstract: Extended Reality (XR) technology is changing online interactions, but its granular data collection sensors may be more invasive to user privacy than web, mobile, and the Internet of Things technologies. Despite an increased interest in studying developers' concerns about XR device privacy, user perceptions have rarely been addressed. We surveyed 464 XR users to assess their awareness, concerns, and coping strategies around XR data in 18 scenarios. Our findings demonstrate that many factors, such as data types and sensitivity, affect users' perceptions of privacy in XR. However, users' limited awareness of XR sensors' granular data collection capabilities, such as involuntary body signals of emotional responses, restricted the range of privacy-protective strategies they used. Our results highlight a need to enhance users' awareness of data privacy threats in XR, design privacy-choice interfaces tailored to XR environments, and develop transparent XR data practices.</p>
<h3>"I know even if you don't tell me": Understanding Users' Privacy Preferences Regarding AI-based Inferences of Sensitive Information for Personalization</h3>
<p>Authors: Nikola Banovic, Zhe Chen, Sumit Asthana, Jane Im</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148250">Link</a></p>
<p>Abstract: Personalization improves user experience by tailoring interactions relevant to each user's background and preferences. However, personalization requires information about users that platforms often collect without their awareness or their enthusiastic consent. Here, we study how the transparency of AI inferences on users' personal data affects their privacy decisions and sentiments when sharing data for personalization. We conducted two experiments where participants (N=877) answered questions about themselves for personalized public arts recommendations. Participants indicated their consent to let the system use their inferred data and explicitly provided data after awareness of inferences. Our results show that participants chose restrictive consent decisions for sensitive and incorrect inferences about them and for their answers that led to such inferences. Our findings expand existing privacy discourse to inferences and inform future directions for shaping existing consent mechanisms in light of increasingly pervasive AI inferences.</p>
<h3>Kinetic Signatures: A Systematic Investigation of Movement-Based User Identification in Virtual Reality</h3>
<p>Authors: Stefan Schneegass, Leon Sabel, Uwe Gruenefeld, Patrick Laskowski, Jordan Hoppen, Jonathan Liebers, Florian Rademaker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147796">Link</a></p>
<p>Abstract: Behavioral Biometrics in Virtual Reality (VR) enable implicit user identification by leveraging the motion data of users' heads and hands from their interactions in VR. This spatiotemporal data forms a Kinetic Signature, which is a user-dependent behavioral biometric trait. Although kinetic signatures have been widely used in recent research, the factors contributing to their degree of identifiability remain mostly unexplored. Drawing from existing literature, this work systematically examines the influence of static and dynamic components in human motion. We conducted a user study (N = 24) with two sessions to reidentify users across different VR sports and exercises after one week. We found that the identifiability of a kinetic signature depends on its inherent static and dynamic factors, with the best combination allowing for 90.91 % identification accuracy after one week had passed. Therefore, this work lays a foundation for designing and refining movement-based identification protocols in immersive environments.</p>
<h3>Awareness, Intention, (In)Action: Individuals' Reactions to Data Breaches</h3>
<p>Authors: Florian Schaub, Peter Mayer, Adam Aviv, Khue Le, Hunter Dyer, Yixin Zou, Byron M. Lowens, PhD</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150899">Link</a></p>
<p>Abstract: Data breaches are prevalent. We provide novel insights into individuals’ awareness, perception, and responses to breaches that affect them through two online surveys: a main survey (𝑛=413) in which we presented participants with up to three breaches that affected them, and a follow-up survey (𝑛=108) in which we investigated whether the main study participants followed through with their intentions to act. Overall, 73% of participants were affected by at least one breach, but participants were unaware of 74% of breaches affecting them. While some reported intention to take action, most participants believed the breach would not impact them. We also found a sizeable intention-behavior gap. Participants did not follow through with their intention when they were apathetic about breaches, considered potential costs, forgot, or felt resigned about taking action. Our findings suggest that breached organizations should be held accountable for more proactively informing and protecting affected consumers.</p>
<h3>Don't Accept All and Continue: Exploring Nudges for More Deliberate Interaction With Tracking Consent Notices</h3>
<p>Authors: Alina Stöver, Verena Zimmermann, Justin Peschke, Nina Gerber</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150877">Link</a></p>
<p>Abstract: Legal frameworks rely on users to make an informed decision about data collection, e.g., by accepting or declining the use of tracking technologies. In practice, however, users hardly interact with tracking consent notices on a deliberate website per website level, but usually accept or decline optional tracking technologies altogether in a habituated behavior.We explored the potential of three different nudge types (color highlighting, social cue, timer) and default settings to interrupt this auto-response in an experimental between-subject design with 167 participants.We did not find statistically significant differences regarding the buttons clicked. Our results showed that opt-in default settings significantly decrease tracking technology use acceptance rates. These results are a first step towards understanding the effects of different nudging concepts on users’ interaction with tracking consent notices.</p>
<h2>Privacy and Trust</h2>
<h3>Computing and the Stigmatized: Trust, Surveillance, and Spatial Politics with the Sex Workers in Bangladesh</h3>
<p>BEST_PAPER</p>
<p>Authors: S M Taiabul Haque, Ayien Utshob Baidya, Syed Ishtiaque Ahmed, Nadira Nowsher, Pratyasha Saha, Nusrat Jahan Mim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148106">Link</a></p>
<p>Abstract: The sex workers in the Global South represent a significant portion of the world sex industry. However, when compared to the relevant HCI literature on sex work and computing, there exists a noticeable gap in comprehending the experiences and circumstances of the sex workers in this region. This study fills the void by presenting the findings of a three-month-long ethnography with 25 legal sex workers in Daulatdia brothel, Bangladesh, revealing their struggles with stigma, low-tech literacy, and the emerging threats of online security, along with their skills and creativity to bypass those. Drawing on the previous literature on South Asian feminism, postcolonial computing, and critical urban studies, we demonstrate how these findings are deeply rooted in the country's history and culture and propelled by a modernist vision of ''development'' that marginalizes such communities. Our discussion advances HCI's discourse on sexuality, privacy, equity, and generates implications for design and policy changes. </p>
<h3>Lies, Deceit, and Hallucinations: Player Perception and Expectations Regarding Trust and Deception in Games</h3>
<p>Authors: Chuoxi Ng, Michael Yin, Emi Wang, Robert Xiao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146790">Link</a></p>
<p>Abstract: Lying and deception are important parts of social interaction; when applied to storytelling mediums such as video games, such elements can add complexity and intrigue. We developed a game, “AlphaBetaCity”, in which non-playable characters (NPCs) made various false statements, and used this game to investigate perceptions of deceptive behaviour. We used a mix of human-written dialogue incorporating deliberate falsehoods and LLM-written scripts with (human-approved) hallucinated responses. The degree of falsehoods varied between believable but untrue statements to outright fabrications. 29 participants played the game and were interviewed about their experiences. Participants discussed methods for developing trust and gauging NPC truthfulness. Whereas perceived intentional false statements were often attributed towards narrative and gameplay effects, seemingly unintentional false statements generally mismatched participants' mental models and lacked inherent meaning. We discuss how the perception of intentionality, the audience demographic, and the desire for meaning are major considerations when designing video games with falsehoods. </p>
<h3>Reliability Criteria for News Websites</h3>
<p>Authors: Hendrik Heuer, Elena Glassman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150911">Link</a></p>
<p>Abstract: Misinformation poses a threat to democracy and to people’s health. Reliability criteria for news websites can help people identify misinformation. But despite their importance, there has been no empirically substantiated list of criteria for distinguishing reliable from unreliable news websites. We identify reliability criteria, describe how they are applied in practice, and compare them to prior work. Based on our analysis, we distinguish between manipulable and less manipulable criteria and compare politically diverse laypeople as end-users and journalists as expert users. We discuss 11 widely recognized criteria, including the following 6 criteria that are difficult to manipulate: content, political alignment, authors, professional standards, what sources are used, and a website’s reputation. Finally, we describe how technology may be able to support people in applying these criteria in practice to assess the reliability of websites.</p>
<h3>Un-Paradoxing Privacy: Considering Hopeful Trust</h3>
<p>Authors: Bran Knowles, Stacey Conchie</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150903">Link</a></p>
<p>Abstract: Extant literature has proposed an important role for trust in moderating people's willingness to disclose personal information, but there is scant HCI literature that deeply explores the relationship between privacy and trust in apparent privacy paradox circumstances. Attending to this gap, this paper reports a qualitative study examining how people account for continuing to use services that conflict with their stated privacy preferences, and how trust features in these accounts. Our findings undermine the notion that individuals engage in strategic thinking about privacy, raising important questions regarding the explanatory power of the well-known privacy calculus model and its proposed relationship between privacy and trust. Finding evidence of \textit{hopeful} trust in participants' accounts, we argue that trust allows people to morally account for their <code>paradoxical' information disclosure behavior. We propose that effecting greater alignment between people's privacy attitudes and privacy behavior---or</code>un-paradoxing privacy'---will require greater regulatory assurances of privacy.</p>
<h3>“I Can’t Believe It’s Not Custodial!”: Usable Trustless Decentralized Key Management</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Tanusree Sharma, Vivek Nair, Yang Wang, Henry Wang, Dawn Song</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147386">Link</a></p>
<p>Abstract: Key management has long remained a difficult unsolved problem in the field of usable security. While password-based key derivation functions (PBKDFs) are widely used to solve this problem in centralized applications, their low entropy and lack of a recovery mechanism make them unsuitable for use in decentralized contexts. The multi-factor key derivation function (MFKDF) is a recently proposed cryptographic primitive that aims to address these deficiencies by incorporating commonly used authentication factors into the key derivation process. In this paper, we implement an MFKDF-based Ethereum wallet and perform a user study with 27 participants to directly compare its usability against traditional cryptocurrency wallet architectures. Our results show that MFKDF-based applications outperform conventional key management approaches on both subjective and objective metrics, with a 37% higher average SUS score (p &lt; 0.0001) and 71% faster task completion times (p &lt; 0.0001) for the MFKDF-based wallet.</p>
<h2>Bodies and Movement in Immersive Realities</h2>
<h3>ShareYourReality: Investigating Haptic Feedback and Agency in Virtual Avatar Co-embodiment</h3>
<p>Authors: Monica Perusquia-Hernandez, Gijs Huisman, Abdallah El Ali, Wo Meijer, Karthikeya Puttur Venkatraj</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147264">Link</a></p>
<p>Abstract: Virtual co-embodiment enables two users to share a single avatar in Virtual Reality (VR). During such experiences, the illusion of shared motion control can break during joint-action activities, highlighting the need for position-aware feedback mechanisms. Drawing on the perceptual crossing paradigm, we explore how haptics can enable non-verbal coordination between co-embodied participants. In a within-subjects study (20 participant pairs), we examined the effects of vibrotactile haptic feedback (None, Present) and avatar control distribution (25-75%, 50-50%, 75-25%) across two VR reaching tasks (Targeted, Free-choice) on participants’ Sense of Agency (SoA), co-presence, body ownership, and motion synchrony. We found (a) lower SoA in the free-choice with haptics than without, (b) higher SoA during the shared targeted task, (c) co-presence and body ownership were significantly higher in the free-choice task, (d) players’ hand motions synchronized more in the targeted task. We provide cautionary considerations when including haptic feedback mechanisms for avatar co-embodiment experiences.</p>
<h3>Process, Roles, Tools, and Team: Understanding the Emerging Medium of Virtual Reality Theatre</h3>
<p>Authors: T.C. Nicholas Graham, Laura Levin, Michaelah Wales, Michael Wheeler, Gabriele Cimolino, Jayna Mees</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147875">Link</a></p>
<p>Abstract: Virtual reality (VR) theatre artists are combining theatre production and game development practices to create live performances in VR. To date, little is known about VR theatre creators' experiences of this process or how staging a play in VR might affect the audience's experience. To capture the experience of developing a VR theatre production we interviewed the production team behind the VR play You Should Have Stayed Home. Members of this team felt the process was a learning experience and shared the lessons they plan to incorporate into their future work. We report on the team's efforts to understand the VR theatre medium, how this team was constructed, and challenges that they encountered. In this paper we present the opportunities that the production team members identified for creating novel experiences for VR audiences, and their own needs as creators.</p>
<h3>TimeTunnel: Integrating Spatial and Temporal Motion Editing for Character Animation in Virtual Reality</h3>
<p>Authors: Qian Zhou, George Fitzmaurice, Fraser Anderson, David Ledo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147369">Link</a></p>
<p>Abstract: Editing character motion in Virtual Reality is challenging as it requires working with both spatial and temporal data using controls with multiple degrees of freedom. The spatial and temporal controls are separated, making it difficult to adjust poses over time and predict the effects across adjacent frames. To address this challenge, we propose TimeTunnel, an immersive motion editing interface that integrates spatial and temporal control for 3D character animation in VR. TimeTunnel provides an approachable editing experience via KeyPoses and Trajectories. KeyPoses are a set of representative poses automatically computed to concisely depict motion. Trajectories are 3D animation curves that pass through the joints of KeyPoses to represent in-betweens. TimeTunnel integrates spatial and temporal control by superimposing Trajectories and KeyPoses onto a 3D character. We conducted two studies to evaluate TimeTunnel. In our quantitative study, TimeTunnel reduced the amount of time required for editing motion, and saved effort in locating target poses. Our qualitative study with domain experts demonstrated how TimeTunnel is an approachable interface that can simplify motion editing, while still preserving a direct representation of motion.</p>
<h3>A Systematic Review and Meta-analysis of the Effectiveness of Body Ownership Illusions in Virtual Reality</h3>
<p>Authors: Kasper Hornbæk, Guido Makransky, Aske Mottelson, Andreea Muresan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150754">Link</a></p>
<p>Abstract: Body ownership illusions (BOIs) occur when participants experience that their actual body is replaced by a body shown in virtual reality (VR). Based on a systematic review of the cumulative evidence on BOIs from 111 research articles published in 2010 to 2021, this article summarizes the findings of empirical studies of BOIs. Following the PRISMA guidelines, the review points to diverse experimental practices for inducing and measuring body ownership. The two major components of embodiment measurement, body ownership and agency, are examined. The embodiment of virtual avatars generally leads to modest body ownership and slightly higher agency. We also find that BOI research lacks statistical power and standardization across tasks, measurement instruments, and analysis approaches. Furthermore, the reviewed studies showed a lack of clarity in fundamental terminology, constructs, and theoretical underpinnings. These issues restrict scientific advances on the major components of BOIs, and together impede scientific rigor and theory-building.</p>
<h2>Children and Family B</h2>
<h3>CHAITok: A Proof-of-Concept System Supporting Children's Sense of Data Autonomy on Social Media</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Nigel Shadbolt, Ge Wang, Max Van Kleek, Zhilin Zhang, Jun Zhao, Samantha-Kaye Johnston</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147781">Link</a></p>
<p>Abstract: Social media has become a primary source of entertainment and education for children globally. While much attention has been given to children's online well-being, a pressing concern often goes unnoticed: the pervasive data harvesting underlying social media and its manipulative impact on undermining children's autonomy. In this paper, we present CHAITok, an Android mobile application designed to enhance children's sense of autonomy over their data on social media. Through 27 user study sessions with 109 children aged 10--13, we offer insights into the current lack of data autonomy among children regarding their online information, and how we can foster children's sense of data autonomy through a socio-technical journey. Our findings inspire design recommendations to respect children's values, support children's evolving autonomy, and design for children's digital rights. We emphasize data autonomy as a fundamental right for children, call for further research, design innovation, and policy changes on this critical issue.</p>
<h3>"It's Not a Replacement:'' Enabling Parent-Robot Collaboration to Support In-Home Learning Experiences of Young Children</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Edward Hubbard, Bilge Mutlu, Hui-Ru Ho</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147068">Link</a></p>
<p>Abstract: Learning companion robots for young children are increasingly adopted in informal learning environments. Although parents play a pivotal role in their children's learning, very little is known about how parents prefer to incorporate robots into their children's learning activities. We developed prototype capabilities for a learning companion robot to deliver educational prompts and responses to parent-child pairs during reading sessions and conducted in-home user studies involving 10 families with children aged 3--5. Our data indicates that parents want to work with robots as collaborators to augment parental activities to foster children's learning, introducing the notion of parent-robot collaboration. Our findings offer an empirical understanding of the needs and challenges of parent-child interaction in informal learning scenarios and design opportunities for integrating a companion robot into these interactions. We offer insights into how robots might be designed to facilitate parent-robot collaboration, including parenting policies, collaboration patterns, and interaction paradigms. </p>
<h3>Cuddling Up With a Print-Braille Book: How Intimacy and Access Shape Parents' Reading Practices with Children</h3>
<p>Authors: Emory Edwards, Jin Seo Kim, Stacy Branham, Sohyeon Park, Cameron Cassidy, Isabela Figueira</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146954">Link</a></p>
<p>Abstract: Like many parents, visually impaired parents (VIPs) read books with their children. However, research on accessible reading technologies predominantly focuses on blind adults reading alone or sighted adults reading with blind children, such that the motivations, strategies, and needs of blind parents reading with their sighted children are still largely undocumented. To address this gap, we interviewed 13 VIPs with young children. We found that VIPs (1) sought familial intimacy through reading with their child, often prioritizing intimacy over their own access needs, (2) took on many types of access labor to read with their children, and (3) desired novel assistive technologies (ATs) for reading that prioritize intimacy while reducing access labor. We contribute the notion of Intimate AT, along with a demonstrative design space, which together constitute a new design paradigm that draws attention to intimacy as a facet of both independently and collaboratively accessible ATs.</p>
<h3>“It looks useful, works just fine, but will it replace me ?" Understanding Special Educators’ Perception of Social Robots for Autism Care in India</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: B Ashwini, Venkata Ratnadeep Suri, Krishnaveni Achary, Jainendra Shukla, ATMADEEP GHOSHAL</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147134">Link</a></p>
<p>Abstract: Social robots, particularly in assisting children with autism, have exhibited positive impacts on mental health. While prior studies concentrated on social robots in the Global North, there's limited exploration in the Global South. It's essential to comprehend special educators' perspectives for effective integration in resource-constrained settings. Our mixed-methods approach, involving interviews, workshops, and a panel discussion with 25 educators in India, uncovers challenges and opportunities in integrating social robots into autism interventions. The findings highlight the urgent need to democratise the benefits of social robotics. Special educators express concerns about their functional capacity and fear potential redundancy due to the replacement of human efforts by social robots. Despite initial scepticism, professionals suggest various ways to incorporate social robots, emphasising the importance of technological innovation in reshaping and enhancing their roles in autism therapy. We discuss the implications of these findings for developing context-aware solutions and policy-level initiatives necessary in resource-constrained settings.</p>
<h2>Communication and Collaboration</h2>
<h3>Understanding Entrainment in Human Groups: Optimising Human-Robot Collaboration from Lessons Learned during Human-Human Collaboration</h3>
<p>Authors: Stanley Celestin, Julie Shah, Eike Schneiders, Malte Jung, Christopher Fourie</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147674">Link</a></p>
<p>Abstract: Successful entrainment during collaboration positively affects trust, willingness to collaborate, and likeability towards collaborators. In this paper, we present a mixed-method study to investigate characteristics of successful entrainment leading to pair and group-based synchronisation. Drawing inspiration from industrial settings, we designed a fast-paced, short-cycle repetitive task. Using motion tracking, we investigated entrainment in both dyadic and triadic task completion. Furthermore, we utilise audio-video recordings and semi-structured interviews to contextualise participants' experiences. This paper contributes to the Human-Computer/Robot Interaction (HCI/HRI) literature using a human-centred approach to identify entrainment characteristics during pair- and group-based collaboration. We present five characteristics related to successful entrainment. These are related to the occurrence of entrainment, leader-follower patterns, interpersonal communication, the importance of the point-of-assembly, and the value of acoustic feedback. Finally, based on our findings, we present three design considerations for future research and design on collaboration with robots.</p>
<h3>Investigating the Potential of Group Recommendation Systems As a Medium of Social Interactions: A Case of Spotify Blend Experiences between Two Users</h3>
<p>Authors: Soobin Park, Hankyung Kim, Daehyun Kwak, Youn-kyung Lim, Inha Cha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147752">Link</a></p>
<p>Abstract: Designing user experiences for group recommendation systems (GRS) is challenging, requiring a nuanced understanding of the influence of social interactions between users. Using Spotify Blend as a real-world case of music GRS, we conducted empirical studies to investigate intricate social interactions among South Korean users in GRS. Through a preliminary survey about Blend experiences in general, we narrowed the focus for the main study to relationships between two users who are acquainted or close. Building on this, we conducted a 21-day diary study and interviews with 30 participants (15 pairs) to probe more in-depth interpersonal dynamics within Blend. Our findings reveal that users engaged in implicit social interactions, including tacit understanding of their companions and indirect communication. We conclude by discussing the newly discovered value of GRS as a social catalyst, along with design attributes and challenges for the social experiences it mediates.</p>
<h3>Mitigating Barriers to Public Social Interaction with Meronymous Communication</h3>
<p>BEST_PAPER</p>
<p>Authors: Nouran Soliman, Matt Latzke, Hyeonsu Kang, David Karger, Joseph Chee Chang, Jonathan Bragg, Amy Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147447">Link</a></p>
<p>Abstract: In communities with social hierarchies, fear of judgment can discourage communication. While anonymity may alleviate some social pressure, fully anonymous spaces enable toxic behavior and hide the social context that motivates people to participate and helps them tailor their communication. We explore a design space of meronymous communication, where people can reveal carefully chosen aspects of their identity and also leverage trusted endorsers to gain credibility. We implemented these ideas in a system for scholars to meronymously seek and receive paper recommendations on Twitter and Mastodon. A formative study with 20 scholars confirmed that scholars see benefits to participating but are deterred due to social anxiety. From a month-long public deployment, we found that with meronymity, junior scholars could comfortably ask "newbie" questions and get responses from senior scholars who they normally found intimidating. Responses were also tailored to the aspects about themselves that junior scholars chose to reveal. </p>
<h3>Examining Voice Community Use</h3>
<p>Authors: Robin Brewer, Manahil Hashmi, Pooja Upadhyay, Sam Ankenbauer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150925">Link</a></p>
<p>Abstract: Visual online communities can present accessibility challenges to older adults or people with vision and motor disabilities. Motivated by this challenge, accessibility and HCI researchers have called for voice-based communities to support aging and disability. This paper extends prior work on voice community design and short-term use by providing empirical data on how people interact with voice communities over time and intentional instances of non-use. We conducted a one-year study with 43 blind and low vision older adults, of whom 21 used a voice-based community. We use vignettes to unpack five different voice community member roles - the obligatory poster, routine poster, cross-platform lurker, busy socialite, and visual expertise seeker - and discuss community interactions over time. Findings show how participation varied based on engagement in other communities and ways that participants sought interaction. We discuss (1) how to design voice communities for member roles and (2) the implications of synchronous and asynchronous voice community interaction in voice-only communities.</p>
<h3>Engaged and Affective Virtual Agents: Their Impact on Social Presence, Trustworthiness, and Decision-Making in the Group Discussion</h3>
<p>Authors: Hanseob Kim, MUHAMMAD FIRDAUS LUBIS, Jae-In Hwang, Jieun Kim, Gerard Kim, Bin Han</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147980">Link</a></p>
<p>Abstract: This study investigates how different virtual agent (VA) behaviors influence subjects' perceptions and group decision-making.</p>
<p>Participants carried out </p>
<p>experimental group discussions with a VA exhibiting varying levels of engagement and affective behavior.</p>
<p>Engagement refers to the VA's focus on the group task, whereas affective behavior reflects the VA's emotional state.</p>
<p>The findings revealed that VA's engagements effectively captured participants' attention even in the group setting and enhanced group synergy, thereby facilitating more in-depth discussion and producing better consensus.</p>
<p>On the other hand, VA's affective behavior negatively affected the</p>
<p>perceived social presence and trustworthiness. Consequently, </p>
<p>in the context of group discussion, participants preferred the engaged and non-affective VA to the non-engaged and affective VA.</p>
<p>The study provides valuable insights for improving the VA's behavioral design as a team member for collaborative tasks.</p>
<h2>Emotions and User Experience</h2>
<h3>EmoWear: Exploring Emotional Teasers for Voice Message Interaction on Smartwatches</h3>
<p>Authors: Zibo Zhang, Qingyuan Ma, Jiawen Zhu, Linghao Du, Che Yan, Jian Zhao, Pengcheng An, Yifei Yin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147276">Link</a></p>
<p>Abstract: Voice messages, by nature, prevent users from gauging the emotional tone without fully diving into the audio content. This hinders the shared emotional experience at the pre-retrieval stage. Research scarcely explored "Emotional Teasers"—pre-retrieval cues offering a glimpse into an awaiting message's emotional tone without disclosing its content. We introduce EmoWear, a smartwatch voice messaging system enabling users to apply 30 animation teasers on message bubbles to reflect emotions. EmoWear eases senders' choice by prioritizing emotions based on semantic and acoustic processing. EmoWear was evaluated in comparison with a mirroring system using color-coded message bubbles as emotional cues (N=24). Results showed EmoWear significantly enhanced emotional communication experience in both receiving and sending messages. The animated teasers were considered intuitive and valued for diverse expressions. Desirable interaction qualities and practical implications are distilled for future design. We thereby contribute both a novel system and empirical knowledge concerning emotional teasers for voice messaging.</p>
<h3>ReactGenie: A Development Framework for Complex Multimodal Interactions Using Large Language Models</h3>
<p>Authors: Yuhan Zhang, Tianshi Li, Daniel Wan Rosli, Monica Lam, Yingtian Shi, James Landay, Karina Li, Jackie Yang, Shuning Zhang, Anisha Jain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147488">Link</a></p>
<p>Abstract: By combining voice and touch interactions, multimodal interfaces can surpass the efficiency of either modality alone. Traditional multimodal frameworks require laborious developer work to support rich multimodal commands where the user’s multimodal command involves possibly exponential combinations of actions/function invocations. This paper presents ReactGenie, a programming framework that better separates multimodal input from the computational model to enable developers to create efficient and capable multimodal interfaces with ease. ReactGenie translates multimodal user commands into NLPL (Natural Language Programming Language), a programming language we created, using a neural semantic parser based on large-language models. The ReactGenie runtime interprets the parsed NLPL and composes primitives in the computational</p>
<p>model to implement complex user commands. As a result, ReactGenie allows easy implementation and unprecedented richness in commands for end-users of multimodal apps. Our evaluation showed that 12 developers can learn and build a non-trivial ReactGenie application in under 2.5 hours on average. In addition, compared with a traditional GUI, end-users can complete tasks faster and with less task load using ReactGenie apps.</p>
<h3>Investigating the Effects of Self-selected Pleasant Scents on Text Composition and Transcription Performance</h3>
<p>Authors: Wendy Haw, Kianna Ng, Yuan Ren, Ahmed Arif</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147458">Link</a></p>
<p>Abstract: The extensive use of computers for text entry has been linked to increased stress, depression, and sleep disturbances, adversely affecting performance. Recent trends involve using scent diffusers to counter these effects. However, the impact of scents on text entry performance is not well-studied. Our empirical study investigated the effects of self-selected pleasant scents on text composition and transcription performance. Results showed that while composing, users were slower with a scent present, potentially due to heightened focus on text quality. Scent did not alter accuracy or text length. In transcription tasks, although scent did not alter typing speed, it adversely affected accuracy, likely due to its impact on concentration levels. Despite these mixed results, users felt more effective and enjoyed the scent, indicating a preference for its continued use. This study opens avenues for further research into scents' influence on computer-based tasks, potentially contributing to the evolving field of olfactory displays.</p>
<h3>Digital Knick-Knacks: Standalone Audiovisual Digital Possessions or Embellishments in Digital Environments</h3>
<p>Authors: Matthew Lakier, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147325">Link</a></p>
<p>Abstract: Inspired by physical possessions displayed in the home, we define "digital knick-knacks" as standalone audiovisual digital possessions or embellishments contained within non-game digital environments. "Neko", a cat that chases the cursor, is a historical example. We propose a taxonomy to define and generate digital knick-knacks based on key publications on consumer behaviour and personal possessions, augmented by results of a brainstorming session with 9 HCI researchers. Using the taxonomy, we prototype three classes of digital knick-knack exemplars: an ambient noise machine, a virtual pet, and a virtual picture frame. In a 10-day diary study, 10 participants design their own variants of the prototypes, and report on their experience using them on a personal device. Our analysis shows how digital knick-knacks can bring value to users, and we suggest implications for designing playful digital embellishments.</p>
<h3>Frustration: Still a Common User Experience</h3>
<p>Authors: Kasper Hornbæk, Morten Hertzum</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150750">Link</a></p>
<p>Abstract: When computers unexpectedly delay or thwart goal attainment, frustration ensues. The central studies of the extent, content, and impact of such frustration were done more than 15 years ago. We revisit this issue after computers have become more mature and computer use is more extensive. To this end, we had 234 crowdsourced participants log the frustrating episodes they experienced with their computers during one hour of computer use. The average time lost due to frustrating episodes was between 11% and 20% of the one-hour period. Though this is less time lost than in the earlier studies, frustration remains a common user experience. While shorter, the median level of frustration during the episodes was high (7 on a 9-point scale). The frustration level correlated with task importance and time lost but was unaffected by computer experience and largely unaffected by computer self-efficacy. In addition, participants indicated that 84% of the episodes had happened before, that 87% could happen again, and that they were unable to resolve 26% of the episodes. This high rate of recurrence and lack of control likely added to the frustration level. The episodes spanned various issues pertaining to performance (49%), usability (36%), and utility (16%)</p>
<h2>Environmental Activism</h2>
<h3>Eternagram: Probing Player Attitudes Towards Climate Change Using a ChatGPT-driven Text-based Adventure</h3>
<p>Authors: Jussi Holopainen, Qinshi Zhang, Latisha Besariani Hendra, Suifang Zhou, Pengfei Zhou, RAY LC</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147145">Link</a></p>
<p>Abstract: Conventional methods of assessing attitudes towards climate change are limited in capturing authentic opinions, primarily stemming from a lack of context-specific assessment strategies and an overreliance on simplistic surveys. Game-based Assessments (GBA) have demonstrated the ability to overcome these issues by immersing participants in engaging gameplay within carefully crafted, scenario-based environments. Concurrently, advancements in AI and Natural Language Processing (NLP) show promise in enhancing the gamified testing environment, achieving this by generating context-aware, human-like dialogues that contribute to a more natural and effective assessment. Our study introduces a new technique for probing climate change attitudes by actualizing a GPT-driven chatbot system in harmony with a game design depicting a futuristic climate scenario. The correlation analysis reveals an assimilation effect, where players' post-game climate awareness tends to align with their in-game perceptions. Key predictors of pro-climate attitudes are identified as traits like 'Openness' and 'Agreeableness', and a preference for democratic values.</p>
<h3>Technical Mentality: Principles for HCI Research and Practice</h3>
<p>Authors: Nadya Peek, Gabrielle Benabdallah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148115">Link</a></p>
<p>Abstract: This paper presents a reflection on the role of ontological inquiry in HCI research and practice. Specifically, we introduce philosopher Gilbert Simondon's proposal of technical mentality, an onto-epistemology based on direct knowledge of technical objects and systems. This paper makes the following contributions: an analysis of Simondon's ontological critique and its connection to technical mentality; a reflection on the ethical and practical implications of Simondon's proposal for systems research; an example of technical mentality in practice; and a discussion of how technical mentality might be extended into a design program for HCI through four principles: extension, integration, legibility, and expression.</p>
<h3>Promoting Eco-Friendly Behaviour through Virtual Reality - Implementation and Evaluation of Immersive Feedback Conditions of a Virtual CO2 Calculator</h3>
<p>Authors: Stephanie Vogt, Nina Döllinger, Carolin Wienrich, David Obremski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148025">Link</a></p>
<p>Abstract: Climate change is one of the most pressing global challenges in the 21st century. Urgent actions favoring the environment's well-being are essential to mitigate its potentially irreversible consequences. However, the delayed and often distant nature of the effects of sustainable behavior makes it challenging for individuals to connect with the issue personally. </p>
<p>Immersive media are an opportunity to introduce innovative feedback mechanisms to highlight the urgency of behavior effects.</p>
<p>We introduce a VR carbon calculator that visualizes users' annual carbon footprint as CO2-filled balloons over multiple periods. </p>
<p>In a 2 x 2 design, participants calculated and visualized their carbon footprint numerically or as balloons over one or three years. </p>
<p>We found no effect of our visualization but a significant impact of the visualized period on participants' environmental self-efficacy. These findings emphasize the importance of target-oriented design in VR behavior interventions.</p>
<h3>From Surplus and Scarcity towards Abundance: Understanding the Use of ICT in Food Resource Sharing Practices</h3>
<p>Authors: Volker Wulf, Dave Randall, Gunnar Stevens, Philip Engelbutzeder, Marvin Landwehr, Konstantin Aal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150852">Link</a></p>
<p>Abstract: Food practices have become an important context for questions around sustainability. Within HCI, Sustainable HCI and Human-Food-Interaction have developed as a response. We argue, nevertheless, that food practices as a social activity remain relatively under-examined and further that sustainable food practices hinge on communal activity. We present the results of action-oriented research with a grassroots movement committed to sustainable food practices at a local, communal level, thereby demonstrating the role of ICT in making food resource sharing a viable practice. We suggest that the current focus on food sharing might usefully be supplemented by attention to food resource sharing, an approach that aligns with a paradigm shift from surplus to abundance. We argue for design that aims to encourage food resource sharing at a local level but that also has wider ramifications. These ‘glocal’ endeavors recognize the complexity of prosumption practices and foster aspirations for ‘deep change’ in food systems.</p>
<h3>Post-growth Human–Computer Interaction</h3>
<p>Authors: Neha Kumar, Bonnie Nardi, Vishal Sharma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150905">Link</a></p>
<p>Abstract: Human–Computer Interaction (HCI) researchers have increasingly been questioning computing’s engagement with unsustainable and unjust economic growth, pushing for identifying alternatives. Incorporating degrowth, post-development, and steady-state approaches, post-growth philosophy offers an alternative not rooted in growth but in improving quality of life. It recommends an equitable reduction in resource use through sensible distributive practices where fulfillment is based on values including solidarity, cooperation, care, social justice, and localized development. In this paper, we describe opportunities for HCI to take a post-growth orientation in research, design, and practice to reimagine the design of sociotechnical systems toward advancing sustainable, just, and humane futures. We aim for the critiques, concerns, and recommendations offered by post-growth to be integrated into transformative HCI practices for technology-mediated change.</p>
<h2>Health Ecosystems</h2>
<h3>Towards AI-Driven Healthcare: Systematic Optimization, Linguistic Analysis, and Clinicians’ Evaluation of Large Language Models for Smoking Cessation Interventions</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Emily Hébert, Michael Businelle, Chongle Pan, Darla Kendzor, Ruosi Shao, Jordan Neil, Yunlong Liu, Paul Calle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147450">Link</a></p>
<p>Abstract: Creating intervention messages for smoking cessation is a labor-intensive process. Advances in Large Language Models (LLMs) offer a promising alternative for automated message generation. Two critical questions remain: 1) How to optimize LLMs to mimic human expert writing, and 2) Do LLM-generated messages meet clinical standards? We systematically examined the message generation and evaluation processes through three studies investigating prompt engineering (Study 1), decoding optimization (Study 2), and expert review (Study 3). We employed computational linguistic analysis in LLM assessment and established a comprehensive evaluation framework, incorporating automated metrics, linguistic attributes, and expert evaluations. Certified tobacco treatment specialists assessed the quality, accuracy, credibility, and persuasiveness of LLM-generated messages, using expert-written messages as the benchmark. Results indicate that larger LLMs, including ChatGPT, OPT-13B, and OPT-30B, can effectively emulate expert writing to generate well-written, accurate, and persuasive messages, thereby demonstrating the capability of LLMs in augmenting clinical practices of smoking cessation interventions.</p>
<h3>PsiNet: Toward Understanding the Design of Brain-to-Brain Interfaces for Augmenting Inter-Brain Synchrony</h3>
<p>BEST_PAPER</p>
<p>Authors: Florian Mueller, Don Samitha Elvitigala, Nathan Semertzidis, Michaela Vranic-Peters, Aryan Saini, Xiao Fang, Rakesh Patibanda</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146996">Link</a></p>
<p>Abstract: Underlying humanity’s social abilities is the brain’s capacity to interpersonally synchronize. Experimental, lab-based neuropsychological studies have demonstrated that inter-brain synchrony can be technologically mediated. However, knowledge in deploying these technologies in-the-wild and studying their user experience, an area HCI excels in, is lacking. With advances in mobile brain sensing and stimulation, we identify an opportunity for HCI to investigate the in-the-wild augmentation of inter-brain synchrony. We designed “PsiNet,” the first wearable brain-to-brain system aimed at augmenting inter-brain synchrony in-the-wild. Participant interviews illustrated three themes that describe the user experience of modulated inter-brain synchrony: hyper-awareness; relational interaction; and the dissolution of self. We contribute these three themes to assist HCI theorists’ discussions of inter-brain synchrony experiences. We also present three practical design tactics for HCI practitioners designing inter-brain synchrony, and hope that our work guides a HCI future of brain-to-brain experiences which fosters human connection.</p>
<h3>Societal-Scale Human-AI Interaction Design? How Hospitals and Companies are Integrating Pervasive Sensing into Mental Healthcare</h3>
<p>Authors: Qian Yang, Meir Friedenberg, Angel Hsing-Chi Hwang, Dan Adler</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148145">Link</a></p>
<p>Abstract: From wearable health tracking to sensor-laden cities, AI-enhanced pervasive sensing platforms promise far-reaching benefits yet also introduce societal risks. How might designers of these platforms effectively navigate their complex ecology and sociotechnical dynamics? To explore this question, we interviewed designers building mental health technologies who undertook this challenge. They are hospital chief medical information officers and startup founders together striving to create new sensors/AI platforms and integrate them into the healthcare ecosystem. We found that, while all designers aspired to build comprehensive care platforms, their efforts focused on serving either consumers or physicians, delivering a subset of healthcare interventions, and demonstrating system effectiveness one metric at a time. Consequently, breakdowns in patient journeys are emerging; societal risks loom large. We describe how the data economy, designers' mindsets, and evaluation challenges led to these unintended design consequences. We discuss implications for designing pervasive sensing and AI platforms for social good.</p>
<h3>Clinician-Facing AI in the Wild: Taking Stock of the Sociotechnical Challenges and Opportunities for HCI</h3>
<p>Authors: Tariq Andersen, Xiang Dai, Dana Li, Hubert Zając, Jonathan Frederik Carlsen, Finn Kensing</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150869">Link</a></p>
<p>Abstract: Artificial Intelligence (AI) in medical applications holds great promise. However, the use of Machine Learning-based (ML) systems in clinical practice is still minimal. It is uniquely difficult to introduce clinician-facing ML-based systems in practice, which has been recognised in HCI and related fields. Recent publications have begun to address the sociotechnical challenges of designing, developing, and successfully deploying clinician-facing ML-based systems. We conducted a qualitative systematic review and provided answers to the question: “How can HCI researchers and practitioners contribute to the successful realisation of ML in medical practice?” We reviewed 25 eligible papers that investigated the real-world clinical implications of concrete clinician-facing ML-based systems. The main contributions of this systematic review are: (1) an overview of the technical aspects of ML innovation and their consequences for HCI researchers and practitioners; (2) a description of the different roles that ML-based systems can take in clinical settings; (3) a conceptualisation of the main activities of medical ML innovation processes; (4) identification of five sociotechnical interdependencies that emerge from medical ML innovation; and (5) implications for HCI researchers and practitioners on how to mitigate the sociotechnical challenges of medical ML innovation.</p>
<h3>“We are Researchers, but we are also Humans”: Creating a Design Space for Managing Graduate Student Stress</h3>
<p>Authors: Stephen Voida, Fujiko Robledo Yamamoto, Amy Voida</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150823">Link</a></p>
<p>Abstract: Graduate students are facing a mental health crisis due to a combination of individual, community, and societal factors. Many existing stress management interventions engage with one factor at a time, typically focusing on providing a user with data about their stress state. We conducted co-design workshops with graduate students who work closely together to explore their strategies for managing stress and to learn about what types of technologies they envision to help address their stress. Using Ecological Systems Theory as an conceptual framework, our analysis of the designs and discussions from these workshops contributes an expanded design space for stress management—one that foregrounds the affordances and challenges of designing interventions that cut across ecological systems levels along with designs that approach stress management using a broader diversity of strategies: controlling, disconnecting, and normalizing stress. We argue that this expanded design space embraces a more holistic and human approach to designing stress management technologies.</p>
<h2>Hybrid and Immersive Experiences</h2>
<h3>Factors Influencing Engagement in Hybrid Virtual and Augmented Reality</h3>
<p>Authors: Yue Li, Eugene Ch'ng, Sue Cobb</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150873">Link</a></p>
<p>Abstract: Hybridity in immersive technologies has not been studied for factors that are likely to influence engagement. A noticeable factor is the spatial enclosure that defines where users meet. This involves a mutual object of interest, contents that the users may generate around the object, and the proximity between users. This study examines these factors, namely how object interactivity, user-generated contents (UGC) and avatar proximity influence engagement. We designed a Hybrid Virtual and Augmented Reality (HVAR) environment that supports paired users to experience cultural heritage in both Virtual Reality (VR) and Augmented Reality (AR). A user study was conducted with 60 participants, providing assessments of engagement and presence via questionnaires, together with mobile electroencephalogram (mEEG) and user activity data that measures VR user engagement in real-time. Our findings provide insights into how engagement between users can occur in HVAR environments for the future hybrid reality with multi-device connectivity.</p>
<h3>Visual Noise Cancellation: Exploring Visual Discomfort and Opportunities for Vision Augmentations</h3>
<p>Authors: Jonathan Sutton, Tobias Langlotz, Holger Regenbrecht, Junlei Hong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150772">Link</a></p>
<p>Abstract: Acoustic noise control or cancellation (ANC) is a commonplace component of modern audio headphones. ANC aims to actively mitigate disturbing environmental noise for a quieter and improved listening experience. ANC is digitally controlling frequency and amplitude characteristics of sound. Much less explored is visual noise and active visual noise control, which we address here. We first explore visual noise and scenarios in which visual noise arises based on findings from four workshops we conducted. We then introduce the concept of visual noise cancellation (VNC) and how it can be used to reduce identified effects of visual noise. In addition, we developed head-worn demonstration prototypes to practically explore the concept of active VNC with selected scenarios in a user study. Finally, we discuss the application of VNC, including vision augmentations that moderate the user's view of the environment to address perceptual needs and to provide augmented reality content.</p>
<h3>\textit{Cohabitant}: The Design, Implementation, and Evaluation of a Virtual Reality Application for Interfaith Learning and Empathy Building</h3>
<p>Authors: Hasan Shahid Ferdous, Mohammad Rashidujjaman Rifat, Dina Sabie, Syed Ishtiaque Ahmed, Reem Ayad, Robert Soden, Bingjian Huang, Selin Okman, Ashratuz Zavin Asha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147831">Link</a></p>
<p>Abstract: Lack of interfaith communication often gives rise to prejudice and group-based conflict in multi-faith societies. Nurturing this communication via interfaith learning may reduce this conflict by fostering interfaith empathy. HCI has a dearth of knowledge on interfaith coexistence and empathy building. To address this gap, we present the design, implementation, and usability of \textit{Cohabitant}: a virtual reality (VR) application that promotes interfaith learning and empathy. \textit{Cohabitant}'s design is theoretically underpinned by Allport's intergroup contact theory and informed by insights from a participatory workshop we ran with members of three religious groups: Christians, Hindus, and Muslims. Our evaluation study, combining quantitative and qualitative data from 30 participants, suggests that \textit{Cohabitant} may enhance general interpersonal empathy, but falls short for ethnocultural empathy. We discuss the possible design and policy implications of using this kind of VR technology for interfaith learning and empathy building.</p>
<h3>Navigating the Virtual Gaze: Social Anxiety's Role in VR proxemics</h3>
<p>Authors: Pascal Knierim, Marissa Verbokkem, Beatriz Mello, Martin Dechant, Robin Welsch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148238">Link</a></p>
<p>Abstract: For individuals with Social Anxiety (SA), interacting with others can be a challenging experience, a concern that extends into the virtual world. While technology has made significant strides in creating more realistic virtual human agents (VHA), the interplay of gaze and interpersonal distance when interacting with VHAs is often neglected. This paper investigates the effect of dynamic and static Gaze animations in VHAs on interpersonal distance and their relation to SA. A Bayesian analysis shows that static centered and dynamic centering gaze led participants to stand closer to VHAs than static averted and dynamic averting gaze, respectively. In the static gaze conditions, this pattern was found to be reversed in SA: participants with higher SA kept larger distances for static-centered gaze than for averted gaze VHAs. These findings update theory, elucidate how nuanced interactions with VHAs must be designed, and offer renewed guidelines for pleasant VHA interaction design.</p>
<h2>Assistive Interactions: Audio Interactions and d/Deaf and Hard of Hearing Users</h2>
<h3>Audio Engineering by People Who Are deaf and Hard of Hearing: Balancing Confidence and Limitations</h3>
<p>Authors: Mark Cartwright, Keita Ohshiro</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146895">Link</a></p>
<p>Abstract: With technological advancements, audio engineering has evolved from a domain exclusive to professionals to one open to amateurs. However, research is limited on the accessibility of audio engineering, particularly for deaf, Deaf, and hard of hearing (DHH) individuals. To bridge this gap, we interviewed eight deaf and hard of hearing (dHH) audio engineers in music to understand accessibility in audio engineering. We found that their hearing magnified challenges in audio engineering: insecurities in sound perception undermined their confidence, and the required extra <code>hearing work'' added complexity. As workarounds, participants employed various technologies and techniques, relied on the support of hearing peers, and developed strategies for learning and growth. Through these practices, they navigate audio engineering while balancing confidence and limitations. For future directions, we recommend exploring technologies that reduce insecurities and</code>hearing work'' to empower DHH audio engineers and working toward a DHH-community-driven approach to accessible audio engineering.</p>
<h3>Look Once to Hear: Target Speech Hearing with Noisy Examples</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Bandhav Veluri, Takuya Yoshioka, Shyamnath Gollakota, Malek Itani, Tuochao Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147319">Link</a></p>
<p>Abstract: In crowded settings, the human brain can focus on speech from a target speaker, given prior knowledge of  how they sound. We introduce a novel intelligent hearable system that achieves this capability, enabling target speech hearing to ignore  all interfering speech and noise, but the target speaker. A naive approach is to  require a clean speech example  to enroll the target speaker. This is however not well aligned with the hearable application domain since  obtaining a clean  example is challenging in  real world scenarios, creating a unique user interface problem. We present the first enrollment interface where the wearer looks at the target speaker for a few seconds to  capture a single, short, highly noisy, binaural example  of the target speaker. This noisy example is used for enrollment and subsequent speech extraction in the presence of interfering speakers and noise.</p>
<p>Our  system achieves a  signal quality improvement of 7.01 dB using less than 5 seconds of noisy enrollment audio and can process 8 ms of audio chunks  in 6.24 ms on an embedded CPU. Our user studies demonstrate generalization to real-world static and mobile speakers in previously unseen indoor and outdoor multipath environments. Finally, our  enrollment interface for noisy examples does not cause performance degradation compared to clean examples, while being convenient and user-friendly. Taking a step back, this paper takes an important step towards  enhancing the human auditory perception with artificial intelligence.</p>
<h3>Communication, Collaboration, and Coordination in a Co-located Shared Augmented Reality Game: Perspectives From Deaf and Hard of Hearing People</h3>
<p>Authors: Nicolas LaLone, Garreth Tigwell, Samuli Laato, Jiangnan Xu, Michael Saker, Sanzida Mojib Luna, John Dunham, Alan Chamberlain, Yihong Wang, Konstantinos Papangelis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147649">Link</a></p>
<p>Abstract: Co-located collaborative shared augmented reality (CS-AR) environments have gained considerable research attention, mainly focusing on design, implementation, accuracy, and usability. Yet, a gap persists in our understanding regarding the accessibility and inclusivity of such environments for diverse user groups, such as deaf and Hard of Hearing (DHH) people. To investigate this domain, we used Urban Legends, a multiplayer game in a co-located CS-AR setting. We conducted a user study followed by one-on-one interviews with 17 DHH participants. Our findings revealed the usage of multimodal communication (verbal and non-verbal) before and during the game, impacting the amount of collaboration among participants and how their coordination with AR components, their surroundings, and other participants improved throughout the rounds. We utilize our data to propose design enhancements, including onscreen visuals and speech-to-text transcription, centered on participant perspectives and our analysis.</p>
<h3>"Voices Help Correlate Signs and Words": Analyzing Deaf and Hard-of-Hearing (DHH) TikTokers’ Content, Practices, and Pitfalls</h3>
<p>Authors: Jiaxun Cao, Fan Liang, Xin Tong, Xuening Peng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148325">Link</a></p>
<p>Abstract: Video-sharing platforms such as TikTok have offered new opportunities for d/Deaf and hard-of-hearing (DHH) people to create public-facing content using sign language -- an integral part of DHH culture. Besides sign language, DHH creators deal with a variety of modalities when creating videos, such as captions and audio. However, hardly any work has comprehensively addressed DHH creators' multimodal practices with the lay public's reactions taken into account. In this paper, we systematically analyzed 308 DHH-authored TikTok videos using a mixed-methods approach, focusing on DHH TikTokers' content, practices, pitfalls, and viewer engagement. Our findings highlight that while voice features such as synchronous voices are scant and challenging for DHH TikTokers, they may help promote viewer engagement. Other empirical findings, including the distributions of topics, practices, pitfalls, and their correlations with viewer engagement, further lead to actionable suggestions for DHH TikTokers and video-sharing platforms.</p>
<h2>Online Toxicity</h2>
<h3>Counterspeakers’ Perspectives: Unveiling Barriers and AI Needs in the Fight against Online Hate</h3>
<p>Authors: Jimin Mun, Cathy Buerger, Joshua Garland, Maarten Sap, Jenny Liang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147002">Link</a></p>
<p>Abstract: Counterspeech, i.e., direct responses against hate speech, has become an important tool to address the increasing amount of hate online while avoiding censorship. Although AI has been proposed to help scale up counterspeech efforts, this raises questions of how exactly AI could assist in this process, since counterspeech is a deeply empathetic and agentic process for those involved. In this work, we aim to answer this question, by conducting in-depth interviews with 10 extensively experienced counterspeakers and a large scale public survey with 342 everyday social media users. In participant responses, we identified four main types of barriers and AI needs related to resources, training, impact, and personal harms. However, our results also revealed overarching concerns of authenticity, agency, and functionality in using AI tools for counterspeech. To conclude, we discuss considerations for designing AI assistants that lower counterspeaking barriers without jeopardizing its meaning and purpose.</p>
<h3>“Vulnerable, Victimized, and Objectified”: Understanding Ableist Hate and Harassment Experienced by Disabled Content Creators on Social Media</h3>
<p>Authors: Sharon Heung, Lucy Jiang, Shiri Azenkot, Aditya Vashistha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147153">Link</a></p>
<p>Abstract: Content creators (e.g., gamers, activists, vloggers) with marginalized identities are at-risk of experiencing hate and harassment. This paper examines the ableist hate and harassment that disabled content creators experience on social media. Through surveys (N=50) and interviews (N=20) with disabled creators, we developed a taxonomy of 11 types of ableist hate and harassment (e.g., eugenics-related speech, denial and stigmatization of accessibility) and outlined how ableism harms creators’ well-being and content creation practices. Using statistical modeling, we investigated differences in ableist experiences given creators’ intersecting identities such as race and sexuality. We found that LGBTQ disabled creators face significantly more ableist hate compared to non-LGBTQ disabled creators. Lastly, we discuss our findings through an infrastructure lens to highlight how disabled creators experience platform-enabled ableism, undergo labor to cope with hate, and develop strategies to safeguard against future hate.</p>
<h3>"It’s Not What We Were Trying to Get At, but I Think Maybe It Should Be": Learning How to Do Trauma-Informed Design With a Data Donation Platform for Online Dating Sexual Violence</h3>
<p>Authors: Michele Parkhill, Emma Walquist, Isha Datey, Dongxiao Zhu, Douglas Zytko, Xiangyu Zhou, Kelly Berishaj, Melissa McDonald, Wenqi Zheng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147295">Link</a></p>
<p>Abstract: A majority of people experience trauma, spurring calls to incorporate trauma-informed approaches (TIA) from public health and social work into technology design. While technologies touted as trauma-informed are starting to propagate the literature, there persists a gap in knowledge around how design teams apply TIA and qualify their technology as adhering to trauma-informed principles. We address this through a 12-month development project with trauma and sexual violence experts to produce Ube, a data donation platform for collecting online dating sexual consent data to improve sexual risk detection AI. Through analysis of design documentation we retrospectively articulate a trauma-informed design process that evolved through the course of Ube’s development, comprising three elements for integrating trauma-informed principles: design goals that adapt the definition of TIA to the application domain, design activities that map to trauma-informed principles, and consequent design choices. We conclude with methodological recommendations to improve trauma-informed design processes.</p>
<h3>"I Got Flagged for Supposed Bullying, Even Though It Was in Response to Someone Harassing Me About My Disability.": A Study of Blind TikTokers’ Content Moderation Experiences</h3>
<p>Authors: Kelley Cotter, Anisa Callis, Yao Lyu, Jie Cai, John Carroll</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146733">Link</a></p>
<p>Abstract: The Human-Computer Interaction (HCI) community has consistently focused on the experiences of users moderated by social media platforms. Recently, scholars have noticed that moderation practices could perpetuate biases, resulting in the marginalization of user groups undergoing moderation. However, most studies have primarily addressed marginalization related to issues such as racism or sexism, with little attention given to the experiences of people with disabilities. In this paper, we present a study on the moderation experiences of blind users on TikTok, also known as "BlindToker," to address this gap. We conducted semi-structured interviews with 20 BlindTokers and used thematic analysis to analyze the data. Two main themes emerged: BlindTokers' situated content moderation experiences and their reactions to content moderation. We reported on the lack of accessibility on TikTok's platform, contributing to the moderation and marginalization of BlindTokers. Additionally, we discovered instances of harassment from trolls that prompted BlindTokers to respond with harsh language, triggering further moderation. We discussed these findings in the context of the literature on moderation, marginalization, and transformative justice, seeking solutions to address such issues.</p>
<h3>Malicious Selling Strategies in Livestream E-commerce: A Case Study of Alibaba’s Taobao and ByteDance’s TikTok</h3>
<p>Authors: Zhicong Lu, Dakuo Wang, Qunfang Wu, Yisi Sang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150847">Link</a></p>
<p>Abstract: Due to the limitations imposed by the COVID-19 pandemic, customers have shifted their shopping patterns from offline to online. Livestream shopping has become popular as one of the online shopping media. However, various streamers’ malicious selling behaviors have been reported. In this research, we sought to explore streamers’ malicious selling strategies and understand how viewers perceive these strategies. First, we recorded 40 livestream shopping sessions from two popular livestream platforms in China—Taobao, and TikTok. We identified 16 malicious selling strategies that were used to deceive, coerce, or manipulate viewers and found that platform designs enhanced nine of the malicious selling strategies. Second, through an interview study with 13 viewers, we report three challenges of overcoming malicious selling in relation to imbalanced power between viewers, streamers, and the platforms. We conclude by discussing the policy and design implications of countering malicious selling.</p>
<h2>Knowledge Workers and Crowdworkers</h2>
<h3>"Are we all in the same boat?" Customizable and Evolving Avatars to Improve Worker Engagement and Foster a Sense of Community in Online Crowd Work</h3>
<p>Authors: Esra de Groot, Ujwal Gadiraju</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146646">Link</a></p>
<p>Abstract: Human intelligence continues to be essential in building ground-truth data, training sets, and for evaluating a plethora of systems. The democratized and distributed nature of online crowd work — an attractive and accessible feature that has led to the proliferation of the paradigm — has also meant that crowd workers may not always feel connected to their remote peers. Despite the prevalence of collaborative crowdsourcing practices, workers on many microtask crowdsourcing platforms work on tasks individually and are seldom directly exposed to other crowd workers. In this context, improving worker engagement on microtask crowdsourcing platforms is an unsolved challenge. At the same time, fostering a sense of community among workers can improve the sustainability and working conditions in crowd work. This work aims to increase worker engagement in conversational microtask crowdsourcing by leveraging evolving avatars that workers can customize as they progress through monotonous task batches. We also aim to improve group identification in individual tasks by creating a community space where workers can share their avatars and feelings on task completion. To this end, we carried out a preregistered between-subjects controlled study (N = 680) spanning five experimental conditions and two task types. We found that evolving and customizable worker avatars can increase worker retention. The prospect of sharing worker avatars and task-related feelings in a community space did not consistently affect group identification. Our exploratory analysis indicated that workers who identify themselves as crowd workers experienced greater intrinsic motivation, subjective engagement, and perceived workload. Furthermore, we discuss how task differences shape the relative effectiveness of our interventions. Our findings have important theoretical and practical implications for designing conversational crowdsourcing tasks and in shaping new directions for research to improve crowd worker experiences. </p>
<h3>How Low is Low? Crowdworker Perceptions of Microtask Payments in Work versus Leisure Situations</h3>
<p>Authors: Ling Jiang, Christian Wagner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147248">Link</a></p>
<p>Abstract: Getting paid for completing microtasks online via crowdsourcing (i.e., microworking) has become a widely accepted way to earn money. Despite disputes over low pay rates, however, little is known about the extent of “lowness” and about the perceptions of microworkers concerning the value of micro-paid online activity. In an online survey on a microtask crowdsourcing platform, respondents demonstrated the dual attitudes of work and leisure toward microworking. Although actual wage rates were lower than microworkers expected, the perceived value of the money earned from microworking was paramount. The monetary equivalent, a newly developed metric calibrating microworkers’ subjective evaluations of monetary and nonmonetary dimensions, of microworking outstripped that of alternative activities, the majority of which were leisure activities. Instead of struggling with below-expectation pay rates, microworkers tend to appreciate the value of small gains, especially in contrast to potential losses incurred by alternatives activities.</p>
<h3>LabelAId: Just-in-time AI Interventions for Improving Human Labeling Quality and Domain Knowledge in Crowdsourcing Systems</h3>
<p>Authors: Zhihan Zhang, Michael Saugstad, Tim Althoff, Jon Froehlich, Vikram Iyer, Xiaoyu Huang, Esteban Safranchik, Chaitanyashareef Kulkarni, Chu Li, Shwetak Patel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147498">Link</a></p>
<p>Abstract: Crowdsourcing platforms have transformed distributed problem-solving, yet quality control remains a persistent challenge. Traditional quality control measures, such as prescreening workers and refining instructions, often focus solely on optimizing economic output. This paper explores just-in-time AI interventions to enhance both labeling quality and domain-specific knowledge among crowdworkers. We introduce LabelAId, an advanced inference model combining Programmatic Weak Supervision (PWS) with FT-Transformers to infer label correctness based on user behavior and domain knowledge. Our technical evaluation shows that our LabelAId pipeline consistently outperforms state-of-the-art ML baselines, improving mistake inference accuracy by 36.7% with 50 downstream samples. We then implemented LabelAId into Project Sidewalk, an open-source crowdsourcing platform for urban accessibility. A between-subjects study with 34 participants demonstrates that LabelAId significantly enhances label precision without compromising efficiency while also increasing labeler confidence. We discuss LabelAId's success factors, limitations, and its generalizability to other crowdsourced science domains.</p>
<h3>How Knowledge Workers Think Generative AI Will (Not) Transform Their Industries</h3>
<p>Authors: Jamila Smith-Loud, Patrick Kelley, Allison Woodruff, Renee Shelby, Lauren Wilcox, Steven Rousso-Schindler</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147564">Link</a></p>
<p>Abstract: Generative AI is expected to have transformative effects in multiple knowledge industries. To better understand how knowledge workers expect generative AI may affect their industries in the future, we conducted participatory research workshops for seven different industries, with a total of 54 participants across three US cities. We describe participants' expectations of generative AI's impact, including a dominant narrative that cut across the groups' discourse: participants largely envision generative AI as a tool to perform menial work, under human review. Participants do not generally anticipate the disruptive changes to knowledge industries currently projected in common media and academic narratives. Participants do however envision generative AI may amplify four social forces currently shaping their industries: deskilling, dehumanization, disconnection, and disinformation. We describe these forces, and then we provide additional detail regarding attitudes in specific knowledge industries. We conclude with a discussion of implications and research challenges for the HCI community.</p>
<h3>“Sometimes it’s Like Putting the Track in Front of the Rushing Train”: Having to Be ‘On Call’ for Work Limits the Temporal Flexibility of Crowdworkers</h3>
<p>Authors: Duncan Brumby, Anna Cox, Sandy Gould, Laura Lascau</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150655">Link</a></p>
<p>Abstract: Research suggests that the temporal flexibility advertised to crowdworkers by crowdsourcing platforms is limited by both client-imposed constraints (e.g., strict completion times) and crowdworkers’ tooling practices (e.g., multitasking). In this article, we explore an additional contributor to workers’ limited temporal flexibility: the design of crowdsourcing platforms, namely requiring crowdworkers to be ‘on call’ for work. We conducted two studies to investigate the impact of having to be ‘on call’ on workers’ schedule control and job control. We find that being ‘on call’ impacted (1) participants’ ability to schedule their time and stick to planned work hours, and (2) the pace at which participants worked and took breaks. The results of the two studies suggest that the ‘on-demand’ nature of crowdsourcing platforms can limit workers’ temporal flexibility by reducing schedule control and job control. We conclude the article by discussing the implications of the results for (a) crowdworkers, (b) crowdsourcing platforms, and (c) the wider platform economy.</p>
<h2>Mid-air Haptics</h2>
<h3>Designing Distinguishable Mid-Air Ultrasound Tactons with Temporal Parameters</h3>
<p>Authors: Gunhyuk Park, Hasti Seifi, Chungman Lim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147761">Link</a></p>
<p>Abstract: Mid-air ultrasound technology offers new design opportunities for contactless tactile patterns (i.e., Tactons) in user applications. Yet, few guidelines exist for making ultrasound Tactons easy to distinguish for users. In this paper, we investigated the distinguishability of temporal parameters of ultrasound Tactons in five studies (n=72 participants). Study 1 established the discrimination thresholds for amplitude-modulated (AM) frequencies. In Studies 2-5, we investigated distinguishable ultrasound Tactons by creating four Tacton sets based on mechanical vibrations in the literature and collected similarity ratings for the ultrasound Tactons. We identified a subset of temporal parameters, such as rhythm and low envelope frequency, that could create distinguishable ultrasound Tactons. Also, a strong correlation (mean Spearman's ρ=0.75) existed between similarity ratings for ultrasound Tactons and similarities of mechanical Tactons from the literature, suggesting vibrotactile designers can transfer their knowledge to ultrasound design. We present design guidelines and future directions for creating distinguishable mid-air ultrasound Tactons.</p>
<h3>Controlled-STM: A two-stage model to predict user’s Perceived Intensity for Multi-point Spatiotemporal Modulation in Ultrasonic Mid-air Haptics</h3>
<p>Authors: Zhouyang Shen, Madhan Kumar Vasudevan, Diego Martinez Plasencia, Zak Morgan, Marianna Obrist</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147738">Link</a></p>
<p>Abstract: Multi-point STM offers a great range of parameters (i.e., drawing frequency, number of points) to produce different tactile sensations. However, existing studies offer limited insight on the effects of these parameters, and ignore their effect on the physical stimuli delivered, limiting effective haptic design.  </p>
<p>We propose a two-stage model to predict response to multi-point STM. The first stage predicts physical stimulus properties with 7.8\% error, while the second stage predicts mean and spread of perceived intensity with 8.0\% and 8.8\% error. </p>
<p>We report 3 studies conducted to derive this model: one to characterize physical stimuli, another one measuring user perceptual thresholds, and a third one measuring user’s perceptual response to multi-point STM. Besides, we characterize 4 effects that influence device performance, confirm if previous effects reported are due to physical or perceptual effects (or both) and derive recommendations for manufacturers, haptic designers and HCI researchers.</p>
<h3>Designing Haptic Feedback for Sequential Gestural Inputs</h3>
<p>Authors: Shan Xu, Tovi Grossman, Carine Rognon, Daylon Walden, Sarah Sykes, Michael Glueck, Parastoo Abtahi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147360">Link</a></p>
<p>Abstract: This work seeks to design and evaluate haptic feedback for sequential gestural inputs, where mid-air hand gestures are used to express system commands. Nine haptic patterns are first designed leveraging metaphors. To pursue efficient interaction, we examine the trade-off between pattern duration and recognition accuracy and find that durations as short as 0.3s-0.5s achieve roughly 80\%-90\% accuracy. We then examine the haptic design for sequential inputs, where we vary when the feedback for each gesture is provided, along with pattern duration, gesture sequence length, and age. Results show that providing haptic patterns right after detected hand gestures leads to significantly more efficient interaction compared with concatenating all haptic patterns after the gesture sequence. Moreover, the number of gestures had little impact on performance, but age is a significant predictor. Our results suggest that immediate feedback with 0.3s and 0.5s pattern duration would be recommended for younger and older users respectively.</p>
<h3>Expressive, Scalable, Mid-Air Haptics with Synthetic Jets</h3>
<p>Authors: Vivian Shen, Chris Harrison, Craig Shultz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150752">Link</a></p>
<p>Abstract: Non-contact, mid-air haptic devices have been utilized for a wide variety of experiences, including those in extended reality, public displays, medical, and automotive domains. In this work, we explore the use of synthetic jets as a promising and under-explored mid-air haptic feedback method. We show how synthetic jets can scale from compact, low-powered devices, all the way to large, long-range, and steerable devices. We built seven functional prototypes targeting different application domains, in order to illustrate the broad applicability of our approach. These example devices are capable of rendering complex haptic effects, varying in both time and space. We quantify the physical performance of our designs using spatial pressure and wind flow measurements, and validate their compelling effect on users with stimuli recognition and qualitative studies. </p>
<h2>Workers, Work Practices and AI</h2>
<h3>The Role of Inclusion, Control, and Ownership in Workplace AI-Mediated Communication</h3>
<p>Authors: Christin Munsch, Kowe Kadoma, Xiyu Fu, Marianne Aubin Le Quere, Danaë Metaxa, Mor Naaman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147700">Link</a></p>
<p>Abstract: Given large language models' (LLMs) increasing integration into workplace software, it is important to examine how biases in the models may impact workers. For example, stylistic biases in the language suggested by LLMs may cause feelings of alienation and result in increased labor for individuals or groups whose style does not match. We examine how such writer-style bias impacts inclusion, control, and ownership over the work when co-writing with LLMs. In an online experiment, participants wrote hypothetical job promotion requests using either hesitant or self-assured autocomplete suggestions from an LLM and reported their subsequent perceptions. We found that the style of the AI model did not impact perceived inclusion. However, individuals with higher perceived inclusion did perceive greater agency and ownership, an effect more strongly impacting participants of minoritized genders. Feelings of inclusion mitigated a loss of control and agency when accepting more AI suggestions.</p>
<h3>“There is a Job Prepared for Me Here”: Understanding How Short Video and Live-streaming Platforms Empower Ageing Job Seekers in China</h3>
<p>Authors: Bo Wen, PiaoHong Wang, Zhicong Lu, Siying Hu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147237">Link</a></p>
<p>Abstract: In recent years, the global unemployment rate has remained persistently high. Compounding this issue, the ageing population in China often encounters additional challenges in finding employment due to prevalent age discrimination in daily life. However, with the advent of social media, there has been a rise in the popularity of short videos and live-streams for recruiting ageing workers. To better understand the motivations of ageing job seekers to engage with these video-based recruitment methods and to explore the extent to which such platforms can empower them, we conducted an interview-based study with ageing job seekers who have had exposure to these short recruitment videos and live-streaming channels. Our findings reveal that these platforms can provide a job-seeking choice that is particularly friendly to ageing job seekers, effectively improving their disadvantaged situation.</p>
<h3>Deconstructing the Veneer of Simplicity: Co-Designing Introductory Generative AI Workshops with Local Entrepreneurs</h3>
<p>Authors: Glenn Ford, Michael Skirpan, Jeffrey Bigham, Angel Anderson, Yasmine Kotturi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147681">Link</a></p>
<p>Abstract: Generative AI platforms and features are permeating many aspects of work. Entrepreneurs from lean economies in particular are well positioned to outsource tasks to generative AI given limited resources. In this paper, we work to address a growing disparity in use of these technologies by building on a four-year partnership with a local entrepreneurial hub dedicated to equity in tech and entrepreneurship. Together, we co-designed an interactive workshops series aimed to onboard local entrepreneurs to generative AI platforms. Alongside four community-driven and iterative workshops with entrepreneurs across five months, we conducted interviews with 15 local entrepreneurs and community providers. We detail the importance of communal and supportive exposure to generative AI tools for local entrepreneurs, scaffolding actionable use (and supporting non-use), demystifying generative AI technologies by emphasizing entrepreneurial power, while simultaneously deconstructing the veneer of simplicity to address the many operational skills needed for successful application.</p>
<h3>How Do Data Analysts Respond to AI Assistance? A Wizard-of-Oz Study</h3>
<p>Authors: Tim Althoff, Jeffrey Heer, Madeleine Grunde-McLaughlin, Ken Gu, Andrew McNutt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146787">Link</a></p>
<p>Abstract: Data analysis is challenging as analysts must navigate nuanced decisions that may yield divergent conclusions. AI assistants have the potential to support analysts in planning their analyses, enabling more robust decision making. Though AI-based assistants that target code execution (e.g., Github Copilot) have received significant attention, limited research addresses assistance for both analysis execution and planning. In this work, we characterize helpful planning suggestions and their impacts on analysts’ workflows. We first review the analysis planning literature and crowd-sourced analysis studies to categorize suggestion content. We then conduct a Wizard-of-Oz study (n=13) to observe analysts’ preferences and reactions to planning assistance in a realistic scenario. Our findings highlight subtleties in contextual factors that impact suggestion helpfulness, emphasizing design implications for supporting different abstractions of assistance, forms of initiative, increased engagement, and alignment of goals between analysts and assistants.</p>
<h3>Building Knowledge through Action: Considerations for Machine Learning in the Workplace</h3>
<p>Authors: Siân Lindley, Denise Wilkins</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150819">Link</a></p>
<p>Abstract: Innovations in machine learning are enabling organisational knowledge bases to be automatically generated from working people’s activities. The potential for these to shift the ways in which knowledge is produced and shared raises questions about what types of knowledge might be inferred from working people’s actions, how these can be used to support work, and what the broader ramifications of this might be. This paper draws on findings from studies of (i) collaborative actions, and (ii) knowledge actions, to explore how these actions might (i) inform automatically generated knowledge bases, and (ii) be better supported through technological innovation. We triangulate findings to develop a framework of actions that are performed as part of everyday work, and use this to explore how mining those actions could result in knowledge being explicitly and implicitly contributed to a knowledge base. We draw on these possibilities to highlight implications and considerations for responsible design.</p>
<h2>Learning and Working</h2>
<h3>Contrasting Perspectives of Workers: Exploring Labor Relations in Workplace Automation and Potential Interventions</h3>
<p>Authors: Hee Rin Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147381">Link</a></p>
<p>Abstract: Many emerging technologies are expected to reconfigure workplaces, and serious concerns have already been raised about their impact on workers, especially those who are already precarious. This study explores what roles designers can play to address power issues regarding workplace automation. Following Marxist researchers addressing the importance of analyzing “struggle” as an event that reveals power relations in workplaces, this study examines conflicting views between stakeholders regarding the value of newly adopted robots, and the value of the human labor that the robots could displace. In this study, workers---even those who perform the same tasks---have conflicting views regarding how their work can be automated: the collective voice of workers is not naturally formed. This observation can be seen as closely related to the weakened solidarity among workers not only in the US but internationally, due to the neoliberal restructuring of labor market and corporations. Considering the unique countervailing power of worker solidarity, this study proposes a new role for designers: facilitator of “inclusive collective imaginaries” by bridging workers’ divided opinions, addressing the importance of inclusive solidarity, and mobilizing them to successfully contribute to shaping automation technologies as a way to intervene in automation-related issues.</p>
<h3>Designing Instructions using Self-Determination Theory to Improve Motivation and Engagement for Learning Craft</h3>
<p>Authors: Carsten Röcker, Gustavo Rovelo Ruiz, Hitesh Dhiman, Danny Leen, Raf Ramakers</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147763">Link</a></p>
<p>Abstract: Recent HCI research has shown significant interest in investigating digital working instructions for guiding novices to perform manual tasks. While performance enhancement has been a primary focus, it is increasingly recognized that technology's impact extends beyond objective metrics. Trainee motivation and engagement plays a pivotal role in enhancing learning outcomes and effectiveness. This paper investigates the utilization of principles from Self Determination Theory--clear attainable goals, meaningful rationale, and perspective taking--in designing multimedia instructions to enhance novice users' indicators of psychological well-being. We present findings from an experiment involving real-world woodworking, where novice users, in a between-subjects study, followed interactive, in-situ projection-based guidance. Results demonstrate that adhering to SDT postulates can positively influence perceived competence, intrinsic motivation and task execution quality. These findings offer valuable insights for designing digital instructions to guide and train novices, emphasizing the importance of psychological well-being alongside task performance.</p>
<h3>Learning from Hybrid Craft: Investigating and Reflecting on Innovating and Enlivening Traditional Craft through Literature Review</h3>
<p>Authors: Li Huang, Guanhong Liu, Yuting Diao, Qingyuan Shi, Tianyu Yu, Zhijun Ma, Yuan Yao, Beituo Liu, Yuan-Ling Feng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147895">Link</a></p>
<p>Abstract: The key to preserving traditional crafts lies in living transmission, which is inseparable from sustaining artistic production, audience consumption, and progressive innovation with the physical media. As HCI researchers, we focus on the hybrid crafts field, which involves numerous cross-disciplinary integration cases between traditional craftsmanship and digital technology at the physical level, providing inspiration for innovating and enlivening traditional crafts. We conducted a multi-perspective review of 85 hybrid craft articles related to traditional crafts over the past decade, considering aspects such as craft categories, digital technology, target users, and research areas. Through reflection, we propose a design framework for fostering innovation and revitalizing traditional crafts. This paper aims to offer insight into the innovation and enlivenment of traditional crafts through a hybrid craft perspective while also serving as a first review of the hybrid craft field from the traditional craftsmanship perspective.</p>
<h3>SharedNeRF: Leveraging Photorealistic and View-dependent Rendering for Real-time and Remote Collaboration</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Bala Kumaravel, Andrew Wilson, Mose Sakashita, Nicolai Marquardt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147720">Link</a></p>
<p>Abstract: Collaborating around physical objects necessitates examining different aspects of design or hardware in detail when reviewing or inspecting physical artifacts or prototypes. When collaborators are remote, coordinating the sharing of views of their physical environment becomes challenging. Video-conferencing tools often do not provide the desired viewpoints for a remote viewer. While RGB-D cameras offer 3D views, they lack the necessary fidelity. We introduce SharedNeRF, designed to enhance synchronous remote collaboration by leveraging the photorealistic and view-dependent nature of Neural Radiance Field (NeRF). The system complements the higher visual quality of the NeRF rendering with the instantaneity of a point cloud and combines them through carefully accommodating the dynamic elements within the shared space, such as hand gestures and moving objects. The system employs a head-mounted camera for data collection, creating a volumetric task space on the fly and updating it as the task space changes. In our preliminary study, participants successfully completed a flower arrangement task, benefiting from SharedNeRF's ability to render the space in high fidelity from various viewpoints.</p>
<h3>Lessons Learnt from a Multimodal Learning Analytics Deployment In-the-wild</h3>
<p>Authors: Simon Buckingham Shum, Roberto Martinez-Maldonado, Lixiang Yan, Vanessa Echeverria, Dragan Gasevic, Samantha Dix, Gloria Fernandez-Nieto, Hollie Jaggard, Rosie Wotherspoon, Linxuan Zhao, Riordan Alfredo, Abra Osborne, Xinyu Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150775">Link</a></p>
<p>Abstract: Multimodal Learning Analytics (MMLA) innovations make use of rapidly evolving sensing and artificial intelligence algorithms to collect rich data about learning activities that unfold in physical spaces. The analysis of these data is opening exciting new avenues for both studying and supporting learning. Yet, practical and logistical challenges commonly appear while deploying MMLA innovations "in-the-wild". These can span from technical issues related to enhancing the learning space with sensing capabilities, to the increased complexity of teachers' tasks. These practicalities have been rarely investigated. This paper addresses this gap by presenting a set of lessons learnt from a 2-year human-centred MMLA in-the-wild study conducted with 399 students and 17 educators in the context of nursing education. The lessons learnt were synthesised into topics related to i) technological/physical aspects of the deployment; ii) multimodal data and interfaces; iii) the design process; iv) participation, ethics and privacy; and v) sustainability of the deployment. </p>
<h2>Better Future Worlds and AI</h2>
<h3>How Culture Shapes What People Want From AI</h3>
<p>Authors: Hazel Rose Markus, Daigo Misaki, Chunchen Xu, Xiao Ge, Jeanne L. Tsai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148201">Link</a></p>
<p>Abstract: There is an urgent need to incorporate the perspectives of culturally diverse groups into AI developments. We present a novel conceptual framework for research that aims to expand, reimagine, and reground mainstream visions of AI using independent and interdependent cultural models of the self and the environment. Two survey studies support this framework and provide preliminary evidence that people apply their cultural models when imagining their ideal AI. Compared with European American respondents, Chinese respondents viewed it as less important to control AI and more important to connect with AI, and were more likely to prefer AI with capacities to influence. Reflecting both cultural models, findings from African American respondents resembled both European American and Chinese respondents. We discuss study limitations and future directions and highlight the need to develop culturally responsive and relevant AI to serve a broader segment of the world population.</p>
<h3>Charting the Future of AI in Project-Based Learning: A Co-Design Exploration with Students</h3>
<p>Authors: Kangyu Yuan, Shuai Ma, Reza Hadi Mogavi, Zhenhui Peng, Chengbo Zheng, Xiaojuan Ma, Bingcan Guo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147096">Link</a></p>
<p>Abstract: Students' increasing use of Artificial Intelligence (AI) presents new challenges for assessing their mastery of knowledge and skills in project-based learning (PBL). This paper introduces a co-design study to explore the potential of students' AI usage data as a novel material for PBL assessment. We conducted workshops with 18 college students, encouraging them to speculate an alternative world where they could freely employ AI in PBL while needing to report this process to assess their skills and contributions. Our workshops yielded various scenarios of students' use of AI in PBL and ways of analyzing such usage grounded by students' vision of how educational goals may transform. We also found that students with different attitudes toward AI exhibited distinct preferences in how to analyze and understand their use of AI. Based on these findings, we discuss future research opportunities on student-AI interactions and understanding AI-enhanced learning.</p>
<h3>Socio-technical Imaginaries: Envisioning and Understanding AI Parenting Supports through Design Fiction</h3>
<p>Authors: Petr Slovak, Melina Petsolari, Seray Ibrahim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147338">Link</a></p>
<p>Abstract: How might emerging modalities (e.g., NLP) be leveraged to transform the provision of parenting support? To explore the role of AI technologies in supporting parenting behaviour—and child-well-being—we surveyed 92 parents to gather their perspectives on nine future-oriented scenarios. We used Design Fiction and Speed Dating to understand parents needs and preferences around the design of agent-based supports. We explore the perceived benefits of AI assistants (i.e., receiving objective feedback, managing emotions and personalised guidance) and the most voiced concerns (i.e., AI undermining parental authority, replacing human interactions, and promoting lazy parenting). Finally, we highlight a number of plausible design directions based on the scenarios that parents were positive about.</p>
<h3>MindTalker: Navigating the Complexities of AI-Enhanced Social Engagement for People with Early-Stage Dementia</h3>
<p>Authors: Anna Xygkou, Chee Siang Ang, Alexandra Covaci, Jonasz Kopecki, Wan-Jou She, Eiman Kanjo, Panote Siriaraya</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146659">Link</a></p>
<p>Abstract: People living with dementia are at risk of social isolation, and conversational AI agents can potentially support such individuals by reducing their loneliness. In our study, a conversational AI agent, called MindTalker, co-designed with therapists and utilizing the GPT-4 Large Language Model (LLM), was developed to support people with early-stage dementia, allowing them to experience a new type of “social relationship” that could be extended to real life. Eight PwD engaged with MindTalker for one month or even longer, and data was collected from interviews. Our findings emphasized that participants valued the novelty of AI, but sought more consistent, deeper interactions. They desired a personal touch from AI, while stressing the irreplaceable value of human interactions. The findings underscore the complexities of AI engagement dynamics, where participants commented on the artificial nature of AI, highlighting important insights into the future design of conversational AI for this population.</p>
<h2>Microoganism and Fossil Interactions</h2>
<h3>Microbial Revolt: Redefining biolab tools and practices for more-than-human care ecologies</h3>
<p>Authors: Yuning Chen, Larissa Pschetz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147452">Link</a></p>
<p>Abstract: Recent work in HCI has called for deeper ethical considerations when engaging with more-than-human organisms in design. In this paper, we introduce Microbial Revolt, a provocative method to support reflection on the perspectives of organisms involved in HCI and design practice. By asking participants to consider the reality of a chosen organism in feral and lab environments and to redesign lab tools in order to account for their “non-participation”, we identified the manifestation of key epistemic differences between approaches to care and ecologies in typical design and biology research - as well as the potential for design and HCI to creatively redefine power dynamics in the lab. Further interviews revealed specific challenges and opportunities that designers and HCI researchers face in adapting practices to lab standards, and lab equipment to their practices, calling for a redefinition of tools, spaces and guidance to accommodate phenomenological perspectives and multiple modes of interaction with living organisms.    </p>
<h3>PaleoScan: Low-Cost Easy-to-Use High-Volume Fossil Scanning</h3>
<p>Authors: Yurii Piadyk, Akinobu Watanabe, Renan Alfredo Machado Bantim, Naiara Cipriano Oliveira, Otavio Gomes, Antonio Alamo Feitosa Saraiva, Maria Beatriz Silva, João Rulff, Flaviana Jorge de Lima, Daniele Panozzo, Claudio Silva</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147092">Link</a></p>
<p>Abstract: Fossils are crucial for understanding our natural history and the digitalization of fossils has paved the way for paleontologists to share and study them in greater detail. Yet, many fossil-dense regions, in particular low- and middle-income countries, lack the resources to digitalize their vast collections. </p>
<p>This project reports on a collaboration between paleontologists and computer scientists to design, build, and operate a device that can be deployed in the field for digitizing a collection of thousands of fossils. We introduce PaleoScan, a user-friendly, cost-effective, high-volume scanner designed to expedite the digitization of extensive fossil collections. PaleoScan is a self-contained 3D scanning system consisting of a light and compact mirrorless camera, a microcontroller, a ChArUco calibration board, and user-controlled LEDs. Software and data processing is cloud-based, where the user interacts with the system through a web application. </p>
<p>We deployed PaleoScan in a museum in Brazil with a world-class fossil collection. Our early results reveal its potential to revolutionize the scanning process for fossils.</p>
<h3>Go-Go Biome: Evaluation of a Casual Game for Gut Health Engagement and Reflection</h3>
<p>Authors: Elise van den Hoven, Jessica Danaher, Nandini Pasumarthy, Shreyas Nisal, Rohit Ashok Khot</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147393">Link</a></p>
<p>Abstract: Experts emphasise that maintaining a healthy gut microbial balance requires the public to understand factors beyond diet, such as physical activity, lifestyle, and other real-world influences. Games as experiential systems are known to foster playful engagement and reflection. We propose a novel approach to promoting activity engagement for gut health and its reflection through the design of the Go-Go Biome game. The game simulates the interplay between friendly and unfriendly gut microbes, encouraging real-world activity engagement for gut-microbial balance through interactive visuals, unstructured play mechanics, and reflective design principles. A field study with 14 participants revealed that important facets of our game design led to awareness, playful visualisation, and reflection on factors influencing gut health. Our findings suggest four design lenses– bio-temporality, visceral conversations, wellness comparison, and inner discovery, to aid future playful design explorations to foster gut health engagement and reflection.</p>
<h3>(Re)activate, (Re)direct, (Re)arrange: Exploring the Design Space of Direct Interactions with Flavobacteria</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Holly McQuillan, Elvin Karana, Joana Martins, Clarice Risseeuw</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148167">Link</a></p>
<p>Abstract: HCI designers increasingly engage in the integration of microbes into artefacts, leveraging their distinct biological affordances for novel interactions. While in many explorations the interaction between humans and microbes is mediated, scholars also highlight the potential of direct interactions, such as visualising mechanical distortions or fostering a sense of relationality with nonhumans through eliciting intimate encounters. Seizing upon this potential, our study delves into the realm of direct interactions involving Flavobacteria, recently introduced as a colour-changing interactive medium in HCI. We present a design space for direct interactions where humans can (re)activate, (re)direct, and (re)arrange Flavobacteria’s colourations, thereby fostering a personal and dynamic interplay between humans and microbes. With our work, we aspire to provide pathways and ignite inspiration among HCI designers to create living artefacts that cultivate active engagement and heightened attentiveness towards microbial worlds and beyond.</p>
<h2>Wellbeing and Mental Health A</h2>
<h3>On Stress: Combining Human Factors and Biosignals to Inform the Placement and Design of a Skin-like Stress Sensor</h3>
<p>Authors: Yasser Khan, Megan Chesnut, Jinxing Li, Pablo Paredes Castro, Zhenan Bao, Akshara Motani, Dalton Duvio, Leanne Williams, James Landay, Amir Foudeh, Jayoung Kim, Keith D. Sudheimer, Matthew Mauriello, Parsa Nowruzi, Jan Liphardt, Boris Murmann, Nicholas Vitale, Erika Shols, Grace Hon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147821">Link</a></p>
<p>Abstract: With advances in electronic-skin and wearable technologies, it is possible to continuously measure stress markers from the skin and sweat to monitor and improve wellbeing and health. Understandably, the sensor's engineering and resolution are important towards its function. However, we find that people looking for an e-skin stress sensor may look beyond measurement precision, demanding a private and stealth design to reduce, for example, social stigmatization. We introduce the idea of a stress sensing "wear index," created from the combination of human-centered design (n=24), physiological (n=10), and biochemical (n=16) data. This wear index can inform the design of stress wearables to fit specific applications, e.g., human factors may be relevant for a wellbeing application, versus a relapse prevention application that may require more sensing precision. Our wear index idea can be further generalized as a method to close gaps between design and engineering practices.</p>
<h3>Reading Between the Lines: Identifying the Linguistic Markers of Anhedonia for the Stratification of Depression</h3>
<p>Authors: Bridianne O'Dea, Mark E Larsen, Taylor Braund, Philip J Batterham, Nick Glozier, Alexis E Whitton</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147595">Link</a></p>
<p>Abstract: Stratifying depressed individuals may help to improve recovery rates by identifying the subgroups who would benefit from targeted treatments. Detecting depressed individuals with prominent anhedonia (i.e. lack of pleasure) may be one effective approach, given these individuals experience poorer treatment outcomes. This paper explores the linguistic features associated with anhedonia among depressed adults. Over 9 weeks, 218 individuals with depressive symptoms completed a fortnightly psychometric measure of depression (PHQ-9) and provided text data (SMS, social media posts, expressive essays, emotion diaries, personal letters). Linguistic features were examined using LIWC-22. Greater use of discrepancy words was significantly associated with higher anhedonia, but in SMS data only. Machine learning showed some utility for predicting increased anhedonia, with discrepancy words the most important linguistic feature in the model. Discrepancy words were not found to be associated with overall depression scores. These results suggest that this linguistic feature may show some promise for the stratification of anhedonic depression.</p>
<h3>"Waves Push Me to Slumberland": Reducing Pre-Sleep Stress through Spatio-Temporal Tactile Displaying of Music.</h3>
<p>Authors: Jianwei Zhang, Wanyi Wei, Huafeng Shan, Ruixiao Zheng, Shirao Yang, Hui Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146869">Link</a></p>
<p>Abstract: Despite the fact that spatio-temporal patterns of vibration, characterized as rhythmic compositions of tactile content, have exhibited an ability to elicit specific emotional responses and enhance the emotion conveyed by music, limited research has explored their underlying mechanism in regulating emotional states within the pre-sleep context. Aiming to investigate whether synergistic spatio-temporal tactile displaying of music can facilitate relaxation before sleep, we developed 16 vibration patterns and an audio-tactile prototype for presenting an ambient experience in a pre-sleep scenario. The stress-reducing effects were further evaluated and compared via a user experiment. The results showed that the spatio-temporal tactile display of music significantly reduced stress and positively influenced users' emotional states before sleep. Furthermore, our study highlights the therapeutic potential of incorporating quantitative and adjustable spatio-temporal parameters correlated with subjective psychophysical perceptions in the audio-tactile experience for stress management.</p>
<h3>MoodCapture: Depression Detection using In-the-Wild Smartphone Images</h3>
<p>Authors: Shayan Mirjafari, Amanda Collins, Weichen Wang, Matthew Nemesure, Nicholas Jacobson, Michael Heinz, Damien Lekkas, Andrew Campbell, Tess Griffin, George Price, Subigya Nepal, Arvind Pillai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148165">Link</a></p>
<p>Abstract: MoodCapture presents a novel approach that assesses depression based on images automatically captured from the front-facing camera of smartphones as people go about their daily lives. We collect over 125,000 photos in the wild from N=177 participants diagnosed with major depressive disorder for 90 days. Images are captured naturalistically while participants respond to the PHQ-8 depression survey question: "I have felt down, depressed, or hopeless''. Our analysis explores important image attributes, such as angle, dominant colors, location, objects, and lighting. We show that a random forest trained with face landmarks can classify samples as depressed or non-depressed and predict raw PHQ-8 scores effectively. Our post-hoc analysis provides several insights through an ablation study, feature importance analysis, and bias assessment. Importantly, we evaluate user concerns about using MoodCapture to detect depression based on sharing photos, providing critical insights into privacy concerns that inform the future design of in-the-wild image-based mental health assessment tools.</p>
<h3>Patient Acceptance of Self-Monitoring on a Smartwatch in a Routine Digital Therapy: A Mixed-Methods Study</h3>
<p>Authors: Gavin Doherty, Corina Sas, Derek Richards, Caroline Earley, Camille Nadal, Angel Enrique</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150631">Link</a></p>
<p>Abstract: Self-monitoring of mood and lifestyle habits is the cornerstone of many therapies, but it is still hindered by persistent issues including inaccurate records, gaps in the monitoring, patient burden, and perceived stigma. Smartwatches have the potential to deliver enhanced self-reports, but their acceptance in clinical mental health settings is unexplored and rendered difficult by a complex theoretical landscape and need for a longitudinal perspective. We present the Mood Monitor smartwatch application for mood and lifestyle habits self-monitoring. We investigated patient acceptance of the app within a routine 8-week digital therapy. We recruited 35 patients of the UK’s National Health Service and evaluated their acceptance through three online questionnaires and a post-study interview. We assessed the clinical feasibility of the Mood Monitor by comparing clinical, usage, and acceptance metrics obtained from the 35 patients with a smartwatch with those from an additional 34 patients without a smartwatch (digital treatment as usual). Findings showed that the smartwatch app was highly accepted by patients, revealed which factors facilitated and impeded this acceptance, and supported clinical feasibility. We provide guidelines for the design of self-monitoring on a smartwatch and reflect on the conduct of human-computer interaction research evaluating user acceptance of mental health technologies.</p>
<h2>Algorithmic Trust and Censorship</h2>
<h3>Dealing with Uncertainty: Understanding the Impact of Prognostic Versus Diagnostic Tasks on Trust and Reliance in Human-AI Decision Making</h3>
<p>Authors: Gaole He, Ujwal Gadiraju, Sara Salimzadeh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147300">Link</a></p>
<p>Abstract: While existing literature has explored and revealed several insights pertaining to the role of human factors (e.g., prior experience, domain knowledge) and attributes of AI systems (e.g., accuracy, trustworthiness), there is a limited understanding around how the important task characteristics of complexity and uncertainty shape human decision-making and human-AI team performance. In this work, we aim to address this research and empirical gap by systematically exploring how task complexity and uncertainty influence human-AI decision-making. Task complexity refers to the load of information associated with a task, while task uncertainty refers to the level of unpredictability associated with the outcome of a task. We conducted a between-subjects user study (N = 258) in the context of a trip-planning task to investigate the impact of task complexity and uncertainty on human trust and reliance on AI systems. Our results revealed that task complexity and uncertainty have a significant impact on user reliance on AI systems. When presented with complex and uncertain tasks, users tended to rely more on AI systems while demonstrating lower levels of appropriate reliance compared to tasks that were less complex and uncertain. In contrast, we found that user trust in the AI systems was not influenced by task complexity and uncertainty. Our findings can help inform the future design of empirical studies exploring human-AI decision-making. Insights from this work can inform the design of AI systems and interventions that are better aligned with the challenges posed by complex and uncertain tasks. Finally, the lens of diagnostic versus prognostic tasks can inspire the operationalization of uncertainty in human-AI decision-making studies. </p>
<h3>Impact of Model Interpretability and Outcome Feedback on Trust in AI</h3>
<p>Authors: Daehwan Ahn, Abdullah Almaatouq, Kartik Hosanagar, Monisha Gulabani</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147213">Link</a></p>
<p>Abstract: This paper bridges the gap in Human-Computer Interaction (HCI) research by comparatively assessing the effects of interpretability and outcome feedback on user trust and collaborative performance with AI. Through novel pre-registered experiments (N=1,511 total participants) using an interactive prediction task, we analyzed how interpretability and outcome feedback influence users’ task performance and trust in AI. The results counter the widespread belief that interpretability drives trust, showing that interpretability led to no robust improvements in trust and that outcome feedback had a significantly greater and more reliable effect. However, both factors had modest effects on participants’ task performance. These findings suggest that (1) interpretability may be less effective at increasing trust than factors like outcome feedback, and (2) augmenting human performance via AI systems may not be a simple matter of increasing trust in AI, as increased trust is not always associated with equally sizable performance improvements. Our exploratory analyses further delve into the mechanisms underlying this trust-performance paradox. These findings present an opportunity for research to focus not only on methods for generating interpretations but also on techniques that ensure interpretations impact trust and performance in practice. </p>
<h3>Exposed or Erased: Algorithmic Censorship of Nudity in Art</h3>
<p>Authors: Thomas Hofmann, Nuria Oliver, Piera Riccio</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148324">Link</a></p>
<p>Abstract: The intersection between art and technology poses new challenges for creative expression in the digital space. This paper investigates the algorithmic censorship of artistic nudity in social platforms by means of a qualitative study via semi-structured interviews with 14 visual artists who have experienced censorship online. We explore the professional, emotional, financial and artistic consequences of content removal or shadow-banning. Focusing on the concept of artistic nudity, our findings emphasize the significant impact on artists of the algorithmic censorship of art, the need to consider art as a special case to safeguard the freedom of expression, the importance of education, the limitations of today's content moderation algorithms and the pressing need for transparency and recourse mechanisms. We advocate for a multi-stakeholder governance model conducive to a more supportive, safer and inclusive online environment that respects and nurtures human creativity.</p>
<h3>Trust in AI-assisted Decision Making: Perspectives from Those Behind the System and Those for Whom the Decision is Made</h3>
<p>Authors: Oleksandra Vereschak, Gilles Bailly, Baptiste Caramiaux, Fatemeh Alizadeh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147306">Link</a></p>
<p>Abstract: Trust between humans and AI in the context of decision-making has acquired an important role in public policy, research and industry. In this context, Human-AI Trust has often been tackled from the lens of cognitive science and psychology, but lacks insights from the stakeholders involved. In this paper, we conducted semi-structured interviews with 7 AI practitioners and 7 decision subjects from various decision domains. We found that 1) interviewees identified the prerequisites for the existence of trust and distinguish trust from trustworthiness, reliance, and compliance; 2) trust in AI-integrated systems is strongly influenced by other human actors, more than the system's features; 3) the role of Human-AI trust factors is stakeholder-dependent. These results provide clues for the design of Human-AI interactions in which trust plays a major role, as well as outline new research directions in Human-AI Trust.</p>
<h3>Understanding Public Perceptions of AI Conversational Agents: A Cross-Cultural Analysis</h3>
<p>Authors: Anfan Chen, Zihan Liu, Renwen Zhang, Han Li, YI-CHIEH LEE</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148182">Link</a></p>
<p>Abstract: Conversational Agents (CAs) have increasingly been integrated into everyday life, sparking significant discussions on social media. While previous research has examined public perceptions of AI in general, there is a notable lack in research focused on CAs, with fewer investigations into cultural variations in CA perceptions. To address this gap, this study used computational methods to analyze about one million social media discussions surrounding CAs and compared people's discourses and perceptions of CAs in the US and China. We find Chinese participants tended to view CAs hedonically, perceived voice-based and physically embodied CAs as warmer and more competent, and generally expressed positive emotions. In contrast, US participants saw CAs more functionally, with an ambivalent attitude. Warm perception was a key driver of positive emotions toward CAs in both countries. We discussed practical implications for designing contextually sensitive and user-centric CAs to resonate with various users' preferences and needs.</p>
<h2>Chronic Conditions B</h2>
<h3>Charting the COVID Long Haul Experience - A Longitudinal Exploration of Symptoms, Activity, and Clinical Adherence</h3>
<p>Authors: Fen Lei Chang, Shaan Chopra, Fayika Farhat Nova, Shion Guha, Taha Liaqat, Jeanne Carroll, Tammy Toscos, Jessica Pater, Juliette Zaccour</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147234">Link</a></p>
<p>Abstract: COVID Long Haul (CLH) is an emerging chronic illness with varied patient experiences. Our understanding of CLH is often limited to data from electronic health records (EHRs), such as diagnoses or problem lists, which do not capture the volatility and severity of symptoms or their impact. To better understand the unique presentation of CLH, we conducted a 3-month long cohort study with 14 CLH patients, collecting objective (EHR, daily Fitbit logs) and subjective (weekly surveys, interviews) data. Our findings reveal a complex presentation of symptoms, associated uncertainty, and the ensuing impact CLH has on patients' personal and professional lives. We identify patient needs, practices, and challenges around adhering to clinical recommendations, engaging with health data, and establishing "new normals" post COVID. We reflect on the potential found at the intersection of these various data streams and the persuasive heuristics possible when designing for this new population and their specific needs. </p>
<h3>Designing online peer support for parents of adolescents at risk of mental health challenges</h3>
<p>Authors: Marie B H Yap, Jue Xie, Dharshani Chandrasekara, Patrick Olivier, Roisin McNaney, Joshua Paolo Seguin, Ling Wu, Mairead Cardamone-Breen, Tom Bartindale</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147515">Link</a></p>
<p>Abstract: While online parenting interventions have been shown to improve youth mental health, parents find it challenging to engage with and implement strategies from self-directed interventions. Our study purposefully designed a parent peer-support community for parents seeking support. Our two-phased qualitative study included parent interviews and design workshops. Our findings show that while parents need others' lived experiences to learn about parenting, perceived judgment and self-doubt can stop them from actively contributing to the peer support group. To address this design challenge, we operationalised parents' needs and challenges gained in the interviews and workshops into design implications. We demonstrate a parent-centered design approach where we formulate design implications that integrate parents' needs and expectations with multidisciplinary theoretical and empirical evidence to deepen and concretise the design for an online parent peer-support community that cultivates empathy, encourages confidence and self-efficacy, and motivates change and growth.</p>
<h3>Co-designing Customizable Clinical Dashboards with Multidisciplinary Teams: Bridging the Gap in Chronic Disease Care</h3>
<p>Authors: Daniela Guerreiro, Diana Miranda, Tiago Reis, Margarida Móteiro, Alexandra Braz, Tiago Guerreiro, Filipa Pona-Ferreira, Rita Miranda, Rita Cardoso, Joana Ramalho, Mariana Leitão, Élia Decoroso, Diogo Branco, Joaquim J Ferreira, Verónica Caniça, Raquel Bouça-Machado, Joana Malheiro, Filipa Rato</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147322">Link</a></p>
<p>Abstract: Providing care to individuals with chronic diseases benefits from a multidisciplinary approach and longitudinal symptom, event, and disease monitoring, in and out of clinical facilities. Technological advancements, including the ubiquitous presence of sensors and devices, present opportunities to collect large amounts of data and extract evidence-based insights about the patient and disease. Nevertheless, practical examples of clinical utility of those technologies remain sparse, and in specific focus areas (e.g, insights from a single device). This paper explores the challenges and opportunities of multidisciplinary clinical dashboards to support clinicians caring for people with chronic diseases. We report on a focus group and co-design workshops with a multidisciplinary team of clinicians and HCI researchers. We offer insights into how technological outcomes and visualizations can enhance clinical practice and the intricacies of information-sharing dynamics. We discuss the potential of dashboards to trigger actions in clinical settings and emphasize the benefits of customizable dashboards.</p>
<h3>Platforming PCOS Treatment Online: FemTech Logics of Care</h3>
<p>Authors: Preeti Mudliar, Taru Jain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146795">Link</a></p>
<p>Abstract: This paper explores how FemTech platforms appropriate the term 'care' to create a collaborative, non-judgmental, and data-driven approach for a sexual and reproductive health condition like Polycystic Ovary Syndrome (PCOS). In contrast, offline healthcare for PCOS is insufficient owing to disruptions in treatment, gynaecological indifference, and a lack of time and attention to patient concerns. We share findings from an ethnographic study conducted in India, involving interviews and observations with FemTech platform founders, gynaecologists, and people with PCOS. Our study highlights how FemTech start-ups, led by engineering and management professionals, establish a unified digital care approach by capitalizing on the shortcomings of traditional offline gynaecological healthcare infrastructures. We identify the logics of care surrounding FemTech platforms and assess their sustainability as digital alternatives to offline gynaecological care. We offer recommendations to FemTech founders and policymakers to build sustainable and inclusive offline and online health infrastructures.</p>
<h3>“Is it Even Giving the Correct Reading or Not?”: How Trust and Relationships Mediate Blood Pressure Management in India</h3>
<p>Authors: Mohit Jain, Indrani Medhi Thies, Nimisha Karnatak, Odeline Mateu-Silvernail, William Thies, Brooke Loughrin, Tiffany Kuo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150874">Link</a></p>
<p>Abstract: While chronic disease afflicts a large Indian population, the technologies used to manage chronic diseases have largely been informed by studies conducted in other sociocultural contexts. To address this gap, we conducted qualitative interviews with 21 patients clinically diagnosed with abnormal blood pressure (BP) living in low-resourced communities of Haryana, Uttarakhand and Uttar Pradesh in India. We found that patients’ trust in the BP ecosystem and social ties plays a significant role in shaping their perceptions of technology and chronic care. Trust in one actor of the ecosystem fosters trust in another, e.g., trust in BP reading depended on the type of device and the person measuring the BP. We also observed nuanced sharing and intermediation of BP devices. Based on our findings, we recommend designs to boost patients’ trust, familiarity, and access to technologies used in BP management and improve their experience of care in low-resource settings in India.</p>
<h2>Conversational Agents</h2>
<h3>Apple’s Knowledge Navigator: Why Doesn’t that Conversational Agent Exist Yet?</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Stephen Gilbert, Maddie Sells, Arthur Perron, Mohammadamin Sanaei, Hila Sabouni, Amanda Newendorp, Katherine Nelson, Michael Dorneich, Nikoo Javadpour</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147981">Link</a></p>
<p>Abstract: Apple’s 1987 Knowledge Navigator video contains a vision of a sophisticated digital personal assistant, but the natural human-agent conversational dialog shown does not currently exist. To investigate why, the authors analyzed the video using three theoretical frameworks: the DiCoT framework, the HAT Game Analysis framework, and the Flows of Power framework. These were used to codify the human-agent interactions and classify the agent’s capabilities. While some barriers to creating such agents are technological, other barriers arise from privacy, social and situational factors, trust, and the financial business case. The social roles and asymmetric interactions of the human and agent are discussed in the broader context of HAT research, along with the need for a new term for these agents that does not rely on a human social relationship metaphor. This research offers designers of conversational agents a research roadmap to build more highly capable and trusted non-human teammates. </p>
<h3>Towards Designing a Question-Answering Chatbot for Online News: Understanding Questions and Perspectives</h3>
<p>Authors: Ayman Mahfuz, Md Naimul Hoque, Mayukha Kindi, Naeemul Hassan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147565">Link</a></p>
<p>Abstract: Large Language Models (LLMs) have created opportunities for designing chatbots that can support complex question-answering (QA) scenarios and improve news audience engagement. However, we still lack an understanding of what roles journalists and readers deem fit for such a chatbot in newsrooms. To address this gap, we first interviewed six journalists to understand how they answer questions from readers currently and how they want to use a QA chatbot for this purpose. To understand how readers want to interact with a QA chatbot, we then conducted an online experiment (N=124) where we asked each participant to read three news articles and ask questions to either the author(s) of the articles or a chatbot. By combining results from the studies, we present alignments and discrepancies between how journalists and readers want to use QA chatbots and propose a framework for designing effective QA chatbots in newsrooms.</p>
<h3>Cooking With Agents: Designing Context-aware Voice Interaction</h3>
<p>BEST_PAPER</p>
<p>Authors: Sabrina Zhong, Iona Gessinger, Duncan Brumby, Donald McMillan, Benjamin Cowan, Razan Jaber, Aida Hosseini, Sanna Kuoppamäki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147273">Link</a></p>
<p>Abstract: Voice Agents (VAs) are touted as being able to help users in complex tasks such as cooking and interacting as a conversational partner to provide information and advice while the task is ongoing. Through conversation analysis of 7 cooking sessions with a commercial VA, we identify challenges caused by a lack of contextual awareness leading to irrelevant responses, misinterpretation of requests, and information overload. Informed by this, we evaluated 16 cooking sessions with a wizard-led context-aware VA. We observed more fluent interaction between humans and agents, including more complex requests, explicit grounding within utterances, and complex social responses. We discuss reasons for this, the potential for personalisation, and the division of labour in VA communication and proactivity. Then, we discuss the recent advances in generative models and the VAs interaction challenges. We propose limited context awareness in VAs as a step toward explainable, explorable conversational interfaces.</p>
<h3>"It's a Fair Game", or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents</h3>
<p>Authors: Bingsheng Yao, Michelle Jia, Zhiping Zhang, Tianshi Li, Hao-Ping (Hank) Lee, Sauvik Das, Ada Lerner, Dakuo Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147902">Link</a></p>
<p>Abstract: The widespread use of Large Language Model (LLM)-based conversational agents (CAs), especially in high-stakes domains, raises many privacy concerns. Building ethical LLM-based CAs that respect user privacy requires an in-depth understanding of the privacy risks that concern users the most. However, existing research, primarily model-centered, does not provide insight into users' perspectives. To bridge this gap, we analyzed sensitive disclosures in real-world ChatGPT conversations and conducted semi-structured interviews with 19 LLM-based CA users. We found that users are constantly faced with trade-offs between privacy, utility, and convenience when using LLM-based CAs. However, users' erroneous mental models and the dark patterns in system design limited their awareness and comprehension of the privacy risks. Additionally, the human-like interactions encouraged more sensitive disclosures, which complicated users' ability to navigate the trade-offs. We discuss practical design guidelines and the needs for paradigm shifts to protect the privacy of LLM-based CA users.</p>
<h3>Metaphors in Voice User Interfaces: A Slippery Fish</h3>
<p>Authors: Michael Twidale, Smit Desai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150773">Link</a></p>
<p>Abstract: We explore a range of different metaphors used for Voice User Interfaces (VUIs) by designers, end-users, manufacturers, and researchers using a novel framework derived from semi-structured interviews and a literature review. We focus less on the well-established idea of metaphors as a way for interface designers to help novice users learn how to interact with novel technology, and more on other ways metaphors can be used. We find that metaphors people use are contextually fluid, can change with the mode of conversation, and can reveal differences in how people perceive VUIs compared to other devices. Not all metaphors are helpful, and some may be offensive. Analyzing this broader class of metaphors can help understand, perhaps even predict problems. Metaphor analysis can be a low-cost tool to inspire design creativity and facilitate complex discussions about sociotechnical issues, enabling us to spot potential opportunities and problems in the situated use of technologies.</p>
<h2>Flavor and Food Interactions</h2>
<h3>FoodSkin: Fabricating Edible Gold Leaf Circuits on Food Surfaces</h3>
<p>Authors: Hiromi Nakamura, Kaori Ikematsu, Yuki Igarashi, Kunihiro Kato, Hinako Suzaki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148251">Link</a></p>
<p>Abstract: We present FoodSkin, a technique for adding interactive elements to foods by implementing edible circuits on the surface of the food. The circuit is easily fabricated using commercially available materials. Existing approaches to enhance the eating experience, such as presenting an electrical taste by making food part of an electronic circuit, are challenging to apply to foods with low water content due to their low conductivity. Our technique enables the integration of dry foods into an electronic circuit and provides displaying (e.g., smell or taste) and sensing (e.g., eating activity) functionalities. We describe our fabrication technique with a library of food materials that we can utilize, evaluate the conductivity and adhesion of the gold-leaf traces, introduce demonstrative applications, and conclude with a workshop we conducted to evaluate the accessibility of our technique. FoodSkin enriches the design space for the computer- augmented eating experience by enabling the digital fabrication of electronics on versatile materials, surfaces, and shapes of foods.</p>
<h3>From Plating to Tasting: Towards Understanding the Choreography of Computational Food</h3>
<p>Authors: Florian Mueller, Patrick Olivier, Nathalie Overdevest, Jialin Deng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147646">Link</a></p>
<p>Abstract: The emerging concept of “computational food” focusing on the material affordances when designing food interactions is gaining traction in Human-Food Interaction (HFI). However, prior HFI research has not yet substantively investigated the dynamic nature of computational food from its creation to consumption, limiting our understanding of the complex interactions among creators, computational food, and consumers. In response, our paper shifts the perspective towards the dynamics of computational food interactions through a study in cooperation with chefs and gastronomists. Utilizing “Dancing Delicacies” as a research artifact – a system that facilitates dynamic dining trajectories – we adopted the concept of “choreography” to unravel the experiential dynamics of computational food. Our study resulted in six themes concerning computational food experiences and detailed four design implications central to culinary choreography. Our work aspires to leverage the choreographic potential of computational food design, paving the way for future HFI innovations.</p>
<h3>Füpop: "Real Food" Flavor Delivery via Focused Ultrasound</h3>
<p>Authors: Alexis Kim, Szu Ting Tung, Katherine Song, Eric Paulos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147226">Link</a></p>
<p>Abstract: Food and flavors are integral to our existence in the world. Nonetheless, taste remains an under-explored sense in interaction design. We present Füpop, a technical platform for delivering in-mouth flavors that leverages advances in electronics and molecular gastronomy. Füpop comprises a fully edible pouch placed inside the mouth against a cheek that programmatically releases different flavors when wirelessly triggered by a focused ultrasound transducer from outside the cheek. Füpop does not interfere with activities such as chewing and drinking, and its electronics may be integrated into devices already used near the cheek, such as mobile phones, audio headphones, and head-mounted displays. Füpop's flavors are from "real foods," not ones imitated with synthetic reagents, providing authentic, nutritive flavors. We envision that with Füpop, flavors may be synced to music, a phone call, or events in virtual reality to enhance a user's experience of their food and the world.</p>
<h2>Haptics: Electrical Stimulation</h2>
<h3>Understanding User Acceptance of Electrical Muscle Stimulation in Human-Computer Interaction</h3>
<p>Authors: Stefan Schneegass, Sarah Faltaous, Julie Williamson, Jonas Keppel, Max Pfeiffer, Marion Koelle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147978">Link</a></p>
<p>Abstract: Electrical Muscle Stimulation (EMS) has unique capabilities that can manipulate users' actions or perceptions, such as actuating user movement while walking, changing the perceived texture of food, and guiding movements for a user learning an instrument. These applications highlight the potential utility of EMS, but such benefits may be lost if users reject EMS. To investigate user acceptance of EMS, we conducted an online survey (N=101). We compared eight scenarios, six from HCI research applications and two from the sports and health domain. To gain further insights, we conducted in-depth interviews with a subset of the survey respondents (N=10). The results point to the challenges and potential of EMS regarding social and technological acceptance, showing that there is greater acceptance of applications that manipulate action than those that manipulate perception. The interviews revealed safety concerns and user expectations for the design and functionality of future EMS applications.</p>
<h3>Designing Unobtrusive Modulated Electrotactile Feedback on Fingertip Edge to Assist Blind and Low Vision (BLV) People in Comprehending Charts</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Emily Kuang, Mingming Fan, Kaihao Zhang, Chutian Jiang, Junan Xie, Yinan FAN</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147036">Link</a></p>
<p>Abstract: Charts are crucial in conveying information across various fields but are inaccessible to blind and low vision (BLV) people without assistive technology. Chart comprehension tools leveraging haptic feedback have been used widely but are often bulky, expensive, and static, rendering them inefficient for conveying chart data. To increase device portability, enable multitasking, and provide efficient assistance in chart comprehension, we introduce a novel system that delivers unobtrusive modulated electrotactile feedback directly to the fingertip edge. Our three-part study with twelve participants confirmed the effectiveness of this system, demonstrating that electrotactile feedback, when applied for 0.5 seconds with a 0.12-second interval, provides the most accurate position and direction recognition. Furthermore, our electrotactile device has proven valuable in assisting BLV participants in comprehending four commonly used charts: line charts, scatterplots, bar charts, and pie charts. We also delve into the implications of our findings on recognition enhancement, presentation modes, and function synergy.</p>
<h3>TacTex: A Textile Interface with Seamlessly-Integrated Electrodes for High-Resolution electrotactile Stimulation</h3>
<p>Authors: Teng Han, Qi Wang, Hongnan Lin, Guanyun Wang, Feng Tian, Shengsheng Jiang, Wei Sun, Xuanyou Liu, Ye Tao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146969">Link</a></p>
<p>Abstract: This paper presents TacTex, a textile-based interface that provides high-resolution haptic feedback and touch-tracking capabilities. TacTex utilizes electrotactile stimulation, which has traditionally posed challenges due to limitations in textile electrode density and quantity. TacTex overcomes these challenges by employing a multi-layer woven structure that separates conductive weft and warp electrodes with non-conductive yarns. The driving system for TacTex includes a power supply, sensing board, and switch boards to enable spatial and temporal control of electrical stimuli on the textile, while simultaneously monitoring voltage changes. TacTex can stimulate a wide range of haptic effects, including static and dynamic patterns and different sensation qualities, with a resolution of $512 \times 512$ and \textcolor{black}{based on linear electrodes spaced as closely as 2mm}. We evaluate the performance of the interface with user studies and demonstrate the potential applications of TacTex interfaces in everyday textiles for adding haptic feedback.</p>
<h3>Paired-EMS: Enhancing Electrical Muscle Stimulation (EMS)-based Force Feedback Experience by Stimulating Both Muscles in Antagonistic Pairs</h3>
<p>Authors: Chia-Yu Cheng, Sitaresmi Handani, Mike Chen, Avijit Balabantaray, Yu Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146902">Link</a></p>
<p>Abstract: Electrical Muscle Stimulation (EMS) has emerged as a key wearable haptic feedback technology capable of simulating a wide range of force feedback, such as the impact force of boxing punches, the weight of virtual objects, and the reaction force from pushing on a wall. To simulate these external forces, EMS stimulates the muscles that oppose (i.e. antagonistic to) the actual muscles that users activate, causing involuntary muscle contraction and haptic sensations that differ from real-world experiences. In this work, we propose Paired-EMS which simultaneously stimulates both the muscles that users activate and that prior EMS stimulates (i.e. antagonistic muscle pairs) to enhance the external force feedback experience. We first conducted a small formative study (n=8) to help design the stimulation intensity of muscle pairs, then conducted a user experience study to evaluate Paired-EMS vs. prior EMS approaches for both isometric and isotonic user actions. Study results (n=32) showed that Paired-EMS significantly improved realism, harmony, and entertainment (p&lt;.05) with similar comfort (p&gt;.36), and was overall preferred by 78% of participants (p&lt;.01).</p>
<h2>Mental Health B</h2>
<h3>Exploring Context-Aware Mental Health Self-Tracking Using Multimodal Smart Speakers in Home Environments</h3>
<p>Authors: Uichin Lee, Youngji Koh, Jieun Lim, Auk Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147776">Link</a></p>
<p>Abstract: People with mental health issues often stay indoors, reducing their outdoor activities. This situation emphasizes the need for self-tracking technology in homes for mental health research, offering insights into their daily lives and potentially improving care. This study leverages a multimodal smart speaker to design a proactive self-tracking research system that delivers mental health surveys using an experience sampling method (ESM). Our system determines ESM delivery timing by detecting user context transitions and allowing users to answer surveys through voice dialogues or touch interactions. Furthermore, we explored the user experience of a proactive self-tracking system by conducting a four-week field study (n=20). Our results show that context transition-based ESM delivery can increase user compliance. Participants preferred touch interactions to voice commands, and the modality selection varied depending on the user's immediate activity context. We explored the design implications for home-based, context-aware self-tracking with multimodal speakers, focusing on practical applications.</p>
<h3>Co-designing the Collaborative Digital Musical Instruments for Group Music Therapy</h3>
<p>Authors: Yuting Diao, Yuan Yao, Haipeng Mi, Zhaoguo Wang, Yu Peng, Hanxuan Li, Yuan-Ling Feng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147511">Link</a></p>
<p>Abstract: Digital Musical Instruments (DMIs) have been integrated into group music therapy, providing therapists with alternative ways to engage in musical dialogues with their clients. However, existing DMIs used in group settings are primarily designed for individual use and often overlook the social dynamics inherent in group therapy. Recognizing the crucial role of social interaction in the effectiveness of group therapy, we argue that Collaborative Digital Musical Instruments (CDMIs), seamlessly integrating social interaction with musical expression, hold significant potential to enhance group music therapy. To better tailor CDMIs for group music therapy, we engaged in a co-design process with music therapists, designing and practicing group therapy sessions involving the prototype ComString. In the end, we reflected on the co-design case to suggest future directions for designing CDMIs in group music therapy.</p>
<h3>Approaches for tailoring between-session mental health therapy activities</h3>
<p>Authors: Patricia Arean, Bruna Oewel, Elena Agapie</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147860">Link</a></p>
<p>Abstract: Mental health activities conducted by patients between therapy sessions (or "therapy homework") are a component of addressing anxiety and depression. However, to be effective, therapy homework must be tailored to the client's needs to address the numerous barriers they encounter in everyday life. In this study, we analyze how therapists and clients tailor therapy homework to their client's needs. We interviewed 13 therapists and 14 clients about their experiences tailoring and engaging in therapy homework. We identify criteria for tailoring homework, such as client skills, discomfort, and external barriers. We present how homework gets adapted, such as through changes in difficulty or by identifying alternatives. We discuss how technologies can better use client information for personalizing mental health interventions, such as adapting to client barriers, adjusting homework to these barriers, and creating a safer environment to support discomfort.</p>
<h3>Challenges and Opportunities for the Design of Inclusive Digital Mental Health Tools: Understanding Culturally Diverse Young People's Experiences</h3>
<p>Authors: Chengcheng Qu, Ewan Soubutts, Paul Marshall, Pranita Shrestha, Roisin McNaney, Brittany Davidson, Aaron Sefi, Charlotte Mindel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146990">Link</a></p>
<p>Abstract:  Mental health issues affect approximately 13% of people aged 10-24 years old worldwide. In Western countries (e.g. USA, UK, Australia), mental health issues are particularly prominent in Culturally and Linguistically Diverse (CALD) individuals, yet they are disproportionately affected in relation to service provision. Despite demand, there is a significant lack of literature explicitly exploring the design of digital mental health tools for CALD populations. Our study engaged five professionals working in CALD mental health, to gain insights into challenges for service access and provision, and then engaged 41 CALD young people to explore their experiences. We contribute a set of unique insights into the barriers that CALD young people face when seeking help, and their needs for future digital mental health tools. We also provide design recommendations for future researchers on how they might better support the inclusion of CALD communities in the design of digital health tools.</p>
<h3>Feeling Stressed and Unproductive? A Field Evaluation of a Therapy-Inspired Digital Intervention for Knowledge Workers</h3>
<p>Authors: Liisa Holsti, Thomas Fritz, Joanna McGrenere, Skye Barbic, Kevin Chow</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150820">Link</a></p>
<p>Abstract: Today's knowledge workers face cognitively demanding tasks and blurred work-life boundaries amidst rising stress and burnout in the workplace. Holistic approaches to supporting workers, which consider both productivity and well-being, are increasingly important. Taking this holistic approach, we designed an intervention inspired by cognitive behavioural therapy that consists of: (1) using the term "Time Well Spent" (TWS) in place of "productivity", (2) a mobile self-logging tool for logging activities, feelings, and thoughts at work, and (3) a visualization that guides users to reflect on their data. We ran a 4-week exploratory qualitative comparison in the field with 24 graduate students to examine our Therapy-inspired intervention alongside a classic Baseline intervention. Participants who used our intervention often shifted towards a holistic perspective of their primary working hours, which included an increased consideration of breaks and emotions. No such change was seen by those who used the Baseline intervention.</p>
<h2>Reproductive Rights and Privacy</h2>
<h3>Unpacking the Lived Experience of Collaborative Pregnancy Tracking</h3>
<p>Authors: Yunan Chen, Elena Agapie, Xi Lu, Jacquelyn Powell, Daniel Epstein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148254">Link</a></p>
<p>Abstract: Pregnancy brings physical, emotional, and economic challenges for expectant parent(s), close relatives, and friends. Existing technology support, including tracking technology, largely targets pregnant people and ignores other stakeholders. We therefore lack an understanding of how to approach designing collaborative pregnancy tracking technology. To understand how people collaborate around pregnancy tracking and wish to do so, we interviewed 13 pregnant people and 11 non-pregnant stakeholders in the U.S., including partners, friends, and grandparents-to-be. We find that people collaborate for goals like social bonding and jointly managing various pregnancy data. Stakeholders collaborated by either dividing up data types or collectively monitoring the same information. We also identify tensions and challenges, such as pregnant people's privacy concerns and stakeholders' varied levels of interest in tracking. In light of socio-cultural norms and stakeholders' distinctive roles around pregnancy, we point to opportunities for designing collaborative technology that aligns with as well as challenges socio-cultural practices around pregnancy tracking.</p>
<h3>“Our Users' Privacy is Paramount to Us”: A Discourse Analysis of How Period and Fertility Tracking App Companies Address the Roe v Wade Overturn</h3>
<p>Authors: Rie Helene (Lindy) Hernandez, Qiurong Song, Xinning Gui, Yubo Kou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146889">Link</a></p>
<p>Abstract: After the overturn of Roe v. Wade gave states the license to ban abortion, numerous people in US have grown to worry about privacy in using period and fertility tracking apps. To address these concerns, some app companies have issued public statements to engage in privacy communication with their users. Prior literature has investigated period and fertility tracking apps’ data practices in their privacy policies. However, there remains a dearth of knowledge regarding how companies use privacy communication to address historic privacy-related events such as the overturn. To address the gap, this study investigated app companies’ public statements addressing the overturn of Roe using a combined approach of thematic and discourse analysis. Our findings revealed that companies strategically emphasize their commitment to privacy by demonstrating how their business practices and values are closely intertwined with their efforts to protect user data. We conclude by discussing translatable implications for privacy research.</p>
<h3>"I Deleted It After the Overturn of Roe v. Wade": Understanding Women's Privacy Concerns Toward Period-Tracking Apps in the Post Roe v. Wade Era</h3>
<p>Authors: Pardis Emami-Naeini, Hiba Laabadli, Jiaxun Cao, Chase Mathis, Rebecca Stern</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147370">Link</a></p>
<p>Abstract: The overturn of Roe v. Wade has taken away the constitutional right to abortion. Prior work shows that period-tracking apps' data practices can be used to detect pregnancy and abortion, hence putting women at risk of being prosecuted. It is unclear how much women know about the privacy practices of such apps and how concerned they are after the overturn. Such knowledge is critical to designing effective strategies for stakeholders to enhance women's reproductive privacy. We conducted an online 183-participant vignette survey with US women from states with diverse policies on abortion. Participants were significantly concerned about the privacy practices of the period-tracking apps, such as data access by law enforcement and third parties. However, participants felt uninformed and powerless about risk mitigation practices. We provide several recommendations to enhance women's privacy awareness toward their period-tracking practices.</p>
<h3>Teen Reproductive Health Information Seeking and Sharing Post-Roe</h3>
<p>Authors: Nora McDonald, Umama Dewan, Cora Sula</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146968">Link</a></p>
<p>Abstract: It has always been challenging for teens to access consistent and reliable information about their reproductive health. But we know little about the impact of recent changes to laws governing sex education and the right to abortion on teen reproductive health information seeking and sharing. We conducted interviews with 15 teens finding that, post-Roe, teens are concerned about risks of their reproductive health data, particularly as it relates to what they search and share on social media and period tracking apps. Different assessments of risk, related to sexual activity, state laws, social context, and cultural and family values, dictate information practices. But social risk (like being harassed or doxxed) is the biggest driver of information seeking and sharing practices among mostly non sexually active teens. We describe the complexities of teens navigating reproductive health post-Roe as well as offer some guidance about teen technology and privacy literacy.</p>
<h3>“I Did Watch ‘The Handmaid’s Tale’”: Threat Modeling Privacy Post-Roe in the United States</h3>
<p>Authors: Nora McDonald, Nazanin Andalibi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150756">Link</a></p>
<p>Abstract: Now that the protections of Roe v. Wade are no longer available throughout the United States, the free flow of personal data can be used by legal authorities to provide evidence of felony. However, we know little about how impacted individuals approach their reproductive privacy in this new landscape. We conducted interviews with 15 individuals who may get/were pregnant to address this gap. While nearly all reported deleting period tracking apps, they were not willing to go much further, even while acknowledging the risks of generating data. Quite a few considered a more inhospitable, Handmaid’s Tale like climate in which their medical history and movements would put them in legal peril but felt that, by definition, this reality was insuperable, and also that they were not the target—the notion that privileged location, stage of life did not make them the focus of government or vigilante efforts. We also found that certain individuals (often younger and/or with reproductive risks) were more attuned to the need to modify their technology or equipped to employ high and low-tech strategies. Using an intersectional lens, we discuss implications for media advocacy and propose privacy intermediation to frame our thinking about reproductive privacy.</p>
<h2>Universal Accessibility B</h2>
<h3>RASSAR: Room Accessibility and Safety Scanning in Augmented Reality</h3>
<p>Authors: Kaiming Cheng, Xia Su, Jon Froehlich, Qiaochu LIU, Jaewook Lee, Han Zhang, Wyatt Olson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148045">Link</a></p>
<p>Abstract: The safety and accessibility of our homes are critical and evolve as we age, become ill, host guests, or experience life events such as having children. Researchers and health professionals have created assessment instruments such as checklists that enable homeowners and trained experts to identify and mitigate safety and access issues. With advances in computer vision, augmented reality (AR), and mobile sensors, new approaches are now possible. We introduce RASSAR, a mobile AR application for semi-automatically identifying, localizing, and visualizing indoor accessibility and safety issues such as an inaccessible table height or unsafe loose rugs using LiDAR and real-time computer vision. We present findings from three studies: a formative study with 18 participants across five stakeholder groups to inform the design of RASSAR, a technical performance evaluation across ten homes demonstrating state-of-the-art performance, and a user study with six stakeholders. We close with a discussion of future AI-based indoor accessibility assessment tools, RASSAR's extensibility, and key application scenarios.</p>
<h3>A Design Space for Vision Augmentations and Augmented Human Perception using Digital Eyewear</h3>
<p>Authors: Jonathan Sutton, Tobias Langlotz, Holger Regenbrecht</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147983">Link</a></p>
<p>Abstract: Head-mounted displays were originally introduced to directly present computer-generated information to the human eye. More recently, the potential to use this kind of technology to support human vision and augment human perception has become actively pursued with applications such as compensating for visual impairments or aiding unimpaired vision. Unfortunately, a systematic analysis of the field is missing. Within this work, we close that gap by presenting a design space for vision augmentations that allows research to systematically explore the field of digital eyewear for vision aid and how it can augment the human visual system. We test our design space against currently available solutions and conceptually develop new solutions. The design space and findings can guide future development and can lead to a consistent categorisation of the many existing approaches.</p>
<h3>“I never realized sidewalks were a big deal”: A Case Study of a Community-Driven Sidewalk Accessibility Assessment using Project Sidewalk</h3>
<p>Authors: Michael Saugstad, Judy Shanley, Yochai Eisenberg, Jon Froehlich, Katrina Ma, Devon Snyder, Molly Delaney, Delphine Labbé, Kie Fujii, Chu Li, Florian P Thomas</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147783">Link</a></p>
<p>Abstract: Despite decades of effort, pedestrian infrastructure in cities continues to be unsafe or inaccessible to people with disabilities. In this paper, we examine the potential of community-driven digital civics to assess sidewalk accessibility through a deployment study of an open-source crowdsourcing tool called Project Sidewalk. We explore Project Sidewalk's potential as a platform for civic learning and service. Specifically, we assess its effectiveness as a tool for community members to learn about human mobility, urban planning, and accessibility advocacy. Our findings demonstrate that community-driven digital civics can support accessibility advocacy and education, raise community awareness, and drive pro-social behavioral change. We also outline key considerations for deploying digital civic tools in future community-led accessibility initiatives.</p>
<h3>A Virtual Reality Scene Taxonomy: Identifying and Designing Accessible Scene-Viewing Techniques</h3>
<p>Authors: Martez Mott, Sasa Junuzovic, Rachel Franz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150645">Link</a></p>
<p>Abstract: Virtual environments (VEs) afford similar interactions to those in physical environments: individuals can navigate and manipulate objects. Yet, a prerequisite for these interactions is being able to view the environment. Despite the existence of numerous scene-viewing techniques (i.e., interaction techniques that facilitate the visual perception of virtual scenes), there is no guidance to help designers choose which techniques to implement. We propose a scene taxonomy based on the visual structure and task within a VE by drawing on literature from cognitive psychology and computer vision, as well as virtual reality (VR) applications. We demonstrate how the taxonomy can be used by applying it to an accessibility problem, namely limited head mobility. We used the taxonomy to classify existing scene-viewing techniques and generate three new techniques that do not require head movement. In our evaluation of the techniques with 16 participants, we discovered that participants identified trade-offs in design considerations such as accessibility, realism, and spatial awareness, that would influence whether they would use the new techniques. Our results demonstrate the potential of the scene taxonomy to help designers reason about the relationships between VR interactions, tasks, and environments.</p>
<h2>Learning Programming with AI</h2>
<h3>How Beginning Programmers and Code LLMs (Mis)read Each Other</h3>
<p>Authors: Molly Feldman, Hannah McLean Babe, Carolyn Anderson, Sydney Nguyen, Arjun Guha, Yangtian Zi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146777">Link</a></p>
<p>Abstract: Generative AI models, specifically large language models (LLMs), have made strides towards the long-standing goal of text-to-code generation. This progress has invited numerous studies of user interaction. However, less is known about the struggles and strategies of non-experts, for whom each step of the text-to-code problem presents challenges: describing their intent in natural language, evaluating the correctness of generated code, and editing prompts when the generated code is incorrect. This paper presents a large-scale controlled study of how 120 beginning coders across three academic institutions approach writing and editing prompts. A novel experimental design allows us to target specific steps in the text-to-code process and reveals that beginners struggle with writing and editing prompts, even for problems at their skill level and when correctness is automatically determined. Our mixed-methods evaluation provides insight into student processes and perceptions with key implications for non-expert Code LLM use within and outside of education.</p>
<h3>Teach AI How to Code: Using Large Language Models as Teachable Agents for Programming Education</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Seonghee Lee, Hyungyu Shin, Hyoungwook Jin, Juho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148146">Link</a></p>
<p>Abstract: This work investigates large language models (LLMs) as teachable agents for learning by teaching (LBT). LBT with teachable agents helps learners identify knowledge gaps and discover new knowledge. However, teachable agents require expensive programming of subject-specific knowledge. While LLMs as teachable agents can reduce the cost, LLMs' expansive knowledge as tutees discourages learners from teaching. We propose a prompting pipeline that restrains LLMs' knowledge and makes them initiate "why" and "how" questions for effective knowledge-building. We combined these techniques into TeachYou, an LBT environment for algorithm learning, and AlgoBo, an LLM-based tutee chatbot that can simulate misconceptions and unawareness prescribed in its knowledge state. Our technical evaluation confirmed that our prompting pipeline can effectively configure AlgoBo's problem-solving performance. Through a between-subject study with 40 algorithm novices, we also observed that AlgoBo's questions led to knowledge-dense conversations (effect size=0.71). Lastly, we discuss design implications, cost-efficiency, and personalization of LLM-based teachable agents.</p>
<h3>ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12</h3>
<p>Authors: Liuqing Chen, Yaxuan Song, Yunnong Chen, Shuhong Xiao, Lingyun Sun, Ruoyu Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147770">Link</a></p>
<p>Abstract: As Computational Thinking (CT) continues to permeate younger age groups in K-12 education, established CT platforms such as Scratch face challenges in catering to these younger learners, particularly those in the elementary school (ages 6-12). Through formative investigation with Scratch experts, we uncover three key obstacles to children's autonomous Scratch learning: artist's block in project planning, bounded creativity in asset creation, and inadequate coding guidance during implementation. To address these barriers, we introduce ChatScratch, an AI-augmented system to facilitate autonomous programming learning for young children. ChatScratch employs structured interactive storyboards and visual cues to overcome artist's block, integrates digital drawing and advanced image generation technologies to elevate creativity, and leverages Scratch-specialized Large Language Models (LLMs) for professional coding guidance. Our study shows that, compared to Scratch, ChatScratch efficiently fosters autonomous programming learning, and contributes to the creation of high-quality, personally meaningful Scratch projects for children.</p>
<h3>“It’s Weird That it Knows What I Want”: Usability and Interactions with Copilot for Novice Programmers</h3>
<p>Authors: Paul Denny, Garrett Powell, James Prather, Brent Reeves, Brett Becker, Juho Leinonen, Andrew Luxton-Reilly, James Finnie-Ansley, Eddie Antonio Santos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150774">Link</a></p>
<p>Abstract: Recent developments in deep learning have resulted in code-generation models that produce source code from natural language and code-based prompts with high accuracy. This is likely to have profound effects in the classroom, where novices learning to code can now use free tools to automatically suggest solutions to programming exercises and assignments. However, little is currently known about how novices interact with these tools in practice. We present the first study that observes students at the introductory level using one such code auto-generating tool, Github Copilot, on a typical introductory programming (CS1) assignment. Through observations and interviews we explore student perceptions of the benefits and pitfalls of this technology for learning, present new observed interaction patterns, and discuss cognitive and metacognitive difficulties faced by students. We consider design implications of these findings, specifically in terms of how tools like Copilot can better support and scaffold the novice programming experience.</p>
<h2>Research Methods and Tools A</h2>
<h3>Designing a Card-Based Design Tool to Bridge Academic Research &amp; Design Practice For Societal Resilience</h3>
<p>BEST_PAPER</p>
<p>Authors: Chia-Fang Chung, Kay Connelly, Clara Caldeira, Novia Nurain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147574">Link</a></p>
<p>Abstract: Professional designers often struggle to apply insights from HCI research in their work. To make academic knowledge more accessible to practitioners, HCI researchers have created translational design tools, such as design cards, that support the translation of research insights into design practice. Prior work explored design cards for behavior change, interaction design, personal health informatics, and the sharing economy. Our work complements prior research by exploring the design and use of translational design cards for social aspects of societal resilience through a two-stage study with 14 student designers and eight professional designers. Our findings provide an empirical understanding of the design cards' generative value for incorporating research insights into the design process. Additionally, we discuss recommendations and highlight opportunities to enhance the design and use of the cards beyond societal resilience.</p>
<h3>Playing with Perspectives and Unveiling the Autoethnographic Kaleidoscope in HCI – A Literature Review of Autoethnographies</h3>
<p>Authors: Johannes Schöning, Annika Kaltenhauser, Evropi Stefanidi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148280">Link</a></p>
<p>Abstract: Autoethnography is a valuable methodological approach bridging the gap between personal experiences and academic inquiry, enabling researchers to gain deep insights into various dimensions of technology use and design. While its adoption in Human-Computer Interaction (HCI) continues to grow, a comprehensive investigation of its function and role within HCI research is still lacking. This paper examines the evolving landscape of autoethnographies within HCI over the past two decades through a systematic literature review. We identify prevalent themes, methodologies, and contributions emerging from autoethnographies by analysing a corpus of 31 HCI publications. Furthermore, we detail data collection techniques and analysis methods and describe reporting standards. Our literature review aims to inform future (HCI) researchers, practitioners, and designers. It encourages them to embrace autoethnography's rich opportunities by providing examples across domains (e.g., embodiment or health and wellbeing) to advance our understanding of the complex relationships between humans and technology.</p>
<h3>The Future of HCI-Policy Collaboration</h3>
<p>Authors: Steven Jackson, Thomas Gilbert, Qian Yang, Sabine Junginger, John Zimmerman, Richmond Wong, Margaret Hagan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147277">Link</a></p>
<p>Abstract: Policies significantly shape computation's societal impact, a crucial HCI concern. However, challenges persist when HCI professionals attempt to integrate policy into their work or affect policy outcomes. Prior research considered these challenges at the "border" of HCI and policy. This paper asks: What if HCI considers policy integral to its intellectual concerns, placing system-people-policy interaction not at the border but nearer the center of HCI research, practice, and education? What if HCI fosters a mosaic of methods and knowledge contributions that blend system, human, and policy expertise in various ways, just like HCI has done with blending system and human expertise? We present this re-imagined HCI-policy relationship as a provocation and highlight its usefulness: It spotlights previously overlooked system-people-policy interaction work in HCI. It unveils new opportunities for HCI's futuring, empirical, and design projects. It allows HCI to coordinate its diverse policy engagements, enhancing its collective impact on policy outcomes.</p>
<h3>DiaryHelper: Exploring the Use of an Automatic Contextual Information Recording Agent for Elicitation Diary Study</h3>
<p>Authors: Junze Li, Changyang He, Xiaojuan Ma, Alon Halevy, Jiaxiong Hu, Boyang Jia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147624">Link</a></p>
<p>Abstract: Elicitation diary studies, a type of qualitative, longitudinal research method, involve participants to self-report aspects of events of interest at their occurrences as memory cues for providing details and insights during post-study interviews. However, due to time constraints and lack of motivation, participants’ diary entries may be vague or incomplete, impairing their later recall. To address this challenge, we designed an automatic contextual information recording agent, DiaryHelper, based on the theory of episodic memory. DiaryHelper can predict five dimensions of contextual information and confirm with participants. We evaluated the use of DiaryHelper in both the recording period and the elicitation interview through a within-subject study (N=12) over a period of two weeks. Our results demonstrated that DiaryHelper can assist participants in capturing abundant and accurate contextual information without significant burden, leading to a more detailed recall of recorded events and providing greater insights.</p>
<h3>CoAIcoder: Examining the Effectiveness of AI-assisted Human-to-Human Collaboration in Qualitative Analysis</h3>
<p>Authors: Simon Perrault, Jie Gao, Roy Ka-Wei Lee, Kenny Tsu Wei Choo, Junming Cao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150647">Link</a></p>
<p>Abstract: While AI-assisted individual qualitative analysis has been substantially studied, AI-assisted collaborative qualitative analysis (CQA) – a process that involves multiple researchers working together to interpret data—remains relatively unexplored. After identifying CQA practices and design opportunities through formative interviews, we designed and implemented CoAIcoder, a tool leveraging AI to enhance human-to-human collaboration within CQA through four distinct collaboration methods. With a between-subject design, we evaluated CoAIcoder with 32 pairs of CQA-trained participants across common CQA phases under each collaboration method. Our findings suggest that while using a shared AI model as a mediator among coders could improve CQA efficiency and foster agreement more quickly in the early coding stage, it might affect the final code diversity. We also emphasize the need to consider the independence level when using AI to assist human-to-human collaboration in various CQA scenarios. Lastly, we suggest design implications for future AI-assisted CQA systems.</p>
<h2>AI for Researchers and Educators</h2>
<h3>PaperWeaver: Enriching Topical Paper Alerts by Contextualizing Recommended Papers with User-collected Papers</h3>
<p>Authors: Pao Siangliulue, Matt Latzke, Hyeonsu Kang, Joseph Chee Chang, Jonathan Bragg, Juho Kim, Yoonjoo Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147172">Link</a></p>
<p>Abstract: With the rapid growth of scholarly archives, researchers subscribe to "paper alert" systems that periodically provide them with recommendations of recently published papers that are similar to previously collected papers. However, researchers sometimes struggle to make sense of nuanced connections between recommended papers and their own research context, as existing systems only present paper titles and abstracts. To help researchers spot these connections, we present PaperWeaver, an enriched paper alerts system that provides contextualized text descriptions of recommended papers based on user-collected papers. PaperWeaver employs a computational method based on Large Language Models (LLMs) to infer users’ research interests from their collected papers, extract context-specific aspects of papers, and compare recommended and collected papers on these aspects. Our user study (N=15) showed that participants using PaperWeaver were able to better understand the relevance of recommended papers and triage them more confidently when compared to a baseline that presented the related work sections from recommended papers.</p>
<h3>Integrating measures of replicability into scholarly search: Challenges and opportunities</h3>
<p>Authors: Sarah Rajtmajer, Tatiana Chakravorti, John Carroll, Chuhao Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146636">Link</a></p>
<p>Abstract: Challenges to reproducibility and replicability have gained widespread attention, driven by large replication projects with lukewarm success rates. A nascent work has emerged developing algorithms to estimate the replicability of published findings. The current study explores ways in which AI-enabled signals of confidence in research might be integrated into the literature search. We interview 17 PhD researchers about their current processes for literature search and ask them to provide feedback on a replicability estimation tool. Our findings suggest that participants tend to confuse replicability with generalizability and related concepts. Information about replicability can support researchers throughout the research design processes. However, the use of AI estimation is debatable due to the lack of explainability and transparency. The ethical implications of AI-enabled confidence assessment must be further studied before such tools could be widely accepted. We discuss implications for the design of technological tools to support scholarly activities and advance replicability.</p>
<h3>How AI Processing Delays Foster Creativity: Exploring Research Question Co-Creation with an LLM-based Agent</h3>
<p>Authors: Andrew Mo, Yun Huang, Yiren Liu, Xiao Ran, Mengxia Yu, Haocong Cheng, Si Chen, Yiliu Tang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146979">Link</a></p>
<p>Abstract: Developing novel research questions (RQs) often requires extensive literature reviews, especially in interdisciplinary fields. To support RQ development through human-AI co-creation, we leveraged Large Language Models (LLMs) to build an LLM-based agent system named CoQuest. We conducted an experiment with 20 HCI researchers to examine the impact of two interaction designs: breadth-first and depth-first RQ generation. The findings revealed that participants perceived the breadth-first approach as more creative and trustworthy upon task completion. Conversely, during the task, participants considered the depth-first generated RQs as more creative. Additionally, we discovered that AI processing delays allowed users to reflect on multiple RQs simultaneously, leading to a higher quantity of generated RQs and an enhanced sense of control. Our work makes both theoretical and practical contributions by proposing and evaluating a mental model for human-AI co-creation of RQs. We also address potential ethical issues, such as biases and over-reliance on AI, advocating for using the system to improve human research creativity rather than automating scientific inquiry. The system’s source is available at: https://github.com/yiren-liu/coquest.</p>
<h3>"This is not a data problem": Algorithms and Power in Public Higher Education in Canada</h3>
<p>Authors: Kelly McConvey, Shion Guha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147823">Link</a></p>
<p>Abstract: Algorithmic decision-making is increasingly being adopted across public higher education. The expansion of data-driven practices by post-secondary institutions has occurred in parallel with the adoption of New Public Management approaches by neoliberal administrations. In this study, we conduct a qualitative analysis of an in-depth ethnographic case study of data and algorithms in use at a public college in Ontario, Canada. We identify the data, algorithms, and outcomes in use at the college. We assess how the college's processes and relationships support those outcomes and the different stakeholders' perceptions of the college's data-driven systems. In addition, we find that the growing reliance on algorithmic decisions leads to increased student surveillance, exacerbation of existing inequities, and the automation of the faculty-student relationship. Finally, we identify a cycle of increased institutional power perpetuated by algorithmic decision-making, and driven by a push towards financial sustainability.</p>
<h3>PaperPlain: Making Medical Research Papers Approachable to Healthcare Consumers with Natural Language Processing</h3>
<p>Authors: Tal August, Jonathan Bragg, Kyle Lo, Andrew Head, Marti Hearst, Lucy Lu Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150900">Link</a></p>
<p>Abstract: When seeking information not covered in patient-friendly documents, healthcare consumers may turn to the research literature. Reading medical papers, however, can be a challenging experience. To improve access to medical papers, we introduce a novel interactive interface---Paper Plain---with four features enabled by natural language processing: definitions of unfamiliar terms, in-situ plain language section summaries, a collection of key questions that guides readers to answering passages, and plain language summaries of those passages. We evaluate Paper Plain, finding that participants who used Paper Plain had an easier time reading research papers without a loss in paper comprehension compared to those who used a typical PDF reader. Altogether, the study results suggest that guiding readers to relevant passages and providing plain language summaries alongside the original paper content can make reading medical papers easier and give readers more confidence to approach these papers.</p>
<h2>Crisis Informatics</h2>
<h3>Choosing the Right Reality: A Comparative Analysis of Tangibility in Immersive Trauma Simulations</h3>
<p>Authors: Benjamin Schuster, Rodrigo Gutierrez, Helmut Schrom-Feiertag, Georg Regal, Manfred Tscheligi, Jakob Uhl</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147464">Link</a></p>
<p>Abstract: In the field of medical first responder training, the choice of training modality is crucial for skill retention and real-world application. This study introduces the Green Manikin, an advanced Mixed Reality (MR) tool, conceptually combining the immersiveness of Virtual Reality (VR) with the tangibility of real-world training, and compares it against traditional real-world simulations and VR training. Our findings indicate that MR and real-world settings excel in Self and Social Presence, and in intention to use, offering heightened psychological presence suitable for complex training scenarios. Effort expectancy was highest in real-world environments, suggesting their ease of use for basic skill acquisition. This nuanced understanding allows for better tailoring of training modalities to specific educational objectives. Our research validates the utility of MR and offers a framework for selecting the most effective training environment for different learning outcomes in medical first responder training.</p>
<h3>Comparison of Spatial Visualization Techniques for Radiation in Augmented Reality</h3>
<p>Authors: Joan Baixauli, Roderick McCall, Fintan McGee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146651">Link</a></p>
<p>Abstract:  Augmented Reality (AR) provides a safe and low-cost option for hazardous safety training that allows for the visualization of aspects that may be invisible, such as radiation. Effectively visually communicating such threats in the environment around the user is not straightforward. This work describes visually encoding radiation using the spatial awareness mesh of an AR Head Mounted Display.  We leverage the AR device’s GPUs to develop a real time solution that accumulates multiple dynamic sources and uses stencils to prevent an environment being over saturated with a visualization, as well as supporting the encoding of direction explicitly in the visualization. We perform a user study (25 participants) of different visualizations and obtain user feedback. Results show that there are complex interactions and while no visual representation was statistically superior or inferior, user opinions vary widely. We also discuss the evaluation approaches and provide recommendations.</p>
<h3>Exploring the Design Space of Optical See-through AR Head-Mounted Displays to Support First Responders in the Field</h3>
<p>Authors: Lance Hartung, Kexin Zhang, Ruijia Chen, Kevin Ponto, Yuhang Zhao, Bryce Sprecher, Brianna Cochran, Ross Tredinnick, Suman Banerjee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146943">Link</a></p>
<p>Abstract: First responders (FRs) navigate hazardous, unfamiliar environments in the field (e.g., mass-casualty incidents), making life-changing decisions in a split second. AR head-mounted displays (HMDs) have shown promise in supporting them due to its capability of recognizing and augmenting the challenging environments in a hands-free manner. However, the design space have not been thoroughly explored by involving various FRs who serve different roles (e.g., firefighters, law enforcement) but collaborate closely in the field. We interviewed 26 first responders in the field who experienced a state-of-the-art optical-see-through AR HMD, as well as its interaction techniques and four types of AR cues (i.e., overview cues, directional cues, highlighting cues, and labeling cues), soliciting their first-hand experiences, design ideas, and concerns. Our study revealed both generic and role-specific preferences and needs for AR hardware, interactions, and feedback, as well as identifying desired AR designs tailored to urgent, risky scenarios (e.g., affordance augmentation to facilitate fast and safe action). While acknowledging the value of AR HMDs, concerns were also raised around trust, privacy, and proper integration with other equipment. Finally, we derived comprehensive and actionable design guidelines to inform future AR systems for in-field FRs.</p>
<h3>Transitioning Cognitive Aids into Decision Support Platforms: Requirements and Design Guidelines</h3>
<p>Authors: Aleksandra Sarcevic, Angela Mastrianni, Randall Burd, Allison Hu, Sarah Gao, Lynn Almengor, Peyton Tempel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150760">Link</a></p>
<p>Abstract: Digital cognitive aids have the potential to serve as clinical decision support platforms, triggering alerts about process delays and recommending interventions. In this mixed-methods study, we examined how a digital checklist for pediatric trauma resuscitation could trigger decision support alerts and recommendations. We identified two criteria that cognitive aids must satisfy to support these alerts: (1) context information must be entered in a timely, accurate, and standardized manner, and (2) task status must be accurately documented. Using co-design sessions and near-live simulations, we created two checklist features to satisfy these criteria: a form for entering the pre-hospital information and a progress slider for documenting the progression of a multi-step task. We evaluated these two features in the wild, contributing guidelines for designing these features on cognitive aids to support alerts and recommendations in time- and safety-critical scenarios.</p>
<h2>Curating Online Content B</h2>
<h3>Bystanders of Online Moderation: Examining the Effects of Witnessing Post-Removal Explanations</h3>
<p>Authors: Himanshu Rathi, Koustuv Saha, Shagun Jhaver</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148129">Link</a></p>
<p>Abstract: Prior research on transparency in content moderation has demonstrated the benefits of offering post-removal explanations to sanctioned users. In this paper, we examine whether the influence of such explanations transcends those who are moderated to the bystanders who witness such explanations. We conduct a quasi-experimental study on two popular Reddit communities (r/AskReddit and r/science) by collecting their data spanning 13 months—a total of 85.5M posts made by 5.9M users. Our causal-inference analyses show that bystanders significantly increase their posting activity and interactivity levels as compared to their matched control set of users. In line with previous applications of Deterrence Theory on digital platforms, our findings highlight that understanding the rationales behind sanctions on other users significantly shapes observers' behaviors. We discuss the theoretical implications and design recommendations of this research, focusing on how investing more efforts in post-removal explanations can help build thriving online communities.</p>
<h3>Community Begins Where Moderation Ends: Peer Support and Its Implications for Community-Based Rehabilitation</h3>
<p>Authors: Zinan Zhang, Yingfan Zhou, Renkai Ma, Xinning Gui, Yubo Kou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146823">Link</a></p>
<p>Abstract: Moderation systems of online games often follow a retributive model inspired by real-world criminal justice, expecting that punishments can help users to reform behavior. However, decades of criminological research show that punishments alone do not work and call for a rehabilitative approach, such as community-based rehabilitation (CBR), to help offenders transform their minds and behavioral patterns. Motivated by this call, we explore how moderated users view punishments in a community context and how other community members respond in League of Legends (LoL), one of the largest online games. Specifically, we focus on how peer support is sought and provided on the /r/LeagueOfLegends subreddit, the largest LoL-related online community. Our content analysis of player discussions characterized the communication between moderated users and peers as informative, constructive, and reflexive. We highlight the importance of involving community in moderation systems and discuss implications for designing CBR mechanisms that could enhance moderation systems.</p>
<h3>Agency Aspirations: Understanding Users’ Preferences And Perceptions Of Their Role In Personalised News Curation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ewa Luger, John Vines, Michael Evans, Anna Rezk, Auste Simkute, Chris Elsden, Rhianne Jones</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147968">Link</a></p>
<p>Abstract: Recommender systems are increasingly employed by journalistic outlets to deliver personalised news, transforming news curation into a reciprocal yet insufficiently defined process influenced by editors, recommender systems, and individual user actions. To understand the tension in this dynamic and users’ preferences and perceptions of their role in personalised news curation, we conducted a study with UK participants aged 16-34. Building on a preliminary survey and interview study, which revealed a strong desire from participants for increased agency in personalisation, we designed an interactive news recommender provotype (provocative design artefact) which probed the role of agency in news curation with participants (n=16). Findings highlighted a behaviour-intention gap, indicating participants desire for agency yet reluctance to intervene actively in personalisation. Our research offers valuable insights into how users perceive their agency in personalised news curation, underscoring the importance for systems to be designed to support individuals becoming active agents in news personalisation.</p>
<h3>Wikibench: Community-Driven Data Curation for AI Evaluation on Wikipedia</h3>
<p>Authors: Kenneth Holstein, Haiyi Zhu, Zirui Cheng, Aaron Halfaker, Jiwoo Kim, Tongshuang Wu, Tzu-Sheng Kuo, Meng-Hsin Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146778">Link</a></p>
<p>Abstract: AI tools are increasingly deployed in community contexts. However, datasets used to evaluate AI are typically created by developers and annotators outside a given community, which can yield misleading conclusions about AI performance. How might we empower communities to drive the intentional design and curation of evaluation datasets for AI that impacts them? We investigate this question on Wikipedia, an online community with multiple AI-based content moderation tools deployed. We introduce Wikibench, a system that enables communities to collaboratively curate AI evaluation datasets, while navigating ambiguities and differences in perspective through discussion. A field study on Wikipedia shows that datasets curated using Wikibench can effectively capture community consensus, disagreement, and uncertainty. Furthermore, study participants used Wikibench to shape the overall data curation process, including refining label definitions, determining data inclusion criteria, and authoring data statements. Based on our findings, we propose future directions for systems that support community-driven data curation.</p>
<h3>Empirical Investigation of Accessibility Bug Reports in Mobile Platforms: A Chromium Case Study</h3>
<p>Authors: Wajdi Aljedaani, Mohamed Wiem Mkaouer, Marouane Kessentini, Marcelo Eler</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147552">Link</a></p>
<p>Abstract: Accessibility is an important quality factor of mobile applications. Many studies have shown that, despite the availability of many resources to guide the development of accessible software, most apps and web applications contain many accessibility issues. Some researchers surveyed professionals and organizations to understand the lack of accessibility during software development, but few studies have investigated how developers and organizations respond to accessibility bug reports. Therefore, this paper analyzes accessibility bug reports posted in the Chromium repository to understand how developers and organizations handle them. More specifically, we want to determine the frequency of accessibility bug reports over time, the time-to-fix compared to traditional bug reports (e.g., functional bugs), and the types of accessibility barriers reported. Results show that the frequency of accessibility reports has increased over the years, and accessibility bugs take longer to be fixed, as they tend to be given low priority.</p>
<h2>Body and Wellbeing</h2>
<h3>Critiquing Menstrual Pain Technologies through the Lens of Feminist Disability Studies</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Marianela Ciolfi Felice, Joo Young Park, Madeline Balaam, Nadia Campo Woytuk, Stacy Hsueh, Xuni Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147659">Link</a></p>
<p>Abstract: Menstrual pain or \textit{dysmenorrhea} refers to abdominal cramping or pain before and during menstruation, causing a spectrum of discomfort among people who menstruate. Menstrual pain is often regarded as `female trouble', as a nuisance that gets dismissed or as a symptom requiring medical intervention. While there are FemTech products that explicitly attend to menstrual pain, they predominantly seek to hide it without accounting for the lived experience of this pain. In this paper we use feminist disability studies (FDS) as a critical analytical lens to reframe the understanding of menstrual pain. Using this lens, we conduct an interaction critique of FemTech market exemplars for alleviating menstrual pain. We then offer three design provocations to better design menstrual pain technology and call for designers to attend to menstrual pain as a cyclical, chronic lived experience with the potential of spurring leaky contagious coalitions.</p>
<h3>Enhancing Auto-Generated Baseball Highlights via Win Probability and Bias Injection Method</h3>
<p>Authors: Bongwon Suh, Kieun Park, Hajin Lim, Joonhwan Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146747">Link</a></p>
<p>Abstract: The automatic generation of sports highlight videos is emerging in both the sports entertainment domain and research community. Earlier methods for generating highlights rely on visual-audio cues or contextual cues, so they may not capture the overall flow of the game well. In this paper, we propose a technique based on Win Probability Added (WPA), an empirical sabermetric baseball statistic, to generate baseball highlights that can better reflect in-game dynamics. Additionally, we introduce methods for generating “biased” highlights toward one team by systematically manipulating WPAs. Through a mixed-method user study with 43 baseball enthusiasts, we found that participants evaluated WPA-based highlights more favorably than existing AI highlights. For (un)favorably biased highlights, the game result(win/loss) was the most dominating factor in user perception, but bias directions and strengths also had nuanced effects on them. Our work contributes to the development of automated tools for generating customized sports highlights.</p>
<h3>Understanding the Effect of Reflective Iteration on Individuals’ Physical Activity Planning</h3>
<p>Authors: Kefan Xu, Mark Newman, Xinghui (Erica) Yan, Myeonghan Ryu, Rosa Arriaga</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148178">Link</a></p>
<p>Abstract: Many people do not get enough physical activity. Establishing routines to incorporate physical activity into people's daily lives is known to be effective, but many people struggle to establish and maintain routines when facing disruptions. In this paper, we build on prior self-experimentation work to assist people in establishing or improving physical activity routines using a framework we call “reflective iteration.” This framework encourages individuals to articulate, reflect upon, and iterate on high-level “strategies” that inform their day-to-day physical activity plans. We designed and deployed a mobile application, Planneregy, that implements this framework. Sixteen U.S. college students used the Planneregy app for 42 days to reflectively iterate on their weekly physical exercise routines. Based on an analysis of usage data and interviews, we found that the reflective iteration approach has the potential to help people find and maintain effective physical activity routines, even in the face of life changes and temporary disruptions.  </p>
<h3>Sensible and Sensitive AI for Worker Wellbeing: Factors that Inform Adoption and Resistance for Information Workers</h3>
<p>BEST_PAPER</p>
<p>Authors: Munmun De Choudhury, Lan Gao, Gregory Abowd, Vedant Das Swain, Abhirup Mondal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146807">Link</a></p>
<p>Abstract: Algorithmic estimations of worker behavior are gaining popularity. Passive Sensing–enabled AI ( PSAI ) systems leverage behavioral traces from workers' digital tools to infer their experience. Despite their conceptual promise, the practical designs of these systems elicit tensions that lead to workers resisting adoption. This paper teases apart the monolithic representation of PSAI by investigating system components that maximize value and mitigate concerns. We conducted an interactive online survey using the Experimental Vignette Method. Using Linear Mixed-effects Models we found that PSAI systems were more acceptable when sensing digital time use or physical activity, instead of visual modes. Inferences using language were only acceptable in work-restricted contexts. Compared to insights into performance, workers preferred insights into mental wellbeing. However, they resisted systems that automatically forwarded these insights to others. Our findings provide a template to reflect on existing systems and plan future implementations of PSAI to be more worker-centered.</p>
<h3>Thrown from Normative Ground: Exploring the Potential of Disorientation as a Critical Methodological Strategy in HCI</h3>
<p>Authors: Heidi Biggs, Shaowen Bardzell</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147235">Link</a></p>
<p>Abstract: We introduce the concept of disorientation as an emerging critical methodological strategy for design research in HCI. Disorientation is a phenomenological concept developed by queer feminist theorist Sarah Ahmed that acknowledges the spatio-embodied ‘orientations’ of societal and cultural norms and the queering potential of ‘disorientations’. We use humanistic close reading to analyze three examples from queer, feminist, and more-than-human work in HCI. Our interpretation focuses on how HCI researchers utilize disorientation as a methodological strategy for questioning norms of technologies as well as generatively, toward alternatives. We discuss the tenets of disorientation and several tactics we saw emerge in practice for other practitioners to build upon. Finally, we reflect on implications for the field, as disorientation requires vulnerability and willingness to undergo change, acknowledges embodied knowledge that emerges before interpretation, and suggests the possibility of generative and alternative orientations stemming from those epistemological commitments.</p>
<h2>Fabrication and Dynamic Structures</h2>
<h3>Reconfigurable Interfaces by Shape Change and Embedded Magnets</h3>
<p>Authors: Andrea Bianchi, Clement Zheng, Kongpyung (Justin) Moon, Jeeeun Kim, Himani Deshpande, Bo Han</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147224">Link</a></p>
<p>Abstract: Reconfigurable physical interfaces empower users to swiftly adapt to tailored design requirements or preferences. Shape-changing interfaces enable such reconfigurability, avoiding the cost of refabrication or part replacements. Nonetheless, reconfigurable interfaces are often bulky, expensive, or inaccessible. </p>
<p>We propose a reversible shape-changing mechanism that enables reconfigurable 3D printed structures via translations and rotations of parts. </p>
<p>We investigate fabrication techniques that enable reconfiguration using magnets and the thermoplasticity of heated polymer.</p>
<p>Proposed interfaces achieve tunable haptic feedback and adjustment of different user affordances by reconfiguring input motions. The design space is demonstrated through applications in rehabilitation, embodied communication, accessibility, safety, and gaming.</p>
<h3>ConeAct: A Multistable Actuator for Dynamic Materials</h3>
<p>Authors: Yash Rajeev Banka, Yuyu Lin, Jesse Gonzalez, Alexandra Ion, Zhitong Cui</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147261">Link</a></p>
<p>Abstract: Complex actuators in a small form factor are essential for dynamic interfaces. In this paper, we propose ConeAct, a cone-shaped actuator that can extend, contract, and bend in multiple directions to support rich expression in dynamic materials. A key benefit of our actuator is that it is self-contained and portable as the whole system. We designed our actuator’s structure to be multistable to hold its shape passively, while we control its transition between states using active materials, i.e., shape memory alloys. We present the design space by showcasing our actuator module as part of self-rolling robots, reconfigurable deployable structures, volumetric shape-changing objects and tactile displays. To assist users in designing such structures, we present an interactive editor including simulation to design such interactive capabilities.</p>
<h3>TensionFab: Fabrication of Room-scale Surface Structures From the Tension-Active Form of Planar Modules</h3>
<p>Authors: Ziyuan Jiang, Yahui Lyu, Alessandro Garzanti, Carlos Garcia Fernandez, Taiga Urata, Yasuaki Kakehi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146649">Link</a></p>
<p>Abstract: We propose TensionFab, a novel technique for creating shape-changeable room-scale structures. This method employs easily available planar materials (plywood, MDF), cuts them into multiple 2D shapes, and then connects the pieces manually to create a unified structure capable of 2D and 3D deformations. Constructed TensionFab structures are characterized by easy achievability of target surfaces, substantial structural strength, shape changeability, time and material savings, and easy storage and transportation. In this paper, we introduce the basic principles of shape-making, module combination, and structural characteristics of TensionFab. We also developed a design assistance tool to allow users to automate design based on the target shape. We evaluate the design results for shape detection and structural performance. Finally, we validate the approach with actual construction and propose a variety of application scenarios. Overall, TensionFab is an efficient strategy for spatial design and structural organization. This paper contributes to research and exploration in the HCI room-scale interaction field.</p>
<h3>Robotic Metamaterials: A Modular System for Hands-On Configuration of Ad-Hoc Dynamic Applications</h3>
<p>Authors: Violet Yinuo Han, Alan Zhu, Shuhong Wang, Willa Yunqi Yang, Tucker Rae-Grant, Alexandra Ion, Scott Hudson, Zhitong Cui</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147544">Link</a></p>
<p>Abstract: We propose augmenting initially passive structures built from simple repeated cells, with novel active units to enable dynamic, shape-changing, and robotic applications. Inspired by metamaterials that can employ mechanisms, we build a framework that allows users to configure cells of this passive structure to allow it to perform complex tasks. A key benefit is that our structures can be repeatedly (re)configured by users inserting our configuration units to turn the passive material into, e.g., locomotion robots, integrated motion platforms, or interactive interfaces, as we demonstrate in this paper. </p>
<p>To this end, we present a mechanical system consisting of a flexible, passive, shearing lattice structure, as well as rigid and active unit cells to be inserted into the lattice for configuration. The active unit is a closed-loop pneumatically controlled shearing cell to dynamically actuate the macroscopic movement of the structure. The passive rigid cells redirect the forces to create complex motion with a reduced number of active cells. Since the placement of the rigid and active units is challenging, we offer a computational design tool. The tool optimizes the cell placement to match the macroscopic, user-defined target motions and generates the control code for the active cells.</p>
<h3>Nothing Like Compilation: How Professional Digital Fabrication Workflows Go Beyond Extruding, Milling, and Machines</h3>
<p>Authors: Nadya Peek, Gabrielle Benabdallah, Jennifer Jacobs, Mare Hirsch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/156318">Link</a></p>
<p>Abstract: Understanding how professionals use digital fabrication in production workflows is critical for future research in digital fabrication technologies. We interviewed thirteen professionals who use digital fabrication for the low-volume manufacturing of commercial products. From these interviews, we describe the workflows used for nine products created with a variety of materials and manufacturing methods. We show how digital fabrication professionals use software development to support physical production, how they rely on multiple partial representations in development, how they develop manufacturing processes, and how machine control is its own design space. We build from these findings to argue that future digital fabrication systems should support the exploration of material and machine behavior alongside geometry, that simulation is insufficient for understanding the design space, and that material constraints and resource management are meaningful design dimensions to support. By observing how professionals learn, we suggest ways digital fabrication systems can scaffold the mastery of new fabrication techniques.</p>
<h2>Indigeonus Communities and Cutural Heritage A</h2>
<h3>Griot-Style Methodology: Longitudinal Study of Navigating Design With Unwritten Stories</h3>
<p>Authors: Lindah Kotut, Morva Saaty, Derek Haqq, Taha Hassan, Neelma Bhatti</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147144">Link</a></p>
<p>Abstract: We describe a seven-year longitudinal study conducted in collaboration with an indigenous community in Kenya. We detail the process of conducting research with an oral community: the deliberate practice of understanding and collecting stories; working with inter-generational community to envision and design technologies that support their ways of storytelling and story preservation; and to influence the design of other technologies. We chronicle how we contended with translating oral stories with rich metaphors to new mediums, and the dimensions of trust we have established and continue to reinforce. We offer our griot-style methodology, informed by working with the community and retrofitting existing HCI approaches: as an example model of what has worked, and the dimensions of challenges at each stage of the research work. The griot-style methodology has prompted a reflection on how we approach research, and present opportunities for other HCI research and practice of handling community stories.</p>
<h3>Where Generalized Equitable Design Practice Meet Specific Indigenous Communities</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Kari Noe, Nurit Kirshenbaum</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148185">Link</a></p>
<p>Abstract: There are many approaches to design frameworks that guide designers through co-designing with Indigenous communities. Designers that want to be respectful to the Indigenous communities look towards these equitable design approaches to ensure they are not perpetuating histories of harm. However, some of these approaches are prescriptive to a generalized “Indigenous community." Through these guidelines designers often develop a practice through their own interpretations of what is equitable for this learned idea of a generalized Indigenous community. This can be limiting, as what are respectful practices to an Indigenous community can be vastly different. This paper engages with these generalized guidelines of co-design to present and discuss a method of developing customized practice to collaborate with specific Indigenous communities. We showcase the framework with our experience of developing a design practice for the Office of Indigenous Knowledge and Innovation’s work with the Kanaka Maoli (Native Hawaiian) community.</p>
<h3>Critical Heritage Studies as a Lens to Understand Short Video Sharing of Intangible Cultural Heritage on Douyin</h3>
<p>Authors: Minzhu Zhao, Wanyang Hu, Huanchen Wang, Zhicong Lu, Yuxin Ma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147828">Link</a></p>
<p>Abstract: Intangible Cultural Heritage (ICH) faces numerous threats that can lead to its destruction. While the emergence of short video platforms provides opportunities for fostering innovation and communication among ICH practitioners and viewers, it is still understudied how different stakeholders present, explain, and manage ICH via short videos. To address this, we conduct a mixed-method study of ICH-related videos on Douyin, a popular short video platform in China with an extensive user base and wealth of ICH content. By adopting the Critical Heritage Studies (CHS) framework, we propose a taxonomy of frames that construct the landscape of ICH short videos and then investigate the interactions among different groups regarding power, identity, and knowledge. Additionally, we analyze viewer responses to different frames and groups based on audience metrics (e.g., # of likes and comments) and comments. Our research reveals that government-affiliated and indigenous groups dominate the promotion and presentation of ICH on Douyin. Contrary to previous literature, viewer responses show a preference for videos from external ICH groups and ordinary individuals, suggesting a tendency to counter authority and exclusivity associated with ICH. Moreover, it highlights a lack of sustainable debates and negotiations among different groups involved in ICH discourse. Situated within CHS, we provide design implications for ICH safeguarding and sustainability through short videos and online media.</p>
<h3>Cultivating Spoken Language Technologies for Unwritten Languages</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ondrej Klejch, Simon Robinson, Jennifer Pearson, Dani Kalarikalayil Raju, Peter Bell, Electra Wallington, Thomas Reitmaier, Matt Jones, Nina Markl</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147443">Link</a></p>
<p>Abstract: We report on community-centered, collaborative research that weaves together HCI, natural language processing, linguistic, and design insights to develop spoken language technologies for unwritten languages. Across three visits to a Banjara farming community in India, we use participatory, technical, and creative methods to engage community members, collect spoken language photo annotations, and develop an information retrieval (IR) system. Drawing on orality theory, we interrogate assumptions and biases of current speech interfaces and create a simple application that leverages our IR system to match fluidly spoken queries with recorded annotations and surface corresponding photos. In-situ evaluations show how our novel approach returns reliable results and inspired the co-creation of media retrieval use-cases that are more appropriate in oral contexts. The very low (&lt; 4h) spoken data requirements makes our approach adaptable to other contexts where languages are unwritten or have no digital language resources available.</p>
<h2>Indigeonus Communities and Cutural Heritage B</h2>
<h3>Partiality and Misconception: Investigating Cultural Representativeness in Text-to-Image Models</h3>
<p>Authors: Lili Zhang, Zaijia Yang, Qiuling Yang, Deshun Li, Chunjie Wang, Baihang Gao, Xi Liao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148011">Link</a></p>
<p>Abstract: Text-to-image (T2I) models enable users worldwide to create high-definition and realistic images through text prompts, where the underrepresentation and potential misinformation of images have raised growing concerns. However, few existing works examine cultural representativeness, especially involving whether the generated content can fairly and accurately reflect global cultures. Combining automated and human methods, we investigate this issue in multiple dimensions quantificationally and conduct a set of evaluations on three prevailing T2I models (DALL-E v2, Stable Diffusion v1.5 and v2.1). Introducing attributes of cultural cluster and subject, we provide a fresh interdisciplinary perspective to bias analysis. The benchmark dataset UCOGC is presented, which encompasses authentic images of unique cultural objects from global clusters. Our results reveal that the culture of a disadvantaged country is prone to be neglected, some specified subjects often present a stereotype or a simple patchwork of elements, and over half of cultural objects are mispresented.</p>
<h3>Examining the "Local" in ICT4D: A Postcolonial Perspective on Participation</h3>
<p>Authors: Pedro Ferreira</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146929">Link</a></p>
<p>Abstract: ICT4D has increasingly adopted participation and community involvement to address power imbalances, namely through the figure of the "local". However, this reliance makes assumptions about the nature of the "local" while limiting scrutiny of research approaches. Through a Postcolonial Critical Discourse Analysis, this paper argues that 1) communities are often essentialized in agency-depriving ways, 2) researchers claim substantial discretionary power in representing communities, and 3) participatory approaches are framed as inherently beneficial, obscuring compromises. The analysis suggests participation serves to maintain the status quo. Going forward, ICT4D research should ground claims in evidence, demonstrate community benefits, acknowledge complexities transparently, and question premises that empirical gaps alone justify research. Rather than participation as a panacea, a reflexive ICT4D should scrutinize representational practices and notions of empowerment that may perpetuate inequities.</p>
<h3>On the Role of Materials Experience for Novel Interactions with Digital Representations of Historical Pop-up and Movable Books</h3>
<p>Authors: Stefano Parisi, Jeff Love, Elvin Karana, Willemijn Elkhuizen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147645">Link</a></p>
<p>Abstract: Direct interaction with cultural heritage (CH) artefacts is frequently unavailable to visitors, offering an opportunity for HCI designers to explore integrating material aspects into digitally-mediated encounters with CH artefacts. We argue that a thorough understanding of the material experiences of CH artefacts can open a novel design space, enabling engaging and meaningful interactions with digital representations. Capitalising on this potential, we present a user study where we systematically explore the material experiences of historic pop-up and movable books. Our analysis identifies five key material qualities to inspire augmentation: fold-ability, slide-ability, tear-ability, age-ability, and print-ability. Highlighting how these material qualities can inspire novel interactions with their digital representations, we present two extended-reality (XR) prototypes of a CH book. With our work, we present HCI designers with a novel approach on designing CH experiences, firmly rooted in materiality, challenging the prevalent paradigms of <code>technology-driven' or</code>as-realistic-as-possible' sensory experiences often found in CH-HCI.</p>
<h3>Cosmovision Of Data: An Indigenous Approach to Technologies for Self-Determination</h3>
<p>BEST_PAPER</p>
<p>Authors: Larissa Pschetz, Carlos Guerrero Millan, Bettina Nissen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148200">Link</a></p>
<p>Abstract: This paper analyses practices of data perception and usage, as well as ongoing and envisioned community technology projects carried out by a Masewal Indigenous group in Mexico through their union of cooperatives, Tosepan. Through fieldwork interviews, Masewal participants expressed how they have been appropriating existing technologies for their people’s self-determination. During a workshop, they imagined how diverse knowledges and lived experiences of their worldview, passed down through generations, could be represented and translated into digital practices more broadly. We draw considerations for the HCI community to embrace novel approaches to data and information systems from the community’s concept of Cosmovision, and develop Micro-, Meso- and Macro- lenses within it. Through these lenses, we discuss how technologies could be designed for specific individual practices and connections with nature (Micro-cosmos) while supporting communal actions for autonomy and self-determination (Meso-cosmos), and considering broader worldmaking processes and implications for identity, prosperity, ecology and plural representations (Macro-cosmos). </p>
<h2>Learning and Teaching Technologies C</h2>
<h3>Enhancing ESL Learners' Experience and Performance through Gradual Adjustment of Video Speed during Extensive Viewing</h3>
<p>Authors: Fu-Yin Cherng, Yu-Jung Chung, Chen-Wei Hsu, Meng-Hsun Chan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147456">Link</a></p>
<p>Abstract: Adjusting video playback speed during extensive viewing is crucial for English-as-a-Second-Language (ESL) learners to enhance their learning experience. </p>
<p>Since existing research suggests that abrupt speed changes might negatively impact the viewing experience, several novel speed-adjustment systems have been proposed to provide adaptive and optimal video playback speed for learners.</p>
<p>However, empirical evidence is still sparse on whether gradual adjustments truly offer a superior experience compared to immediate changes. </p>
<p>To delve into this, we conducted a study with 32 ESL participants, comparing direct and gradual adjustments on flow state, cognitive load, and behavioral measures. </p>
<p>Employing both objective metrics, such as pupil diameter, and subjective feedback from surveys, our results strongly favor the gradual method. </p>
<p>It not only enhanced flow state and video comprehension but was also less obtrusive to learners.</p>
<p>These findings underscore the advantages of gradual speed adjustment for ESL learners, offering insights for the design of next-generation speed-adjustment systems.</p>
<h3>A Piece of Theatre: Investigating How Teachers Design LLM Chatbots to Assist Adolescent Cyberbullying Education</h3>
<p>Authors: Xinda Ma, Qian Yang, Natalie Bazarova, Ryun Shim, Michael Hedderich, Wenting Zou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147517">Link</a></p>
<p>Abstract: Cyberbullying harms teenagers' mental health, and teaching them upstanding intervention is crucial. Wizard-of-Oz studies show chatbots can scale up personalized and interactive cyberbullying education, but implementing such chatbots is a challenging and delicate task. We created a no-code chatbot design tool for K-12 teachers. Using large language models and prompt chaining, our tool allows teachers to prototype bespoke dialogue flows and chatbot utterances. In offering this tool, we explore teachers' distinctive needs when designing chatbots to assist their teaching, and how chatbot design tools might better support them. Our findings reveal that teachers welcome the tool enthusiastically. Moreover, they see themselves as playwrights guiding both the students' and the chatbot's behaviors, while allowing for some improvisation. Their goal is to enable students to rehearse both desirable and undesirable reactions to cyberbullying in a safe environment. We discuss the design opportunities LLM-Chains offer for empowering teachers and the research opportunities this work opens up.</p>
<h3>Morphing Matter for Teens: Research Processes as a Template for Cross-Disciplinary Activities</h3>
<p>Authors: Sunniva Liu, Alisha Collins, Harshika Jain, Melinda Chen, Lining Yao, Lea Albaugh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147219">Link</a></p>
<p>Abstract: We distilled a set of core practices within <code>morphing matter'' research, derived a set of underlying skills and values, and developed these into a weekend workshop for high-school students. Participants in our workshop sampled a variety of research processes, including materials science and contextual design, incorporating curriculum-appropriate learning goals, toward an integrated pneumatic fashion project. We describe our approach, activity plan, and assessment as well as opportunities for research as an educational template to push beyond current</code>STEAM''-based educational practices for cross-disciplinary engagement.</p>
<h3>Toward Supporting Adaptation: Exploring Affect’s Role in Cognitive Load when Using a Literacy Game</h3>
<p>Authors: Gisele Arevalo, Carrie Demmans Epp, Sin Sze Tang, Genaro Rebolledo Mendez, Yalmaz Abdullah, Minghao Cai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147807">Link</a></p>
<p>Abstract: Educational technologies have been argued to enhance specific aspects of affect, such as motivation, and through that learner experiences and outcomes. Until recently, affect has been considered separately from cognition. In this study, we investigated how learner affect (valence and activation) was tied to learner cognitive load and behaviours during game-based literacy activities. We employed experience sampling as part of a lab-based case study where 35 English language learners used an adaptive educational game. The results indicated that both positive and negative affect predicted learner cognitive load, with negative affect predicting extraneous (unnecessary) load. These results and the newly identified interaction patterns that accompanied learner affect and cognitive-load trajectories provide insight into the role of affect during learning. They show a need for considering affect when studying cognitive load and have implications for how systems should adapt to learners. </p>
<h3>Time-Turner: A Bichronous Learning Environment to Support Positive In-class Multitasking of Online Learners</h3>
<p>BEST_PAPER</p>
<p>Authors: Sahar Mavali, Sidney Fels, Dongwook Yoon, Luanne Sinnamon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147103">Link</a></p>
<p>Abstract: University students engage in a substantial amount of multitasking in online classes despite being aware of its negative impacts on their learning. Depending on the learner’s goals, in-class multitasking can be a positive strategic behavior to increase productivity. In a formative pilot study (N=10), we established the structure and scope for our design by exploring students' motivations, perceptions, and challenges in in-class multitasking and identified several promising design elements. Our design facilitates multitasking in online synchronous classes by providing a novel bichronous (blending of synchronous and asynchronous) learning environment manifested in Time-Turner that enables asynchronous guided accelerated viewing of past content during synchronous classes. A summative evaluation of our prototype showed significant improvement in learning outcomes when multitasking (N=20). Furthermore, 95% of users found Time-Turner helpful and expressed interest in having it in their online classes. Our findings show the great potential of supporting positive multitasking in synchronous online classes.</p>
<h2>Movement and Motor Learning A</h2>
<h3>Real-time 3D Target Inference via Biomechanical Simulation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Chenyu Li, Yi-Chi Liao, Hee-Seung Moon, Byungjoo Lee, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147400">Link</a></p>
<p>Abstract: Selecting a target in a 3D environment is often challenging, especially with small/distant targets or when sensor noise is high. To facilitate selection, target-inference methods must be accurate, fast, and account for noise and motor variability. However, traditional data-free approaches fall short in accuracy since they ignore variability. While data-driven solutions achieve higher accuracy, they rely on extensive human datasets so prove costly, time-consuming, and transfer poorly. In this paper, we propose a novel approach that leverages biomechanical simulation to produce synthetic motion data, capturing a variety of movement-related factors, such as limb configurations and motor noise. Then, an inference model is trained with only the simulated data. Our simulation-based approach improves transfer and lowers cost; variety-rich data can be produced in large quantities for different scenarios. We empirically demonstrate that our method matches the accuracy of human-data-driven approaches using data from seven users. When deployed, the method accurately infers intended targets in challenging 3D pointing conditions within 5–10 milliseconds, reducing users' target-selection error by 71% and completion time by 35%.</p>
<h3>WAVE: Anticipatory Movement Visualization for VR Dancing</h3>
<p>Authors: Monica Tamariz, Nadia Ady, Perttu Hämäläinen, Markus Laattala, Roosa Piitulainen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147795">Link</a></p>
<p>Abstract: Dance games are one of the most popular game genres in Virtual Reality (VR), and active dance communities have emerged on social VR platforms such as VR Chat. However, effective instruction of dancing in VR or through other computerized means remains an unsolved human-computer interaction problem. Existing approaches either only instruct movements partially, abstracting away nuances, or require learning and memorizing symbolic notation. In contrast, we investigate how realistic, full-body movements designed by a professional choreographer can be instructed on the fly, without prior learning or memorization. Towards this end, we describe the design and evaluation of WAVE, a novel anticipatory movement visualization technique where the user joins a group of dancers performing the choreography with different time offsets, similar to spectators making waves in sports events. In our user study (N=36), the participants more accurately followed a choreography using WAVE, compared to following a single model dancer.</p>
<h3>Designing for Human Operations on the Moon: Challenges and Opportunities of Navigational HUD Interfaces</h3>
<p>Authors: Paul Demedeiros, Aidan Cowley, Andreas Gerndt, Michael Preutenborbeck, Tommy Nilsson, Georgia Albuquerque, Nicolas Herzberger, Frank Flemisch, Jan Wulkop, Florian Dufresne, Leonie Bensch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148215">Link</a></p>
<p>Abstract: Future crewed missions to the Moon will face significant environmental and operational challenges, posing risks to the safety and performance of astronauts navigating its inhospitable surface. Whilst head-up displays (HUDs) have proven effective in providing intuitive navigational support on Earth, the design of novel human-spaceflight solutions typically relies on costly and time-consuming analogue deployments, leaving the potential use of lunar HUDs largely under-explored. This paper explores an alternative approach by simulating navigational HUD concepts in a high-fidelity Virtual Reality (VR) representation of the lunar environment. In evaluating these concepts with astronauts and other aerospace experts (n=25), our mixed methods study demonstrates the efficacy of simulated analogues in facilitating rapid design assessments of early-stage HUD solutions. We illustrate this by elaborating key design challenges and guidelines for future lunar HUDs. In reflecting on the limitations of our approach, we propose directions for future design exploration of human-machine interfaces for the Moon.</p>
<h3>Watch This! Observational Learning in VR Promotes Better Far Transfer than Active Learning for a Fine Psychomotor Task</h3>
<p>Authors: Michael Proulx, Manoela Milena Oliveira da Silva, Christopher Clarke, Christof Lutteroth, Elizabeth Dark, Isabel Fitton, Jeremy Dalton</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146854">Link</a></p>
<p>Abstract: Virtual Reality (VR) holds great potential for psychomotor training, with existing applications using almost exclusively a `learning-by-doing' active learning approach, despite the possible benefits of incorporating observational learning. </p>
<p>We compared active learning (n=26) with different variations of observational learning in VR for a manual assembly task. For observational learning, we considered three levels of visual similarity between the demonstrator avatar and the user, dissimilar (n=25), minimally similar (n=26), or a self-avatar (n=25), as similarity has been shown to improve learning. </p>
<p>Our results suggest observational learning can be effective in VR when combined with `hands-on' practice and can lead to better far skill transfer to real-world contexts that differ from the training context. Furthermore, we found self-similarity in observational learning can be counterproductive when focusing on a manual task, and skills decay quickly without further training. We discuss these findings and derive design recommendations for future VR training.</p>
<h2>Movement and Motor Learning B</h2>
<h3>Metrics of Motor Learning for Analyzing Movement Mapping in Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Difeng Yu, Mark Schram Christensen, Joanna Bergström, Mantas Cibulskis, Erik Mortensen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147038">Link</a></p>
<p>Abstract: Virtual reality (VR) techniques can modify how physical body movements are mapped to the virtual body. However, it is unclear how users learn such mappings and, therefore, how the learning process may impede interaction. To understand and quantify the learning of the techniques, we design new metrics explicitly for VR interactions based on the motor learning literature. We evaluate the metrics in three object selection and manipulation tasks, employing linear-translational and nonlinear-rotational gains and finger-to-arm mapping. The study shows that the metrics demonstrate known characteristics of motor learning similar to task completion time, typically with faster initial learning followed by more gradual improvements over time. More importantly, the metrics capture learning behaviors that task completion time does not. We discuss how the metrics can provide new insights into how users adapt to movement mappings and how they can help analyze and improve such techniques.</p>
<h3>WieldingCanvas: Interactive Sketch Canvases for Freehand Drawing in VR</h3>
<p>Authors: Teng Han, Can Liu, Mingming Fan, Feng Tian, Tianren Luo, Zitao Liu, Mi Tian, Zhenxuan He, Xiaohui Tan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147341">Link</a></p>
<p>Abstract: Sketching in Virtual Reality (VR) is challenging mainly due to the absence of physical surface support and virtual depth perception cues, which induce high cognitive and sensorimotor load. This paper presents WieldingCanvas, an interactive VR sketching platform that integrates canvas manipulations to draw lines and curves in 3D. Informed by real-life examples of two-handed creative activities. WieldingCanvas interprets users' spatial gestures to move, swing, rotate, transform, or fold a virtual canvas, whereby users simply draw primitive strokes on the canvas, which are turned into finer and more sophisticated shapes via the manipulation of the canvas. We evaluated the capability and user experience of WieldingCanvas with three studies where participants were asked to sketch target shapes. A set of freehand sketches of high aesthetic qualities were created, and the results demonstrated that WieldingCanvas can assist users with creating 3D sketches.</p>
<h3>Better Definition and Calculation of Throughput and Effective Parameters for Steering to Account for Subjective Speed-accuracy Tradeoffs</h3>
<p>Authors: Yosuke Oba, Homei Miyashita, Nobuhito Kasahara, Wolfgang Stuerzlinger, Anil Ufuk Batmaz, Shota Yamanaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147190">Link</a></p>
<p>Abstract: In Fitts' law studies to investigate pointing, throughput is used to characterize the performance of input devices and users, which is claimed to be independent of task difficulty or the user's subjective speed-accuracy bias. While throughput has been recognized as a useful metric for target-pointing tasks, the corresponding formulation for path-steering tasks and its evaluation have not been thoroughly examined in the past. In this paper, we conducted three experiments using linear, circular, and sine-wave path shapes to propose and investigate a novel formulation for the effective parameters and the throughput of steering tasks. Our results show that the effective width substantially improves the fit to data with mixed speed-accuracy biases for all task shapes. Effective width also smoothed out the throughput across all biases, while the usefulness of the effective amplitude depended on the task shape. Our study thus advances the understanding of user performance in trajectory-based tasks.</p>
<h3>Design Space of Visual Feedforward And Corrective Feedback in XR-Based Motion Guidance Systems</h3>
<p>Authors: Michael Sedlmair, Benjamin Lee, Xingyao Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147637">Link</a></p>
<p>Abstract: Extended reality (XR) technologies are highly suited in assisting individuals in learning motor skills and movements---referred to as motion guidance. In motion guidance, the <code>feedforward’’ provides instructional cues of the motions that are to be performed, whereas the</code>feedback’’ provides cues which help correct mistakes and minimize errors. Designing synergistic feedforward and feedback is vital to providing an effective learning experience, but this interplay between the two has not yet been adequately explored. Based on a survey of the literature, we propose design space for both motion feedforward and corrective feedback in XR, and describe the interaction effects between them. We identify common design approaches of XR-based motion guidance found in our literature corpus, and discuss them through the lens of our design dimensions. We then discuss additional contextual factors and considerations that influence this design, together with future research opportunities for motion guidance in XR.</p>
<h2>Privacy in Real Contexts</h2>
<h3>An Investigation of US Universities' Implementation of FERPA Student Directory Policies and Student Privacy Preferences</h3>
<p>Authors: Katherine Quintanilla, Sarah Radway, Cordelia Ludden, Daniel Votipka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146893">Link</a></p>
<p>Abstract: The Family Education Rights and Privacy Act (FERPA) is intended to protect student privacy, but has not adapted well to current technology. We consider a special class of student data: directory information. Unlike other FERPA-controlled data, directory information (e.g., student names, contact information, university affiliation) can be shared publicly online or by request without explicit permission.</p>
<p>To understand this policy's impact, we investigated 100 top-ranked US universities' directory information sharing practices, finding they publish student contact information online, and provide PII offline by request to many parties, including data brokers. Universities provide limited opt out choices, and focus on negative effects when advising students about opting out. Lastly, we evaluate student preferences regarding the identified directory practices through a survey of 991 US university students. Based on these results, we provide recommendations to align directory practices with student privacy preferences.</p>
<h3>Out-of-Device Privacy Unveiled: Designing and Validating the Out-of-Device Privacy Scale (ODPS)</h3>
<p>Authors: Habiba Farzand, Karola Marky, Mohamed Khamis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147478">Link</a></p>
<p>Abstract: This paper proposes an Out-of-Device Privacy Scale (ODPS) - a reliable, validated psychometric privacy scale that measures users’ importance of out-of-device privacy. In contrast to existing scales, ODPS is designed to capture the importance individuals attribute to protecting personal information from out-of-device threats in the physical world, which is essential when designing privacy protection mechanisms. We iteratively developed and refined ODPS in three high-level steps: item development, scale development, and scale validation, with a total of N=1378 participants. Our methodology included ensuring content validity by following various approaches to generate items. We collected insights from experts and target audiences to understand response variability. Next, we explored the underlying factor structure using multiple methods and performed dimensionality, reliability, and validity tests to finalise the scale. We discuss how ODPS can support future work predicting user behaviours and designing protection methods to mitigate privacy risks.</p>
<h3>"We Have No Security Concerns": Understanding the Privacy-Security Nexus in Telehealth for Audiologists and Speech-Language Pathologists</h3>
<p>Authors: Josiah Dykstra, Prashanth Rajivan, Faiza Tazi, Sanchari Das</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147706">Link</a></p>
<p>Abstract: The advent of telehealth revolutionizes healthcare by enabling remote consultations, yet poses complex security and privacy challenges. These are often acutely felt by lower-resourced, allied-healthcare practices. To address this, our study focuses on audiologists and speech-language pathologists (SLPs) in private practice settings, often characterized by limited information technology resources. Over the course of six months, we conducted semi-structured interviews with ten audiologists and ten SLPs to understand their telehealth experiences and concerns. Key findings reveal a diversity of opinions on technology trustworthiness, data security concerns, implemented security protocols, and patient behaviors. Given the nature of the medical practitioners' primary work, participants expressed varied concerns about data breaches and platform vulnerabilities, yet trusted third-party services like Zoom due to inadequate expertise and time to evaluate security protocols. This work underscores the imperative of bridging the technology-healthcare gap to foster secure, patient/provider-centered telehealth as the prevailing practice. It also emphasizes the need to synergize security, privacy, and usability to securely deliver care through telehealth.</p>
<h3>On the Feasibility of Predicting Users' Privacy Concerns using Contextual Labels and Personal Preferences</h3>
<p>Authors: yaqing YANG, Tony Li, Haojian Jin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147126">Link</a></p>
<p>Abstract: Predicting users’ privacy concerns is challenging due to privacy’s subjective and complex nature. Previous research demonstrated that generic attitudes, such as those captured by Westin’s Privacy Segmentation Index, are inadequate predictors of context-specific attitudes. We introduce ContextLabel, a method enabling practitioners to capture users’ privacy profiles across domains and predict their privacy concerns towards unseen data practices. ContextLabel’s key innovations are (1) using non-mutually exclusive labels</p>
<p>to capture more nuances of data practices, and (2) capturing users’ privacy profiles by asking them to express privacy concerns to a few data practices. To explore the feasibility of ContextLabel, we asked 38 participants to express their thoughts in free text towards 13</p>
<p>distinct data practices across five days. Our mixed-methods analysis shows that a preliminary version of ContextLabel can predict users’ privacy concerns towards unseen data practices with an accuracy (73%) surpassing Privacy Segmentation Index (56%) and methods using categorical factors (59%).</p>
<h2>Designing for Privacy</h2>
<h3>Encoding Privacy: Sociotechnical Dynamics of Data Protection Compliance Work</h3>
<p>Authors: Rohan Grover</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147127">Link</a></p>
<p>Abstract: How do developers shape data protection regulations when they are passed from the policy arena to technical teams for compliance? This study explores data protection compliance work (DPCW) as a sociotechnical process mediated by developers’ attitudes and experiences. We draw on 14 semi-structured interviews with individuals responsible for GDPR and/or CCPA compliance to examine how developers approach DPCW and the resulting implications for user privacy. We highlight three key ways in which developers can shape compliance: by creatively interpreting ambiguous regulatory requirements; by exploiting expectations of technical expertise and low accountability; and by reducing DPCW to a one-time project. We conclude by discussing the implications for both researchers and practitioners and by recommending how to conceptualize and conduct DPCW otherwise. This article adds specificity to understanding why and how developers' attitudes and experiences affect data protection regulations in the field.</p>
<h3>Redesigning Privacy with User Feedback: The Case of Zoom Attendee Attention Tracking</h3>
<p>Authors: Tony Li, Arshia Arya, Haojian Jin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148211">Link</a></p>
<p>Abstract: Software engineers' unawareness of user feedback in earlier stages of design contributes to privacy issues in many products. Although extensive research exists on gathering and analyzing user feedback, there is limited understanding about how developers can integrate user feedback to improve product designs to better meet users' privacy expectations. We use Zoom's deprecated attendee attention tracking feature to explore issues with integrating user privacy feedback into software development, presenting public online critiques about this deprecated feature to 18 software engineers in semi-structured interviews and observing how they redesign this feature. Our results suggest that while integrating user feedback for privacy is potentially beneficial, it's also fraught with challenges of polarized design suggestions, confirmation bias, and limited scope of perceived responsibility.</p>
<h3>Designing Accessible Obfuscation Support for Blind Individuals’ Visual Privacy Management</h3>
<p>Authors: Lotus Zhang, Tanusree Sharma, Inan Xu, Leah Findlater, Yang Wang, Yu-Yun Tseng, Abigale Stangl, Danna Gurari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147347">Link</a></p>
<p>Abstract: Blind individuals commonly share photos in everyday life. Despite substantial interest from the blind community in being able to independently obfuscate private information in photos, existing tools are designed without their inputs. In this study, we prototyped a preliminary screen reader-accessible obfuscation interface to probe for feedback and design insights. We implemented a version of the prototype through off-the-shelf AI models (e.g., SAM, BLIP2, ChatGPT) and a Wizard-of-Oz version that provides human-authored guidance. Through a user study with 12 blind participants who obfuscated diverse private photos using the prototype, we uncovered how they understood and approached visual private content manipulation, how they reacted to frictions such as inaccuracy with existing AI models and cognitive load, and how they envisioned such tools to be better designed to support their needs (e.g., guidelines for describing visual obfuscation effects, co-creative interaction design that respects blind users’ agency).</p>
<h3>An Empathy-Based Sandbox Approach to Bridge the Privacy Gap among Attitudes, Goals, Knowledge, and Behaviors</h3>
<p>Authors: Weijun Li, Toby Li, Chaoran Chen, Wenxin Song, Yaxing Yao, Yanfang Ye</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146765">Link</a></p>
<p>Abstract: Managing privacy to reach privacy goals is challenging, as evidenced by the privacy attitude-behavior gap. Mitigating this discrepancy requires solutions that account for both system opaqueness and users' hesitations in testing different privacy settings due to fears of unintended data exposure. We introduce an empathy-based approach that allows users to experience how privacy attributes may alter system outcomes in a risk-free sandbox environment from the perspective of artificially generated personas. To generate realistic personas, we introduce a novel pipeline that augments the outputs of large language models (e.g., GPT-4) using few-shot learning, contextualization, and chain of thoughts. Our empirical studies demonstrated the adequate quality of generated personas and highlighted the changes in privacy-related applications (e.g., online advertising) caused by different personas. Furthermore, users demonstrated cognitive and emotional empathy towards the personas when interacting with our sandbox. We offered design implications for downstream applications in improving user privacy literacy.</p>
<h2>Social Activism A</h2>
<h3>"We happen to be different and different is not bad": Designing for Intersectional Fat-Positive Information-Seeking</h3>
<p>Authors: Kelley Cotter, Ankolika De, Rebecca Jonas</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147459">Link</a></p>
<p>Abstract: Fat liberation is a social movement advocating for equal treatment of fat people, who are currently subjected to harmful stereotypes, harassment, discrimination at school and work, and medical mistreatment, and is an understudied movement in HCI research. Due to the social and legal acceptability of anti-fatness, many physical spaces, such as businesses and healthcare providers, are unsafe or inaccessible for fat people. We conducted three in-person and virtual participatory design workshops with fat liberationist organizers and community members (N = 15) to imagine fat positive technologies. Participants designed a system to help them find size-inclusive resources, services, and healthcare providers in the offline world with design features centered around intersectionality, and participants' desire for technologies that recognized their diverse identities and characteristics. We present features and values for a fat-positive information-seeking system and synthesize present and historical HCI theories into a design framework for intersectional fat-positive HCI.</p>
<h3>Negotiating Sociotechnical Boundaries: Moderation Work to Counter Racist Attacks in Online Communities</h3>
<p>Authors: Tayara Romero, Bryan Semaan, Qunfang Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146991">Link</a></p>
<p>Abstract: Online communities are susceptible to racist attacks, even when community policies explicitly prohibit racism. Drawing on the concept of symbolic boundary, we explored how community members sustained their communities against the perpetuation of racist logics and practices on Reddit. We drew on trace ethnography to analyze conversations about crime in two city subreddits (i.e., r/baltimore and r/chicago). The findings illustrate that the fragility of community boundaries was contributed by race baiting posts, covert racism, and racist brigading. At the same time, our research highlights that moderation efforts maintained and established institutional, cultural, and geographical boundaries to combat racist attacks. We discuss boundary as a design technique for building safe spaces for community members. Content warning: This work contains racist quotes that can upset or harm some readers.</p>
<h3>Examining the Unique Online Risk Experiences and Mental Health Outcomes of LGBTQ+ versus Heterosexual Youth</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Joshua Anderson, Mamtaj Akter, Mary Jean Amon, Tangila Islam Tanni, Pamela Wisniewski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146887">Link</a></p>
<p>Abstract: We collected and analyzed Instagram direct messages (DMs) from 173 youth aged 13–21 (including 86 LGBTQ+ youth). We examined youth's risk-flagged social media trace data with their self-reported mental health outcomes to examine how the differing online experiences of LGBTQ+ youth compare with their heterosexual counterparts. We found that LGBTQ+ youth experienced significantly more high-risk online interactions compared to heterosexual youth. LGBTQ+ youth reported overall poorer mental health, with online harassment specifically amplifying Self-Harm and Injury. LGBTQ+ youth's mental well-being linked positively to sexual messages, unlike heterosexual youth. Qualitatively, we found that most of the risk-flagged messages of LGBTQ+ youth were sexually motivated; however, a silver lining was that they sought support for their sexual identity from peers on the platform. The study highlights the importance of tailored online safety and inclusive design for LGBTQ+ youth, with implications for CHI community advancements in fostering a supportive online environments.</p>
<h3>“Some Hope, Many Despair”: Experiences of the Normalization within Online Dating among Queer Women in a Closeted Society</h3>
<p>Authors: Seora Park, Hajin Lim, Joonhwan Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147298">Link</a></p>
<p>Abstract: Online dating technology mediates various social interactions for LGBTQ+ communities, yet how such technology shapes queerness remains understudied, particularly within queer women's communities in non-Western settings. To address this gap, we conducted a qualitative study with 17 queer women, aiming to uncover their experiences and challenges in online dating within the conservative context of South Korea. Contrary to their initial expectations of exploring open-ended forms of interaction, we found that dating applications tended to systematically normalize queerness in sexuality presentation, relationship building, and shared identities in the community. These mechanisms forced them to conform to the "normalized queerness," thereby impeding non-normative and flexible aspects of queer interactions. Building upon these findings, we discuss how the technological affordances of online dating platforms facilitate the normalization of queerness under the influence of sociocultural contexts of South Korea.</p>
<h3>See Widely, Think Wisely: Toward Designing a Generative Multi-agent System to Burst Filter Bubbles</h3>
<p>Authors: Mingming Fan, Liuxin Zhang, Qianying Wang, Cen Yao, Xin Geng, Yu Zhang, Yong Rui, Jingwei Sun, Li Feng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148309">Link</a></p>
<p>Abstract: The proliferation of AI-powered search and recommendation systems has accelerated the formation of "filter bubbles" that reinforce people's biases and narrow their perspectives. Previous research has attempted to address this issue by increasing the diversity of information exposure, which is often hindered by a lack of user motivation to engage with. In this study, we took a human-centered approach to explore how Large Language Models (LLMs) could assist users in embracing more diverse perspectives. We developed a prototype featuring LLM-powered multi-agent characters that users could interact with while reading social media content. We conducted a participatory design study with 18 participants and found that multi-agent dialogues with gamification incentives could motivate users to engage with opposing viewpoints. Additionally, progressive interactions with assessment tasks could promote thoughtful consideration. Based on these findings, we provided design implications with future work outlooks for leveraging LLMs to help users burst their filter bubbles.</p>
<h2>Social Activism B</h2>
<h3>Socioeconomic Class in Physical Activity Wearables Research and Design</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Whitney-Jocelyn Kouaho, Daniel Epstein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147491">Link</a></p>
<p>Abstract: Wearable technology for physical activity promotion is a frequent research topic within HCI and health, and researchers have documented that much of our knowledge is sourced from understanding the needs of populations from college educated, racially privileged, Western backgrounds. However socioeconomic class, a core component for how people perceive physical activity, wearables, and even wearable studies, has not often been contended with. In this critical discussion of the literature, incorporating examples from over 30 deployment studies involving wearables and over 70 other related works, we investigate how socioeconomic class shows up in study design and identify how class cultures are embedded in the design of wearable technology. We hypothesize that common study components related to time and activity type engenders high SES class cultures and ultimately risk creating intervention generated inequalities. We discuss the implications of ignoring class such as further perpetuating inequities in subsequent waves of wearable device maturity.</p>
<h3>Engaging recently incarcerated and gang affiliated Black and Latino/a young adults in designing social collocated applications for mixed reality smart glasses through community-based participatory design workshops.</h3>
<p>BEST_PAPER</p>
<p>Authors: kurt squire, Richard Martinez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146915">Link</a></p>
<p>Abstract: Involving Black and Latina/o communities early and often in emerging technology design can make innovation more democratic, address bias, and reduce harm against these marginalized groups. To the best of our knowledge, no work has examined how recently incarcerated and gang affiliated young adults conceptualize mixed reality (MR) use for social collocated scenarios based on their everyday interactions and meaning-making. To explore this topic, we used a design-based implementation research (DBIR) and community-based participatory design (CBPD) approach to elicit social-technical insights grounded in the personal and critical perspectives of these youth. We find participants frequently grounded design ideas as embodied design elements to surface intangible and invisible qualities such as emotions and reflections on lived experiences, namely criticizing institutional structures that have maintained exclusionary practices against them. We discuss how DBIR and CBPD can uncover larger societal issues impacting marginalized communities through emerging technology design, and we contribute design recommendations for social collocated interactions in MR.</p>
<h3>Evaluating the Experience of LGBTQ+ People Using Large Language Model Based Chatbots for Mental Health Support</h3>
<p>Authors: Zhaoyuan Su, Yinru Long, Zilin Ma, Krzysztof Gajos, Yiyang Mei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146739">Link</a></p>
<p>Abstract: LGBTQ+ individuals are increasingly turning to chatbots powered by large language models (LLMs) to meet their mental health needs. However, little research has explored whether these chatbots can adequately and safely provide tailored support for this demographic. We interviewed 18 LGBTQ+ and 13 non-LGBTQ+ participants about their experiences with LLM-based chatbots for mental health needs. LGBTQ+ participants relied on these chatbots for mental health support, likely due to an absence of support in real life. Notably, while LLMs offer prompt support, they frequently fall short in grasping the nuances of LGBTQ-specific challenges. Although fine-tuning LLMs to address LGBTQ+ needs can be a step in the right direction, it isn't the panacea. The deeper issue is entrenched in societal discrimination. Consequently, we call on future researchers and designers to look beyond mere technical refinements and advocate for holistic strategies that confront and counteract the societal biases burdening the LGBTQ+ community. </p>
<h2>Sound Interaction</h2>
<h3>Show, Not Tell: A Human-AI Collaborative Approach for Designing Sound Awareness Systems</h3>
<p>Authors: Jeremy Huang, Dhruv Jain, Hriday Chhabria, Reyna Wood</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147942">Link</a></p>
<p>Abstract: Current sound recognition systems for deaf and hard of hearing (DHH) people identify sound sources or discrete events. However, these systems do not distinguish similar sounding events (e.g., a patient monitor beep vs. a microwave beep). In this paper, we introduce HACS, a novel futuristic approach to designing human-AI sound awareness systems. HACS assigns AI models to identify sounds based on their characteristics (e.g., a beep) and prompts DHH users to use this information and their contextual knowledge (e.g., “I am in a kitchen”) to recognize sound events (e.g., a microwave). As a first step for implementing HACS, we articulated a sound taxonomy that classifies sounds based on sound characteristics using insights from a multi-phased research process with people of mixed hearing abilities. We then performed a qualitative (with 9 DHH people) and a quantitative (with a sound recognition model) evaluation. Findings demonstrate the initial promise of HACS for designing accurate and reliable human-AI systems.</p>
<h3>Interactive Shape Sonification for Tumor Localization in Breast Cancer Surgery</h3>
<p>Authors: Christoph Leuze, Anh Thien Doan, Nassir Navab, Bruce Daniel, Jacqueline Tsai, Laura Schütz, Trishia El Chemaly, Emmanuelle Weber</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147377">Link</a></p>
<p>Abstract: About 20 percent of patients undergoing breast-conserving surgery require reoperation due to cancerous tissue remaining inside the breast. Breast cancer localization systems utilize auditory feedback to convey the distance between a localization probe and a small marker (seed) implanted into the breast tumor prior to surgery. However, no information on the location of the tumor margin is provided. To reduce the reoperation rate by improving the usability and accuracy of the surgical task, we developed an auditory display using shape sonification to assist with tumor margin localization. Accuracy and usability of the interactive shape sonification were determined on models of the female breast in three user studies with both breast surgeons and non-clinical participants. The comparative studies showed a significant increase in usability (p&lt;0.05) and localization accuracy (p&lt;0.001) of the shape sonification over the auditory feedback currently used in surgery.</p>
<h3>Using Low-frequency Sound to Create Non-contact Sensations On and In the Body</h3>
<p>Authors: Kasper Hornbæk, Asier Marzo, Waseem Hassan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147059">Link</a></p>
<p>Abstract: This paper proposes a method for generating non-contact sensations using low-frequency sound waves without requiring user instrumentation. This method leverages the fundamental acoustic response of a confined space to produce predictable pressure spatial distributions at low frequencies, called modes. These modes can be used to produce sensations either throughout the body, in localized areas of the body, or within the body. We first validate the location and strength of the modes simulated by acoustic modeling. Next, a perceptual study is conducted to show how different frequencies produce qualitatively different sensations across and within the participants' bodies. The low-frequency sound offers a new way of delivering non-contact sensations throughout the body. The results indicate a high accuracy for predicting sensations at specific body locations.</p>
<h3>Remembering through Sound: Co-creating Sound-based Mementos together with People with Blindness</h3>
<p>Authors: MinYoung Yoo, Samien Shamsher, Samuel Barnett, Arne Berger, Gillian Russell, Priscilla Lo, William Odom, Lauren Knight, Sadhbh Kenny</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147012">Link</a></p>
<p>Abstract: Sound is a preferred and dominant medium that people with blindness use to capture, share and reflect on meaningful moments in their lives. Within the timeframe of 12 months, we worked with seven people with blindness and two of their sighted loved ones to engage in a multi-stage co-creative design process involving multiple steps building toward the final co-design workshop. We report three types of sonic mementos, designed together with the participants, that Encapsulate, Augment and Re-imagine personal audio recordings into more interesting and meaningful sonic memories. Building on these sonic mementos, we critically reflect and describe insights into designing sound that supports personal and social experiences of reminiscence for people with blindness through sound. We propose design opportunities to promote collective remembering between people with blindness and their sighted loved ones and design recommendations for remembering through sound.</p>
<h2>Working with Data B</h2>
<h3>Automatic Macro Mining from Interaction Traces at Scale</h3>
<p>Authors: Forrest Huang, Tao Li, Yang Li, Gang Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147479">Link</a></p>
<p>Abstract: Macros are building block tasks of our everyday smartphone activity (e.g., "login", or "booking a flight"). Effectively extracting macros is important for understanding mobile interaction and enabling task automation. These macros are however difficult to extract at scale as they can be comprised of multiple steps yet hidden within programmatic components of mobile apps. In this paper, we introduce a novel approach based on Large Language Models (LLMs) to automatically extract semantically meaningful macros from both random and user-curated mobile interaction traces. The macros produced by our approach are automatically tagged with natural language descriptions and are fully executable. We conduct multiple studies to validate the quality of extracted macros, including user evaluation, comparative analysis against human-curated tasks, and automatic execution of these macros. These experiments and analyses demonstrate the effectiveness of our approach and the usefulness of extracted macros in various downstream applications.</p>
<h3>Bridging the Gulf of Envisioning: Cognitive Challenges in Prompt Based Interactions with LLMs</h3>
<p>Authors: Roy Pea, Maneesh Agrawala, Hariharan Subramonyam, Colleen Seifert, Christopher Pondoc</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147633">Link</a></p>
<p>Abstract: Large language models (LLMs) exhibit dynamic capabilities and appear to comprehend complex and ambiguous natural language prompts. However, calibrating LLM interactions is challenging for interface designers and end-users alike. A central issue is our limited grasp of how human cognitive processes begin with a goal and form intentions for executing actions, a blindspot even in established interaction models such as Norman's gulfs of execution and evaluation. To address this gap, we theorize how end-users `envision' translating their goals into clear intentions and craft prompts to obtain the desired LLM response. We define a process of \textit{Envisioning} by highlighting three misalignments on not knowing: (1)  what the task should be, (2) how to instruct the LLM to do the task, and (3) what to expect for the LLM’s output in meeting the goal. Finally, we make recommendations to narrow the envisioning gulf in human-LLM interactions. </p>
<h3>If in a Crowdsourced Data Annotation Pipeline, a GPT-4</h3>
<p>Authors: Zeyu He, Ting-Hao Huang, Chien-Kuang Ding, Chieh-Yang Huang, Shaurya Rohatgi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148078">Link</a></p>
<p>Abstract: Recent studies indicated GPT-4 outperforms online crowd workers in data labeling accuracy, notably workers from Amazon Mechanical Turk (MTurk). However, these studies were criticized for deviating from standard crowdsourcing practices and emphasizing individual workers' performances over the whole data-annotation process. This paper compared GPT-4 and an ethical and well-executed MTurk pipeline, with 415 workers labeling 3,177 sentence segments from 200 scholarly articles using the CODA-19 scheme. Two worker interfaces yielded 127,080 labels, which were then used to infer the final labels through eight label-aggregation algorithms. Our evaluation showed that despite best practices, MTurk pipeline's highest accuracy was 81.5%, whereas GPT-4 achieved 83.6%. Interestingly, when combining GPT-4's labels with crowd labels collected via an advanced worker interface for aggregation, 2 out of the 8 algorithms achieved an even higher accuracy (87.5%, 87.0%). Further analysis suggested that, when the crowd's and GPT-4's labeling strengths are complementary, aggregating them could increase labeling accuracy.</p>
<h3>SEAM-EZ: Simplifying Stateful Analytics through Visual Programming</h3>
<p>Authors: Joel Goldfoot, Vyas Sekar, Henry Milner, Zhengyan Yu, Yang Wang, Jiang Guo, Hun Namkung</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146955">Link</a></p>
<p>Abstract: Across many domains (e.g., media/entertainment, mobile apps, finance, IoT, cybersecurity), there is a growing need for stateful analytics over streams of events to meet key business outcomes. Stateful analytics over event streams entails carefully modeling the sequence, timing, and contextual correlations of events to dynamic attributes. Unfortunately, existing frameworks and languages (e.g., SQL, Flink, Spark) entail significant code complexity and expert effort to express such stateful analytics because of their dynamic and stateful nature. Our overarching goal is to simplify and democratize stateful analytics. Through an iterative design and evaluation process including a foundational user study and two rounds of formative evaluations with 15 industry practitioners, we created SEAM-EZ, a no-code visual programming platform for quickly creating and validating stateful metrics. SEAM-EZ features a node-graph editor, interactive tooltips, embedded data views, and auto-suggestion features to facilitate the creation and validation of stateful analytics. We then conducted three real-world case studies of SEAM-EZ with 20 additional practitioners. Our results suggest that practitioners who previously could not or had to spend significant effort to create stateful metrics using traditional tools such as SQL or Spark can now easily and quickly create and validate such metrics using SEAM-EZ.</p>
<h3>Spreadsheets on Interactive Surfaces: Breaking through the Grid with the Pen</h3>
<p>Authors: Caroline Appert, Emmanuel Pietriga, Vincent Cavez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150829">Link</a></p>
<p>Abstract: Spreadsheet programs for interactive surfaces have limited manipulations capabilities and are often frustrating to use. One key reason is that the spreadsheet grid creates a layer that intercepts most user input events, making it difficult to reach the cell values that lie underneath. We conduct an analysis of commercial spreadsheet programs and an elicitation study to understand what users can do and what they would like to do with spreadsheets on interactive surfaces. Informed by these, we design interaction techniques that leverage the precision of the pen to mitigate friction between the different layers. These enable more operations by direct manipulation on and through the grid, targeting not only cells and groups of cells, but values and substrings within and across cells as well. We prototype these interaction techniques and conduct a qualitative study with information workers who perform a variety of spreadsheet operations on their own data.</p>
<h2>Working Practices and Tools A</h2>
<h3>Lessons From Working in the Metaverse: Challenges, Choices, and Implications from a Case Study</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Daehwan Ahn, Hyanghee Park, Joonhwan Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148220">Link</a></p>
<p>Abstract: Although the metaverse workspace has the potential to solve some of the drawbacks of remote work while maintaining its benefits, there are few real-world cases of adopting the metaverse as a legitimate workspace and fewer subsequent studies on how to design and operate the metaverse workspace. Thus, questions exist about the organizational or sociotechnical challenges that may emerge and how decisions are made when adopting and operating the metaverse workspace in a real-world setting. To answer such questions, we scrutinized the startup company Zigbang, which has completely replaced their physical office with Soma— a metaverse platform they developed where thousands of people work and other cooperative companies have moved in as tenants. By conducting field observations and semi-structured interviews with various workers and Zigbang’s stakeholders, we identify essential design challenges and decisions when adopting a metaverse workspace and highlight the key takeaways learned from the company’s trials and errors.</p>
<h3>ChunkyEdit: Text-first video interview editing via chunking</h3>
<p>Authors: Wilmot Li, Mackenzie Leake</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148086">Link</a></p>
<p>Abstract: The early stages of video editing present many cognitively demanding tasks that require editors to remember and structure large amounts of video. In our formative work we learned that editors break down the editing process into smaller parts by labeling and organizing footage around central themes. Using current video editing tools, this process is slow and largely manual. We present a system called ChunkyEdit for helping editors group video interview clips into thematically coherent chunks, which can then be exported to existing video editing tools and composed into an edited narrative. By focusing on this intermediate step, we leverage computation to do tedious organizational tasks, while preserving the editor's ability to control the primary storytelling decisions. We explore four different topic modeling approaches to creating video chunks. We then evaluate our tool with eight professional video editors to learn how a chunking-based approach could be incorporated into video editing workflows.</p>
<h3>The Hidden Toll of Instant Messaging Use in Remote Work: Interaction Dynamics Between Subordinates and Supervisors</h3>
<p>Authors: Chien Wen (Tina) Yuan, Chia Hsin Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147176">Link</a></p>
<p>Abstract: The research centers on examining the utilization of instant messaging (IM) in remote work interactions between supervisors and subordinates. Through a series of one-on-one in-depth interviews (n = 12), our findings unveil distinct nuances in how subordinates and supervisors perceive and engage with IM, encompassing aspects such as response strategies, interaction frequency, and interaction nature. Notably, a significant finding emerged concerning the practice of self-censorship in IM, acting as a strategy for impression management, predominantly adopted by subordinates in their interactions with supervisors. Additionally, our investigation sheds light on a contrasting viewpoint regarding the social use of IM. While supervisor participants acknowledged its potential to bolster work-related collaboration, this perspective appeared less pronounced among subordinate participants. Our study concludes by delving into the design implications for IM application design, offering insights that can shape collaborative dynamics within remote work environments.</p>
<h3>"If the Machine Is As Good As Me, Then What Use Am I?" – How the Use of ChatGPT Changes Young Professionals' Perception of Productivity and Accomplishment</h3>
<p>Authors: Fiona Draxler, Charlotte Kobiella, Yarhy Flores López, Albrecht Schmidt, Franz Waltenberger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148304">Link</a></p>
<p>Abstract: Large language models (LLMs) like ChatGPT have been widely adopted in work contexts. We explore the impact of ChatGPT on young professionals' perception of productivity and sense of accomplishment. We collected LLMs' main use cases in knowledge work through a preliminary study, which served as the basis for a two-week diary study with 21 young professionals reflecting on their ChatGPT use. Findings indicate that ChatGPT enhanced some participants' perceptions of productivity and accomplishment by enabling greater creative output and satisfaction from efficient tool utilization. Others experienced decreased perceived productivity and accomplishment, driven by a diminished sense of ownership, perceived lack of challenge, and mediocre results. We found that the suitability of task delegation to ChatGPT varies strongly depending on the task nature. It's especially suitable for comprehending broad subject domains, generating creative solutions, and uncovering new information. It's less suitable for research tasks due to hallucinations, which necessitate extensive validation.</p>
<h3>Analysis and Implementation of Nanotargeting on LinkedIn Based on Publicly Available Non-PII</h3>
<p>Authors: Rubén Cuevas, Ángel Cuevas, Angel Merino, José González-Cabañas</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147940">Link</a></p>
<p>Abstract: The literature has shown that combining a few non-Personal Identifiable Information (non-PII) is enough to make a user unique in a dataset including millions of users. This work demonstrates that a combination of a few non-PII items can be activated to nanotarget users. We demonstrate that the combination of the location and 5 rare (13 random) skills in a LinkedIn profile is enough to become unique in a user base of ∼970M users with a probability of 75%. The novelty is that these attributes are publicly accessible to anyone registered on LinkedIn and can be activated through advertising campaigns. We ran an experiment configuring ad campaigns using the location and skills of three of the paper's authors, demonstrating how all the ads using &gt;13 skills were delivered exclusively to the targeted user. We reported this vulnerability to LinkedIn, which initially ignored the problem, but fixed it as of November 2023.</p>
<h2>Assistive Technologies for Learning and Information with Neurodiversity</h2>
<h3>Discovering Accessible Data Visualizations for People with ADHD</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Hae-Na Lee, Ji Hwan Park, Tien Tran</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147522">Link</a></p>
<p>Abstract: There have been many studies on understanding data visualizations regarding general users. However, we have a limited understanding of how people with ADHD comprehend data visualizations and how it might be different from the general users. To understand accessible data visualization for people with ADHD, we conducted a crowd-sourced survey involving 70 participants with ADHD and 77 participants without ADHD. Specifically, we tested the chart components of color, text amount, and use of visual embellishments/pictographs, finding that some of these components and ADHD affected participants' response times and accuracy. We outlined the neurological traits of ADHD and discussed specific findings on accessible data visualizations for people with ADHD. We found that various chart embellishment types affected accuracy and response times for those with ADHD differently depending on the types of questions. Based on these results, we suggest visual design recommendations to make accessible data visualizations for people with ADHD.</p>
<h3>Collaborative School Mental Health System: Leveraging a Conversational Agent for Enhancing Children's Executive Function</h3>
<p>Authors: Yee-Jin Shin, Minseo Cho, Myounglee Choo, Doeun Park, Jinwoo Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146654">Link</a></p>
<p>Abstract: Attention deficit hyperactivity disorder (ADHD) is a common childhood psychiatric disorder. Schools can play a vital role in the early detection and treatment of mental health issues. However, stigma and fear regarding mental health often prevent schools from engaging in active interventions. ADHD is characterized by deficits in executive function, a critical contributor to children’s self-directed behavior. We developed a conversational agent to assist children in planning and accomplishing daily tasks, with the aim of enhancing their executive function. We also designed supportive systems for both parents and teachers, proposing a collaborative school mental health system that incorporates various stakeholders. Through practical implementation with first-graders, this study confirmed the system’s potential to improve structured living and symptoms among children with ADHD. Surveys involving parents and teachers confirmed that the application improved executive function and reduced inattention. Therefore, we suggest an enhanced mental health support system.</p>
<h3>Examining the Use of VR as a Study Aid for University Students with ADHD</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Juliana Goncalves de Souza, Joshua Langberg, Thomas Fritz, Isabelle Cuber, David Shepherd, Caroline Lowman, Irene Jacobs</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148326">Link</a></p>
<p>Abstract: Attention-deficit/hyperactivity disorder (ADHD) is a neurodevelopmental condition characterized by patterns of inattention and impulsivity, which lead to difficulties maintaining concentration and motivation while completing academic tasks.</p>
<p>University settings, characterized by a high student-to-staff ratio, make treatments relying on human monitoring challenging. One potential replacement is Virtual Reality (VR) technology, which has shown potential to enhance learning outcomes and promote flow experience.</p>
<p>In this study, we investigate the usage of VR with 27 university students with ADHD, in an effort to improve their performance in completing homework, including an exploration of automated feedback via a technology probe. Quantitative results show significant increases in concentration, motivation, and effort levels during these VR sessions and qualitative data offers insight into considerations like comfort and deployment. Together, the results suggest that VR can be a valuable tool in leveling the playing field for university students with ADHD.</p>
<h3>Narrating Routines through Game Dynamics: Impact of a Gamified Routine Management App for Autistic Individuals</h3>
<p>Authors: Hwajung Hong, Kyungsik Han, Bogoan Kim, Dayoung Jeong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147891">Link</a></p>
<p>Abstract: Maintaining a daily routine has profound implications for physical, emotional, and social well-being. Autistic individuals may experience various challenges in establishing and maintaining a healthy daily routine due to their tendency to be inactive in daily life combined with their characteristics and preferences. Previous studies employing mobile technology to support autistic individuals have primarily focused on self-help functions, with limited exploration into the detailed needs of these individuals to develop and maintain personalized routines. In this study, we conducted a nine-week field study with 18 autistic individuals using RoutineAid, a gamified app designed to support key routines of autistic individuals (i.e., physical activity, diet, mindfulness, and sleep). Our analysis incorporated five measures of self-evaluation on daily life, app usage logs, Fitbit physical activity data, and interviews. Our findings demonstrate the effectiveness of RoutineAid and highlight its two primary affordances for autistic individuals: (1) promoting self-efficacy and embedding health behavior and (2) refining daily routines for healthier outcomes. We discuss salient design insights for developing daily routine management systems for autistic individuals.</p>
<h3>StarRescue: the Design and Evaluation of A Turn-Taking Collaborative Game for Facilitating Autistic Children's Social Skills</h3>
<p>Authors: Ming Li, Yuhang Zhao, Xin Tong, Yihe Wang, Yajie Liu, Yuxuan Huang, Rongqi Bei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147262">Link</a></p>
<p>Abstract: Autism Spectrum Disorder (ASD) presents challenges in social interaction skill development, particularly in turn-taking. Digital interventions offer potential solutions for improving autistic children's social skills but often lack addressing specific collaboration techniques. Therefore, we designed a prototype of a turn-taking collaborative tablet game, StarRescue, which encourages children's distinct collaborative roles and interdependence while progressively enhancing sharing and mutual planning skills. We further conducted a controlled study with 32 autistic children to evaluate StarRescue's usability and potential effectiveness in improving their social skills. Findings indicated that StarRescue has great potential to foster turn-taking skills and social communication skills (e.g., prompting, negotiation, task allocation) within the game and also extend beyond the game. Additionally, we discussed implications for future work, such as including parents as game spectators and understanding autistic children's territory awareness in collaboration. Our study contributes a promising digital intervention for autistic children's turn-taking social skill development via a scaffolding approach and valuable design implications for future research.</p>
<h2>Smart Homes and Cities</h2>
<h3>Better to Ask Than Assume: Proactive Voice Assistants’ Communication Strategies That Respect User Agency in a Smart Home Environment</h3>
<p>Authors: Wooseok Kim, Sangsu Lee, Hyeonjeong Im, Jeesun Oh, Sungbae Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147244">Link</a></p>
<p>Abstract: Proactive voice assistants (VAs) in smart homes predict users’ needs and autonomously take action by controlling smart devices and initiating voice-based features to support users’ various activities. Previous studies on proactive systems have primarily focused on determining action based on contextual information, such as user activities, physiological state, or mobile usage. However, there is a lack of research that considers user agency in VAs’ proactive actions, which empowers users to express their dynamic needs and preferences and promotes a sense of control. Thus, our study aims to explore verbal communication through which VAs can proactively take action while respecting user agency. To delve into communication between a proactive VA and a user, we used the Wizard of Oz method to set up a smart home environment, allowing controllable devices and unrestrained communication. This paper proposes design implications for the communication strategies of proactive VAs that respect user agency.</p>
<h3>Signs of the Smart City: Exploring the Limits and Opportunities of Transparency</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Graham Dove, Eric Corbett</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147824">Link</a></p>
<p>Abstract: This paper reports on a research through design (RtD) inquiry into public perceptions of transparency of Internet of Things (IoT) sensors increasingly deployed within urban neighborhoods as part of smart city programs. In particular, we report on the results of three participatory design workshops during which 40 New York City residents used physical signage as a medium for materializing transparency concerns about several sensors. We found that people’s concerns went beyond making sensors more transparent but instead sought to reveal the technology’s interconnected social, political, and economic processes. Building from these findings, we highlight the opportunities to move from treating transparency as an object to treating it as an ongoing activity. We argue that this move opens opportunities for designers and policy-makers to provide meaningful and actionable transparency of smart cities.</p>
<h3>More than just informed: The importance of consent facets in smart homes</h3>
<p>Authors: Yi-Shyuan Chiang, Adam Bates, Camille Cobb, Omar Khan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148007">Link</a></p>
<p>Abstract: Data collection without proper consent is a growing concern as smart home devices gain prevalence. It is especially difficult to obtain consent from incidental users because they may be unaware or feel pressured to consent. To understand what appropriate consent means in smart homes, we conducted an online survey (N=360) covering 6 common consent facets: freely given, revertible, informed, enthusiastic, specific, and unburdensome. We study how these facets affect perceived acceptability of data collection and how users would allocate responsibility for obtaining consent. Our results show that all facets have meaningful impacts on perceived acceptability of data collection, and eroding freely given had the greatest impact. Device owners were considered the most responsible for obtaining consent. Based on these findings, we provide recommendations for users, device manufacturers, and policymakers to improve consent practices in smart homes, such as designing consent interfaces that prioritize multiple facets of consent. </p>
<h3>Connecting Home: Human-Centric Setup Automation in the Augmented Smart Home</h3>
<p>Authors: Christof Weinhardt, Marius Schenkluhn, Michael Knierim, Francisco Kiss</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147010">Link</a></p>
<p>Abstract: Controlling smart homes via vendor-specific apps on smartphones is cumbersome. Augmented Reality (AR) offers a promising alternative by enabling direct interactions with Internet of Things (IoT) devices. However, using AR for smart home control requires knowledge of each device's 3D position. In this paper, we introduce and evaluate three concepts for identifying IoT device positions with varying degrees of automation. Our mixed-methods laboratory study with 28 participants revealed that, despite being recognized as the most efficient option, the majority of participants opted against a fast, fully automated detection, favoring a balance between efficiency and perceived autonomy and control. We link this decision to psychological needs grounded in self-determination theory and discuss the strengths and weaknesses of each alternative, motivating a user-adaptive solution. Additionally, we observed a “wow-effect” in response to AR interaction for smart homes, suggesting potential benefits of a human-centric approach to the smart home of the future.</p>
<h3>FLUID-IoT : Flexible and Fine-Grained Access Control in Shared IoT Environments via Multi-user UI Distribution</h3>
<p>Authors: Minwoo Jeong, Sunjae Lee, Jean Song, Junyoung Choi, Insik Shin, Daye Song, Seoyun Son</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147714">Link</a></p>
<p>Abstract: The rapid growth of the Internet of Things (IoT) in shared spaces has led to an increasing demand for sharing IoT devices among multiple users. Yet, existing IoT platforms often fall short by offering an all-or-nothing approach to access control, not only posing security risks but also inhibiting the growth of the shared IoT ecosystem. This paper introduces FLUID-IoT, a framework that enables flexible and granular multi-user access control, even down to the User Interface (UI) component level. Leveraging a multi-user UI distribution technique, FLUID-IoT transforms existing IoT apps into centralized hubs that selectively distribute UI components to users based on their permission levels. Our performance evaluation, encompassing coverage, latency, and memory consumption, affirm that FLUID-IoT can be seamlessly integrated with existing IoT platforms and offers adequate performance for daily IoT scenarios. An in-lab user study further supports that the framework is intuitive and user-friendly, requiring minimal training for efficient utilization.</p>
<h2>Online Communities: Engagement B</h2>
<h3>Not What it Used to Be: Characterizing Content and User-base Changes in Newly Created Online Communities</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Karrie Karahalios, Vinay Koshy, Alex Atcheson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147485">Link</a></p>
<p>Abstract: Attracting new members is vital to the health of many online communities. Yet, prior qualitative work suggests that newcomers to online communities can be disruptive -- either due to a lack of awareness around existing community norms or to differing expectations around how the community should operate. Consequently, communities may have to navigate a trade-off between growth and development of community identity. We evaluate the presence of this trade-off through a longitudinal analysis of two years of commenting data for each of 1,620 Reddit communities. We find that, on average, communities become less linguistically distinctive as they grow. These changes appear to be driven almost equally by newcomers and returning users. Surprisingly, neither heavily moderated communities nor communities undergoing major user-base diversification are any more or less likely to maintaining distinctiveness. Taken together, our results complicate the assumption that growth is inherently beneficial for online communities.</p>
<h3>Observer Effect in Social Media Use</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Munmun De Choudhury, Emre Kiciman, Koustuv Saha, Gloria Mark, Pranshu Gupta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148032">Link</a></p>
<p>Abstract: While social media data is a valuable source for inferring human behavior, its in-practice utility hinges on extraneous factors. Notable is the ``observer effect,'' where awareness of being monitored can alter people's social media use. We present a causal-inference study to examine this phenomenon on the longitudinal Facebook use of 300+ participants who voluntarily shared their data spanning an average of 82 months before and 5 months after study enrollment. We measured deviation from participants' expected social media use through time series analyses. Individuals with high cognitive ability and low neuroticism decreased posting immediately after enrollment, and those with high openness increased posting. The sharing of self-focused content decreased, while diverse topics emerged. We situate the findings within theories of self-presentation and self-consciousness. We discuss the implications of correcting observer effect in social media data-driven measurements, and how this phenomenon shines light on the ethics of these measurements. </p>
<h3>Choosing What You Want Versus Getting What You Want: An Experiment with Choice in Video Ad Placement</h3>
<p>Authors: Karrie Karahalios, Silas Hsu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147760">Link</a></p>
<p>Abstract: User agency and control serve as cornerstones of design in HCI, with numerous studies finding that choice improves user experiences. However, few studies examine how users benefit from the act of choosing, independent from the fulfillment of their chosen option; making this distinction is crucial for refining guidelines on when to provide user control.  In our experiment on YouTube, participants randomly experienced either a pre-roll ad, a mid-roll ad, or a choice between the two.  Participants then rated their subjective experiences.  Mid-roll ads negatively affected experience ratings, but ratings between those choosing a pre-roll ad and those assigned a pre-roll ad were similar.  That is, the right ad timing had a much larger impact than choosing an ad timing.  The findings suggest that user interfaces should not offer choices solely for the sake of offering choices, and suggest scenarios where automation would be preferable to fine-grained user control.</p>
<h3>Recordkeeping in Voice-based Remote Community Engagement</h3>
<p>Authors: Delvin Varghese, Patrick Olivier, Dan Richardson, Md Adnanul Islam, Pratyasha Saha, Muhamad Risqi U. Saputra, Tom Bartindale, Manika Saha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148203">Link</a></p>
<p>Abstract: Driven by pragmatic, cost-related, and environmental factors, voice-based remote community engagement tools (such as Interactive Voice Response) are emerging as a key modality for engaging marginalized communities. These voice-based digital solutions offer new opportunities for distributed community engagement and empowerment, and the ability to capture, store, and access a wide range of different records (i.e., recordings, interactions and contextual metadata) associated with community engagements. This potential for large scale, distributed community record collection necessitates an understanding of inclusive and effective recordkeeping approaches for appraisal, documentation, preservation, and accessibility of different types of records (such as audio recordings, transcripts, reports, and observatory notes) related to voice-based community engagements. Through qualitative analysis of stakeholder focus group discussions with domestic workers (as marginalized community members) and NGOs working in the sector, we present valuable insights and recommendations for the development of recordkeeping approaches tailored to voice-based remote community engagement records.</p>
<h3>Behind the Pup-ularity Curtain: Understanding the Motivations, Challenges, and Work Performed in Creating and Managing Pet Influencer Accounts</h3>
<p>Authors: Khai Truong, Kevin Pu, Suhyeon Yoo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147143">Link</a></p>
<p>Abstract: Creating dedicated accounts to post users’ pet content is a growing trend on Instagram. </p>
<p>While these account owners derive joy from this pursuit, they may also struggle with criticisms and challenges.</p>
<p>Yet, there remains a knowledge gap on how pet account owners manage their pets' online presence and navigate these obstacles successfully. </p>
<p>Drawing from interviews with 21 Instagram pet account owners, we uncover the motivations behind pet account creation, spanning personal, altruistic, and commercial goals. </p>
<p>We learn about the strategies employed for crafting their pets' online identities and personas, as well as the challenges faced by both owners and their pets in navigating the complexities of digital identity management. </p>
<p>We discuss the evolving dynamics between humans and their pets, positioning pet identity cultivation as a form of collaborative work, akin to the ``third shift'', highlighting the need to design interfaces that support this unique identity management process.</p>
<h2>Exercising and Sports</h2>
<h3>Exploring Opportunities for Augmenting Homes to Support Exercising</h3>
<p>Authors: Hanna Suominen, Michelle Adiwangsa, Mingze Xi, Penny Sweetser, Duncan Stevenson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148103">Link</a></p>
<p>Abstract: Although exercising at home has benefits, it is not always engaging or motivating. Augmented Reality (AR) head-mounted displays (HMDs) offer the potential to make in-home exercising and exergaming more inclusive and immersive, but there is limited research investigating how such systems can be designed. We employed a participatory design approach involving semi-structured interviews to investigate how homes can be augmented to facilitate exercising experiences. We developed 10 recommendations for developing home-based exercising experiences using AR HMDs. Our results further contribute to the existing body of research on the use of AR for exercising, home applications, and everyday objects by presenting the first foundational study investigating the wide range of exercises that can be supported through AR HMDs in home environments and the different ways home elements may support these exercises, and laying the groundwork for future work developing home-based exergaming through AR HMDs to increase people's physical activity levels.</p>
<h3>Grand Challenges in SportsHCI</h3>
<p>Authors: Elise van den Hoven, Lars Elbæk, Florian Mueller, Armağan Karahanoğlu, Vincent van Rheden, Maria Montoya, Don Samitha Elvitigala, Paolo Buono, Fabio Zambetta, Florian Daiber, Regina Bernhaupt, Robby van Delden, Xipei Ren, Dees Postma, Carine Lallemand, Perttu Hämäläinen, Laia Turmo Vidal, Lisa Burr, Dennis Reidsma, Daniel Harrison, Andrii Matviienko, Michael Jones, Rakesh Patibanda</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146749">Link</a></p>
<p>Abstract: The field of Sports Human-Computer Interaction (SportsHCI) investigates interaction design to support a physically active human being. Despite growing interest and dissemination of SportsHCI literature over the past years, many publications still focus on solving specific problems in a given sport. We believe in the benefit of generating fundamental knowledge for SportsHCI more broadly to advance the field as a whole. To achieve this, we aim to identify the grand challenges in SportsHCI, which can help researchers and practitioners in developing a future research agenda. Hence, this paper presents a set of grand challenges identified in a five-day workshop with 22 experts who have previously researched, designed, and deployed SportsHCI systems. Addressing these challenges will drive transformative advancements in SportsHCI, fostering better athlete performance, athlete-coach relationships, spectator engagement, but also immersive experiences for recreational sports or exercise motivation, and ultimately, improve human well-being.</p>
<h3>Enhancing Home Exercise Experiences with Video Motion-Tracking for Automatic Display Height Adjustment</h3>
<p>Authors: Yuqi Li, Jintao Chen, Xinyu Chen, Jiabao Li, Pinyan Tang, Chong Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147402">Link</a></p>
<p>Abstract: The increasing demand for home fitness solutions underscores the need for interactive displays that enhance user experiences. This study introduces a technology that autonomously adjusts display height using the skeletal information of demonstrators from videos, catering to home fitness needs. A user study involving thirty participants compared fixed height, manual adjustment, and automatic adjustment conditions. Head flexion angles and NASA-TLX survey responses were used for evaluation. Results showed a significant reduction in head flexion angles with automatic adjustment, promoting proper spinal alignment. NASA-TLX responses indicated lower mental, effort, and frustration ratings, along with improved performance and perceived support in the automatic adjustment condition compared to other conditions. These findings confirm that motion-based height adjustment improves posture and enhances the overall interactive experience. This research demonstrates the feasibility of integrating responsive ergonomics into interactive displays and suggests the importance of further personalization, conducting diverse user studies, and refining algorithms to fully leverage the potential of this technology.</p>
<h3>Born to Run, Programmed to Play: Mapping the Extended Reality Exergames Landscape</h3>
<p>Authors: Lennart Nacke, Sukran Karaosmanoglu, Frank Steinicke, Sebastian Cmentowski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148327">Link</a></p>
<p>Abstract: Many people struggle to exercise regularly, raising the risk of serious health-related issues. Extended reality (XR) exergames address these hurdles by combining physical exercises with enjoyable, immersive gameplay. While a growing body of research explores XR exergames, no previous review has structured this rapidly expanding research landscape. We conducted a scoping review of the current state of XR exergame research to (i) provide a structured overview, (ii) highlight trends, and (iii) uncover knowledge gaps. After identifying 1318 papers in human-computer interaction and medical databases, we ultimately included 186 papers in our analysis. We provide a quantitative and qualitative summary of XR exergame research, showing current trends and potential future considerations. Finally, we provide a taxonomy of XR exergames to help future design and methodological investigation and reporting.</p>
<h3>Is it just a score? Understanding Training Load Management Practices Beyond Sports Tracking</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Aykut Coşkun, Armağan Karahanoğlu, Jasper Reenalda, Dees Postma, Ruben Gouveia, Bouke Scheltinga, Dennis Reidsma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147430">Link</a></p>
<p>Abstract: Training Load Management (TLM) is crucial for achieving optimal athletic performance and preventing chronic sports injuries. Current sports trackers provide runners with data to manage their training load. However, little is known about the extent and the way sports trackers are used for TLM. We conducted a survey (N=249) and interviews (N=24) with runners to understand sports tracker use in TLM practices. We found that runners possess some understanding of training load and generally trust their trackers to provide accurate training load-related data. Still, they hesitate to strictly follow trackers’ suggestions in managing their training load, often relying on their intuitions and body signals to determine and adapt training plans. Our findings contribute to SportsHCI research by shedding light on how sports trackers are incorporated into TLM practices and providing implications for developing trackers that better support runners in managing their training load.</p>
<h2>Autonomous Vehicles</h2>
<h3>Exploring the Impact of Interconnected External Interfaces in Autonomous Vehicles on Pedestrian Safety and Experience</h3>
<p>Authors: Martin Tomitsch, Yiyuan Wang, Marius Hoggenmüller, Tram Tran, Callum Parker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148231">Link</a></p>
<p>Abstract: Policymakers advocate for the use of external Human-Machine Interfaces (eHMIs) to allow autonomous vehicles (AVs) to communicate their intentions or status. Nonetheless, scalability concerns in complex traffic scenarios arise, such as potentially increasing pedestrian cognitive load or conveying contradictory signals. Building upon precursory works, our study explores 'interconnected eHMIs,' where multiple AV interfaces are interconnected to provide pedestrians with clear and unified information. In a virtual reality study (N=32), we assessed the effectiveness of this concept in improving pedestrian safety and their crossing experience. We compared these results against two conditions: no eHMIs and unconnected eHMIs. Results indicated interconnected eHMIs enhanced safety feelings and encouraged cautious crossings. However, certain design elements, such as the use of the colour red, led to confusion and discomfort. Prior knowledge slightly influenced perceptions of interconnected eHMIs, underscoring the need for refined user education. We conclude with practical implications and future eHMI design research directions.</p>
<h3>"It Must Be Gesturing Towards Me": Gesture-Based Interaction between Autonomous Vehicles and Pedestrians</h3>
<p>Authors: Yuxin Cai, Haolin Cai, Jiangtao Gong, Tingmin Yan, Xiaoyan Dong, Guyue Zhou, Zihe Chen, Xiang Chang, Zherui Zhou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147022">Link</a></p>
<p>Abstract: Interacting with pedestrians understandably and efficiently is one of the toughest challenges faced by autonomous vehicles (AVs) due to the limitations of current algorithms and external human-machine interfaces (eHMIs). In this paper, we design eHMIs based on gestures inspired by the most popular method of interaction between pedestrians and human drivers. Eight common gestures were selected to convey AVs' yielding or non-yielding intentions at uncontrolled crosswalks from previous literature. Through a VR experiment (N1 = 31) and a following online survey (N2 = 394), we discovered significant differences in the usability of gesture-based eHMIs compared to current eHMIs. Good gesture-based eHMIs increase the efficiency of pedestrian-AV interaction while ensuring safety. Poor gestures, however, cause misinterpretation. The underlying reasons were explored: ambiguity regarding the recipient of the signal and whether the gestures are precise, polite, and familiar to pedestrians. Based on this empirical evidence, we discuss potential opportunities and provide valuable insights into developing comprehensible gesture-based eHMIs in the future to support better interaction between AVs and other road users.</p>
<h3>Multi-Modal eHMIs: The Relative Impact of Light and Sound in AV-Pedestrian Interaction</h3>
<p>Authors: Mark Colley, Debargha Dey, Wendy Ju, Azra Habibovic, Toros Senan, Bart Hengeveld</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148159">Link</a></p>
<p>Abstract: External Human-Machine Interfaces (eHMIs) have been evaluated to facilitate interactions between Automated Vehicles (AVs) and pedestrians. Most eHMIs are, however, visual/ light-based solutions, and multi-modal eHMIs have received little attention to date. We ran an experimental video study (N = 29) to systematically understand the effect on pedestrian's willingness to cross the road and user preferences of a light-based eHMI (light bar on the bumper) and two sound-based eHMIs (bell sound and droning sound), and combinations thereof. We found no objective change in pedestrians' willingness to cross the road based on the nature of eHMI, although people expressed different subjective preferences for the different ways an eHMI may communicate, and sometimes even strong dislike for multi-modal eHMIs. This shows that the modality of the evaluated eHMI concepts had relatively little impact on their effectiveness. Consequently, this lays an important groundwork for accessibility considerations of future eHMIs, and points towards the insight that provisions can be made for taking user preferences into account without compromising effectiveness. </p>
<h3>Light it Up: Evaluating Versatile Autonomous Vehicle-Cyclist External Human-Machine Interfaces</h3>
<p>Authors: Ammar Al-Taie, Euan Freeman, Frank Pollick, Graham Wilson, Stephen Brewster</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148184">Link</a></p>
<p>Abstract: The social cues drivers exchange with cyclists to negotiate space-sharing will disappear as autonomous vehicles (AVs) join our roads, leading to safety concerns. External Human-Machine Interfaces (eHMIs) on vehicles can replace driver social signals, but how these should be designed to communicate with cyclists is unknown. We evaluated three eHMIs across multiple traffic scenarios in two stages. First, we compared eHMI versatility, acceptability and usability in a VR cycling simulator. Cyclists preferred colour-coded signals communicating AV intent, easily seen through quick glances. Second, we refined the interfaces based on our findings and compared them outdoors. Participants cycled around a moving car with real eHMIs. They preferred eHMIs using large surfaces on the vehicle and animations reinforcing colour changes. We conclude with novel design guidelines for versatile eHMIs based on first-hand interaction feedback. Our findings establish the factors that enable AVs to operate safely around cyclists across different traffic scenarios.</p>
<h3>One Size Does Not Fit All: Designing and Evaluating Criticality-Adaptive Displays in Highly Automated Vehicles</h3>
<p>Authors: Yaohan Ding, Na Du, Lesong Jia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147703">Link</a></p>
<p>Abstract: To promote drivers' overall experiences in highly automated vehicles, we designed three objective criticality-adaptive displays:IO display highlighting Influential Objects, CO display highlighting Critical Objects, and ICO display highlighting Influential and Critical Objects differently. We conducted an online video-based survey study with 295 participants to evaluate them in varying traffic conditions. Results showed that low-trust propensity participants found ICO display more useful while high-trust propensity participants found CO displays more useful. When interacting with vulnerable road users (VRUs), participants had higher situational awareness (SA) but worse non-driving related task (NDRT) performance. Aging and CO displays also led to slower NDRT reactions. Nonetheless, older participants found displays more useful. We recommend providing different criticality-adaptive displays based on drivers' trust propensity, age, and NDRT choice to enhance driving and NDRT performance and suggest carefully treating objects of different categories in traffic.</p>
<h2>Locomotion in Virtual Environments</h2>
<h3>Doorways Do Not Always Cause Forgetting: Studying the Effect of Locomotion Technique and Doorway Visualization in Virtual Reality</h3>
<p>Authors: Yiannis Kalaitzoglou, Joanna Bergström, Sean Chew, Thomas van Gemert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148003">Link</a></p>
<p>Abstract: The “doorway effect” predicts that crossing an environmental boundary affects memory negatively. In virtual reality (VR), we can design the crossing and the appearance of such boundaries in non-realistic ways. However, it is unclear whether locomotion techniques like teleportation, which avoid crossing the boundary altogether, still induce the effect. Furthermore, it is unclear how different appearances of a doorway act as a boundary and thus induce the effect. To address these questions, we conducted two lab studies. First, we conceptually replicated prior doorway effect studies in VR using natural walking and teleportation. Second, we investigated the effect of five doorway visualizations, ranging from doors to portals. The results show no difference in object recognition performance due to the presence of a doorway, locomotion technique, or doorway visualization. We discuss the implications of these findings on the role of boundaries in event-based memory and the design of boundary interactions in VR.</p>
<h3>Exploring Experience Gaps Between Active and Passive Users During Multi-user Locomotion in VR</h3>
<p>Authors: Teng Han, Fangzhi Yan, Jin Huang, Jiafu Lv, Feng Tian, Fenglin Lu, Tianren Luo, Chun Yu, Chang Liu, Xiaohui Tan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146669">Link</a></p>
<p>Abstract: Multi-user locomotion in VR has grown increasingly common, posing numerous challenges. A key factor contributing to these challenges is the gaps in experience between active and passive users during co-locomotion. Yet, there remains a limited understanding of how and to what extent these experiential gaps manifest in diverse multi-user co-locomotion scenarios. This paper systematically explores the gaps in physiological and psychological experience indicators between active and passive users across various locomotion situations. Such situations include when active users walk, fly by joystick, or teleport, and passive users stand still or look around. We also assess the impact of factors such as sub-locomotion type, speed/teleport-interval, motion sickness susceptibility, etc. Accordingly, we delineate acceptability disparities between active and passive users, offering insights into leveraging notable experimental findings to mitigate discomfort during co-locomotion through avoidance or intervention.</p>
<h3>Investigating Virtual Reality Locomotion Techniques with Blind People</h3>
<p>Authors: André Rodrigues, Renato Ribeiro, Carlos Duarte, Manuel Piçarra, Letícia Seixas Pereira, João Guerreiro, Inês Gonçalves</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147547">Link</a></p>
<p>Abstract: Many Virtual Reality (VR) locomotion techniques have been proposed, but those explored for and with blind people are often custom-made or require specialized equipment. Consequently, it is unclear how popular techniques can support blind people's VR locomotion, blocking access to most VR experiences. We implemented three popular techniques -- Arm Swinging, Linear Movement (joystick-based steering), and Point &amp; Teleport -- with minor adaptations for accessibility. We conducted a study with 14 blind participants consisting of navigation tasks with these techniques and a semi-structured interview. We found no differences in overall performance (e.g., completion time), but contrasting preferences. Findings highlight the challenges and advantages of each technique and participants’ strategies. We discuss, among others, how augmenting the techniques enabled blind people to navigate in VR, the greater control of movement of Arm Swinging, the simplicity and familiarity of Linear Movement, and the potential for efficiency and for scanning the environment of Point &amp; Teleport. </p>
<h3>The Effect of Spatial Audio on Curvature Gains in VR Redirected Walking</h3>
<p>Authors: Christof van Nimwegen, Julian Frommel, Michael Rietzler, Maarten Gerritse</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146928">Link</a></p>
<p>Abstract: Redirected walking (RDW) is a technique that allows users to navigate larger physical spaces in virtual reality (VR) environments by manipulating the users' view of the virtual world. In this study, we investigate the effect of adding spatial audio elements to curvature gains in RDW aiming to increase the perceptual threshold for the manipulation and allowing for higher levels of unnoticed redirection. We conducted a user study (n = 18), evaluating perceptual thresholds across conditions with and without spatial audio elements across different curvature gains. We found that spatial audio can significantly increase thresholds with a large effect size. This finding indicates the value of spatial audio for RDW. It could facilitate higher levels of redirection, while maintaining a convincing experience, leading to more freedom to navigate virtual environments in even smaller physical spaces.</p>
<h3>Stacked Retargeting: Combining Redirected Walking and Hand Redirection to Expand Haptic Retargeting's Coverage</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Aldrich Clarence, Michael Wybrow, Jarrod Knibbe, Maxime Cordeil</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148329">Link</a></p>
<p>Abstract: We present Stacked Retargeting—combining haptic retargeting and redirected walking—to maximise the use of passive proxy objects for VR haptics. Haptic retargeting work to date has considered stationary reaching and grasping interactions, and this inherently limits a proxy object’s scope. We consider exactly where this reaching and grasping occurs from, to increase the potential of each proxy. We present (a) a staged approach to implementing Stacked Retargeting, (b) five redirected walking approaches that enable users to arrive anywhere at the site of interaction, and (c) a usability magnitude estimation evaluation of these techniques. We demonstrate how Stacked Retargeting can meaningfully increase the practical use of proxy objects for VR haptics without degrading the user experience.</p>
<h2>Supporting Communication and Intimacy</h2>
<h3>Rehearsal: Simulating Conflict to Teach Conflict Resolution</h3>
<p>Authors: Omar Shaikh, Diyi Yang, Michele Gelfand, Michael Bernstein, Valentino Chai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147513">Link</a></p>
<p>Abstract: Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill -- one that can be learned through deliberate practice -- but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual "what if?" scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own setting. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations. In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training. Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67%, while doubling their use of cooperative strategies. Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills.</p>
<h3>Seeking Soulmate via Voice: Understanding Promises and Challenges of Online Synchronized Voice-Based Mobile Dating</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yan Xu, Chenxinran Shen, Zhicong Lu, RAY LC</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147442">Link</a></p>
<p>Abstract: Online dating has become a popular way for individuals to connect with potential romantic partners. Many dating apps use personal profiles that include a headshot and self-description, allowing users to present themselves and search for compatible matches. However, this traditional model often has limitations. In this study, we explore a non-traditional voice-based dating app called “Soul”. Unlike traditional platforms that rely heavily on profile information, Soul facilitates user interactions through voice-based communication. We conducted semi-structured interviews with 18 dedicated Soul users to investigate how they engage with the platform and perceive themselves and others in this unique dating environment. Our findings indicate that the role of voice as a moderator influences impression management and shapes perceptions between the sender and the receiver of the voice. Additionally, the synchronous voice-based and community-based dating model offers benefits to users in the Chinese cultural context. Our study contributes to understanding the affordances introduced by voice-based interactions in online dating in China.</p>
<h3>A Change of Scenery: Transformative Insights from Retrospective VR Embodied Perspective-Taking of Conflict With a Close Other</h3>
<p>Authors: Leo Cui, Seraphina Yong, Svetlana Yarosh, Evan Suma Rosenberg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147966">Link</a></p>
<p>Abstract: Close relationships are irreplaceable social resources, yet prone to high-risk conflict. Building on findings from the fields of HCI, virtual reality, and behavioral therapy, we evaluate the unexplored potential of retrospective VR-embodied perspective-taking to fundamentally influence conflict resolution in close others. We develop a biographically-accurate Retrospective Embodied Perspective-Taking system (REPT) and conduct a mixed-methods evaluation of its influence on close others’ reflection and communication, compared to video-based reflection methods currently used in therapy (treatment as usual, or TAU). Our key findings provide evidence that REPT was able to significantly improve communication skills and positive sentiment of both partners during conflict, over TAU. The qualitative data also indicated that REPT surpassed basic perspective-taking by exclusively stimulating users to embody and reflect on both their own and their partner’s experiences at the same level. In light of these findings, we provide implications and an agenda for social embodiment in HCI design: conceptualizing the use of ‘embodied social cognition,’ and envisioning socially-embodied experiences as an interactive context.</p>
<h3>"Delete it and Move On": Digital Management of Shared Sexual Content after a Breakup</h3>
<p>Authors: Allison McDonald, Kathryn Coduto</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147003">Link</a></p>
<p>Abstract: Sexting is a common and healthy behavior in romantic and sexual relationships. However, not every relationship lasts. When a relationship ends, the fate of sexual content that was previously shared can be a source of discomfort, anxiety, or fear for individuals who may no longer trust their former partners. In extreme cases, intimate content may be leaked or misused by its recipient. To investigate opportunities for building safer sexting tools with breakups in mind, we conducted a survey with 310 U.S. adults who have sexted in the last year. We asked about their sexting practices, communication practices within their relationship about sexting, and preferences for their own sexting content after a breakup. We find that most people save sexts in some form, either actively (e.g., via screenshots) or passively (e.g., in chat history). There is no consensus around what one should do with an ex's content: although most (55%) want their content to be deleted at the end of a relationship, many others don't care (25%) or even hope their ex keeps the material (11%). However, most have never spoken to their partner about this preference. We end with design recommendations that support sexting while keeping the entire relationship lifecycle in mind.</p>
<h3>Sharing Frissons among Online Video Viewers: Exploring the Design of Affective Communication for Aesthetic Chills</h3>
<p>Authors: Xinyi Cao, Zeyu Huang, Xiaojuan Ma, Yuanhao Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147357">Link</a></p>
<p>Abstract: On online video platforms, viewers often lack a channel to sense others’ and express their affective state on the fly compared to co-located group-viewing. This study explored the design of complementary affective communication specifically for effortless, spontaneous sharing of frissons during video watching. Also known as aesthetic chills, frissons are instant psycho-physiological reactions like goosebumps and shivers to arousing stimuli. We proposed an approach that unobtrusively detects viewers’ frissons using skin electrodermal activity sensors and presents the aggregated data alongside online videos. Following a design process of brainstorming, focus group interview (N=7), and design iterations, we proposed three different designs to encode viewers’ frisson experiences, namely, ambient light, icon, and vibration. A mixed-methods within-subject study (N=48) suggested that our approach offers a non-intrusive and efficient way to share viewers’ frisson moments, increases the social presence of others as if watching together, and can create affective contagion among viewers.</p>
<h2>Arts and Creative AI</h2>
<h3>Art or Artifice? Large Language Models and the False Promise of Creativity</h3>
<p>Authors: Tuhin Chakrabarty, Philippe Laban, Divyansh Agarwal, Smaranda Muresan, Chien-Sheng Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147597">Link</a></p>
<p>Abstract: Researchers have argued that large language models (LLMs) exhibit high-quality writing capabilities from blogs to stories. However, evaluating objectively the creativity of a piece of writing is challenging. Inspired by the Torrance Test of Creative Thinking (TTCT), which measures creativity as a process, we use the Consensual Assessment Technique and propose Torrance Test of Creative Writing (TTCW) to evaluate creativity as product. TTCW consists of 14 binary tests organized into the original dimensions of Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative writers and implement a human assessment of 48 stories written either by professional authors or LLMs using TTCW. Our analysis shows that LLM-generated stories pass 3-10X less TTCW tests than stories written by professionals. In addition, we explore the use of LLMs as assessors to automate the TTCW evaluation, revealing that none of the LLMs positively correlate with the expert assessments.</p>
<h3>Authors' Values and Attitudes Towards AI-bridged Scalable Personalization of Creative Language Arts</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Matthew Kay, John Chung, Hyomin Han, Eytan Adar, Taewook Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147512">Link</a></p>
<p>Abstract: Generative AI has the potential to create a new form of interactive media: AI-bridged creative language arts (CLA), which bridge the author and audience by personalizing the author's vision to the audience's context and taste at scale. However, it is unclear what the authors' values and attitudes would be regarding AI-bridged CLA. To identify these values and attitudes, we conducted an interview study with 18 authors across eight genres (e.g., poetry, comics) by presenting speculative but realistic AI-bridged CLA scenarios. We identified three benefits derived from the dynamics between author, artifact, and audience: those that 1) authors get from the process, 2) audiences get from the artifact, and 3) authors get from the audience. We found how AI-bridged CLA would either promote or reduce these benefits, along with authors' concerns. We hope our investigation hints at how AI can provide intriguing experiences to CLA audiences while promoting authors' values.</p>
<h3>Generative AI in Creative Practice: ML-Artist Folk Theories of T2I Use, Harm, and Harm-Reduction</h3>
<p>Authors: Negar Rostamzadeh, Renee Shelby, Shalaleh Rismani</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148258">Link</a></p>
<p>Abstract: Understanding how communities experience algorithms is necessary to mitigate potential harmful impacts. This paper presents folk theories of text-to-image (T2I) models to enrich understanding of how artist communities experience creative machine learning systems. This research draws on data collected from a workshop with 15 artists from 10 countries who incorporate T2I models in their creative practice. Through reflexive thematic analysis of workshop data, we highlight artist folk theories of T2I use, harm, and harm reduction. Folk theories of use envision T2I models as an artistic medium, a mundane tool, and locate true creativity as rising above model affordances. Theories of harm articulate T2I models as harmed by engineering efforts to eliminate glitches and product policy efforts to limit functionality. Theories of harm-reduction orient towards protecting T2I models for creative practice through transparency and distributed governance. We examine how these theories relate, and conclude by discussing how folk theorization informs responsible AI efforts.</p>
<h3>Jess+: AI and robotics with inclusive music-making</h3>
<p>Authors: Craig Vear, Adrian Hazzard, Johann Benerradi, Solomiya Moroz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147296">Link</a></p>
<p>Abstract: This paper discusses the findings from a cross-sector research project investigating how a digital score created using AI and robot-ics might stimulate new creative opportunities and relationships within the practices of an inclusive music ensemble. Through the concept of a digital score [65], AI and a robotic arm were introduced into an ensemble’s musical practice to evaluate the impact and ben-efits of using autonomous systems to challenge barriers around a disabled musician's access to creative music-making. Throughout the development process we placed an emphasis on involvement and togetherness of not only the AI and robots' contribution to shared creativity amongst the ensemble, but also to the social as-pects of the creative process across the team of musicians, develop-ers, researchers and supporting organisations. The findings were surprising with many aspects of the project exceeding the expecta-tions of the original aims. In short, all the musicians benefited from the introduction of these unfamiliar technologies with practices enhanced and relationships transformed. </p>
<h2>Assistive Interactions: Navigation and Visualisation for Users Who are Blind or Low Vision</h2>
<h3>Navigating Real-World Challenges: A Quadruped Robot Guiding System for Visually Impaired People in Diverse Environments</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mohd Alqama Shaikh, SHAOJUN CAI, Shengdong Zhao, Kotaro Hara, Zhengtai Gou, Yingjia Wan, Yu-An Chen, David Hsu, Ashwin Ram</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147169">Link</a></p>
<p>Abstract: Blind and Visually Impaired (BVI) people find challenges in navigating unfamiliar environments, even using assistive tools such as white canes or smart devices. Increasingly affordable quadruped robots offer us opportunities to design autonomous guides that could improve how BVI people find ways around unfamiliar environments and maneuver therein. In this work, we designed RDog, a quadruped robot guiding system that supports BVI individuals' navigation and obstacle avoidance in indoor and outdoor environments. RDog combines an advanced mapping and navigation system to guide users with force feedback and preemptive voice feedback. Using this robot as an evaluation apparatus, we conducted experiments to investigate the difference in BVI people's ambulatory behaviors using a white cane, a smart cane, and RDog. Results illustrated the benefits of RDog-based ambulation, including faster and smoother navigation with fewer collisions and limitations, and reduced cognitive load. We discuss the implications of our work for multi-terrain assistive guidance systems.</p>
<h3>TADA: Making Node-link Diagrams Accessible to Blind and Low-Vision People</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yichun Zhao, Mahadeo Sukhai, Miguel Nacenta, Sowmya Somanath</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147533">Link</a></p>
<p>Abstract: Diagrams often appear as node-link representations in contexts such as taxonomies, mind maps and networks in textbooks. Despite their pervasiveness, they present accessibility challenges for blind and low-vision people. To address this challenge, we introduce Touch-and-Audio-based Diagram Access (TADA), a tablet-based interactive system that makes diagram exploration accessible through musical tones and speech. We designed TADA informed by an interview study with 15 participants who shared their challenges and strategies with diagrams. TADA enables people to access a diagram by: i) engaging in open-ended touch-based explorations, ii) searching for nodes, iii) navigating between nodes and iv) filtering information. We evaluated TADA with 25 participants and found it useful for gaining different perspectives on diagrammatic information.</p>
<h3>Umwelt: Accessible Structured Editing of Multi-Modal Data Representations</h3>
<p>Authors: Daniel Hajas, Jonathan Zong, Arvind Satyanarayan, Isabella Pedraza Pineros, Mengzhu (Katie) Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146952">Link</a></p>
<p>Abstract: We present Umwelt, an authoring environment for interactive multimodal data representations. In contrast to prior approaches, which center the visual modality, Umwelt treats visualization, sonification, and textual description as coequal representations: they are all derived from a shared abstract data model, such that no modality is prioritized over the others. To simplify specification, Umwelt evaluates a set of heuristics to generate default multimodal representations that express a dataset's functional relationships. To support smoothly moving between representations, Umwelt maintains a shared query predicated that is reified across all modalities — for instance, navigating the textual description also highlights the visualization and filters the sonification. In a study with 5 blind / low-vision expert users, we found that Umwelt's multimodal representations afforded complementary overview and detailed perspectives on a dataset, allowing participants to fluidly shift between task- and representation-oriented ways of thinking.</p>
<h3>How Do Low-Vision Individuals Experience Information Visualization?</h3>
<p>Authors: Yuhang Zhao, Yanan Wang, Yea-Seul Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147037">Link</a></p>
<p>Abstract: In recent years, there has been a growing interest in enhancing the accessibility of visualizations for people with visual impairments. While much of the research has focused on improving accessibility for screen reader users, the specific needs of people with remaining vision (i.e., low-vision individuals) have been largely unaddressed. To bridge this gap, we conducted a qualitative study that provides insights into how low-vision individuals experience visualizations. We found that participants utilized various strategies to examine visualizations using the screen magnifiers and also observed that the default zoom level participants use for general purposes may not be optimal for reading visualizations. We identified that participants relied on their prior knowledge and memory to minimize the traversing cost when examining visualization. Based on the findings, we motivate a personalized tool to accommodate varying visual conditions of low-vision individuals and derive the design goals and features of the tool.</p>
<h3>“Customization is Key”: Reconfigurable Textual Tokens for Accessible Data Visualizations</h3>
<p>Authors: Daniel Hajas, Jonathan Zong, Arvind Satyanarayan, Isabella Pedraza Pineros, Shuli Jones</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146771">Link</a></p>
<p>Abstract: Customization is crucial for making visualizations accessible to blind and low-vision (BLV) people with widely-varying needs. But what makes for usable or useful customization? We identify four design goals for how BLV people should be able to customize screen-reader-accessible visualizations: presence, or what content is included; verbosity, or how concisely content is presented; ordering, or how content is sequenced; and, duration, or how long customizations are active. To meet these goals, we model a customization as a sequence of content tokens, each with a set of adjustable properties. We instantiate our model by extending Olli, an open-source accessible visualization toolkit, with a settings menu and command box for persistent and ephemeral customization respectively. Through a study with 13 BLV participants, we find that customization increases the ease of identifying and remembering information. However, customization also introduces additional complexity, making it more helpful for users familiar with similar tools.</p>
<h2>Attention: multitasking and Interruptions</h2>
<h3>Supporting Task Switching with Reinforcement Learning</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Alexander Lingler, Jussi Jokinen, Philipp Wintersberger, Dinara Talypova, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147418">Link</a></p>
<p>Abstract: Attention management systems aim to mitigate the negative effects of multitasking. However, sophisticated real-time attention management is yet to be developed. We present a novel concept for attention management with reinforcement learning that automatically switches tasks. The system was trained with a user model based on principles of computational rationality. Due to this user model, the system derives a policy that schedules task switches by considering human constraints such as visual limitations and reaction times. We evaluated its capabilities in a challenging dual-task balancing game. Our results confirm our main hypothesis that an attention management system based on reinforcement learning can significantly improve human performance, compared to humans’ self-determined interruption strategy. The system raised the frequency and difficulty of task switches compared to the users while still yielding a lower subjective workload. We conclude by arguing that the concept can be applied to a great variety of multitasking settings.</p>
<h3>Augmented Reality Cues Facilitate Task Resumption after Interruptions in Computer-Based and Physical Tasks</h3>
<p>Authors: Lucas Plabst, Tobias Grundgeiger, Lucas Tiemann, Kilian Bahnsen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147918">Link</a></p>
<p>Abstract: Many work domains include numerous interruptions, which can contribute to errors. We investigated the potential of augmented reality (AR) cues to facilitate primary task resumption after interruptions of varying lengths. Experiment 1 (N = 83) involved a computer-based primary task with a red AR arrow at the to-be-resumed task step which was placed via a gesture by the participants or automatically. Compared to no cue, both cues significantly reduced the resumption lag (i.e., the time between the end of the interruption and the resumption of the primary task) following long but not short interruptions. Experiment 2 (N = 38) involved a tangible sorting task, utilizing only the automatic cue. The AR cue facilitated task resumption compared to not cue after both short and long interruptions. We demonstrated the potential of AR cues in mitigating the negative effects of interruptions and make suggestions for integrating AR technologies for task resumption.</p>
<h3>Heads-Up Multitasker: Simulating Attention Switching On Optical Head-Mounted Displays</h3>
<p>Authors: Aleksi Ikkala, Shengdong Zhao, Lucia Wang, Yunpeng Bai, Pengzhi Yang, Peisen Xu, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147957">Link</a></p>
<p>Abstract: Optical Head-Mounted Displays (OHMDs) allow users to read digital content while walking. A better understanding of how users allocate attention between these two tasks is crucial for improving OHMD interfaces. This paper introduces a computational model for simulating users' attention switches between reading and walking. We model users' decision to deploy visual attention as a hierarchical reinforcement learning problem, wherein a supervisory controller optimizes attention allocation while considering both reading activity and walking safety. Our model simulates the control of eye movements and locomotion as an adaptation to the given task priority, design of digital content, and walking speed. The model replicates key multitasking behaviors during OHMD reading while walking, including attention switches, changes in reading and walking speeds, and reading resumptions.</p>
<h3>SplitBody: Reducing Mental Workload while Multitasking via Muscle Stimulation</h3>
<p>BEST_PAPER</p>
<p>Authors: Yun Ho, Pedro Lopes, Romain Nith</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146989">Link</a></p>
<p>Abstract: Techniques like electrical muscle stimulation (EMS) offer promise in assisting physical tasks by automating movements, e.g., shaking a spray-can or tapping a button. However, existing actuation systems improve the performance of a task that users are already focusing on (e.g., users are already focused on using the spray-can). Instead, we investigate whether these interactive-actuation systems (e.g., EMS) offer any benefits if they automate a task that happens in the background of the user's focus. Thus, we explored whether automating a repetitive movement via EMS would reduce mental workload while users perform parallel tasks (e.g., focusing on writing an essay while EMS stirs a pot of soup). In our study, participants performed a cognitively-demanding multitask aided by EMS (SplitBody condition) or performed by themselves (baseline). We found that with SplitBody performance increased (35% on both tasks, 18% on the non-EMS-automated task), physical-demand decreased (31%), and mental-workload decreased (26%).</p>
<h3>Improving Attention Using Wearables via Haptic and Multimodal Rhythmic Stimuli</h3>
<p>Authors: Sam Chin, Patrick Chwalek, Samantha Chan, Pattie Maes, Jingru Zhang, Nathan Whitmore</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147209">Link</a></p>
<p>Abstract: Rhythmic light, sound and haptic stimuli can improve cognition through neural entrainment and by modifying autonomic nervous system function. However, the effects and user experience of using wearables for inducing such rhythmic stimuli have been under-investigated. We conducted a study with 20 participants to understand the effects of rhythmic stimulation wearables on attention. We found that combined sound and light stimuli from a glasses device provided the strongest improvement to attention but were the least usable and socially acceptable. Haptic vibration stimuli from a wristband also improved attention and were the most usable and socially acceptable. Our field study (N=12) with haptic stimuli from a smartwatch showed that such systems can be easy to use and were used frequently in a range of contexts but more exploration is needed to improve the comfort. Our work contributes to developing future wearables to support attention and cognition.</p>
<h2>Creative Media and AI</h2>
<h3>ContextCam: Bridging Context Awareness with Creative Human-AI Image Co-Creation</h3>
<p>Authors: Fenggui Rao, Zihan Wu, Teng Tu, Xianzhe Fan, Weinan Shi, Chun Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148054">Link</a></p>
<p>Abstract: The rapid advancement of AI-generated content (AIGC) promises to transform various aspects of human life significantly. This work particularly focuses on the potential of AIGC to revolutionize image creation, such as photography and self-expression. We introduce ContextCam, a novel human-AI image co-creation system that integrates context awareness with mainstream AIGC technologies like Stable Diffusion. ContextCam provides user's image creation process with inspiration by extracting relevant contextual data, and leverages Large Language Model-based (LLM) multi-agents to co-create images with the user. A study with 16 participants and 136 scenarios revealed that ContextCam was well-received, showcasing personalized and diverse outputs as well as interesting user behavior patterns. Participants provided positive feedback on their engagement and enjoyment when using ContextCam, and acknowledged its ability to inspire creativity.</p>
<h3>InkBrush: A Sketching Tool for 3D Ink Painting</h3>
<p>Authors: Xing-Dong Yang, Zhihao Yao, Haipeng Mi, Guanhong Liu, Yao Lu, Qirui Sun, Beituo Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147709">Link</a></p>
<p>Abstract: InkBrush is a new sketch-based 3D drawing tool for creating 3D ink paintings using free-form 3D ink strokes. It offers a digital calligraphy brush and various editing tools to generate realistic ink-like brush strokes with attributes like hairy edges, ink drips, and scattered dots. Users can adjust parameters such as moisture, color, darkness, dryness, and stroke style to customize the appearance of the brush strokes. The development of InkBrush was guided by a design study involving artists and designers. It was developed as a plugin for Blender, a popular 3D modeling tool, and its effectiveness and usability were evaluated through a user study involving 75 participants. Preliminary feedback from the participants was overwhelmingly positive, indicating that InkBrush was intuitive and easy to use. Following this, we also sought in-depth assessments from experts in ink painting and 3D design. Their evaluations further demonstrated the effectiveness of InkBrush.</p>
<h3>TutoAI: a cross-domain framework for AI-assisted mixed-media tutorial creation on physical tasks</h3>
<p>Authors: Yuexi Chen, Anh Truong, Zhicheng Liu, Vlad Morariu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147303">Link</a></p>
<p>Abstract: Mixed-media tutorials, which integrate videos, images, text, and diagrams to teach procedural skills, offer more browsable alternatives than timeline-based videos. However, manually creating such tutorials is tedious, and existing automated solutions are often restricted to a particular domain. While AI models hold promise, it is unclear how to effectively harness their powers, given the multi-modal data involved and the vast landscape of models. We present TutoAI, a cross-domain framework for AI-assisted mixed-media tutorial creation on physical tasks. First, we distill common tutorial components by surveying existing work; then, we present an approach to identify, assemble, and evaluate AI models for component extraction; finally, we propose guidelines for designing user interfaces (UI) that support tutorial creation based on AI-generated components. We show that TutoAI has achieved higher or similar quality compared to a baseline model in preliminary user studies. </p>
<h3>OutlineSpark: Igniting AI-powered Presentation Slides Creation from Computational Notebooks through Outlines</h3>
<p>Authors: Haotian Li, Yanna Lin, Fengjie Wang, Min Zhu, Huamin Qu, Mingyang Gu, Leni Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147593">Link</a></p>
<p>Abstract: Computational notebooks are widely utilized for exploration and analysis. However, creating slides to communicate analysis results from these notebooks is quite tedious and time-consuming. Researchers have proposed automatic systems for generating slides from notebooks, which, however, often do not consider the process of users conceiving and organizing their messages from massive code cells. Those systems ask users to go directly into the slide creation process, which causes potentially ill-structured slides and burdens in further refinement. Inspired by the common and widely recommended slide creation practice: drafting outlines first and then adding concrete content, we introduce OutlineSpark, an AI-powered slide creation tool that generates slides from a slide outline written by the user. The tool automatically retrieves relevant notebook cells based on the outlines and converts them into slide content. We evaluated OutlineSpark with 12 users. Both the quantitative and qualitative feedback from the participants verify its effectiveness and usability.</p>
<h3>Prompting for Discovery: Flexible Sense-Making for AI Art-Making with Dreamsheets</h3>
<p>Authors: Shm Almeda, J.D. Zamfirescu-Pereira, Bjoern Hartmann, Kyu Won Kim, Pradeep Mani Rathnam</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147361">Link</a></p>
<p>Abstract: Design space exploration (DSE) for Text-to-Image (TTI) models entails navigating a vast, opaque space of possible image outputs, through a commensurately vast input space of hyperparameters and prompt text. Perceptually small movements in prompt-space can surface unexpectedly disparate images. How can interfaces support end-users in reliably steering prompt-space explorations towards interesting results?</p>
<p>Our design probe, DreamSheets, supports user-composed exploration strategies with LLM-assisted prompt construction and large-scale simultaneous display of generated results, hosted in a spreadsheet interface. </p>
<p>Two studies, a preliminary lab study and an extended two-week study where five expert artists developed custom TTI sheet-systems, reveal various strategies for targeted TTI design space exploration---such as using templated text generation to define and layer semantic <code>axes'' for exploration. We identified patterns in exploratory structures across our participants' sheet-systems: configurable exploration</code>units'' that we distill into a UI mockup, and generalizable UI components to guide future interfaces.</p>
<h2>Digital Healthcare and Communication</h2>
<h3>A case for "little English" in Nurse Notes from the Telehealth Intervention Program for Seniors: Implications for Future Design and Research</h3>
<p>Authors: Veena Calambur, DongWhan Jun, Melody Schiaffino, Zhan Zhang, Jina Huh-Yoo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146808">Link</a></p>
<p>Abstract: Community telehealth programs (CTPs) enable low-income older adults to receive telehealth services in community settings (e.g., retirement homes). The Telehealth Intervention Program for Seniors (TIPS) is a CTP that provides vital sign monitoring services managed by remote nurses. TIPS has successfully recruited and retained Limited English Proficient (LEP) participants, but lack of language services might hinder LEP participants' equitable access to care. We conducted a two-part mixed-methods study. We first qualitatively analyzed 40 nurse notes to identify challenges nurses encounter gathering information due to language barriers and the workarounds they employed to address these. We then tested our qualitative findings on 23,975 nurse notes to quantify and compare how these challenges and workarounds scale between LEP and English-proficient TIPS participants. We present future research implications beyond low-hanging solutions, such as automated translation services, and discuss how novel technological solutions can support and ameliorate nurse workarounds and caregiver burden.</p>
<h3>Leveraging Implementation Science in Human-Centred Design for Digital Health</h3>
<p>Authors: Joe Wherton, Christopher Prawira, Patrick Olivier, Peta Stragalinos, Joshua Paolo Seguin, Victoria Manning, Ling Wu, Jessica Watterson, Dan Lubman, Alex Waddell, Jasmin Grigg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146775">Link</a></p>
<p>Abstract: There are increasing concerns that digital interventions in healthcare settings could be better designed for scalable and sustained use. Implementation science is the scientific study of how to embed evidence-based interventions in practice. Calls to integrate implementation science and Human-Centred Design methods have focused on integrating design methods within implementation science processes. By contrast, we present a novel approach to integrating implementation science within Human-Centred Design for digital health interventions. Our approach leverages the socio-technical Nonadoption, abandonment, scale-up, spread, and sustainability (NASSS) framework within the distinct phases of the Double Diamond process. To illustrate our proposal we demonstrate its application in the redesign of a brief health promotion intervention to reduce the risk of alcohol-attributable breast cancer in women attending routine mammography. We discuss reflections on the approach and implications for future research that targets implementation within design. </p>
<h3>Promoting Engagement in Remote Patient Monitoring Using Asynchronous Messaging</h3>
<p>Authors: Eyal de Lara, Alex Mariakakis, Tiago Falk, Robert Wu, Salaar Liaqat, Nisha Patel, Andrea Gershon, Tatiana Son, Daniyal Liaqat</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148308">Link</a></p>
<p>Abstract: Remote patient monitoring is becoming increasingly instrumental to healthcare delivery but can substantially hamper the interpersonal communication that underlies standard clinical practice. In this work, we explore the benefits imparted to patients, clinicians, and researchers by an asynchronous messaging feature within a platform called COVIDFree@Home. We created COVIDFree@Home to assist the healthcare system in a large metropolitan city in North America during the COVID-19 pandemic. Clinicians used COVIDFree@Home to monitor the self-reported symptoms and vital signs of over 350 COVID-19 patients post-infection. Using thematic analysis of user-initiated messages, we found the messaging feature helped maintain protocol adherence while allowing patients to ask questions about their health and clinicians to convey empathetic care. This feedback cycle also led to higher quality data for hospitalization prediction, as the revisions significantly improved the AUROC of a machine learning model trained on demographic variables, vital signs data, and self-reported symptoms from 0.53 to 0.59. </p>
<h3>To Reach the Unreachable: Exploring the Potential of VR Hand Redirection for Upper Limb Rehabilitation</h3>
<p>Authors: Xin Li, Yukai Zhang, Mingming Fan, Jinni ZHOU, Xiquan Hu, Shihan Fu, Peixuan Xiong, Nandi Zhang, Yadan Zheng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147545">Link</a></p>
<p>Abstract: Rehabilitation therapies are widely employed to assist people with motor impairments in regaining control over their affected body parts. Nevertheless, factors such as fatigue and low self-efficacy can hinder patient compliance during extensive rehabilitation processes. Utilizing hand redirection in virtual reality (VR) enables patients to accomplish seemingly more challenging tasks, thereby bolstering their motivation and confidence. While previous research has investigated user experience and hand redirection among able-bodied people, its effects on motor-impaired people remain unexplored. In this paper, we present a VR rehabilitation application that harnesses hand redirection. Through a user study and semi-structured interviews, we examine the impact of hand redirection on the rehabilitation experiences of people with motor impairments and its potential to enhance their motivation for upper limb rehabilitation. Our findings suggest that patients are not sensitive to hand movement inconsistency, and the majority express interest in incorporating hand redirection into future long-term VR rehabilitation programs.</p>
<h3>Investigating the Mechanisms by which Prevalent Online Community Behaviors Influence Responses to Misinformation: Do Perceived Norms Really Act as a Mediator?</h3>
<p>Authors: Eric Baumer, Zhila Aghajari, Nabarun Dasgupta, Dominic DiFranzo, Allison Lazard</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148042">Link</a></p>
<p>Abstract: This study addresses two currently open questions about  how behaviors of online community members influence others' responses to misinformation. First, in contrast to prior work, it directly measures norm perception to address whether (1) norm perception actually acts as a mediator, (2) others' behaviors directly influence individuals' responses to misinformation, (3) both direct and mediated effects occur. Second, it investigates norm perceptions about a behavior that is not readily observable in online communities, but is prone to misinformation, specifically, vaccination. To do so, it experimentally manipulates the prevalence of communicating about vaccination (an unobservable behavior) within an online community. The results demonstrate no evidence of a direct effect---the causal relationship between prevalence of communicating a behavior and intentions to respond to misinformation only occurs via norm perception as a mediator. The paper highlights implications of these findings for designing community-centered interventions to influence perceived norms, thereby mitigating misinformation spread and impacts.</p>
<h2>Ethics of AI</h2>
<h3>Fair Machine Guidance to Enhance Fair Decision Making in Biased People</h3>
<p>Authors: Mingzhe Yang, Hiromi Arai, Naomi Yamashita, Yukino Baba</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147109">Link</a></p>
<p>Abstract: Teaching unbiased decision-making is crucial for addressing biased decision-making in daily life. Although both raising awareness of personal biases and providing guidance on unbiased decision-making are essential, the latter topics remains under-researched. In this study, we developed and evaluated an AI system aimed at educating individuals on making unbiased decisions using fairness-aware machine learning. In a between-subjects experimental design, 99 participants who were prone to bias performed personal assessment tasks. They were divided into two groups: a) those who received AI guidance for fair decision-making before the task and b) those who received no such guidance but were informed of their biases. The results suggest that although several participants doubted the fairness of the AI system, fair machine guidance prompted them to reassess their views regarding fairness, reflect on their biases, and modify their decision-making criteria. Our findings provide insights into the design of AI systems for guiding fair decision-making in humans.</p>
<h3>Exploring the Association between Moral Foundations and Judgements of AI Behaviour</h3>
<p>Authors: Joe Brailsford, Frank Vetere, Eduardo Velloso</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147538">Link</a></p>
<p>Abstract: How do individual differences in personal morality affect perceptions and judgments of morally contentious behaviours from AI systems? By applying Moral Foundations Theory (MFT) to the context of AI, this study sought to develop a predictive Bayesian model for assessing moral judgements based on individual differences in moral constitution. Participants (N=240) were asked to assess six different scenarios, carefully designed to elicit reflection on the behaviour of AI systems. Together, with results from the Moral Foundations Questionnaire, we performed both Bayesian modelling and reflexive thematic analysis to investigate the associations between individual differences in moral foundations and judgements of the AI systems. Results revealed a mild association between individual MFT scores and judgments of AI behaviours. Qualitative responses suggested a participant’s technical understanding of AI systems, rather than intrinsic moral values, predominantly influenced their judgments, with those who judged the behaviour as wrong tending to anthropomorphise the AI systems behaviour.</p>
<h3>Which Artificial Intelligences Do People Care About Most? A Conjoint Experiment on Moral Consideration</h3>
<p>Authors: Jamie Harris, Ali Ladak, Jacy Anthis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147255">Link</a></p>
<p>Abstract: Many studies have identified particular features of artificial intelligences (AI), such as their autonomy and emotion expression, that affect the extent to which they are treated as subjects of moral consideration. However, there has not yet been a comparison of the relative importance of features as is necessary to design and understand increasingly capable, multi-faceted AI systems. We conducted an online conjoint experiment in which 1,163 participants evaluated descriptions of AIs that varied on these features. All 11 features increased how morally wrong participants considered it to harm the AIs. The largest effects were from human-like physical bodies and prosociality (i.e., emotion expression, emotion recognition, cooperation, and moral judgment). For human-computer interaction designers, the importance of prosociality suggests that, because AIs are often seen as threatening, the highest levels of moral consideration may only be granted if the AI has positive intentions.</p>
<h3>The Illusion of Artificial Inclusion</h3>
<p>Authors: Stevie Bergman, Mark Diaz, Seliem El-Sayed, William Agnew, Shakir Mohamed, Jennifer Chien, Jaylen Pittman, Kevin McKee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147179">Link</a></p>
<p>Abstract: Human participants play a central role in the development of modern artificial intelligence (AI) technology, in psychological science, and in user research. Recent advances in generative AI have attracted growing interest to the possibility of replacing human participants in these domains with AI surrogates. We survey several such "substitution proposals" to better understand the arguments for and against substituting human participants with modern generative AI. Our scoping review indicates that the recent wave of these proposals is motivated by goals such as reducing the costs of research and development work and increasing the diversity of collected data. However, these proposals ignore and ultimately conflict with foundational values of work with human participants: representation, inclusion, and understanding. This paper critically examines the principles and goals underlying human participation to help chart out paths for future work that truly centers and empowers participants.</p>
<h3>“They only care to show us the wheelchair”: disability representation in text-to-image AI models</h3>
<p>Authors: Shaun Kane, Rida Qadri, Remi Denton, Cynthia Bennett, Kelly Avery Mack</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147662">Link</a></p>
<p>Abstract: This paper reports on disability representation in images output from text-to-image (T2I) generative AI systems. Through eight focus groups with 25 people with disabilities, we found that models repeatedly presented reductive archetypes for different disabilities. Often these representations reflected broader societal stereotypes and biases, which our participants were concerned to see reproduced through T2I. Our participants discussed further challenges with using these models including the current reliance on prompt engineering to reach satisfactorily diverse results. Finally, they offered suggestions for how to improve disability representation with solutions like showing multiple, heterogeneous images for a single prompt and including the prompt with images generated. Our discussion reflects on tensions and tradeoffs we found among the diverse perspectives shared to inform future research on representation-oriented generative AI system evaluation metrics and development processes.</p>
<h2>Explainable AI</h2>
<h3>User Characteristics in Explainable AI: The Rabbit Hole of Personalization?</h3>
<p>Authors: Marios Constantinides, Ke Zhou, Daniele Quercia, Simone Stumpf, Robert Nimmo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148017">Link</a></p>
<p>Abstract: As Artificial Intelligence (AI) becomes ubiquitous, the need for Explainable AI (XAI) has become critical for transparency and trust among users. A significant challenge in XAI is catering to diverse users, such as data scientists, domain experts, and end-users. Recent research has started to investigate how users' characteristics impact interactions with and user experience of explanations, with a view to personalizing XAI. However, are we heading down a rabbit hole by focusing on unimportant details? Our research aimed to investigate how user characteristics are related to using, understanding, and trusting an AI system that provides explanations. Our empirical study with 149 participants who interacted with an XAI system that flagged inappropriate comments showed that very few user characteristics mattered; only age and the personality trait openness influenced actual understanding. Our work provides evidence to reorient user-focused XAI research and question the pursuit of personalized XAI based on fine-grained user characteristics.</p>
<h3>Incremental XAI: Memorable Understanding of AI with Incremental Explanations</h3>
<p>Authors: Pan Hao, Jessica Bo, Brian Lim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147050">Link</a></p>
<p>Abstract: Many explainable AI (XAI) techniques strive for interpretability by providing concise salient information, such as sparse linear factors. However, users either only see inaccurate global explanations, or highly-varying local explanations. We propose to provide more detailed explanations by leveraging the human cognitive capacity to accumulate knowledge by incrementally receiving more details. Focusing on linear factor explanations (factors × values = outcome), we introduce Incremental XAI to automatically partition explanations for general and atypical instances by providing Base + Incremental factors to help users read and remember more faithful explanations. Memorability is improved by reusing base factors and reducing the number of factors shown in atypical cases. In modeling, formative, and summative user studies, we evaluated the faithfulness, memorability and understandability of Incremental XAI against baseline explanation methods. This work contributes towards more usable explanation that users can better ingrain to facilitate intuitive engagement with AI.</p>
<h3>Why the Fine, AI? The Effect of Explanation Level on Citizens' Fairness Perception of AI-based Discretion in Public Administrations</h3>
<p>Authors: Saja Aljuneidi, Susanne Boll, Larbi Abdenebaoui, Maria Wolters, Wilko Heuten</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147920">Link</a></p>
<p>Abstract: The integration of Artificial Intelligence into decision-making processes within public administration extends to AI-systems that exercise administrative discretion. This raises fairness concerns among citizens, possibly leading to AI-systems abandonment. Uncertainty persists regarding explanation elements impacting citizens' perception of fairness and technology adoption level. In a video-vignette online-survey (N=847), we investigated the impact of explanation levels on citizens' perceptions of informational fairness, distributive fairness, and system adoption level. We enhanced explanations in three stages: none, factor explanations, culminating in factor importance explanations. We found that more detailed explanations improved informational and distributive fairness perceptions, but did not affect citizens' willingness to reuse the system. Interestingly, citizens with higher AI-literacy expressed greater willingness to adopt the system, regardless of the explanation levels. Qualitative findings revealed that greater human involvement and appeal mechanisms could positively influence citizens' perceptions. Our findings highlight the importance of citizen-centered design of AI-based decision-making in public administration.</p>
<h3>EXMOS: Explanatory Model Steering through Multifaceted Explanations and Data Configurations</h3>
<p>Authors: Aditya Bhattacharya, Gregor Stiglic, Lucija Gosak, Katrien Verbert, Simone Stumpf</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146863">Link</a></p>
<p>Abstract: Explanations in interactive machine-learning systems facilitate debugging and improving prediction models. However, the effectiveness of various global model-centric and data-centric explanations in aiding domain experts to detect and resolve potential data issues for model improvement remains unexplored. This research investigates the influence of data-centric and model-centric global explanations in systems that support healthcare experts in optimising models through automated and manual data configurations. We conducted quantitative (n=70) and qualitative (n=30) studies with healthcare experts to explore the impact of different explanations on trust, understandability and model improvement. Our results reveal the insufficiency of global model-centric explanations for guiding users during data configuration. Although data-centric explanations enhanced understanding of post-configuration system changes, a hybrid fusion of both explanation types demonstrated the highest effectiveness. Based on our study results, we also present design implications for effective explanation-driven interactive machine-learning systems.</p>
<h3>The Who in XAI: How AI Background Shapes Perceptions of AI Explanations</h3>
<p>Authors: I-Hsiang Lee, Mark Riedl, Larry Chan, Upol Ehsan, Michael Muller, Q. Vera Liao, Samir Passi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147327">Link</a></p>
<p>Abstract: Explainability of AI systems is critical for users to take informed actions. Understanding who opens the black-box of AI is just as important as opening it. We conduct a mixed-methods study of how two different groups—people with and without AI background—perceive different types of AI explanations. Quantitatively, we share user perceptions along five dimensions. Qualitatively, we describe how AI background can influence interpretations, elucidating the differences through lenses of appropriation and cognitive heuristics. We find that (1) both groups showed unwarranted faith in numbers for different reasons and (2) each group found value in different explanations beyond their intended design. Carrying critical implications for the field of XAI, our findings showcase how AI generated explanations can have negative consequences despite best intentions and how that could lead to harmful manipulation of trust. We propose design interventions to mitigate them. </p>
<h2>Fabrication, Circuits and Tangibles</h2>
<h3>E-Acrylic: Electronic-Acrylic Composites for Making Interactive Artifacts</h3>
<p>Authors: Clement Zheng, Bo Han, Ching Chiuan Yen, Xin Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147806">Link</a></p>
<p>Abstract: Electronic composites incorporate computing into physical materials, expanding the materiality of interactive systems for designers. In this research, we investigated acrylic as a substrate for electronics. Acrylic is valued for its visual and structural properties and is used widely in industrial design. We propose e-acrylic, an electronic composite that incorporates electronic circuits with acrylic sheets. Our approach to making this composite is centered on acrylic making practices that industrial designers are familiar with. We outline this approach systematically, including leveraging laser cutting to embed circuits into acrylic sheets, as well as different ways to shape e-acrylic into 3D objects. With this approach, we explored using e-acrylic to design interactive artifacts. We reflect on these applications to surface a design space of tangible interactive artifacts possible with this composite. We also discuss the implications of aligning electronics to an existing making practice, and working with the holistic materiality that e-acrylic embodies.</p>
<h3>Painting Inferno: Novel Heat and Stiffness Control Methods with Carbon Nanomaterial Conductive Heating Paint</h3>
<p>Authors: Tatsuya Kobayashi, Yutaka Tokuda</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147168">Link</a></p>
<p>Abstract: We introduce Painting Inferno, a novel method for controlling heat and stiffness using highly electrically conductive carbon nanomaterial heating paint. Heat has found widespread applications in thermochromic displays, shape-changing interfaces, haptic devices, and materials with adjustable stiffness. Although Joule heaters based on heating circuits using electrically conductive materials have been widely used,  the complex design and fabrication processes limit the freedom to create custom heaters in scale, shape, and material.</p>
<p>As an alternative Joule heating method, we explore the potential of carbon nanomaterial heating paints, which enable the rapid generation of uniform heat at low voltages. We present simple fabrication methods for creating handmade heaters using off-the-shelf materials and cutting machines and demonstrate the feasibility of crafting heaters with complex shapes and grid-array configurations. Leveraging the heating paint's compatibility with various materials, we showcase the versatile applications for interactive thermal displays, stiffness modulation devices, and pneumatic interfaces for stiffness-shape transformations.</p>
<h3>SnapInflatables: Designing Inflatables with Snap-through Instability for Responsive Interaction</h3>
<p>Authors: Jiang WU, Zhuoyi Zhang, Kuangqi Zhu, Yue Yang, Yongbo Ni, Qi Wang, Xinyan Li, Lei Ren, Guanyun Wang, Chuang Chen, Bin Hu, Lingyun Sun, Jiayi Wu, Junzhe Ji, Yanchen Shen, Ye Tao, Yuyang Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148172">Link</a></p>
<p>Abstract: Snap-through instability, like the rapid closure of the Venus flytrap, is gaining attention in robotics and HCI. It offers rapid shape reconfiguration, self-sensing, actuation, and enhanced haptic feedback. However, conventional snap-through structures face limitations in fabrication efficiency, scale, and tunability. We introduce SnapInflatables, enabling safe, multi-scale interaction with adjustable sensitivity and force reactions, utilizing the snap-through instability of inflatables. We designed six types of heat-sealing structures enabling versatile snap-through passive motion of inflatables with diverse reaction and trigger directions. A block structure enables ultra-sensitive states for rapid energy release and force amplification. The motion range is facilitated by geometry parameters, while force feedback properties are tunable through internal pressure settings. Based on experiments, we developed a design tool for creating desired inflatable snap-through shapes and motions, offering previews and inflation simulations. Example applications, including a self-locking medical stretcher, interactive animals, and a bounce button, demonstrate enhanced passive interaction with inflatables.</p>
<h3>LaCir: A multilayered laser-cuttable material to co-fabricate circuitry and structural components.</h3>
<p>Authors: Niels Buch, Valkyrie Savage, Daniel Ashbrook, Carlos Tejada</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148299">Link</a></p>
<p>Abstract: Rapid prototyping is an important tool for designers, but many fabrication techniques are slow and create bulky components requiring multiple machines and processes to achieve desired device shape and electronic functionality. Prior work explored ways to ease fabricating shapes or designing electronics, but we focus on creating shape and electrical pathways at the same time from a single material and machine.</p>
<p>LaCir leverages a three-layered, laser-cuttable material to incorporate circuits into the structural substrate of the design using laser cutters. Our substrate features a layer of conductive material sandwiched between thermoplastic sheets, allowing designers to cut electrical traces and assembleable, 3D object geometry in a single pass.</p>
<p>We evaluate different composite materials, weighing their cuttability, ease of assembly, and conductivity; we also show using fully laser-cut joints as structural and electrical connections. We demonstrate LaCir's flexibility through several example artifacts.</p>
<h3>Design Space Exploration for Board-level Circuits: Exploring Alternatives in Component-based Design</h3>
<p>Authors: Ankur Mehta, Parth Pandhare, Bjoern Hartmann, Rohit Ramesh, Prabal Dutta, Richard Lin, Kai Jun Tay</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147466">Link</a></p>
<p>Abstract: While recent work explores novel tools to make electronics and device design easier and more accessible, these tend to be either highly automated (great for novices, but limiting for more advanced users) or highly manual (suitable for experts, but imposes a higher skill barrier to entry). In this work, we examine a middle ground: user-guided design space exploration to bridge an intuitive-but-ambiguous high-level representation to a fully-specified, fabrication-ready circuit. Our system helps users understand and make design choices by sweeping the design space of alternatives for electronics parts (e.g., choice of microcontroller), marking invalid options, and plotting points to visualize trade-offs (e.g., for power and size). We discuss the overall system and its structure, report on the results of a small but in-depth user study with participants from a wide range of electronics backgrounds, and draw insights on future directions for improving electronics design for everyone.</p>
<h2>Fabrication: 3D Printing B</h2>
<h3>CeraMetal: A New Approach to Low-Cost Metal 3D Printing with Bronze Clay</h3>
<p>Authors: Fiona Bell, Jaime Gould, Leah Buechley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147951">Link</a></p>
<p>Abstract: This paper introduces CeraMetal, a low-cost and robust approach to desktop metal 3D printing based on a custom "metal clay". We present three recipes for 3D printable bronze clay along with a workflow that includes print parameters and a sintering schedule. We introduce custom slicing software that generates continuous extrusion toolpaths for metal clay printing. We analyze the shrink- age, density, tensile strength and flexibility of prints produced with Cerametal and find the material’s performance comparable to parts produced via other bronze 3D printing methods. Finally, we provide several examples of 3D printed metal objects and a discussion of limitations and future research opportunities.</p>
<h3>Palette-PrintAR: augmented reality design and simulation for multicolor resin 3D printing</h3>
<p>Authors: Joseph DeSimone, Gabriel Lipkowitz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147395">Link</a></p>
<p>Abstract: While 3D printing affords designers unprecedented geometrical complexity, fewer interactive design tools for multimaterial platforms exist. Recent work in resin 3D printing specifically promises fast, multicolor printing by growing fluidic channels concurrent with the object itself, infusing different resins spatioselectively into the vat; however, no design tools have been developed enabling users to interact with such novel personal fabrication machines \textit{in situ}. Here, we introduce an augmented reality-based design tool allowing users to engage with this multicolor fabrication method so as to "paint" growing 3D objects. We define the design process and mode of user interaction with our tool, Palette-PrintAR, which integrates situated 3D model manipulation with real-time computational fluid dynamics simulation and computer vision-based tracking and analysis. We detail our 3D printer hardware add-on implementation and AR software architecture, along with characterizing the design flexibilities and limitations of our AR-based multicolor fabrication method.</p>
<h3>Understanding the Challenges of OpenSCAD Users for 3D Printing</h3>
<p>Authors: Audrey Girouard, Thomas Pietrzak, Géry Casiez, J Gonzalez Avila</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146848">Link</a></p>
<p>Abstract: Direct manipulation has been established as the main interaction paradigm for Computer-Aided Design (CAD) for decades. It provides fast, incremental, and reversible actions that allow for an iterative process on a visual representation of the result. Despite its numerous advantages, some users prefer a programming-based approach where they describe the 3D model they design with a specific programming language, such as OpenSCAD. It allows users to create complex structured geometries and facilitates abstraction. Unfortunately, most current knowledge about CAD practices only focuses on direct manipulation programs. In this study, we interviewed 20 programming-based CAD users to understand their motivations and challenges. Our findings reveal that this programming-oriented population presents difficulties in the design process in tasks such as 3D spatial understanding, validation and code debugging, creation of organic shapes, and code-view navigation.</p>
<h3>Touch-n-Go: Designing and Fabricating Touch Fastening Structures by FDM 3D Printing</h3>
<p>Authors: Ye Tao, Deying Pan, Boyi Lian, Yue Tao, Hongyi Hu, Guanyun Wang, Shanghua Lou, Lingyun Sun, Junzhe Ji, Yitao Fan, Yuyang Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147487">Link</a></p>
<p>Abstract: Touch fastening structures are widely used to quickly assemble and disassemble an object with multiple parts. However, such structures are under-explored in the context of additive manufacturing for personal fabrication. We proposed Touch-n-Go, a method for designing touch-fastening structures with customizable mechanical properties such as holding capacities or shearing strength. Additionally, the customization of fastener patterns enables both static and dynamic connections, and the dynamic connections grant the freedom of rotation and translation. To facilitate the customization process, we developed a design tool that allows the integration of fastening structures on the surface of a 3D-printed object. Furthermore, we validated the fastening properties of Touch-n-Go through a series of experiments, and the result exhibits performances that match or even surpass off-the-shelf fasteners. Finally, we demonstrated the implementation of Touch-n-Go through a collection of applications.</p>
<h3>WeaveSlicer: Expanding the Range of Printable Geometries in Clay</h3>
<p>Authors: Deanna Gelosi, Fiona Bell, Leah Buechley, Camila Friedman-Gerlicz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147620">Link</a></p>
<p>Abstract: Clay 3D printing is a relatively new technology and only a narrow range of geometries is 3D printable if one is employing commercially available slicing software. We experienced these limitations in an artist residency program where artists discovered that many desired geometries failed to print successfully. This motivated us to develop WeaveSlicer, a slicer optimized for 3D printing in clay that maintains constant wall thickness throughout the form. We achieve constant wall thickness by generating an oscillating path where the amplitude of the oscillation is determined by the form's overhang angle. We demonstrate the effectiveness of our approach by comparing a range of successful prints, sliced by WeaveSlicer, to failed prints of the same forms sliced by Cura, a widely used slicing software.  We then showcase a collection of complex artifacts designed by artists in residence that were constructed with WeaveSlicer. </p>
<h2>Gaze Interaction in Immersive Environments</h2>
<h3>Towards an Eye-Brain-Computer Interface: Combining Gaze with the Stimulus-Preceding Negativity for Target Selections in XR</h3>
<p>Authors: Michael Proulx, Leanne Hirshfield, Anthony Ries, G S Rajshekar Reddy</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146977">Link</a></p>
<p>Abstract: Gaze-assisted interaction techniques enable intuitive selections without requiring manual pointing but can result in unintended selections, known as Midas touch. A confirmation trigger eliminates this issue but requires additional physical and conscious user effort. Brain-computer interfaces (BCIs), particularly passive BCIs harnessing anticipatory potentials such as the Stimulus-Preceding Negativity (SPN) - evoked when users anticipate a forthcoming stimulus - present an effortless implicit solution for selection confirmation. Within a VR context, our research uniquely demonstrates that SPN has the potential to decode intent towards the visually focused target. We reinforce the scientific understanding of its mechanism by addressing a confounding factor - we demonstrate that the SPN is driven by the user's intent to select the target, not by the stimulus feedback itself. Furthermore, we examine the effect of familiarly placed targets, finding that SPN may be evoked quicker as users acclimatize to target locations; a key insight for everyday BCIs.</p>
<h3>Gaze on the Go: Effect of Spatial Reference Frame on Visual Target Acquisition During Physical Locomotion in Extended Reality</h3>
<p>Authors: Hans Gellersen, Pavel Manakhov, Ken Pfeuffer, Ludwig Sidenmark</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146967">Link</a></p>
<p>Abstract: Spatial interaction relies on fast and accurate visual acquisition. In this work, we analyse how visual acquisition and tracking of targets presented in a head-mounted display is affected by the user moving linearly at walking and jogging paces. We study four reference frames in which targets can be presented: Head and World where targets are affixed relative to the head and environment, respectively; HeadDelay where targets are presented in the head coordinate system but follow head movement with a delay, and novel Path where targets remain at fixed distance in front of the user, in the direction of their movement. Results of our study in virtual reality demonstrate that the more stable the target is relative to the environment, the faster and more precise it can be fixated. The results have practical significance as head-mounted displays enable interaction during mobility, and in particular when eye tracking is considered as input.</p>
<h3>MOSion: Gaze Guidance with Motion-triggered Visual Cues by Mosaic Patterns</h3>
<p>Authors: Arisa Kohtani, Hidetaka Katsuyama, Hideki Koike, Shio Miyafuji, Keishiro Uragaki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148121">Link</a></p>
<p>Abstract: We propose a gaze-guiding method called MOSion to adjust the guiding strength reacted to observers’ motion based on a high-speed projector and the afterimage effect in the human vision system. Our method decomposes the target area into mosaic patterns to</p>
<p>embed visual cues in the perceived images. The patterns can only direct the attention of the moving observers to the target area. The stopping observer can see the original image with little distortion because of light integration in the visual perception. The pre computation of the patterns provides the adaptive guiding effect without tracking devices and computational costs depending on the movements. The evaluation and the user study show that the mosaic decomposition enhances the perceived saliency with a few visual artifacts, especially in moving conditions. Our method embedded in white lights works in various situations such as planar posters, advertisements, and curved objects.</p>
<h3>FocusFlow: 3D Gaze-Depth Interaction in Virtual Reality Leveraging Active Visual Depth Manipulation</h3>
<p>Authors: Elahe Soltanaghai, Eric Shaffer, Chenyang Zhang, Tiansu Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146886">Link</a></p>
<p>Abstract: Gaze interaction presents a promising avenue in Virtual Reality (VR) due to its intuitive and efficient user experience. Yet, the depth control inherent in our visual system remains underutilized in current methods. In this study, we introduce FocusFlow, a hands-free interaction method that capitalizes on human visual depth perception within the 3D scenes of Virtual Reality. We first develop a binocular visual depth detection algorithm to understand eye input characteristics. We then propose a layer-based user interface and introduce the concept of "Virtual Window" that offers an intuitive and robust gaze-depth VR interaction, despite the constraints of visual depth accuracy and precision spatially at further distances. Finally, to help novice users actively manipulate their visual depth, we propose two learning strategies that use different visual cues to help users master visual depth control. Our user studies on 24 participants demonstrate the usability of our proposed virtual window concept as a gaze-depth interaction method. In addition, our findings reveal that the user experience can be enhanced through an effective learning process with adaptive visual cues, helping users to develop muscle memory for this brand-new input mechanism. We conclude the paper by discussing potential future research topics of gaze-depth interaction.</p>
<h3>Snap, Pursuit and Gain: Virtual Reality Viewport Control by Gaze</h3>
<p>Authors: Hans Gellersen, Hock Siang Lee, Ludwig Sidenmark, Florian Weidner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147889">Link</a></p>
<p>Abstract: Head-mounted displays let users explore virtual environments through a viewport that is coupled with head movement. In this work, we investigate gaze as an alternative modality for viewport control, enabling exploration of virtual worlds with less head movement.</p>
<p>We designed three techniques that leverage gaze based on different eye movements: Dwell Snap for viewport rotation in discrete steps, Gaze Gain for amplified viewport rotation based on gaze angle, and Gaze Pursuit for central viewport alignment of gaze targets. All three techniques enable 360-degree viewport control through naturally coordinated eye and head movement.</p>
<p>We evaluated the techniques in comparison with controller snap and head amplification baselines, for both coarse and precise viewport control, and found them to be as fast and accurate. We observed a high variance in performance which may be attributable to the different degrees to which humans tend to support gaze shifts with head movement.</p>
<h2>Gig Workers</h2>
<h3>"At the end of the day, I am accountable": Gig Workers' Self-Tracking for Multi-Dimensional Accountability Management</h3>
<p>Authors: Rie Helene (Lindy) Hernandez, Qiurong Song, Xinning Gui, Yubo Kou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147575">Link</a></p>
<p>Abstract: Tracking is inherent in and central to the gig economy. Platforms track gig workers' performance through metrics such as acceptance rate and punctuality, while gig workers themselves engage in self-tracking. Although prior research has extensively examined how gig platforms track workers through metrics – with some studies briefly acknowledging the phenomenon of self-tracking among workers – there is a dearth of studies that explore how and why gig workers track themselves. To address this, we conducted 25 semi-structured interviews, revealing how gig workers self-track to manage accountabilities to themselves and external entities across three identities: the holistic self, the entrepreneurial self, and the platformized self. We connect our findings to neoliberalism, through which we contextualize gig workers' self-accountability and the invisible labor of self-tracking. We further discuss how self-tracking mitigates information and power asymmetries in gig work and offer design implications to support gig workers’ multi-dimensional self-tracking.</p>
<h3>Silent Delivery: Practices and Challenges of Delivering Among Deaf or Hard of Hearing Couriers</h3>
<p>Authors: Shi Chen, Weijun Li, Xiaodong Wang, Jiaqi Teng, Zhihan Zeng, Jingao Zhang, Yuge Qi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147217">Link</a></p>
<p>Abstract: This paper explores the motivations, practices, and challenges of Deaf and Hard of Hearing (DHH) couriers in China's food delivery industry. Interviews reveal a preference for this industry due to better pay, job satisfaction, and community belonging. DHH couriers tend to and frequently disclose their DHH disability using platform tags and text messages.  They also utilize accessible communication tools provided by the delivery platforms, such as AI voice calls, voice-to-text technologies, and electronic communication cards, to facilitate communication during the delivery process. Despite these technological aids, human intervention remains crucial throughout the delivery process. Challenges encountered include safety risks when riding mopeds, the complexities of multitasking, and user mistrust in AI voice calls. Our findings offer valuable insights for designing more inclusive delivery platforms and have broader implications for creating employment opportunities for DHH, particularly in developing countries.</p>
<h3>Bodywork at Work: Attending to Bodily Needs in Gig, Shift, and Knowledge Work</h3>
<p>Authors: Kasper Karlgren, Barry Brown, Donald McMillan, Airi Lampinen, Deepika Yadav, Riyaj Shaikh, Karey Helms</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148300">Link</a></p>
<p>Abstract: The concept of `bodywork´ refers to the work individuals undertake on their own bodies and the bodies of others. One aspect is attending to bodily needs, which is often overlooked in the workplace and HCI/CSCW research on work practices. Yet, this labour can be a significant barrier to work, consequential to work, and prone to spill over into other aspects of life. We present three empirical cases of bodywork: gig-based food delivery, shift work in hospitals and bars, and office-based knowledge work. We describe what attending to bodily needs at work entails and illustrate tactics employed so that work can be carried on, even when the body (or technology optimising it) breaks down. Arguing that all systems are bodily systems, we conclude with a call to acknowledge the centrality of bodies in all work and the roles technologies can play in supporting or constraining bodywork differently for different workers.</p>
<h3>GigSousveillance: Designing Gig Worker Centric Sousveillance Tools</h3>
<p>Authors: Saiph Savage, Michael Muller, Kimberly Do, Maya De Los Santos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147008">Link</a></p>
<p>Abstract: As independently-contracted employees, gig workers disproportionately suffer the consequences of workplace surveillance, which include increased pressures to work, breaches of privacy, and decreased digital autonomy. Despite the negative impacts of workplace surveillance, gig workers lack the tools, strategies, and workplace social support to protect themselves against these harms. Meanwhile, some critical theorists have proposed sousveillance as a potential means of countering such abuses of power, whereby those under surveillance monitor those in positions of authority (e.g., gig workers collect data about requesters/platforms). To understand the benefits of sousveillance systems in the gig economy, we conducted semi-structured interviews and led co-design activities with gig workers. We use care ethics as a guiding concept to understand our interview and co-design data, while also focusing on empathic sousveillance technology design recommendations. Through our study we identify gig workers' attitudes towards and past experiences with sousveillance. We also uncover the type of sousveillance technologies imagined by workers, provide design recommendations, and finish by discussing how to create empowering, empathic spaces on gig platforms.</p>
<h3>Not Just A Dot on The Map: Food Delivery Workers as Infrastructure</h3>
<p>Authors: Anubha Singh, Barry Brown, Airi Lampinen, Riyaj Shaikh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147254">Link</a></p>
<p>Abstract: Food delivery platforms are location-based services that rely on minimal, quantifiable data points, such as GPS location, to represent and manage labor. Drawing upon an ethnographic study of food delivery work in India during the COVID-19 pandemic, we illustrate the challenges gig workers face when working with a platform that uses their (phone’s) GPS location to monitor and control their movement. Further, we describe how these, along with the platform's opaque, location-based logics, shape the delivery workflow. We also document how the platform selectively represented workers’ bodies during the pandemic to portray them as safe and sterile, describing workers’ tactics in responding to issues arising from asymmetric platform policies. In discussion, we consider what we can learn from understanding gig workers as `infrastructure’, commonly overlooked but visible upon breakdown. We conclude by reflecting on how we might center gig workers’ well-being and bodily needs in design.</p>
<h2>Haptics and Immersive Interactions</h2>
<h3>Augmenting Perceived Length of Handheld Controllers: Effects of Object Handle Properties</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Seungmoon Choi, Chaeyong Park</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147414">Link</a></p>
<p>Abstract: In the realm of virtual reality (VR), shape-changing controllers have emerged as a means to enhance visuo-haptic congruence during user interactions. The major emphasis has been placed on manipulating the inertia tensor of a shape-changing controller to control the perceived shape. This paper delves deeper by exploring how the material properties of the controller's handle, distinct from the inertial information, affect the perceived shape, focusing on the perceived length. We conducted three perceptual experiments to examine the effects of the handle's softness, thermal conductivity, and texture, respectively.  Results demonstrated that a softer handle increases the perceived length, whereas a handle with higher thermal conductivity reduces it. Texture, in the form of varying bumps, also alters the length perception. These results provide more comprehensive knowledge of the intricate relationship between perceived length and controller handle properties, expanding the design alternatives for shape-changing controllers for immersive VR experiences.</p>
<h3>VeeR: Exploring the Feasibility of Deliberately Designing VR Motion that Diverges from Mundane, Everyday Physical Motion to Create More Entertaining VR Experiences</h3>
<p>Authors: Pin Chun Lu, Alvaro Lopez, Wei Tian Mireille Tan, LI-CHUN LU, Chiao-Ju Chang, Ching-Yi Tsai, Mike Chen, Yu Lun Hsu, Che Wei Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148319">Link</a></p>
<p>Abstract: This paper explores the feasibility of deliberately designing VR motion that diverges from users’ physical movements to turn mundane, everyday transportation motion (e.g., metros, trains, and cars) into more entertaining VR motion experiences, in contrast to prior car-based VR approaches that synchronize VR motion to physical car movement exactly. To gain insight into users’ preferences for veering rate and veering direction for turning (left/right) and pitching (up/down) during the three phases of acceleration (accelerating, cruising, and decelerating), we conducted a formative, perceptual study (n=24) followed by a VR experience evaluation (n=18), all conducted on metro trains moving in a mundane, straight-line motion. Results showed that participants preferred relatively high veering rates, and preferred pitching upward during acceleration and downward during deceleration. Furthermore, while veering decreased comfort as expected, it significantly enhanced immersion (p&lt;.01) and entertainment (p&lt;.001) and the overall experience, with comfort being considered, was preferred by 89% of participants.</p>
<h3>InflatableBots: Inflatable Shape-Changing Mobile Robots for Large-Scale Encountered-Type Haptics in VR</h3>
<p>Authors: Ryo Suzuki, Kazuki Takashima, Ryota Gomi, Kazuyuki Fujita, Yoshifumi Kitamura</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147815">Link</a></p>
<p>Abstract: We introduce InflatableBots, shape-changing inflatable robots for large-scale encountered-type haptics in VR. Unlike traditional inflatable shape displays, which are immobile and limited in interaction areas, our approach combines mobile robots with fan-based inflatable structures. This enables safe, scalable, and deployable haptic interactions on a large scale. We developed three coordinated inflatable mobile robots, each of which consists of an omni-directional mobile base and a reel-based inflatable structure. The robot can simultaneously change its height and position rapidly (horizontal: 58.5 cm/sec, vertical: 10.4 cm/sec, from 40 cm to 200 cm), which allows for quick and dynamic haptic rendering of multiple touch points to simulate various body-scale objects and surfaces in real-time across large spaces (3.5 m x 2.5 m). We evaluated our system with a user study (N = 12), which confirms the unique advantages in safety, deployability, and large-scale interactability to significantly improve realism in VR experiences. </p>
<h3>Experiencing Dynamic Weight Changes in Virtual Reality Through Pseudo-Haptics and Vibrotactile Feedback</h3>
<p>Authors: Jan-Niklas Voigt-Antons, Tanja Kojic, Johannes Schöning, Carolin Stellmacher, Feri Pujianto</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147460">Link</a></p>
<p>Abstract: Virtual reality (VR) objects react dynamically to users' touch interactions in real-time. However, experiencing changes in weight through the haptic sense remains challenging with consumer VR controllers due to their limited vibrotactile feedback. While prior works successfully applied pseudo-haptics to perceive absolute weight by manipulating the control-display (C/D) ratio, we continuously adjusted the C/D ratio to mimic weight changes. Vibrotactile feedback additionally emphasises the modulation in the virtual object's physicality. In a study (N=18), we compared our multimodal technique with pseudo-haptics alone and a baseline condition to assess participants' experiences of weight changes. Our findings demonstrate that participants perceived varying degrees of weight change when the C/D ratio was adjusted, validating its effectiveness for simulating dynamic weight in VR. However, the additional vibrotactile feedback did not improve weight change perception. This work extends the understanding of designing haptic experiences for lightweight VR systems by leveraging perceptual mechanisms.</p>
<h3>Exploring Mobile Devices as Haptic Interfaces for Mixed Reality</h3>
<p>Authors: Yannick Weiss, Florian Mathis, Johannes Schöning, Carolin Stellmacher, Nadine Wagener, Meagan Loerakker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148298">Link</a></p>
<p>Abstract: Dedicated handheld controllers facilitate haptic experiences of virtual objects in mixed reality (MR). However, as mobile MR becomes more prevalent, we observe the emergence of controller-free MR interactions. To retain immersive haptic experiences, we explore the use of mobile devices as a substitute for specialised MR controller. In an exploratory gesture elicitation study (n = 18), we examined users' (1) intuitive hand gestures performed with prospective mobile devices and (2) preferences for real-time haptic feedback when exploring haptic object properties. Our results reveal three haptic exploration modes for the mobile device, as an object, hand substitute, or as an additional tool, and emphasise the benefits of incorporating the device's unique physical features into the object interaction. This work expands the design possibilities using mobile devices for tangible object interaction, guiding the future design of mobile devices for haptic MR experiences.</p>
<h2>Haptics: Force, Thermal and Tactile Feedback</h2>
<h3>Stick&amp;Slip: Altering Fingerpad Friction via Liquid Coatings</h3>
<p>Authors: Jacob Serfaty, Pedro Lopes, Alex Mazursky</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148219">Link</a></p>
<p>Abstract: We present Stick&amp;Slip, a novel approach that alters friction between the fingerpad &amp; surfaces by depositing liquid droplets that coat the fingerpad. The liquid coating modifies the finger’s coefficient of friction, allowing users to feel surfaces up to ±60% more slippery or sticky. We selected our fluids to rapidly evaporate so that the surface returns to its original friction. Unlike traditional friction-feedback, such as electroadhesion or vibration, our approach: (1) alters friction on a wide range of surfaces and geometries, making it possible to modulate nearly any non-absorbent surface; (2) scales to many objects without requiring instrumenting the target surfaces (e.g., with conductive electrode coatings or vibromotors); and (3) both in/decreases friction via a single device. We identified nine liquids and characterized their practicality by measuring evaporation rates, etc. To illustrate the applicability of our approach, we demonstrate how it enables friction in virtual/mixed-reality or, even, while using everyday objects/tools.</p>
<h3>HIFU Embossment of Acrylic Sheets</h3>
<p>Authors: Ryosei Kojima, Kengo Tanaka, Takahito Murakami, Ayaka Tsutsui, Tatsuki Fushimi, Yoichi Ochiai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147095">Link</a></p>
<p>Abstract: Tactile interfaces such as embossment facilitate information transfer through touch in Human-Computer Interaction (HCI). Traditional embossing methods, while enabling the creation of intricate patterns, face limitations due to mold reliance and material thickness restrictions, hindering bespoke embossment creation. In this study, we propose High-Intensity Focused Ultrasound (HIFU) as an alternative technique to produce tailored embossed designs on acrylic without the need for traditional molds. We uncover specific HIFU parameters, such as amplitude, irradiation time, and distance that directly impact essential qualities of embossment including embossment height, transparency, and line generation. Additionally, the capability of embossing without the use of molds expands the applications for quick prototyping and customization of embossed designs within HCI. Furthermore, we introduce a user interface developed to streamline the design and application of customizable tactile graphics using HIFU, aimed at non-expert users. Preliminary user studies reveal positive feedback on the interface’s intuitiveness and the quality of the HIFU embossment. Our study indicates that HIFU embossment presents a viable approach for creating embossed features in interactive systems, with the potential to offer methods for personal customization in the design of tactile materials.</p>
<h3>Shaping Compliance: Inducing Haptic Illusion of Compliance in Different Shapes with Electrotactile Grains</h3>
<p>Authors: Jürgen Steimle, Arata Jingu, Nihar Sabnis, Paul Strohmeier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147156">Link</a></p>
<p>Abstract: Compliance, the degree of displacement under applied force, is pivotal in determining the material perception when touching an object. Vibrotactile actuators can be used for creating grain-based virtual compliance, but they have poor spatial resolution and a limiting rigid form factor. We propose a novel electrotactile compliance illusion that renders grains of electrical pulses on an electrode array in response to finger force changes. We demonstrate its ability to render compliance in distinct shapes through a thin, lightweight, and flexible finger-worn interface. Detailed technical parameters and the implementation of our device are provided. A controlled experiment confirms the technique can (1) create virtual compliance; (2) adjust the compliance magnitude with grain and electrode parameters; and (3) render compliance with specific shapes. In three example applications, we present how this illusion can enhance physical objects, elements in graphical user interfaces, and virtual reality experiences.</p>
<h3>AirPush: A Pneumatic Wearable Haptic Device Providing Multi-Dimensional Force Feedback on a Fingertip</h3>
<p>Authors: Hwan Kim, Yuxin Ma, Tianze Xie, Peng Zhang, Seungwoo Je</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148229">Link</a></p>
<p>Abstract: Finger wearable haptic devices enrich virtual reality experiences by offering haptic feedback corresponding to the virtual environment. However, despite the effectiveness of current finger wearable haptic devices in delivering haptic feedback, many are often constrained in their ability to provide force feedback across a diverse range of directions or to sustain it. Therefore, we present AirPush, a finger wearable haptic device capable of generating continuously adjustable force feedback in multiple directions using compressed air. To evaluate its usability, we conducted a technical evaluation and four user studies: (1) we obtained the user's perceptual thresholds of angles under different directions on horizontal and vertical planes, (2) in perception studies, we found that users can identify five different magnitudes of force and eight different motion when using AirPush, and (3) using it in VR applications, we confirmed that users felt more realistic and immersed when using AirPush than the HTC VIVE Controller or AirPush with a fixed nozzle.</p>
<h3>ALCool: Utilizing Alcohol's Evaporative Cooling for Ubiquitous Cold Sensation Feedback</h3>
<p>Authors: Hiroyuki Kajimoto, Izumi Mizoguchi, Keigo Ushiyama, Taiki Takami, Takumi Hamazaki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148230">Link</a></p>
<p>Abstract: Tactile technologies are important for novel user experiences. </p>
<p>Among several tactile submodalities, cold sensation is essential for realistically portraying materials and environments.</p>
<p>However, current cold presentations such as Peltier devices face challenges like low energy efficiency and the need for complicated equipment.</p>
<p>To address these, we suggest leveraging alcohol's endothermic property during evaporation.</p>
<p>Our prototype, a wristwatch wearable with a fan, capitalizes on alcohol's high volatility by absorbing ambient heat upon evaporation.</p>
<p>The device further enhances the cooling effect by circulating air around the skin.</p>
<p>This approach simplifies the setup required for cooling technologies and is more energy-efficient than Peltier-based systems.</p>
<p>We also integrated perfume, which is a mixture of alcohol and scent substance, and presented a unique cooling and scent experience.</p>
<p>The use of alcohol as a cooling method was not considered conventional, but social changes after COVID-19 made it easy to obtain a tiny amount of alcohol.</p>
<h2>Health and AI C</h2>
<h3>Memoro: Using Large Language Models to Realize a Concise Interface for Real-Time Memory Augmentation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Samantha Chan, Wazeer Zulfikar, Pattie Maes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147083">Link</a></p>
<p>Abstract: People have to remember an ever-expanding volume of information. Wearables that use information capture and retrieval for memory augmentation can help but can be disruptive and cumbersome in real-world tasks, such as in social settings. To address this, we developed Memoro, a wearable audio-based memory assistant with a concise user interface. Memoro uses a large language model (LLM) to infer the user’s memory needs in a conversational context, semantically search memories, and present minimal suggestions. The assistant has two interaction modes: Query Mode for voicing queries and Queryless Mode for on-demand predictive assistance, without explicit query. Our study of (N=20) participants engaged in a real-time conversation, demonstrated that using Memoro reduced device interaction time and increased recall confidence while preserving conversational quality. We report quantitative results and discuss the preferences and experiences of users. This work contributes towards utilizing LLMs to design wearable memory augmentation systems that are minimally disruptive.</p>
<h3>Artful Path to Healing: Using Machine Learning for Visual Art Recommendation to Prevent and Reduce Post-Intensive Care Syndrome (PICS)</h3>
<p>Authors: Chan Mi Kim, Bereket YILMA, Luis Leiva, Gerald C. Cupchik</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147432">Link</a></p>
<p>Abstract: Staying in the intensive care unit (ICU) is often traumatic, leading to post-intensive care syndrome (PICS), which encompasses physical, psychological, and cognitive impairments. Currently, there are limited interventions available for PICS. Studies indicate that exposure to visual art may help address the psychological aspects of PICS and be more effective if it is personalized. We develop Machine Learning-based Visual Art Recommendation Systems (VA RecSys) to enable personalized therapeutic visual art experiences for post-ICU patients. We investigate four state-of-the-art VA RecSys engines, evaluating the relevance of their recommendations for therapeutic purposes compared to expert-curated recommendations. We conduct an expert pilot test and a large-scale user study (n=150) to assess the appropriateness and effectiveness of these recommendations. Our results suggest all recommendations enhance temporal affective states. Visual and multimodal VA RecSys engines compare favourably with expert-curated recommendations, indicating their potential to support the delivery of personalized art therapy for PICS prevention and treatment.</p>
<h3>Explainable Notes: Examining How to Unlock Meaning in Medical Notes with Interactivity and Artificial Intelligence</h3>
<p>Authors: Hita Kambhamettu, Kevin Johnson, Danaë Metaxa, Andrew Head</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147476">Link</a></p>
<p>Abstract: Medical progress notes have recently become available to patients at an unprecedented scale. Progress notes offer patients insight into their care that they cannot find elsewhere. That said, reading a note requires patients to contend with the language, unspoken assumptions, and clutter common to clinical documentation. As the health system reinvents many of its interfaces to incorporate AI assistance, this paper examines what intelligent interfaces could do to help patients read their progress notes. In a qualitative study, we examine the needs of patients as they read a progress note. We then formulate a vision for the explainable note, an augmented progress note that provides support for directing attention, phrase-level understanding, and tracing lines of reasoning. This vision manifests in a set of patient-inspired opportunities for advancing intelligent interfaces for writing and reading progress notes.</p>
<h3>ConverSense: An Automated Approach to Assess Patient-Provider Interactions using Social Signals</h3>
<p>Authors: Reggie Casanova-Perez, Janice Sabin, Sarah Borsotto, Deepansha Singh, Anuujin Tsedenbal, Nadir Weibel, Manas Satish Bedmutha, Wanda Pratt, Andrea Hartzler, Brian Wood, Emily Bascom, Kelly Tobar, Kimberly Sladek</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148138">Link</a></p>
<p>Abstract: Patient-provider communication influences patient health outcomes, and analyzing such communication could help  providers identify opportunities for improvement, leading to better care. Interpersonal communication can be assessed through “social-signals” expressed in non-verbal, vocal behaviors like interruptions, turn-taking, and pitch. To automate this assessment, we introduce a machine-learning pipeline that ingests audiostreams of conversations and tracks the magnitude of four social-signals:  dominance, interactivity, engagement, and warmth. This pipeline is embedded into ConverSense, a web-application for providers to visualize their communication patterns, both within and across visits. Our user study with 5 clinicians and 10 patient visits demonstrates ConverSense's potential to provide feedback on communication challenges, as well as the need for this feedback to be contextualized within the specific underlying visit and patient interaction. Through this novel approach that uses data-driven self-reflection, ConverSense can help providers improve their communication with patients to deliver improved quality of care.</p>
<h3>Sketching AI Concepts with Capabilities and Examples: AI Innovation in the Intensive Care Unit</h3>
<p>Authors: Sher Shah Amin, Adam Perer, John Minturn, Jeremy Kahn, Billie Davis, Sarah M. Preum, Susanna Zlotnikov, Venkatesh Sivaraman, Leigh Bukowski, Andrew J King, James McCann, John Zimmerman, Dan Ricketts, Kathryn Riman, Nur Yildirim, Deniz Sayar, Lu Tang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146925">Link</a></p>
<p>Abstract: Advances in artificial intelligence (AI) have enabled unprecedented capabilities, yet innovation teams struggle when envisioning AI concepts. Data science teams think of innovations users do not want, while domain experts think of innovations that cannot be built. A lack of effective ideation seems to be a breakdown point. How might multidisciplinary teams identify buildable and desirable use cases? This paper presents a first hand account of ideating AI concepts to improve critical care medicine. As a team of data scientists, clinicians, and HCI researchers, we conducted a series of design workshops to explore more effective approaches to AI concept ideation and problem formulation. We detail our process, the challenges we encountered, and practices and artifacts that proved effective. We discuss the research implications for improved collaboration and stakeholder engagement, and discuss the role HCI might play in reducing the high failure rate experienced in AI innovation.</p>
<h2>Input, Interaction and Time</h2>
<h3>User Performance in Consecutive Temporal Pointing: An Exploratory Study</h3>
<p>Authors: Dawon Lee, Sunjun Kim, Byungjoo Lee, Junyong Noh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147090">Link</a></p>
<p>Abstract: A significant amount of research has recently been conducted on user performance in so-called temporal pointing tasks, in which a user is required to perform a button input at the timing required by the system. Consecutive temporal pointing (CTP), in which two consecutive button inputs must be performed while satisfying temporal constraints, is common in modern interactions, yet little is understood about user performance on the task. Through a user study involving 100 participants, we broadly explore user performance in a variety of CTP scenarios. The key finding is that CTP is a unique task that cannot be considered as two ordinary temporal pointing processes. Significant effects of button input method, motor limitations, and different hand use were also observed.</p>
<h3>Waiting Time Perceptions for Faster Count-downs/ups Are More Sensitive Than Slower Ones: Experimental Investigation and Its Application</h3>
<p>Authors: Chenxi Xie, Takanori Komatsu, Seiji Yamada</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146709">Link</a></p>
<p>Abstract: Countdowns and count-ups are very useful displays that explicitly show how long users should wait and also show the current processing states of a given task. Most countdowns or count-ups decrease or increase their digit every one second exactly, and most users have an implicit assumption that the digit changes every one second exactly. However, there are no studies that investigate how users perceive wait times with these countdowns and count-ups and that consider changing users' perception of time passing as shorter than the actual passage of time by means of countdowns and count-ups while taking into account such user assumptions. To clarify these issues, we first investigated how users perceive countdowns "from 3/5/10 to 0" and count-ups "from 0 to 3/5/10" that have different lengths of intervals from 800 to 1200 msec (Experiment 1). Next, on the basis of the results of Experiment 1, we explored a novel method for presenting countdowns to make users perceive the wait time as being shorter than the actual wait time (Experiment 2) and investigated whether such countdowns can be used in realistic applications or not (Experiment 3). As a result, we found that countdowns and count-ups that were "from 250 msec shorter to 10% longer" than 3, 5, or 10 sec were perceived as 3, 5, or 10 sec, respectively, and those "from 5 to 0" (their lengths were 5 sec) that first displayed extremely shorter intervals were perceived as being shorter than their actual length (5 sec). Finally, we confirmed the applicability and effectiveness of such displays in a realistic application. Thus, we strongly argue that these findings could become indispensable knowledge for researchers in this research field to reduce users' cognitive load during wait times.</p>
<h3>Mouse2Vec: Learning Reusable Semantic Representations of Mouse Behaviour</h3>
<p>Authors: Zhiming Hu, Andreas Bulling, Guanhua Zhang, Mihai Bâce</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147945">Link</a></p>
<p>Abstract: The mouse is a pervasive input device used for a wide range of interactive applications. However, computational modelling of mouse behaviour typically requires time-consuming design and extraction of handcrafted features, or approaches that are application-specific. We instead propose Mouse2Vec – a novel self-supervised method designed to learn semantic representations of mouse behaviour that are reusable across users and applications. Mouse2Vec uses a Transformer-based encoder-decoder architecture, which is specifically geared for mouse data: During pretraining, the encoder learns an embedding of input mouse trajectories while the decoder reconstructs the input and simultaneously detects mouse click events. We show that the representations learned by our method can identify interpretable mouse behaviour clusters and retrieve similar mouse trajectories. We also demonstrate on three sample downstream tasks that the representations can be practically used to augment mouse data for training supervised methods and serve as an effective feature extractor.</p>
<h3>The Effect of Latency on Movement Time in Path-steering</h3>
<p>Authors: Wolfgang Stuerzlinger, Shota Yamanaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147611">Link</a></p>
<p>Abstract: In current graphical user interfaces, there exists a (typically unavoidable) end-to-end latency from each pointing-device movement to its corresponding cursor response on the screen, which is known to affect user performance in target selection, e.g., in terms of movement time (MT). Previous work also reported that a long latency increases MTs in path-steering tasks, but the quantitative relationship between latency and MT had not been previously investigated for path-steering. In this work, we derive models to predict MTs for path-steering and evaluate them with five tasks: goal crossing as a preliminary task for model derivation, linear-path steering, circular-path steering, narrowing-path steering, and steering with target pointing. The results show that the proposed models yielded an adjusted R^2 &gt; 0.94, with lower AICs and smaller cross-validation RMSEs than the baseline models, enabling more accurate prediction of MTs.</p>
<h2>Interaction and Perception in Immersive Environments</h2>
<h3>MAF: Exploring Mobile Acoustic Field for Hand-to-Face Gesture Interactions</h3>
<p>Authors: Longfei Shangguan, Yujing Huang, Yongjie Yang, Xiuzhen Guo, Tao Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147716">Link</a></p>
<p>Abstract: We present MAF, a novel acoustic sensing approach that leverages the commodity hardware in bone conduction earphones for hand-to-face gesture interactions. Briefly, by shining audio signals with bone conduction earphones, we observe that these signals not only propagate along the surface of the human face but also dissipate into the air, creating an acoustic field that envelops the individual’s head. We conduct benchmark studies to understand how various hand-to-face gestures and human factors influence this acoustic field. Building on the insights gained from these initial studies, we then propose a deep neural network combined with signal preprocessing techniques. This combination empowers MAF to effectively detect, segment, and subsequently recognize a variety of hand-to-face gestures, whether in close contact with the face or above it. Our comprehensive evaluation based on 22 participants demonstrates that MAF achieves an average gesture recognition accuracy of 92% across ten different gestures tailored to users' preferences.</p>
<h3>PhoneInVR: An Evaluation of Spatial Anchoring and Interaction Techniques for Smartphone Usage in Virtual Reality</h3>
<p>Authors: Tovi Grossman, Fengyuan Zhu, Mauricio Sousa, Ludwig Sidenmark</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147762">Link</a></p>
<p>Abstract: When users wear a virtual reality (VR) headset, they lose access to their smartphone and accompanying apps. Past work has proposed smartphones as enhanced VR controllers, but little work has explored using existing smartphone apps and performing traditional smartphone interactions while in VR. In this paper, we consider three potential spatial anchorings for rendering smartphones in VR: On top of a tracked physical smartphone which the user holds (Phone-locked), on top of the user’s empty hand, as if holding a virtual smartphone (Hand-locked), or in a static position in front of the user (World-locked). </p>
<p>We conducted a comparative study of target acquisition, swiping, and scrolling tasks across these anchorings using direct Touch or above-the-surface Pinch. Our findings indicate that physically holding a smartphone with Touch improves accuracy and speed for all tasks, and Pinch performed better with virtual smartphones. These findings provide a valuable foundation to enable smartphones in VR. </p>
<h3>Exploring Visualizations for Precisely Guiding Bare Hand Gestures in Virtual Reality</h3>
<p>Authors: Xizi Wang, Ben Lafreniere, Jian Zhao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147775">Link</a></p>
<p>Abstract: Bare hand interaction in augmented or virtual reality (AR/VR) systems, while intuitive, often results in errors and frustration. However, existing methods, such as a static icon or a dynamic tutorial, can only inform simple and coarse hand gestures and lack corrective feedback. This paper explores various visualizations for enhancing precise hand interaction in VR. Through a comprehensive two-part formative study with 11 participants, we identified four types of essential information for visual guidance and designed different visualizations that manifest these information types. We further distilled four visual designs and conducted a controlled lab study with 15 participants to assess their effectiveness for various single- and double-handed gestures. Our results demonstrate that visual guidance significantly improved users' gesture performance, reducing time and workload while increasing confidence. Moreover, we found that the visualization did not disrupt most users' immersive VR experience or their perceptions of hand tracking and gesture recognition reliability.</p>
<h3>Assessing the Influence of Visual Cues in Virtual Reality on the Spatial Perception of Physical Thermal Stimuli</h3>
<p>Authors: Max Mühlhäuser, Robin Buhlmann, Alexandra Skogseide, Sebastian Günther</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148210">Link</a></p>
<p>Abstract: Advancements in haptics for Virtual Reality (VR) increased the quality of immersive content. Particularly, recent efforts to provide realistic temperature sensations have gained traction, but most often require very specialized or large complex devices to create precise thermal actuations. However, being largely detached from the real world, such a precise correspondence between the physical location of thermal stimuli and the shown visuals in VR might not be necessary for an authentic experience. In this work, we contribute the findings of a controlled experiment with 20 participants, investigating the spatial localization accuracy of thermal stimuli while having matching and non-matching visual cues of a virtual heat source in VR. Although participants were highly confident in their localization decisions, their ability to accurately pinpoint thermal stimuli was notably deficient.</p>
<h3>Improving Electromyographic Muscle Response Times through Visual and Tactile Prior Stimulation in Virtual Reality</h3>
<p>Authors: Valentin Schwind, Karsten Weyers, Leonardo Leite Ferreira, Amir Mahmood, Jessica Sehrt, Thomas Kosch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148137">Link</a></p>
<p>Abstract: Electromyography (EMG) enables hands-free interactions by detecting muscle activity at different human body locations. Previous studies have demonstrated that input performance based on isometric contractions is muscle-dependent and can benefit from synchronous biofeedback. However, it remains unknown whether stimulation before interaction can help to localize and tense a muscle faster. In a response-based VR experiment (N=21), we investigated whether prior stimulation using visual or tactile cues at four different target muscles (biceps, triceps, upper leg, calf) can help reduce the time to perform isometric muscle contractions. The results show that prior stimulation decreases EMG reaction times with visual, vibrotactile, and electrotactile cues. Our experiment also revealed important findings regarding learning and fatigue at the different body locations. We provide qualitative insights into the participants' perceptions and discuss potential reasons for the improved interaction. We contribute with implications and use cases for prior stimulated muscle activation.</p>
<h2>Politics of Data</h2>
<h3>Products of Positionality: How Tech Workers Shape Identity Concepts in Computer Vision</h3>
<p>BEST_PAPER</p>
<p>Authors: Jed Brubaker, Morgan Scheuerman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147182">Link</a></p>
<p>Abstract: There has been a great deal of scholarly attention on issues of identity-related bias in machine learning. Much of this attention has focused on data and data workers, workers who do annotation tasks. Yet tech workers—like engineers, data scientists, and researchers—introduce their own “biases” when defining “identity” concepts. More specifically, they instill their own positionalities, the way they understand and are shaped by the world around them. Through interviews with industry tech workers who focus on computer vision, we show how workers embed their own positional perspectives into products and how positional gaps can lead to unforeseen and undesirable outcomes. We discuss how worker positionality is mutually shaped by the contexts in which they are embedded. We provide implications for researchers and practitioners to engage with the positionalities of tech workers, as well as those in contexts outside of development that influence tech workers.</p>
<h3>SalChartQA: Question-driven Saliency on Information Visualisations</h3>
<p>Authors: Yao Wang, Mayar Elfares, Weitian Wang, Zhiming Hu, Abdullah Abdelhafez, Andreas Bulling, Mihai Bâce</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147419">Link</a></p>
<p>Abstract: Understanding the link between visual attention and users' information needs when visually exploring information visualisations is under-explored due to a lack of large and diverse datasets to facilitate these analyses. </p>
<p>To fill this gap we introduce SalChartQA -- a novel crowd-sourced dataset that uses the BubbleView interface to track user attention and a question-answering (QA) paradigm to induce different information needs in users. </p>
<p>SalChartQA contains 74,340 answers to 6,000 questions on 3,000 visualisations. </p>
<p>Informed by our analyses demonstrating the close correlation between information needs and visual saliency, we propose the first computational method to predict question-driven saliency on visualisations. </p>
<p>Our method outperforms state-of-the-art saliency models for several metrics, such as the correlation coefficient and the Kullback-Leibler divergence.</p>
<p>These results show the importance of information needs for shaping attentive behaviour and pave the way for new applications, such as task-driven optimisation of visualisations or explainable AI in chart question-answering. </p>
<h3>"Things on the Ground are Different": Utility, Survival and Ethics in Multi-Device Ownership and Smartphone Sharing</h3>
<p>Authors: Lindah Kotut, Hummd Alikhan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148190">Link</a></p>
<p>Abstract: As phones have become cheaper, there are still instances where people share them. Researchers have explored the sharing in the context of developing economies and brought to light the barriers to ownership and highlight the resulting power differentials. In this work, we explore the dynamics of single and multi-device ownership and sharing in Kenya. Through interviews with 34 participants, we seek to understand what these ownership patterns inform us about affordances and unstated needs--adding to our knowledge of device usage. We find that these dimensions of ownership raise new questions about ethics and survival, and we describe how they also serve as bellwethers to designing for a developing economy--especially in the context of access to money and other financial infrastructures. We discuss the impact and harms of unregulated policies and the influence of survival on peoples' choices, the implications on ethics, and further explore strategies for identifying, auditing, and mitigating these risks. </p>
<h3>A Canary in the AI Coal Mine: American Jews May Be Disproportionately Harmed by Intellectual Property Dispossession in Large Language Model Training</h3>
<p>Authors: Brent Hecht, Allison McDonald, Heila Precel, Nicholas Vincent</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148186">Link</a></p>
<p>Abstract: Systemic property dispossession from minority groups has often been carried out in the name of technological progress. In this paper, we identify evidence that the current paradigm of large language models (LLMs) likely continues this long history. Examining common LLM training datasets, we find that a disproportionate amount of content authored by Jewish Americans is used for training without their consent. The degree of over-representation ranges from around 2x to around 6.5x. Given that LLMs may substitute for the paid labor of those who produced their training data, they have the potential to cause even more substantial and disproportionate economic harm to Jewish Americans in the coming years. This paper focuses on Jewish Americans as a case study, but it is probable that other minority communities (e.g., Asian Americans, Hindu Americans) may be similarly affected and, most importantly, the results should likely be interpreted as a ``canary in the coal mine'' that highlights deep structural concerns about the current LLM paradigm whose harms could soon affect nearly everyone. We discuss the implications of these results for the policymakers thinking about how to regulate LLMs as well as for those in the AI field who are working to advance LLMs. Our findings stress the importance of working together towards alternative LLM paradigms that avoid both disparate impacts and widespread societal harms.</p>
<h3>When the Body Became Data: Historical Data Cultures and Anatomical Illustration</h3>
<p>Authors: Laura Garrison, Michael Correll</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146916">Link</a></p>
<p>Abstract: With changing attitudes around knowledge, medicine, art, and technology, the human body has become a source of information and, ultimately, shareable and analyzable data. Centuries of illustrations and visualizations of the body occur within particular historical, social, and political contexts. These contexts are enmeshed in different so-called data cultures: ways that data, knowledge, and information are conceptualized and collected, structured and shared. In this work, we explore how information about the body was collected as well as the circulation, impact, and persuasive force of the resulting images. We show how mindfulness of data cultural influences remain crucial for today's designers, researchers, and consumers of visualizations. We conclude with a call for the field to reflect on how visualizations are not timeless and contextless mirrors on objective data, but as much a product of our time and place as the visualizations of the past.</p>
<h2>Reality-Virtuality Continuum: Interaction and Collaboration</h2>
<h3>From Real to Virtual: Exploring Replica-Enhanced Environment Transitions along the Reality-Virtuality Continuum</h3>
<p>Authors: Hans-Christian Jetter, Fabian Pointecker, Judith Friedl-Knirsch, Christoph Anthes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146699">Link</a></p>
<p>Abstract: Recent Head-Mounted Displays enable users to perceive the real environment using a video-based see-through mode and the fully virtual environment within a single display. Leveraging these advancements, we present a generic concept to seamlessly transition between the real and virtual environment, with the goal of supporting users in engaging with and disengaging from any real environment into Virtual Reality. This transition process uses a digital replica of the real environment and incorporates various stages of Milgram’s Reality-Virtuality Continuum, along with visual transitions that facilitate gradual navigation between them. We implemented the overall transition concept and four object-based transition techniques. The overall transition concept and four techniques were evaluated in a qualitative user study, focusing on user experience, the use of the replica and visual coherence. </p>
<p>The results of the user study show, that most participants stated that the replica facilitates the cognitive processing of the transition and supports spatial orientation.</p>
<h3>Blended Whiteboard: Physicality and Reconfigurability in Remote Mixed Reality Collaboration</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Hans Gellersen, Jens Emil Grønbæk, Germán Leiva, Ken Pfeuffer, Eduardo Velloso, Juan Sánchez Esquivel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147453">Link</a></p>
<p>Abstract: The whiteboard is essential for collaborative work. To preserve its physicality in remote collaboration, Mixed Reality (MR) can blend real whiteboards across distributed spaces.</p>
<p>Going beyond reality, MR can further enable interactions like panning and zooming in a virtually reconfigurable infinite whiteboard. However, this reconfigurability conflicts with the sense of physicality. To address this tension, we introduce Blended Whiteboard, a remote collaborative MR system enabling reconfigurable surface blending across distributed physical whiteboards. Blended Whiteboard supports a unique collaboration style, where users can sketch on their local whiteboards but also reconfigure the blended space to facilitate transitions between loosely and tightly coupled work. We describe design principles inspired by proxemics; supporting users in changing between facing each other and being side-by-side, and switching between navigating the whiteboard synchronously and independently. Our work shows exciting benefits and challenges of combining physicality and reconfigurability in the design of distributed MR whiteboards.</p>
<h3>SwitchSpace: Understanding Context-Aware Peeking Between VR and Desktop Interfaces</h3>
<p>Authors: Tovi Grossman, George Fitzmaurice, Johann Wentzel, Fraser Anderson, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147514">Link</a></p>
<p>Abstract: Cross-reality tasks, like creating or consuming virtual reality (VR) content, often involve inconvenient or distracting switches between desktop and VR. An initial formative study explores cross-reality switching habits, finding most switches are momentary "peeks" between interfaces, with specific habits determined by current context. The results inform a design space for context-aware "peeking" techniques that allow users to view or interact with desktop from VR, and vice versa, without fully switching. We implemented a set of peeking techniques and evaluated them in two levels of a cross-reality task: one requiring only viewing, and another requiring input and viewing. Peeking techniques made task completion faster, with increased input accuracy and reduced perceived workload.</p>
<h3>Seated-WIP: Enabling Walking-in-Place Locomotion for Stationary Chairs in Confined Spaces</h3>
<p>BEST_PAPER</p>
<p>Authors: Ming Yun Hsu, Liwei Chan, Tzu-Wei Mi, Yi-Ci Huang, ZHUNG HAO HSUEH</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147661">Link</a></p>
<p>Abstract: We introduce Seated-WIP, a footstep-based locomotion technique tailored for users seated in confined spaces such as on an airplane. It emulates real-world walking using forefoot or rearfoot in-place stepping, enhancing embodiment while reducing fatigue for pro- longed interactions. Our footstep-locomotion maps users’ footstep motions to four locomotion actions: walking forward, turning-in- place, walking backward, and sidestepping. Our first study examined embodiment and fatigue levels across various sitting positions using forefoot, rearfoot, and fullfoot stepping methods. While all these methods effectively replicated walking, users favored the forefoot and rearfoot methods due to reduced fatigue. In our sec- ond study, we compared the footstep-locomotion to leaning- and controller-locomotion on a multitasking navigation task. Results indicate that footstep locomotion offers the best embodied sense of walking and has comparable fatigue levels to controller-locomotion, albeit with slightly reduced efficiency than controller-locomotion. In seated VR environments, footstep locomotion offers a harmonious blend of embodiment, fatigue mitigation, and efficiency.</p>
<h3>Volumetric Hybrid Workspaces: Interactions with Objects in Remote and Co-located Telepresence</h3>
<p>Authors: Mesut Latifoglu, Brandon Syiem, Thuong Hoang, Frank Vetere, Andrew Irlitti</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147499">Link</a></p>
<p>Abstract: Volumetric telepresence aims to create a shared space, allowing people in local and remote settings to collaborate seamlessly. Prior telepresence examples typically have asymmetrical designs, with volumetric capture in one location and objects in one format. In this paper, we present a volumetric telepresence mixed reality system that supports real-time, symmetrical, multi-user, partially distributed interactions, using objects in multiple formats, across multiple locations. We align two volumetric environments around a common spatial feature to create a shared workspace for remote and co-located people using objects in three formats: physical, virtual, and volumetric. We conducted a study with 18 participants over 6 sessions, evaluating how telepresence workspaces support spatial coordination and hybrid communication for co-located and remote users undertaking collaborative tasks. Our findings demonstrate the successful integration of remote spaces, effective use of proxemics and deixis to support negotiation, and strategies to manage interactivity in hybrid workspaces.</p>
<h2>Smart Textiles</h2>
<h3>Ecothreads: Prototyping Biodegradable E-textiles Through Thread-based Fabrication</h3>
<p>Authors: Jingwen Zhu, Lily Winagle, Cindy Hsin-Liu Kao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147320">Link</a></p>
<p>Abstract: We present EcoThreads, a sustainable e-textile prototyping approach for fabricating biodegradable functional threads. We synthesized two thread-based fabrication methods, wet spinning and thread coating, to fabricate functional threads from biomaterials or modify natural fiber to achieve conductive or interactive functionality. We built a wet spinning tool from a modified DIY syringe pump to spin biodegradable conductive threads. The conductive and interactive threads can be further integrated into textiles through weaving, knitting, embroidery, and braiding. We conducted a workshop study inviting e-textile practitioners to use the materials to fabricate e-textile swatches for transient use cases. The EcoThreads approach presents a path for individual creators to incorporate biodegradable material choices toward sustainable e-textile practices. </p>
<h3>KnitScape: Computational Design and Yarn-Level Simulation of Slip and Tuck Colorwork Knitting Patterns</h3>
<p>Authors: Emily Whiting, Nadya Peek, Hannah Twigg-Smith</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147407">Link</a></p>
<p>Abstract: Slipped and tucked stitches introduce small areas of deformation that compound and result in emergent textures on knitted fabrics. When used together with color changes and ladders, these can also produce dramatic colorwork and openwork effects. However, designing slip and tuck colorwork patterns is challenging due to the complex interactions between operations, yarns, and deformations. We present KnitScape, a browser-based tool for design and simulation of stitch patterns for knitting. KnitScape provides a design interface to specify 1) operation repeats, 2) color changes, and 3) needle positions. These inputs are used to build a graph of yarn topology and run a yarn-level spring simulation. This enables visualization of the deformation that arises from slip and tuck operations. Through its design tool and simulation, KnitScape enables rapid exploration of a complex colorwork design space. We demonstrate KnitScape with a series of example swatches.</p>
<h3>Expressive Clothing: Understanding Hobbyist-Sewers' Visions for Self-Expression Through Clothing</h3>
<p>Authors: Charles Perin, Sabrina Lakhdhir, Sowmya Somanath</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147610">Link</a></p>
<p>Abstract: Researchers have found that hobbyist-sewers seek to create new or adapted clothing designs that foster self-expression through communicating ideas, opinions and emotions. Although existing sewing technologies enable designing new patterns, they focus only on the technical aspects of pattern drafting and not on how information can be expressed. To address this gap, we conducted a qualitative diary study with 12 hobbyist-sewers to better understand how they envision creating expressive clothing. From our analysis of the 24 expressive clothing sketches participants created and participant interviews, we identified i) five distinctive multifaceted approaches participants used for self-expression; and ii) four challenges participants identified from their design process. Informed by these insights, we present a set of implications for the design of future technologies that can better support hobbyist-sewers in designing and creating expressive clothing.</p>
<h3>Desktop Biofibers Spinning: An Open-Source Machine for Exploring Biobased Fibers and their Application Towards Sustainable Smart Textile Design</h3>
<p>Authors: Laura Devendorf, Mirela Alistar, Eldy Lazaro Vasquez, Michael Rivera</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147405">Link</a></p>
<p>Abstract: Smart textiles combine electronics with traditional textile forms, showing great promise in creating soft and flexible interactive systems for human-computer interaction and robotics. However, they also present significant sustainability challenges as they merge two substantial waste streams: textiles and electronics. This paper contributes to sustainability efforts by focusing on the integration of biobased materials that are biodegradable, compostable, and recyclable in the design of smart textiles. We introduce a Desktop Biofibers Spinning Machine to enable smart textile innovators to explore biobased fibers (i.e., biofibers) and envision applications in sustainable smart textiles. We describe the machine's design, a usage walkthrough, considerations for fiber spinning, and an exploration of various formulations to make gelatin biofibers. We provide several examples of biofibers integrated into smart textile applications. Finally, we discuss lessons learned from working with biofibers and the unique opportunities our machine brings to the fiber design space in HCI.</p>
<h3>IntelliTex: Fabricating Low-cost and Washable Functional Textiles using A Double-coating Process</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yue Yang, Yuecheng Peng, Danchang Yan, Weitao Song, Guanyun Wang, Lingyun Sun, Ye Tao, Haotian Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146867">Link</a></p>
<p>Abstract: We present IntelliTex, a low-cost and highly accessible double-coating fabrication method for washable and reusable functional textiles with customized input functionalities. Specifically, off-the-shelf textiles are firstly coated with conductive carbon black using pen ink, which endows textiles with rich sensing capabilities, such as pressure, stretch, slide, and temperature. Secondly, textiles are coated with polyurethane to enhance the sensing stability over wash cycles for good reusability. To support user customization, we enrich the design space of double-coating by exploring various coating methods and diverse textiles to be coated. We further contribute a comprehensive library of input components and an online document to make our approach accessible to novice users. Finally, five application examples and a user study showcase the versatile functionalities and user accessibility of our method, with which we hope to support designers, makers, and researchers to easily create functional textiles ready to use in everyday life.</p>
<h2>Education and AI B</h2>
<h3>Scientific and Fantastical: Creating Immersive, Culturally Relevant Learning Experiences with Augmented Reality and Large Language Models</h3>
<p>Authors: Arjun Sharma, David Wright, Melissa Ran, Roy Pea, Bala Vinaithirthan, Anthony Xie, Meng Guo, Shihe (Tracy) Luan, Andrea Cuadra, Khuyen Le, James Landay, Alan Cheng, Arpit Ranasaria</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147314">Link</a></p>
<p>Abstract: Motivating children to learn is a major challenge in education. One way to inspire motivation to learn is through immersion. We combine the immersive potential of augmented reality (AR), narrative, and large language models (LLMs) to bridge fantasy with reality in a mobile application, Moon Story, that teaches elementary schoolers astronomy and environmental science. Our system also builds upon learning theories such as culturally-relevant pedagogy. Using our application, a child embarks on a journey inspired by Chinese mythology, engages in real-world AR activities, and converses with a fictional character powered by a LLM. We conducted a controlled experiment (N=50) with two conditions: one using an LLM and one that was hard-coded. Both conditions resulted in learning gains, high engagement levels, and increased science learning motivation. Participants in the LLM condition also wrote more relevant answers. Finally, participants of both Chinese and non-Chinese heritage found the culturally-based narrative compelling.</p>
<h3>VIVID: Human-AI Collaborative Authoring of Vicarious Dialogues from Lecture Videos</h3>
<p>Authors: Hyewon Lee, Juho Kim, Seulgi Choi, Yoonjoo Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148330">Link</a></p>
<p>Abstract: The lengthy monologue-style online lectures cause learners to lose engagement easily. Designing lectures in a “vicarious dialogue” format can foster learners’ cognitive activities more than monologue-style. However, designing online lectures in a dialogue style catered to the diverse needs of learners is laborious for instructors. We conducted a design workshop with eight educational experts and seven instructors to present key guidelines and the potential use of large language models (LLM) to transform a monologue lecture script into pedagogically meaningful dialogue. Applying these design guidelines, we created VIVID which allows instructors to collaborate with LLMs to design, evaluate, and modify pedagogical dialogues. In a within-subjects study with instructors (N=12), we show that VIVID helped instructors select and revise dialogues efficiently, thereby supporting the authoring of quality dialogues. Our findings demonstrate the potential of LLMs to assist instructors with creating high-quality educational dialogues across various learning stages.</p>
<h3>Exploring AI Problem Formulation with Children via Teachable Machines</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Salma Elsayed-Ali, Elizabeth Bonsignore, Hernisa Kacorri, Utkarsh Dwivedi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147040">Link</a></p>
<p>Abstract: Emphasizing problem formulation in AI literacy activities with children is vital, yet we lack empirical studies on their structure and affordances. We propose that participatory design involving teachable machines facilitates problem formulation activities. To test this, we integrated problem reduction heuristics into storyboarding and invited a university-based intergenerational design team of 10 children (ages 8-13) and 9 adults to co-design a teachable machine. We find that children draw from personal experiences when formulating AI problems; they assume voice and video capabilities, explore diverse machine learning approaches, and plan for error handling. Their ideas promote human involvement in AI, though some are drawn to more autonomous systems. Their designs prioritize values like capability, logic, helpfulness, responsibility, and obedience, and a preference for a comfortable life, family security, inner harmony, and excitement as end-states. We conclude by discussing how these results can inform the design of future participatory AI activities. </p>
<h3>Mathemyths: Leveraging Large Language Models to Teach Mathematical Language through Child-AI Co-Creative Storytelling</h3>
<p>Authors: Chi-Lin Yu, Ying Xu, Soobin Jeon, Xuechen Liu, Katherine Ziska, Chao Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148341">Link</a></p>
<p>Abstract: Mathematical language is a cornerstone of a child's mathematical development, and children can effectively acquire this language through storytelling with a knowledgeable and engaging partner. In this study, we leverage the recent advances in large language models to conduct free-form, creative conversations with children. Consequently, we developed Mathemyths, a joint storytelling agent that takes turns co-creating stories with children while integrating mathematical terms into the evolving narrative. This paper details our development process, illustrating how prompt-engineering can optimize LLMs for educational contexts. Through a user study involving 35 children aged 4-8 years, our results suggest that when children interacted with Mathemyths, their learning of mathematical language was comparable to those who co-created stories with a human partner. However, we observed differences in how children engaged with co-creation partners of different natures. Overall, we believe that LLM applications, like Mathemyths, offer children a unique conversational experience pertaining to focused learning objectives.</p>
<h3>Testing, Socializing, Exploring: Characterizing Middle Schoolers’ Approaches to and Conceptions of ChatGPT</h3>
<p>Authors: Atefeh Mahdavi Goloujeh, Yasmine Belghith, Brian Magerko, Jessica Roberts, Tom McKlin, Duri Long</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148187">Link</a></p>
<p>Abstract: As generative AI rapidly enters everyday life, educational interventions for teaching about AI need to cater to how young people, in particular middle schoolers who are at a critical age for reasoning skills and identity formation, conceptualize and interact with AI. We conducted nine focus groups with 24 middle school students to elicit their interests, conceptions of, and approaches to a popular generative AI tool, ChatGPT. We highlight a) personally and culturally-relevant topics to this population, b) three distinct approaches in students' open-ended interactions with ChatGPT: AI testing-oriented, AI socializing-oriented, and content exploring-oriented, and 3) an improved understanding of youths' conceptions and misconceptions of generative AI. While misconceptions highlight gaps in understanding what generative AI is and how it works, most learners show interest in learning about what AI is and what it can do. We discuss the implications of these conceptions for designing AI literacy interventions in museums.</p>
<h2>Users Privacy Needs</h2>
<h3>Personalizing Privacy Protection With Individuals' Regulatory Focus: Would You Preserve or Enhance Your Information Privacy?</h3>
<p>Authors: Reza Ghaiumy Anaraky, Danny Yuxing Huang, Hichang Cho, Oded Nov, Kaileigh Angela Byrne, Yao Li, Bart Knijnenburg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146995">Link</a></p>
<p>Abstract: In this study, we explore the effectiveness of persuasive messages endorsing the adoption of a privacy protection technology (IoT Inspector) tailored to individuals' regulatory focus (promotion or prevention). We explore if and how regulatory fit (i.e., tuning the goal-pursuit mechanism to individuals' internal regulatory focus) can increase persuasion and adoption. We conducted a between-subject experiment (N = 236) presenting participants with the IoT Inspector in gain ("Privacy Enhancing Technology"---PET) or loss ("Privacy Preserving Technology"---PPT) framing. Results show that the effect of regulatory fit on adoption is mediated by trust and privacy calculus processes: prevention-focused users who read the PPT message trust the tool more. Furthermore, privacy calculus favors using the tool when promotion-focused individuals read the PET message. We discuss the contribution of understanding the cognitive mechanisms behind regulatory fit in privacy decision-making to support privacy protection.</p>
<h3>Towards Understanding Family Privacy and Security Literacy Conversations at Home: Design Implications for Privacy Literacy Interfaces</h3>
<p>Authors: Adel Hrncic, Nikita Soni, Karthik Singh, Sumanth Kunisetty, Yaxing Yao, Kenan Alghythee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147976">Link</a></p>
<p>Abstract: Policymakers and researchers have emphasized the crucial role of parent-child conversations in shaping children's digital privacy and security literacy. Despite this emphasis, little is known about the current nature of these parent-child conversations, including their content, structure, and children's engagement during these conversations. This paper presents the findings of an interview study involving 13 parents of children ages under 13 reflecting on their privacy literacy practices at home. Through qualitative thematic analysis, we identify five categories of parent-child privacy and security conversations and examine parents' perceptions of their children's engagement during these discussions. Our findings show that although parents used different conversation approaches, rule-based conversations were one of the most common approaches taken by our participants, with example-based conversations perceived to be effective by parents. We propose important design implications for developing effective privacy educational technologies for families to support parent-child conversations.</p>
<h3>Do You Need to Touch? Exploring Correlations between Personal Attributes and Preferences for Tangible Privacy Mechanisms</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Anh Dao Phuong, Karola Marky, Sarah Delgado Rodriguez, Florian Alt, Priyasha Chatterjee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147786">Link</a></p>
<p>Abstract: This paper explores how personal attributes, such as age, gender, technological expertise, or "need for touch", correlate with people's preferences for properties of tangible privacy protection mechanisms, for example, physically covering a camera. For this, we conducted an online survey (N = 444) where we captured participants' preferences of eight established tangible privacy mechanisms well-known in daily life, their perceptions of effective privacy protection, and personal attributes. We found that the attributes that correlated most strongly with participants' perceptions of the established tangible privacy mechanisms were their "need for touch" and previous experiences with the mechanisms. We use our findings to identify desirable characteristics of tangible mechanisms to better inform future tangible, digital, and mixed privacy protections. We also show which individuals benefit most from tangibles, ultimately motivating a more individual and effective approach to privacy protection in the future.</p>
<h3>"I know what you did last semester": Understanding Privacy Expectations and Preferences in the Smart Campus</h3>
<p>Authors: Injung Kim, Adam Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148155">Link</a></p>
<p>Abstract: Sensing technologies in smart campuses help make them sustainable and well-connected environments. However, as with other smart environments, smart campuses can cause privacy concerns during and after deployment. We present the results of a 14-day in-situ study designed to understand peoples’ sentiments about sensing capabilities in smart campuses and how they would specify privacy preferences. In contrast to prior work, which reported the importance of sensing modality and purpose, our findings indicate that indoor location type and recipient are primary determinants for comfort, surprise, notification preferences, and allowance of data collection. Further, we observed that indoor location type influences privacy control willingness and how users specify sensor controlling rule. For example, our participants allowed policy-controlled data collection in group areas while denying it in learning areas. Finally, we suggest that academic environments are unique, possibly due to the complex relationships between students, staff, and faculty.</p>
<h3>“It doesn’t tell me anything about how my data is used”: User Perceptions of Data Collection Purposes</h3>
<p>Authors: Abraham Mhaidli, Asia Biega, Lin Kyi, Franziska Roesner, Cristiana Teixeira Santos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148272">Link</a></p>
<p>Abstract: Data collection purposes and their descriptions are presented on almost all privacy notices under the GDPR, yet there is a lack of research focusing on how effective they are at informing users about data practices. We fill this gap by investigating users’ perceptions of data collection purposes and their descriptions, a crucial aspect of informed consent. We conducted 23 semi-structured interviews with European users to investigate user perceptions of six common purposes (Strictly Necessary, Statistics and Analytics, Performance and Functionality, Marketing and Advertising, Personalized Advertising, and Personalized Content) and identified elements of an effective purpose name and description.</p>
<p>We found that most purpose descriptions do not contain the information users wish to know, and that participants preferred some purpose names over others due to their perceived transparency or ease of understanding. Based on these findings, we suggest how the framing of purposes can be improved toward meaningful informed consent.</p>
<h2>Wellbeing and Mental Health C</h2>
<h3>The Role of AI in Peer Support for Young People: A Study of Preferences for Human- and AI-Generated Responses</h3>
<p>Authors: Laala M Jawara, Brian Daly, Diep Nguyen, Jina Huh-Yoo, Afsaneh Razi, Jordyn Young</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148227">Link</a></p>
<p>Abstract: Generative Artificial Intelligence (AI) is integrated into everyday technology, including news, education, and social media. AI has further pervaded private conversations as conversational partners, auto-completion, and response suggestions. As social media becomes young people's main method of peer support exchange, we need to understand when and how AI can facilitate and assist in such exchanges in a beneficial, safe, and socially appropriate way. We asked 622 young people to complete an online survey and evaluate blinded human- and AI-generated responses to help-seeking messages. We found that participants preferred the AI-generated response to situations about relationships, self-expression, and physical health. However, when addressing a sensitive topic, like suicidal thoughts, young people preferred the human response. We also discuss the role of training in online peer support exchange and its implications for supporting young people's well-being. Disclaimer: This paper includes sensitive topics, including suicide ideation. Reader discretion is advised.</p>
<h3>The Social Journal: Investigating Technology to Support and Reflect on Social Interactions</h3>
<p>Authors: Tabea Blenk, Sophia Sakel, Luke Haliburton, Albrecht Schmidt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147877">Link</a></p>
<p>Abstract: Social interaction is a crucial part of what it means to be human. Maintaining a healthy social life is strongly tied to positive outcomes for both physical and mental health. While we use personal informatics data to reflect on many aspects of our lives, technology-supported reflection for social interactions is currently under-explored. To address this, we first conducted an online survey (N=124) to understand how users want to be supported in their social interactions. Based on this, we designed and developed an app for users to track and reflect on their social interactions and deployed it in the wild for two weeks (N=25). Our results show that users are interested in tracking meaningful in-person interactions that are currently untraced and that an app can effectively support self-reflection on social interaction frequency and social load. We contribute insights and concrete design recommendations for technology-supported reflection for social interaction.</p>
<h3>S-ADL: Exploring Smartphone-based Activities of Daily Living to Detect Blood Alcohol Concentration in a Controlled Environment</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Uichin Lee, Sang Won Bae, Hansoo Lee, Auk Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146856">Link</a></p>
<p>Abstract: In public health and safety, precise detection of blood alcohol concentration (BAC) plays a critical role in implementing responsive interventions that can save lives. While previous research has primarily focused on computer-based or neuropsychological tests for BAC identification, the potential use of daily smartphone activities for BAC detection in real-life scenarios remains largely unexplored. Drawing inspiration from Instrumental Activities of Daily Living (I-ADL), our hypothesis suggests that Smartphone-based Activities of Daily Living (S-ADL) can serve as a viable method for identifying BAC. In our proof-of-concept study, we propose, design, and assess the feasibility of using S-ADLs to detect BAC in a scenario-based controlled laboratory experiment involving 40 young adults. In this study, we identify key S-ADL metrics, such as delayed texting in SMS, site searching, and finance management, that significantly contribute to BAC detection (with an AUC-ROC and accuracy of 81%). We further discuss potential real-life applications of the proposed BAC model.</p>
<h3>Exploring an Extended Reality Floatation Tank Experience to Reduce the Fear of Being in Water</h3>
<p>Authors: Florian Mueller, Sarah Jane Pell, Hannah Qiao, Maria Montoya, Don Samitha Elvitigala, Prasanth Sasikumar, Suranga Nanayakkara</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148060">Link</a></p>
<p>Abstract: People with a fear of being in water rarely engage in water activities and hence miss out on the associated health benefits. Prior research suggested virtual exposure to treat fears. However, when it comes to a fear of being in water, virtual water might not capture water’s immersive qualities, while real water can pose safety risks. We propose extended reality to combine both advantages: We conducted a study (N=12) where participants with a fear of being in water interacted with playful water-inspired virtual reality worlds while floating inside a floatation tank. Our findings, supported quantitatively by heart rate variability and qualitatively by interviews, suggest that playful extended reality could mitigate fear responses in an entertaining way. We also present insights for the design of future systems that aim to help people with a fear of being in water and other phobias by using the best of the virtual and physical worlds.</p>
<h2>Accessibility and Aging</h2>
<h3>Designing a Multisensory VR Game Prototype for Older Adults - the Acceptability and Design Implications</h3>
<p>Authors: Yasuyuki Gondo, Xin Suzuki, Kin Wa Fung, Xiaoxuan Li, Xiangshi Ren, Naoaki Yamaji</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146682">Link</a></p>
<p>Abstract: Simultaneous declines in visual function (e.g., dynamic visual acuity), cognitive ability (e.g., cognitive control/multitasking), and physical function (e.g., balance) are major symptoms of aging. Integrating stimulation for those sensory channels into a game could be a suitable way for older adults to engage in long-term health interventions. However, existing game design has not considered the relationship and synergistic impact of multisensory channels of dynamic visual acuity, cognitive ability, and physical function for older adults. We therefore developed the first multisensory VR game system prototype based on cognitive psychology paradigms (e.g., multitasking and Go/No-Go tasks), full-body movement (limb movement), and dynamic visual acuity exercises (horizontal, vertical and forward-backward eye movements) in the VR system environment. We then conducted an experiment to measure the acceptability (in terms of e.g., cybersickness, mental workload, etc.) of our VR game for older adults. The young adults and a PC task were included for comparisons.  Qualitative and quantitative results showed that older adults did not experience cybersickness in either sitting or standing postures during the VR gameplay; they well-accepted the workload of the VR game compared to the PC task. Our findings revealed that the design combination of three sensory channels shows synergistic benefits for older adults. Our game encourages older adults to engage in extensive body movement in sitting and standing postures, this is particularly important to people with disabilities who cannot stand. Design implications are provided for the future development and implementation of VR game design for older adults. Our work provides empirical support for the acceptability of multisensory VR systems in older adults, and contributes to the future design of VR games for older adults.</p>
<h3>Exploring the Opportunity of Augmented Reality (AR) in Supporting Older Adults to Explore and Learn Smartphone Applications</h3>
<p>Authors: Xiaofu Jin, Emily Kuang, Xian Wang, Mingming Fan, Xiaoying Wei, Huamin Qu, Xiaoyu Mo, Wai Tong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146706">Link</a></p>
<p>Abstract: The global aging trend compels older adults to navigate the evolving digital landscape, presenting a substantial challenge in mastering smartphone applications. While Augmented Reality (AR) holds promise for enhancing learning and user experience, its role in aiding older adults' smartphone app exploration remains insufficiently explored. Therefore, we conducted a two-phase study: (1) a workshop with 18 older adults to identify app exploration challenges and potential AR interventions, and (2) tech-probe participatory design sessions with 15 participants to co-create AR support tools. Our research highlights AR's effectiveness in reducing physical and cognitive strain among older adults during app exploration, especially during multi-app usage and the trial-and-error learning process. We also examined their interactional experiences with AR, yielding design considerations on tailoring AR tools for smartphone app exploration. Ultimately, our study unveils the prospective landscape of AR in supporting the older demographic, both presently and in future scenarios.</p>
<h3>Reducing Search Space on Demand Helps Older Adults Find Mobile UI Features Quickly, on Par With Younger Adults</h3>
<p>Authors: Debaleena Chattopadhyay, Ja Eun Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147297">Link</a></p>
<p>Abstract: As mobile user interfaces (UI) become feature-rich, navigation gets more complex. Finding features quickly starts demanding information-intensive strategies for decision-making — which can be challenging for older adults. Older adults examine fewer details, requiring fewer cognitive resources, when searching for information with a large number of alternatives. In this paper, we first systematically examine various ways to convey a reduced feature space. Visually emphasizing three relevant options helped older adults find a specific feature more quickly — on par with younger adults. Older users were more efficient when options were highlighted along with their context or with a weighted zoom than when just highlighted, and they also preferred these two the most. We then present Nav Nudge, an interaction technique that uses voice input and large language models to visually reduce the feature search space on demand — and discuss how older adults use it within a mobile map application.</p>
<h3>Toward Making Virtual Reality (VR) More Inclusive for Older Adults: Investigating Aging Effect on Target Selection and Manipulation Tasks in VR</h3>
<p>Authors: Duotun Wang, Zeyu Wang, Mingming Fan, Yuru Huang, Zhiqing Wu, Shumeng Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147356">Link</a></p>
<p>Abstract: Recent studies show the promise of VR in improving physical, cognitive, and emotional health of older adults. However, prior work on optimizing object selection and manipulation performance in VR was mostly conducted among younger adults. It remains unclear how older adults would perform such tasks compared to younger adults and the challenges they might face. To fill in this gap, we conducted two studies with both older and younger adults to understand their performances and user experiences of object selection and manipulation in VR respectively. Based on the results, we delineated interaction difficulties that older adults exhibited in VR and identified multiple factors, such as headset-related neck fatigue, extra head movements from out-of-view interactions, and slow spatial perceptions, that significantly decreased the motor performance of older adults. We further proposed design recommendations for improving the accessibility of direct interaction experiences in VR for older adults.</p>
<h3>HelpCall: Designing Informal Technology Assistance for Older Adults via Videoconferencing</h3>
<p>Authors: Jiamin Dai, Teerapaun Tanprasert, Joanna McGrenere</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147212">Link</a></p>
<p>Abstract: Older adults commonly rely on younger family members for remote tech support, but the current general-purpose video-conferencing platforms fall short of effectively catering to their needs. We introduce the design concept and prototypes for HelpCall, an augmentation of these platforms that provides aids for learning computer tasks, including a step-by-step visual guide automatically generated from synchronous human instruction. Through observations and interviews with older adults (N=14), we assessed the potential of the HelpCall concept and compared its two design candidates: Tooltip with numbered location markers and List of written steps. All participants acknowledged HelpCall's potential to improve the comfort and efficiency of synchronous tech support. Tooltip emerged as more promising and could be enhanced by incorporating the well-received features from List. Our findings provide clear directions for advancing HelpCall design and new insights into designing synchronous software help for older adults, taking a step towards universal accessibility of digital technology.</p>
<h2>User Security Needs</h2>
<h3>A First Look into Targeted Clickbait and its Countermeasures: The Power of Storytelling</h3>
<p>Authors: Matthew Wright, Mahdi Nasrullah Al-Ameen, Saniat Sohrawardi, Audrey Flood, Ankit Shrestha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146835">Link</a></p>
<p>Abstract: Clickbait headlines work through superlatives and intensifiers, creating information gaps to increase the relevance of their associated links that direct users to time-wasting and sometimes even malicious websites. This approach can be amplified using targeted clickbait that takes publicly available information from social media to align clickbait to users' preferences and beliefs. In this work, we first conducted preliminary studies to understand the influence of targeted clickbait on users' clicking behavior. Based on our findings, we involved 24 users in the participatory design of story-based warnings against targeted clickbait. Our analysis of user-created warnings led to four design variations, which we evaluated through an online survey over Amazon Mechanical Turk. Our findings show the significance of integrating information with persuasive narratives to create effective warnings against targeted clickbait. Overall, our studies provide valuable insights into understanding users' perceptions and behaviors towards targeted clickbait, and the efficacy of story-based interventions.</p>
<h3>Not as easy as just update: Survey of System Administrators and Patching Behaviours</h3>
<p>Authors: Kami Vaniea, Maria Wolters, Adam Jenkins, Linsen Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147837">Link</a></p>
<p>Abstract: Patching software theoretically leads to improvements including security critical changes, but it can also lead to new issues. For System Administrators (sysadmins) new issues can negatively impact operations at their organization. While mitigation options like test environments exist, little is known about their prevalence or how contextual factors like size of organization impact the practice of Patch Management. We surveyed 220 sysadmins engaged in Patch Management to investigate self-reported behaviors. We found that dedicated testing environments are not as prevalent as previously assumed. We also expand on known behaviours that sysadmins perform when facing a troublesome patch, such as employing a range of problem solving behaviours to inform their patching decisions. </p>
<h3>Understanding User-Perceived Security Risks and Mitigation Strategies in the Web3 Ecosystem</h3>
<p>Authors: Janice Jianing SI, Kanye Ye WANG, Tanusree Sharma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146662">Link</a></p>
<p>Abstract: The advent of Web3 technologies promises unprecedented levels of user control and autonomy. However, this decentralization shifts the burden of security onto the users, making it crucial to understand their security behaviors and perceptions. To address this, our study introduces a comprehensive framework that identifies four core components of user interaction within the Web3 ecosystem: blockchain infrastructures, Web3-based Decentralized Applications (DApps), online communities, and off-chain cryptocurrency platforms. We delve into the security concerns perceived by users in each of these components and analyze the mitigation strategies they employ, ranging from risk assessment and aversion to diversification and acceptance. We further discuss the landscape of both technical and human-induced security risks in the Web3 ecosystem, identify the unique security differences between Web2 and Web3, and highlight key challenges that render users vulnerable, to provide implications for security design in Web3.</p>
<h3>Self-Efficacy and Security Behavior: Results from a Systematic Review of Research Methods</h3>
<p>Authors: Imke Böse, Malte Elson, Angela Sasse, Nele Borgert, Jennifer Friedauer, Luisa Jansen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147732">Link</a></p>
<p>Abstract: Amidst growing IT security challenges, psychological underpinnings of security behaviors have received considerable interest, e.g. cybersecurity Self-Efficacy (SE), the belief in one’s own ability to enact cybersecurity-related skills. Due to diverging definitions and proposed mechanisms, research methods in this field vary considerably, potentially impeding replicable evidence and meaningful research synthesis. We report a preregistered systematic literature review investigating (a) cybersecurity SE measures, (b) SE’s proposed roles, and (c) intervention approaches. We minimized selection bias by detailed exclusion criteria, interdisciplinary search strategy, and double coding. Among 174 cybersecurity SE studies (2010-2021) from 18 databases with 55,758 subjects, we identified 173 different SE measures with considerable differences in psychometric quality and validity evidence. We found 276 variables as assumed causes/outcomes of cybersecurity SE and identified 13 intervention designs. This review demonstrates the extent of methodological and conceptual fragmentation in cybersecurity SE research. We offer recommendations to inspire our research community toward standardization.</p>
<h3>A Comparative Long-Term Study of Fallback Authentication Schemes</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Markus Dürmuth, Leona Lassak, Elizabeth Stobert, Maximilian Golla, Philipp Markert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148199">Link</a></p>
<p>Abstract: Fallback authentication, the process of re-establishing access to an account when the primary authenticator is unavailable, holds critical significance. Approaches range from secondary channels like email and SMS to personal knowledge questions (PKQs) and social authentication. A key difference to primary authentication is that the duration between enrollment and authentication can be much longer, typically months or years. However, few systems have been studied over extended timeframes, making it difficult to know how well these systems truly help users recover their accounts. We also lack meaningful comparisons of schemes as most prior work examined two mechanisms at most. We report the results of a long-term user study of the usability of fallback authentication over 18 months to provide a fair comparison of the four most commonly used fallback authentication methods. We show that users prefer email and SMS-based methods, while mechanisms based on PKQs and trustees lag regarding successful resets and convenience.</p>
<h2>Assistive Interactions: Solutions for d/Deaf and Hard of Hearing Users</h2>
<h3>Towards Inclusive Video Commenting: Introducing Signmaku for the Deaf and Hard-of-Hearing</h3>
<p>Authors: Lawrence Angrave, Yun Huang, Desirée Kirst, Qi Wang, Saumya Malhotra, Haocong Cheng, Suzy Su, Jason Situ, Si Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146831">Link</a></p>
<p>Abstract: Previous research underscored the potential of danmaku: a text-based commenting feature on videos for engaging hearing audiences. However, many Deaf and hard-of-hearing (DHH) users prioritize American Sign Language (ASL) over English. To improve inclusivity, we introduce Signmaku, a commenting mechanism that uses ASL as a sign language version of danmaku. Through a need-finding study (N=12) and a within-subject experiment (N=20), we evaluated three design styles: real human faces, cartoon-like, and robotic depictions. We found that cartoon signmaku not only provided entertainment but also prompted participants to create and share ASL comments with fewer privacy concerns compared to the other designs. Conversely, the robotic design's limited accuracy in conveying hand movements and facial expressions increased cognitive demands. Realist signmaku elicited the lowest cognitive load and was the easiest to understand among all three types. Our findings offer unique design implications for leveraging generative AI to create signmaku comments, enhancing co-learning experiences for DHH users.</p>
<h3>How Users Experience Closed Captions on Live Television: Quality Metrics Remain a Challenge</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Matthew Seita, Molly Feanny, Bernard Thompson, Christian Vogler, Mariana Arroyo Chavez, Abraham Glasser, Skyler Officer, Raja Kushalnagar, Keith Delk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146961">Link</a></p>
<p>Abstract: This paper presents a mixed methods study on how deaf, hard of hearing and hearing viewers perceive live TV caption quality with captioned video stimuli designed to mirror TV captioning experiences. To assess caption quality, we used four commonly-used quality metrics focusing on accuracy: word error rate, weighted word error rate, automated caption evaluation (ACE), and its successor ACE2. We calculated the correlation between the four quality metrics and viewer ratings for subjective quality and found that the correlation was weak, revealing that other factors besides accuracy affect user ratings. Additionally, even high-quality captions are perceived to have problems, despite controlling for confounding factors. Qualitative analysis of viewer comments revealed three major factors affecting their experience: Errors within captions, difficulty in following captions, and caption appearance. The findings raise questions as to how objective caption quality metrics can be reconciled with the user experience across a diverse spectrum of viewers.</p>
<h3>Assessment of Sign Language-Based versus Touch-Based Input for Deaf Users Interacting with Intelligent Personal Assistants</h3>
<p>Authors: Matthew Seita, Christian Vogler, Abraham Glasser, Raja Kushalnagar, Nina Tran, Paige DeVries</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147208">Link</a></p>
<p>Abstract: With the recent advancements in intelligent personal assistants (IPAs), their popularity is rapidly increasing when it comes to utilizing Automatic Speech Recognition within households. In this study, we used a Wizard-of-Oz methodology to evaluate and compare the usability of American Sign Language (ASL), Tap to Alexa, and smart home apps among 23 deaf participants within a limited-domain smart home environment. Results indicate a slight usability preference for ASL. Linguistic analysis of the participants' signing reveals a diverse range of expressions and vocabulary as they interacted with IPAs in the context of a restricted-domain application. On average, deaf participants exhibited a vocabulary of 47 +/- 17 signs with an additional 10 +/- 7 fingerspelled words, for a total of 246 different signs and 93 different fingerspelled words across all participants. We discuss the implications for the design of limited-vocabulary applications as a stepping-stone toward general-purpose ASL recognition in the future.</p>
<h3>Unspoken Sound: Identifying Trends in Non-Speech Audio Captioning on YouTube</h3>
<p>Authors: Sooyeon Lee, Jhanvi Pai, Lloyd May, Magdalena Fuentes, Khang Dang, Mark Cartwright, Sripathi Sridhar, Keita Ohshiro</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146864">Link</a></p>
<p>Abstract: High-quality closed captioning of both speech and non-speech elements (e.g., music, sound effects, manner of speaking, and speaker identification) is essential for the accessibility of video content, especially for d/Deaf and hard-of-hearing individuals. While many regions have regulations mandating captioning for television and movies, a regulatory gap remains for the vast amount of web-based video content, including the staggering 500+ hours uploaded to YouTube every minute. Advances in automatic speech recognition have bolstered the presence of captions on YouTube. However, the technology has notable limitations, including the omission of many non-speech elements, which are often crucial for understanding content narratives. This paper examines the contemporary and historical state of non-speech information (NSI) captioning on YouTube through the creation and exploratory analysis of a dataset of over 715k videos. We identify factors that influence NSI caption practices and suggest avenues for future research to enhance the accessibility of online video content.</p>
<h3>Towards Co-Creating Access and Inclusion: A Group Autoethnography on a Hearing Individual's Journey Towards Effective Communication in Mixed-Hearing Ability Higher Education Settings</h3>
<p>Authors: Matthew Seita, Christian Vogler, Qi Wang, James Waller, Raja Kushalnagar, Si Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147946">Link</a></p>
<p>Abstract: We present a group autoethnography detailing a hearing student's journey in adopting communication technologies at a mixed-hearing ability summer research camp. Our study focuses on how this student, a research assistant with emerging American Sign Language (ASL) skills, (in)effectively communicates with deaf and hard-of-hearing (DHH) peers and faculty during the ten-week program. The DHH members also reflected on their communication with the hearing student. We depict scenarios and analyze the (in)effectiveness of how emerging technologies like live automatic speech recognition (ASR) and typing are utilized to facilitate communication. We outline communication strategies to engage everyone with diverse signing skills in conversations - \textit{directing visual attention}, \textit{pause-for-attention-and-proceed}, and \textit{back-channeling via expressive body}. These strategies promote inclusive collaboration and leverage technology advancements. Furthermore, we delve into the factors that have motivated individuals to embrace more inclusive communication practices and provide design implications for accessible communication technologies within the mixed-hearing ability context.</p>
<h2>Assistive Interactions: Everyday Interactions for Users Who are Blind or Low Vision</h2>
<h3>Help Supporters: Exploring the Design Space of Assistive Technologies to Support Face-to-Face Help Between Blind and Sighted Strangers</h3>
<p>Authors: Connor Courtien, Maryam Aziz, Rajan Vaish, Yves Tseng, Brian Smith, Avery Reyna, Jacqueline Gibson, David Rios, Yuanyang Teng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147252">Link</a></p>
<p>Abstract: Blind and low-vision (BLV) people face many challenges when venturing into public environments, often wishing it were easier to get help from people nearby. </p>
<p>Ironically, while many sighted individuals are willing to help, such interactions are infrequent. Asking for help is socially awkward for BLV people, and sighted people lack experience in helping BLV people. Through a mixed-ability research-through-design process, we explore four diverse approaches toward how assistive technology can serve as help supporters that collaborate with both BLV and sighted parties throughout the help process. These approaches span two phases: the connection phase (finding someone to help) and the collaboration phase (facilitating help after finding someone). Our findings from a 20-participant mixed-ability study reveal how help supporters can best facilitate connection, which types of information they should present during both phases, and more. We discuss design implications for future approaches to support face-to-face help.</p>
<h3>Visual Cues for Data Analysis Features Amplify Challenges for Blind Spreadsheet Users</h3>
<p>Authors: Bongshin Lee, Minoli Perera, Eun Kyoung Choe, Kim Marriott</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146687">Link</a></p>
<p>Abstract: Spreadsheets are widely used for storing, manipulating, analyzing, and visualizing data. Features such as conditional formatting, formulas, sorting, and filtering play an important role when understanding and analyzing data in spreadsheets. They employ visual cues, but we have little understanding of the experiences of blind screen reader (SR) users with such features. We conducted a study with 12 blind SR users to gain insights into their challenges, workarounds, and strategies in understanding and extracting information from a spreadsheet consisting of multiple tables that incorporated data analysis features. We identified five factors that impact blind SR users' experiences: cognitive overload, time-information trade-off, lack of awareness and expertise, inadequate system feedback, and delayed and absent SR responses. Drawn from these findings, we discuss design suggestions and future research agenda to improve SR users' spreadsheet experiences.</p>
<h3>A Contextual Inquiry of People with Vision Impairments in Cooking</h3>
<p>Authors: Shaun Kane, Patrick Carrington, Michael Xieyang Liu, Franklin Mingzhe Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147075">Link</a></p>
<p>Abstract: Individuals with vision impairments employ a variety of strategies for object identification, such as pans or soy sauce, in the culinary process. In addition, they often rely on contextual details about objects, such as location, orientation, and current status, to autonomously execute cooking activities. To understand how people with vision impairments collect and use the contextual information of objects while cooking, we conducted a contextual inquiry study with 12 participants in their own kitchens. This research aims to analyze object interaction dynamics in culinary practices to enhance assistive vision technologies for visually impaired cooks. We outline eight different types of contextual information and the strategies that blind cooks currently use to access the information while preparing meals. Further, we discuss preferences for communicating contextual information about kitchen objects as well as considerations for the deployment of AI-powered assistive technologies.</p>
<h3>Towards Inclusive Source Code Readability Based on the Preferences of Programmers with Visual Impairments</h3>
<p>Authors: Maulishree Pandey, Andrew Begel, Steve Oney</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146818">Link</a></p>
<p>Abstract: Code readability is crucial for program comprehension, maintenance, and collaboration. However, many of the standards for writing readable code are derived from sighted developers' readability needs. We conducted a qualitative study with 16 blind and visually impaired (BVI) developers to better understand their readability preferences for common code formatting rules such as identifier naming conventions, line length, and the use of indentation. Our findings reveal how BVI developers' preferences contrast with those of sighted developers and how we can expand the existing rules to improve code readability on screen readers. Based on the findings, we contribute an inclusive understanding of code readability and derive implications for programming languages, development environments, and style guides. Our work helps broaden the meaning of readable code in software engineering and accessibility research.</p>
<h3>FetchAid: Making Parcel Lockers More Accessible to Blind and Low Vision People With Deep-learning Enhanced Touchscreen Guidance, Error-Recovery Mechanism, and AR-based Search Support</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zeyu Xiong, Mingming Fan, Zhitong Guan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147721">Link</a></p>
<p>Abstract: Parcel lockers have become an increasingly prevalent last-mile delivery method. However, a recent study revealed their accessibility challenges to blind and low-vision (BLV) people. Informed by the study, we designed FetchAid, a standalone intelligent mobile app assisting BLV in using a parcel locker in real-time by integrating computer vision and augmented reality (AR) technologies. FetchAid first uses a deep network to detect the user's fingertip and relevant buttons on the touch screen of the parcel locker to guide the user to reveal and scan the QR code to open the target compartment door and then interactively guide the user to reach the door safely with AR-based context-aware audio feedback. Moreover, FetchAid provides an error-recovery mechanism and real-time feedback to keep the user on track. We evaluated it with 12 BLV people and found that FetchAid substantially improved task accomplishment and efficiency, and reduced frustration and overall effort.</p>
<h2>Assistive Interactions: Social and Collaborative Interactions for Users Who or Blind or Low Vision</h2>
<h3>"I Don't Really Get Involved In That Way": Investigating Blind and Visually Impaired Individuals’ Experiences of Joint Attention with Sighted People</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Katherine Jones, Ute Leonards, Oussama Metatla</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147896">Link</a></p>
<p>Abstract: Joint attention (JA) is a crucial component of social interaction, relying heavily on visual cues like eye gaze and pointing. This creates barriers for blind and visually impaired people (BVI) to engage in JA with sighted peers. Yet, little research has characterised these barriers or the strategies BVI people employ to overcome them. We interviewed ten BVI adults to understand JA experiences and analysed videos of four BVI children with eight sighted partners engaging in activities conducive to JA. Interviews revealed that lack of JA feedback is perceived as voids that block engagement, exacerbated in group settings, with an emphasis on oneself to fill those voids. Video analysis anchored the absence of the person element within typical JA triads, suggesting a potential for technology to foster alternative dynamics between BVI and sighted people. We argue these findings could inform technology design that supports more inclusive JA interactions.</p>
<h3>BubbleCam: Engaging Privacy in Remote Sighted Assistance</h3>
<p>Authors: Sooyeon Lee, He Zhang, Rui Yu, John Carroll, Jingyi Xie, Syed Masum Billah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147457">Link</a></p>
<p>Abstract: Remote sighted assistance (RSA) offers prosthetic support to people with visual impairments (PVI) through image- or video-based conversations with remote sighted assistants. While useful, RSA services introduce privacy concerns, as PVI may reveal private visual content inadvertently. Solutions have emerged to address these concerns on image-based asynchronous RSA, but exploration into solutions for video-based synchronous RSA remains limited. In this study, we developed BubbleCam, a high-fidelity prototype allowing PVI to conceal objects beyond a certain distance during RSA, granting them privacy control. Through an exploratory field study with 24 participants, we found that 22 appreciated the privacy enhancements offered by BubbleCam. The users gained autonomy, reducing embarrassment by concealing private items, messy areas, or bystanders, while assistants could avoid irrelevant content. Importantly, BubbleCam maintained RSA's primary function without compromising privacy. Our study highlighted a cooperative approach to privacy preservation, transitioning the traditionally individual task of maintaining privacy into an interactive, engaging privacy-preserving experience. </p>
<h3>Conveying Emotions through Shape-changing to Children with and without Visual Impairment</h3>
<p>Authors: Isabel Neto, Filipa Correia, Filipa Rocha, Hugo Nicolau, Ana Paiva, Yuhan Hu, Guy Hoffman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147053">Link</a></p>
<p>Abstract: Shape-changing skin is an exciting modality due to its accessible and engaging nature. Its softness and flexibility make it adaptable to different interactive devices that children with and without visual impairments can share. Although their potential as an emotionally expressive medium has been shown for sighted adults, their potential as an inclusive modality remains unexplored. This work explores the shape-emotional mappings in children with and without visual impairment. We conducted a user study with 50 children (26 with visual impairment) to investigate their emotional associations with five skin shapes and two movement conditions. Results show that shape-emotional mappings are dependent on visual abilities. Our study raises awareness of the influence of visual experiences on tactile vocabulary and emotional mapping among sighted, low-vision, and blind children. We finish discussing the causal associations between tactile stimuli and emotions and suggest inclusive design recommendations for shape-changing devices.</p>
<h3>Unblind Text Inputs: Predicting Hint-text of Text Input in Mobile Apps via LLM</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mengzhuo Chen, Yuekai Huang, Chunyang Chen, Jun Hu, Zhe Liu, Boyu Wu, Junjie Wang, Qing Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147794">Link</a></p>
<p>Abstract: Mobile apps have become indispensable for accessing and participating in various environments, especially for low-vision users. Users with visual impairments can use screen readers to read the content of each screen and understand the content that needs to be operated. Screen readers need to read the hint-text attribute in the text input component to remind visually impaired users what to fill in. Unfortunately, based on our analysis of 4,501 Android apps with text inputs, over 76% of them are missing hint-text. These issues are mostly caused by developers’ lack of awareness when considering visually impaired individuals. To overcome these challenges, we developed an LLM-based hint-text generation model called HintDroid, which analyzes the GUI information of input components and uses in-context learning to generate the hint-text. To ensure the quality of hint-text generation, we further designed a feedback-based inspection mechanism to further adjust hint-text. The automated experiments demonstrate the high BLEU and a user study further confirms its usefulness. HintDroid can not only help visually impaired individuals, but also help ordinary people understand the requirements of input components. HintDroid demo video: https://youtu.be/FWgfcctRbfI.</p>
<h3>Designing to Support Blind and Visually Impaired Older Adults in Managing the Invisible Labor of Social Participation: Opportunities and Challenges</h3>
<p>Authors: Aqueasha Martin-Hammond, Pranali Shinde</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148126">Link</a></p>
<p>Abstract: Continued social participation is a key determinant of healthy aging and lowers the risks of isolation and loneliness. While online technologies can provide a convenient way for older adults to connect socially, some prefer connecting offline with others in their community, which can pose different challenges, especially for those with disabilities. Yet, we still know little about how older adults with visual disabilities might leverage technology to address their needs for engaging in social events in their communities. We interviewed 16 blind or visually impaired (BVI) adults 60 years or older to understand their experiences engaging in community social activities and the role of technology in the process. We describe the challenges participants faced connecting with others in their community and their use of technology to overcome them. Based on our findings, we discuss design opportunities for technology to help BVI older adults manage the hidden labor social participation.</p>
<h2>Assistive Technologies</h2>
<h3>Designing Gaze-Assisted Upper-Body Gesture Interaction with and for People with Spinal Muscular Atrophy in VR</h3>
<p>Authors: Mingming Fan, Junan Xie, Jingze Tian, Franklin Mingzhe Li, yafeng niu, Liyi Xu, Keye Yu, Yingna Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147764">Link</a></p>
<p>Abstract: Recent research proposed gaze-assisted gestures to enhance interaction within virtual reality (VR), providing opportunities for people with motor impairments to experience VR. Compared to people with other motor impairments, those with Spinal Muscular Atrophy (SMA) exhibit enhanced distal limb mobility, providing them with more design space. However, it remains unknown what gaze-assisted upper-body gestures people with SMA would want and be able to perform. We conducted an elicitation study in which 12 VR-experienced people with SMA designed upper-body gestures for 26 VR commands, and collected 312 user-defined gestures. Participants predominantly favored creating gestures with their hands. The type of tasks and participants' abilities influence their choice of body parts for gesture design. Participants tended to enhance their body involvement and preferred gestures that required minimal physical effort, and were aesthetically pleasing. Our research will contribute to creating better gesture-based input methods for people with motor impairments to interact with VR.</p>
<h3>Beyond Repairing with Electronic Speech: Towards Embodied Communication and Assistive Technology</h3>
<p>Authors: Humphrey Curtis, Timothy Neate</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147301">Link</a></p>
<p>Abstract: Traditionally, Western philosophies have strongly favoured a dualist interpretation of consciousness - emphasising the importance of the <code>mind' over the</code>body'. However, we argue that adopted assistive technologies become embodied and extend intentionality within environments. In this paper, we restore an embodied view of the mind to theoretically enhance: understandings of assistive technology and human-human communication. Initially, we explore literature on: phenomenological theories of human experience, post-phenomenological accounts of technology, embodied accounts of assistive technology and participatory design. We then present a case study demonstrating the generative and disruptive effects of the embodied framework for co-designing AAC with people living with aphasia. Our findings show that the embodied framework supports a more multidimensional account of experience and suggests a shift from AAC devices that seek to `repair' users' speech. Reflecting on our case study, we then outline concerns with nascent technologies that could disembody and limit accessibility.</p>
<h3>People with Disabilities Redefining Identity through Robotic and Virtual Avatars: A Case Study in Avatar Robot Cafe</h3>
<p>Authors: Hiroaki Kato, Giulia Barbareschi, Yuji Hatada, Kentaro Yoshifuji, Takuji Narumi, Kazuaki Takeuchi, Kouta Minamizawa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148080">Link</a></p>
<p>Abstract: Robotic avatars and telepresence technology enable people with disabilities to engage in physical work. Despite the recent popularity of the metaverse, few studies have explored the use of virtual avatars and environments by people with disabilities. In this study, seven disabled participants working in a cafe where remote customer service is provided via robotic avatars, were engaged in the development and use of personalized virtual avatars displayed on a large screen in-situ in combination with existing physical robots, creating a hybrid cyber-physical space. We conducted longitudinal semi-structured interviews to investigate the psychological changes experienced by the participants. The results revealed that mass-produced robotic avatars allowed participants to not disclose their disability if they did not want to, but also backgrounded their identities; by contrast, customized virtual avatars shaped without physical constraints, highlighted their personalities. The combined use of robotic and virtual avatars complemented each other and can support pilots in redefining their identity.</p>
<h3>“Can It Be Customized According to My Motor Abilities?”: Toward Designing User-Defined Head Gestures for People with Dystonia</h3>
<p>Authors: Mingming Fan, Su-Jing Wang, Jingting Li, Qin Sun, Yunqi Hu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148234">Link</a></p>
<p>Abstract: Recent studies proposed above-the-neck gestures for people with upper-body motor impairments interacting with mobile devices without finger touch, resulting in an appropriate user-defined gesture set. However, many gestures involve sustaining eyelids in closed or open states for a period. This is challenging for people with dystonia, who have difficulty sustaining and intermitting muscle contractions. Meanwhile, other facial parts, such as the tongue and nose, can also be used to alleviate the sustained use of eyes in the interaction. Consequently, we conducted a user study inviting 16 individuals with dystonia to design gestures based on facial muscle movements for 26 common smartphone commands. We collected 416 user-defined head gestures involving facial features and shoulders. Finally, we obtained the preferred gestures set for individuals with dystonia. Participants preferred to make the gestures with their heads and use unnoticeable gestures. Our findings provide valuable references for the universal design of natural interaction technology.</p>
<h3>Barriers to Photosensitive Accessibility in Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Caglar Yildirim, Amy Pavel, Laura South, Michelle Borkin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147690">Link</a></p>
<p>Abstract: Virtual reality (VR) systems have grown in popularity as an immersive modality for daily activities such as gaming, socializing, and working. However, this technology is not always accessible for people with photosensitive epilepsy (PSE) who may experience seizures or other adverse symptoms when exposed to certain light stimuli (e.g., flashes or strobes). How can VR be made more inclusive and safer for people with PSE? In this paper, we report on a series of semi-structured interviews about current perceptions of accessibility in VR among people with PSE. We identify 12 barriers to accessibility that fall into four categories: physical VR equipment, VR interfaces and content, specific VR applications, and individual differences in sensitivity. Our findings allow researchers and practitioners to better understand the meaning of photosensitive accessibility in the context of VR, and provide a step towards enabling people with PSE to enjoy the benefits offered by immersive technology. </p>
<h2>Assistive Technologies: Work  Independent Living with Neurodiversity</h2>
<h3>Designing for Strengths: Opportunities to Support Neurodiversity in the Workplace</h3>
<p>Authors: Rachel Lowy, Kaely Hall, Parth Arora, Jennifer Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148212">Link</a></p>
<p>Abstract: Supported employment programs have demonstrated the ability to enhance employment outcomes for neurodivergent individuals by offering personalized job coaching that aligns with the strengths of each individual. While various technological interventions have been designed to support these programs, technologies that hyperfocus on users' assumed challenges through deficit-based design have been criticized due to their potential to undermine the agency of neurodivergent individuals. Therefore, we use strengths-based co-design to explore the opportunities for a technology that supports neurodivergent employees using their strengths. The co-design activities uncovered our participants' current strategies to address workplace challenges, the strengths they employ, and the technology designs that our participants developed to operationalize those strengths in a supportive technology. We find that incorporating strengths-based strategies for emotional regulation, interpersonal problem solving, and learning job-related skills can provide a supportive technology experience that bolsters neurodiverse employees’ agency and independence in the workplace. In response, we suggest design implications for using neurodiverse strengths as design requirements and how to design for independence in workplace.</p>
<h3>Collaborative Job Seeking for People with Autism: Challenges and Design Opportunities</h3>
<p>Authors: Vivian Genaro Motti, Zinat Ara, Slobodan Vucetic, Amrita Ganguly, Donna Peppard, Dongjun Chung, Sungsoo Ray Hong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148323">Link</a></p>
<p>Abstract: Successful job search results from job seekers' well-shaped social communication.</p>
<p>While well-known differences in communication exist between people with autism and neurotypicals, little is known about how people with autism collaborate with their social surroundings to strive in the job market.</p>
<p>To better understand the practices and challenges of collaborative job seeking for people with autism, we interviewed 20 participants including applicants with autism, their social surroundings, and career experts.</p>
<p>Through the interviews, we identified social challenges that people with autism face during their job seeking; the social support they leverage to be successful; and the technological limitations that hinder their collaboration.</p>
<p>We designed four probes that represent major collaborative features found from the interviews--executive planning, communication, stage-wise preparation, and neurodivergent community formation--and discussed their potential usefulness and impact through three focus groups.</p>
<p>We provide implications regarding how our findings can enhance collaborative job seeking experiences for people with autism through new designs.</p>
<h3>“It’s the only thing I can trust”: Envisioning Large Language Model Use by Autistic Workers for Communication Assistance</h3>
<p>Authors: Patrick Carrington, Sanika Moharana, JiWoong Jang, Andrew Begel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147834">Link</a></p>
<p>Abstract: Autistic adults often experience stigma and discrimination at work, leading them to seek social communication support from coworkers, friends, and family despite emotional risks. Large language models (LLMs) are increasingly considered an alternative. In this work, we investigate the phenomenon of LLM use by autistic adults at work and explore opportunities and risks of LLMs as a source of social communication advice. We asked 11 autistic participants to present questions about their own workplace-related social difficulties to (1) a GPT-4-based chatbot and (2) a disguised human confederate. Our evaluation shows that participants strongly preferred LLM over confederate interactions. However, a coach specializing in supporting autistic job-seekers raised concerns that the LLM was dispensing questionable advice. We highlight how this divergence in participant and practitioner attitudes reflects existing schisms in HCI on the relative privileging of end-user wants versus normative good and propose design considerations for LLMs to center autistic experiences.</p>
<h3>Understanding Online Job and Housing Search Practices of Neurodiverse Young Adults to Support Their Independence</h3>
<p>Authors: Ha-Kyung Kong, Saloni Yadav, Daniella Ruzinov, Rachel Lowy, Jennifer Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146962">Link</a></p>
<p>Abstract: Securing employment and housing are key aspects of pursuing independent living. As these activities are increasingly practiced online, web accessibility of related services becomes critical for a successful major life transition. Support for this transition is especially important for people with autism or intellectual disability, who often face issues of underemployment and social isolation. In this study, we conducted semi-structured interviews and contextual inquiries with neurotypical adults and adults with autism or intellectual disability to understand common and unique goals, strategies, and challenges of neurodiverse adults when searching for employment and housing resources online. Our findings revealed that current interfaces adequately support practical (e.g., finance) goals but lack information on social (e.g., inclusivity) goals. Furthermore, unexpected search results and inaccessible social and contextual information diminished search experiences for neurodivergent users, which suggests the need for predictability and structured guidance in searching online. We conclude with design suggestions to make neurodivergent users' online search experience an opportunity to demonstrate their independence.</p>
<h3>Towards Digital Independence: Identifying the Tensions between Autistic Young Adults and Their Support Network When Mediating Social Media</h3>
<p>Authors: Xinru Page, Elizabeth Johnson, Spring Cullen, Pamela Wisniewski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146625">Link</a></p>
<p>Abstract: We conducted an ethnographically-informed study with 28 participants (9 autistic Young Adults or "YAs'" in need of substantial daily support, 6 parents, 13 support staff) to understand how autistic YAs self-regulate and receive mediation on social media. We found that autistic YAs relied on blanket boundary rules and struggled with impulse control; therefore, they coped by asking their support network to help them deal with negative social experiences. Their support networks responded by providing informal advice, in-the-moment instruction, and formal education, but often resorted to monitoring and restrictive mediation when more proactive approaches were ineffective. Overall, we saw boundary tensions arise between Autistic YAs and their support networks as they struggled to find the right balance between providing oversight versus promoting autonomy. This work contributes to the critical disability literature by revealing the benefits and tensions of allyship in the context of helping young autistic adults navigate social media.</p>
<h2>Augmented Stories</h2>
<h3>Comfortable Mobility vs. Attractive Scenery: The Key to Augmenting Narrative Worlds in Outdoor Locative Augmented Reality Storytelling</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ikbeom Jeon, Hyunjin Lee, Woontack Woo, Aram Min, Maryam Shakeri, HYERIM PARK</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147164">Link</a></p>
<p>Abstract: We investigate how path context, encompassing both comfort and attractiveness, shapes user experiences in outdoor locative storytelling using Augmented Reality (AR). Addressing a research gap that predominantly concentrates on indoor settings or narrative backdrops, our user-focused research delves into the interplay between perceived path context and locative AR storytelling on routes with diverse walkability levels. We examine the correlation and causation between narrative engagement, spatial presence, perceived workload, and perceived path context. Our findings show that on paths with reasonable path walkability, attractive elements positively influence the narrative experience. However, even in environments with assured narrative walkability, inappropriate safety elements can divert user attention to mobility, hindering the integration of real-world features into the narrative. These results carry significant implications for path creation in outdoor locative AR storytelling, underscoring the importance of ensuring comfort and maintaining a balance between comfort and attractiveness to enrich the outdoor AR storytelling experience.</p>
<h3>Investigating the Design of Augmented Narrative Spaces Through Virtual-Real Connections: A Systematic Literature Review</h3>
<p>Authors: Hayun Kim, Woontack Woo, HYERIM PARK, Jae-eun Shin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147128">Link</a></p>
<p>Abstract: Augmented Reality (AR) is regarded as an innovative storytelling medium that presents novel experiences by layering a virtual narrative space over a real 3D space. However, understanding of how the virtual narrative space and the real space are connected with one another in the design of augmented narrative spaces has been limited. For this, we conducted a systematic literature review of 64 articles featuring AR storytelling applications and systems in HCI, AR, and MR research. We investigated how virtual narrative spaces have been paired, functionalized, placed, and registered in relation to the real spaces they target. Based on these connections, we identified eight dominant types of augmented narrative spaces that are primarily categorized by whether they virtually narrativize reality or realize the virtual narrative. We discuss our findings to propose design recommendations on how virtual-real connections can be incorporated into a more structured approach to AR storytelling. </p>
<h3>AudioXtend: Assisted Reality Visual Accompaniments for Audiobook Storytelling During Everyday Routine Tasks</h3>
<p>Authors: Wei Zhen Suen, Yun Huang, Shengdong Zhao, Christophe Hurter, Felicia Tan, Ashwin Ram, Peisen Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148039">Link</a></p>
<p>Abstract: The rise of multitasking in contemporary lifestyles has positioned audio-first content as an essential medium for information consumption. We present AudioXtend, an approach to augment audiobook experiences during daily tasks by integrating glanceable, AI-generated visuals through optical see-through head-mounted displays (OHMDs). Our initial study showed that these visual augmentations not only preserved users' primary task efficiency but also dramatically enhanced immediate auditory content recall by 33.3% and 7-day recall by 32.7%, alongside a marked improvement in narrative engagement. Through participatory design workshops involving digital arts designers, we crafted a set of design principles for visual augmentations that are attuned to the requirements of multitaskers. Finally, a 3-day take-home field study further revealed new insights for everyday use, underscoring the potential of assisted reality (aR) to enhance heads-up listening and incidental learning experiences.</p>
<h3>Jigsaw: Authoring Immersive Storytelling Experiences with Augmented Reality and Internet of Things</h3>
<p>Authors: Rajan Vaish, Andrés Monroy-Hernández, Ava Robinson, Lei Zhang, Daekun Kim, Youjean Cho, Yu Jiang Tham</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147993">Link</a></p>
<p>Abstract: Augmented Reality (AR) presents new opportunities for immersive storytelling. However, this immersiveness faces two main hurdles. First, AR's immersive quality is often confined to visual elements, such as pixels on a screen. Second, crafting immersive narratives is complex and generally beyond the reach of amateurs due to the need for advanced technical skills. We introduce Jigsaw, a system that empowers beginners to both experience and craft immersive stories, blending virtual and physical elements. Jigsaw uniquely combines mobile AR with readily available Internet-of-things (IoT) devices. We conducted a qualitative study with 20 participants to assess Jigsaw's effectiveness in both consuming and creating immersive narratives. The results were promising: participants not only successfully created their own immersive stories but also found the playback of three such stories deeply engaging. However, sensory overload emerged as a significant challenge in these experiences. We discuss design trade-offs and considerations for future endeavors in immersive storytelling involving AR and IoT.</p>
<h3>Augmented Reality at Zoo Exhibits: A Design Framework for Enhancing the Zoo Experience</h3>
<p>Authors: Ryan Kelly, Sarah Webber, Jorge Goncalves, Brandon Syiem, Eduardo Velloso, Qiushi Zhou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148105">Link</a></p>
<p>Abstract: Augmented Reality (AR) offers unique opportunities for contributing to zoos' objectives of public engagement and education about animal and conservation issues. However, the diversity of animal exhibits pose challenges in designing AR applications that are not encountered in more controlled environments, such as museums. To support the design of AR applications that meaningfully engage the public with zoo objectives, we first conducted two scoping reviews to interrogate previous work on AR and broader technology use at zoos. We then conducted a workshop with zoo representatives to understand the challenges and opportunities in using AR to achieve zoo objectives. Additionally, we conducted a field trip to a public zoo to identify exhibit characteristics that impacts AR application design. We synthesise the findings from these studies into a framework that enables the design of diverse AR experiences. We illustrate the utility of the framework by presenting two concepts for feasible AR applications.</p>
<h2>Chronic Conditions A</h2>
<h3>Good Days, Bad Days: Understanding the Trajectories of Technology Use During Chronic Fatigue Syndrome</h3>
<p>Authors: Sarah Homewood, Léa Paymal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147030">Link</a></p>
<p>Abstract: People with chronic illness often fluctuate between “good days” and “bad days” where symptoms are more or less severe depending on a range of factors and triggers. Our research contributes preliminary empirical knowledge on technology use during chronic illness depending on fluctuations in symptoms over time. We conducted a scoping study with people with myalgic encephalomyelitis/chronic fatigue syndrome (ME/CFS) to understand how their illness shapes how they use technologies in their everyday lives. This research contributes a timely HCI lens on the under-researched illness of ME/CFS, proposes the “trajectories of technology use” model that can be used to articulate how technologies are used during chronic illness, and points to design openings for technologies that are more accessible for people who experience chronic fatigue, sensory sensitivities and cognitive limitations. These design openings include non-screen-based technologies, and designing technologies that acknowledge and adapt to the changing body during fluctuations in symptoms.</p>
<h3>MigraineTracker: Examining Patient Experiences with Goal-Directed Self-Tracking for a Chronic Health Condition</h3>
<p>BEST_PAPER</p>
<p>Authors: Jessica Schroeder, Liwei Jiang, Carla Castillo, Shaan Chopra, James Fogarty, Allison Cole, Anant Mittal, Yasaman Sefidgar, Natalia Murinova, Sean Munson, Hyeyoung Ryu, Tae Jones</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147528">Link</a></p>
<p>Abstract: Self-tracking and personal informatics offer important potential in chronic condition management, but such potential is often undermined by difficulty in aligning self-tracking tools to an individual's goals. Informed by prior proposals of goal-directed tracking, we designed and developed MigraineTracker, a prototype app that emphasizes explicit expression of goals for migraine-related self-tracking. We then examined migraine patient experiences in a deployment study for an average of 12+ months, including a total of 50 interview sessions with 10 patients working with 3 different clinicians. Patients were able to express multiple types of goals, evolve their goals over time, align tracking to their goals, personalize their tracking, reflect in the context of their goals, and gain insights that enabled understanding, communication, and action. We discuss how these results highlight the importance of accounting for distinct and concurrent goals in personal informatics together with implications for the design of future goal-directed personal informatics tools.</p>
<h3>PD-Insighter: A Visual Analytics System to Monitor Daily Actions for Parkinson's Disease Treatment</h3>
<p>Authors: Danielle Szafir, Daniel Szafir, Qian Zhang, Henry Fuchs, Howard Jiang, Michael Lewek, Pranav Wagh, Angelos Angelopoulos, Chelsea Duppen, Jade Kandel, Ashley Neall</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148175">Link</a></p>
<p>Abstract: People with Parkinson's Disease (PD) can slow the progression of their symptoms with physical therapy. However, clinicians lack insight into patients’ motor function during daily life, preventing them from tailoring treatment protocols to patient needs. This paper introduces PD-Insighter, a system for comprehensive analysis of a person's daily movements for clinical review and decision-making. PD-Insighter provides an overview dashboard for discovering motor patterns and identifying critical deficits during activities of daily living and an immersive replay for closely studying the patient's body movements with environmental context. Developed using an iterative design study methodology in consultation with clinicians, we found that PD-Insighter's ability to aggregate and display data with respect to time, actions, and local environment enabled clinicians to assess a person's overall functioning during daily life outside the clinic. PD-Insighter's design offers future guidance for generalized multiperspective body motion analytics, which may significantly improve clinical decision-making and slow the functional decline of PD and other medical conditions.</p>
<h3>Creating Safe Places: Understanding the Lived Experiences of Families Managing Cystic Fibrosis in Young Children</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yunan Chen, Zhaoyuan Su, Pornchai Tirakitsoontorn, Sunil P. Kamath</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147391">Link</a></p>
<p>Abstract: While previous HCI research has examined chronic care management for children, less is known about supporting families with young children facing serious illnesses. We interviewed 12 families affected by cystic fibrosis (CF) to understand their experiences and explore opportunities to support CF management. We identified three stages of CF management in young children: diagnosis at birth, parental navigation of CF management in the early years, and gradual involvement of children in their CF care. We underscore child development milestones as a key macro-temporal structure in children’s health management, the multifaceted and evolving parental values in crafting a safe place for children, and the balancing acts parents conduct to recreate this safe place as their children grow. We provide design implications to inform the future of child-centered and family-oriented health technologies that can evolve with parents’ and children’s values to assist in creating a safe environment for managing children’s health.</p>
<h3>GlucoMaker: Enabling Collaborative Customization of Glucose Monitors</h3>
<p>Authors: Charles Perin, Sabrina Lakhdhir, Liisa Holsti, Irina Kondratova, Helene Fournier, Fraser Anderson, Sowmya Somanath, Chehak Nayar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147409">Link</a></p>
<p>Abstract: Millions of individuals with diabetes use glucose monitors to track blood sugar levels. Research shows that such individuals seek to customize different aspects of their interactions with these devices, including how they engage with, decorate, and wear them. However, it remains challenging to tailor both device form and function to accommodate individual needs. To address this challenge, we introduce GlucoMaker, a system for collaboratively customizing physical design aspects of glucose monitors. Prior to designing GlucoMaker, we conducted a prototyping and focus group study to understand customization preferences and collaboration benefits. GlucoMaker provides individuals with the ability to a) select monitor form and function preferences, b) alter predefined and downloadable digital model files, c) receive feedback on monitor designs from stakeholders, and d) learn technical design aspects. We further demonstrate the versatility and design space of GlucoMaker with three examples of different form and function use cases.</p>
<h2>Chronic Conditions C</h2>
<h3>“I think it saved me. I think it saved my heart”: The Complex Journey From Self-Tracking With Wearables To Diagnosis</h3>
<p>Authors: Rachel Keys, Aisling Ann O'Kane, Paul Marshall, Graham Stuart</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148252">Link</a></p>
<p>Abstract: Despite their nonclinical origins, wearables are emerging as valuable tools in supporting the diagnosis of cardiovascular disease, one of the leading causes of death worldwide. Diagnostic data once only available via a cardiologist is now available to consumers simply by wearing a smartwatch, so understanding how smartwatches currently support diagnosis is important for healthcare providers and for the designers of increasingly sophisticated personal informatics technology. We conducted a qualitative study comprising interviews and analysis of posts on an online community of accounts of smartwatch assisted cardiac diagnosis. Our findings reveal how smartwatches bridge a current gap in clinical diagnostic modalities, facilitating a diagnostic journey instigated and shaped by the interplay of self-collected data, bodily self-awareness, and increasing clinical acceptance. These insights focus attention on the consequences of the democratisation of health data, with ethical and design implications for health providers, consumer electronic companies, and third-party application designers.</p>
<h3>"It's like a glimpse into the future": Exploring the Role of Blood Glucose Prediction Technologies for Type 1 Diabetes Self-Management</h3>
<p>Authors: Jürgen Bernard, Clara-Maria Barth, Elaine M. Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148048">Link</a></p>
<p>Abstract: Self-management of type 1 diabetes (T1D) involves multiple factors, frequent anticipation of changes in blood glucose, and complex decision-making. ML-based blood glucose predictions (BGP) may be valuable in supporting T1D management. However, it may be difficult for people with T1D to integrate BGP into their decision-making due to prediction uncertainty and interpretation. In this study, we investigate the lived experience of people with T1D focusing on their needs and expectations in using apps that provide BGP. We designed MOON-T1D, an app that shows simulated BGP and conducted a five-day study using the Experience Sampling Method coupled with semi-structured interviews with 15 individuals with T1D who used MOON-T1D. A reflexive thematic analysis of our data revealed implications for the design and use of BGP, including the complex role of emotions and trust surrounding predictions, and ways in which BGP may ease or complicate T1D management.</p>
<h3>HIV Client Perspectives on Digital Health in Malawi</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Evelyn Viola, Odala Sande, Richard Anderson, Jacqueline Huwa, Hannock Tweya, Agness Thawani, Lisa Orii, Christine Kiruthu-Kamamia, Caryl Feldacker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147847">Link</a></p>
<p>Abstract: eHealth has strong potential to advance HIV care in low- and middle-income countries. Given the sensitivity of HIV-related information and the risks associated with unintended HIV status disclosure, clients’ privacy perceptions towards eHealth applications should be examined to develop client-centered technologies. Through focus group discussions with antiretroviral therapy (ART) clients from Lighthouse Trust, Malawi’s public HIV care program, we explored perceptions of data security and privacy, including their understanding of data flow and their concerns about data confidentiality across several layers of data use. Our findings highlight the broad privacy concerns that affect ART clients’ day-to-day choices, clients’ trust in Malawi's health system, and their acceptance of, and familiarity with, point-of-care technologies used in HIV care. Based on our findings, we provide recommendations for building robust digital health systems in low- and middle-income countries with limited resources, nascent privacy regulations, and political will to take action to protect client data.</p>
<h3>“Obviously, Nothing's Gonna Happen in Five Minutes”: How Adolescents and Young Adults Infrastructure Resources to Learn Type 1 Diabetes Management</h3>
<p>Authors: Tian Xu, Casey Fiesler, Laurel H. Messer, Gregory Forlenza, Paul Cook, Stephen Voida, Sriram Sankaranarayanan, Emily Jost</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148225">Link</a></p>
<p>Abstract: Learning personalized self-management routines is pivotal for people with type 1 diabetes (T1D), particularly early in diagnosis. Context-aware technologies, such as hybrid closed-loop (HCL) insulin pumps, are important tools for diabetes self-management. However, clinicians have observed that practices using these technologies involve significant individual differences. We conducted interviews with 20 adolescents and young adults who use HCL insulin pump systems for managing T1D, and we found that these individuals leverage both technological and non-technological means to maintain situational awareness about their condition. We discuss how these practices serve to infrastructure their self-management routines, including medical treatment, diet, and glucose measurement-monitoring routines. Our study provides insights into adolescents’ and young adults’ lived experiences of using HCL systems and related technology to manage diabetes, and contributes to a more nuanced understanding of how the HCI community can support the contextualized management of diabetes through technology design.</p>
<h2>Coding with AI</h2>
<h3>Validating AI-Generated Code with Live Programming</h3>
<p>Authors: Sorin Lerner, Michael James, Nadia Polikarpova, Ruanqianqian (Lisa) Huang, Kasra Ferdowsi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146703">Link</a></p>
<p>Abstract: AI-powered programming assistants are increasingly gaining popularity, with GitHub Copilot alone used by over a million developers worldwide. These tools are far from perfect, however, producing code suggestions that may be incorrect in subtle ways. As a result, developers face a new challenge: validating AI's suggestions. This paper explores whether Live Programming (LP), a continuous display of a program's runtime values, can help address this challenge. To answer this question, we built a Python editor that combines an AI-powered programming assistant with an existing LP environment. Using this environment in a between-subjects study (N=17), we found that by lowering the cost of validation by execution, LP can mitigate over- and under-reliance on AI-generated programs and reduce the cognitive load of validation for certain types of tasks.</p>
<h3>Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT &amp; NetLogo Chat</h3>
<p>Authors: Yuzhou Du, Uri Wilensky, Mike Horn, John Chen, Xi Lu, Ruth Bagley, Michael Rejtig</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148257">Link</a></p>
<p>Abstract: Large Language Models (LLMs) have the potential to fundamentally change the way people engage in computer programming. Agent-based modeling (ABM) has become ubiquitous in natural and social sciences and education, yet no prior studies have explored the potential of LLMs to assist it. We designed NetLogo Chat to support the learning and practice of NetLogo, a programming language for ABM. To understand how users perceive, use, and need LLM-based interfaces, we interviewed 30 participants from global academia, industry, and graduate schools. Experts reported more perceived benefits than novices and were more inclined to adopt LLMs in their workflow. We found significant differences between experts and novices in their perceptions, behaviors, and needs for human-AI collaboration. We surfaced a knowledge gap between experts and novices as a possible reason for the benefit gap. We identified guidance, personalization, and integration as major needs for LLM-based interfaces to support the programming of ABM.</p>
<h3>Ivie: Lightweight Anchored Explanations of Just-Generated Code</h3>
<p>Authors: Zhiyuan Wu, Alyssa Hwang, Andrew Head, Litao Yan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147626">Link</a></p>
<p>Abstract: Programming assistants have reshaped the experience of programming into one where programmers spend less time writing and more time critically examining code. In this paper, we explore how programming assistants can be extended to accelerate the inspection of generated code. We introduce an extension to the programming assistant called Ivie, or instantly visible in-situ explanations. When using Ivie, a programmer's generated code is instantly accompanied by explanations positioned just adjacent to the code. Our design was optimized for extremely low-cost invocation and dismissal. Explanations are compact and informative. They describe meaningful expressions, from individual variables to entire blocks of code. We present an implementation of Ivie that forks VS Code, applying a modern LLM for timely segmentation and explanation of generated code. In a lab study, we compared Ivie to a contemporary baseline tool for code understanding. Ivie improved understanding of generated code, and was received by programmers as a highly useful, low distraction, desirable complement to the programming assistant.</p>
<h3>Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Eric Horvitz, Hussein Mozannar, Gagan Bansal, Adam Fourney</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146797">Link</a></p>
<p>Abstract: Code-recommendation systems, such as Copilot and CodeWhisperer, have the potential to improve programmer productivity by suggesting and auto-completing code. However, to fully realize their potential, we must understand how programmers interact with these systems and identify ways to improve that interaction. To seek insights about human-AI collaboration with code recommendations systems, we studied GitHub Copilot, a code-recommendation system used by millions of programmers daily. </p>
<p>We developed CUPS, a taxonomy of common programmer activities when interacting with Copilot. Our study of 21 programmers, who completed coding tasks and retrospectively labeled their sessions with CUPS, showed that CUPS can help us understand how programmers interact with code-recommendation systems, revealing inefficiencies and time costs. Our insights reveal how programmers interact with Copilot and motivate new interface designs and metrics. </p>
<h3>CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs</h3>
<p>Authors: Paul Denny, Tovi Grossman, Michelle Craig, Austin Henley, Runlong Ye, Xiaoning Wang, Majeed Kazemitabaar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147379">Link</a></p>
<p>Abstract: Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student's incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI's unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.</p>
<h2>Colors</h2>
<h3>Exploring Interactive Color Palettes for Abstraction-Driven Exploratory Image Colorization</h3>
<p>Authors: Ryan Rossi, Mingyu Liu, Xinyu Shi, Jian Zhao, Ali Neshati, Ziqi Zhou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147505">Link</a></p>
<p>Abstract: Color design is essential in areas such as product, graphic, and fashion design. However, current tools like Photoshop, with their concrete-driven color manipulation approach, often stumble during early ideation, favoring polished end results over initial exploration. We introduced Mondrian as a test-bed for abstraction-driven approach using interactive color palettes for image colorization. Through a formative study with six design experts, we selected three design options for visual abstractions in color design and developed Mondrian where humans work with abstractions and AI manages the concrete aspects. We carried out a user study to understand the benefits and challenges of each abstraction format and compare the Mondrian with Photoshop. A survey involving 100 participants further examined the influence of each abstraction format on color composition perceptions. Findings suggest that interactive visual abstractions encourage a non-linear exploration workflow and an open mindset during ideation, thus providing better creative affordance.</p>
<h3>Cieran: Designing Sequential Colormaps via In-Situ Active Preference Learning</h3>
<p>Authors: Danielle Szafir, Zachary Sunberg, Matt-Heun Hong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147642">Link</a></p>
<p>Abstract: Quality colormaps can help communicate important data patterns. However, finding an aesthetically pleasing colormap that looks "just right" for a given scenario requires significant design and technical expertise. We introduce Cieran, a tool that allows any data analyst to rapidly find quality colormaps while designing charts within Jupyter Notebooks. Our system employs an active preference learning paradigm to rank expert-designed colormaps and create new ones from pairwise comparisons, allowing analysts who are novices in color design to tailor colormaps to their data context. We accomplish this by treating colormap design as a path planning problem through the CIELAB colorspace with a context-specific reward model. In an evaluation with twelve scientists, we found that Cieran effectively modeled user preferences to rank colormaps and leveraged this model to create new quality designs. Our work shows the potential of active preference learning for supporting efficient visualization design optimization.</p>
<h3>Palette, Purpose, Prototype: The Three Ps of Color Design and How Designers Navigate Them</h3>
<p>Authors: Lena Hegemann, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147335">Link</a></p>
<p>Abstract: This paper contributes to understanding of a fundamental process</p>
<p>in design: choosing colors. While much has been written on color</p>
<p>theory and about general design processes, understanding of designers’</p>
<p>actual color-design practice and experiences remains patchy.</p>
<p>To address this gap, this paper presents qualitative findings from</p>
<p>an interview-based study with 12 designers and, on their basis,</p>
<p>a conceptual framework of three interlinked color design spaces:</p>
<p>purpose, palette, and prototype. Respectively, these represent a</p>
<p>meaning the colors should deliver, a proposed set of colors fitting</p>
<p>this purpose, and a possible allocation of these colors to a candidate</p>
<p>design. Through a detailed report on how designers iteratively navigate</p>
<p>these spaces, the findings offer a rich account of color-design</p>
<p>practice and point to possible design benefits from computational</p>
<p>toolsthat integrate considerations of all three.</p>
<h3>Color Maker: a Mixed-Initiative Approach to Creating Accessible Color Maps</h3>
<p>Authors: Amey Salvi, Khairi Reda, Kecheng Lu, Yunhai Wang, Michael Papka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147098">Link</a></p>
<p>Abstract: Quantitative data is frequently represented using color, yet designing effective color mappings is a challenging task, requiring one to balance perceptual standards with personal color preference. Current design tools either overwhelm novices with complexity or offer limited customization options. We present ColorMaker, a mixed-initiative approach for creating colormaps. ColorMaker combines fluid user interaction with real-time optimization to generate smooth, continuous color ramps. Users specify their loose color preferences while leaving the algorithm to generate precise color sequences, meeting both designer needs and established guidelines. ColorMaker can create  new colormaps, including designs accessible for people with color-vision deficiencies, starting from scratch or with only partial input, thus supporting ideation and iterative refinement. We show that our approach can generate designs with similar or superior perceptual characteristics to standard colormaps. A user study demonstrates how designers of varying skill levels can use this tool to create custom, high-quality colormaps. ColorMaker is available at: https://colormaker.org</p>
<h3>Piet: Facilitating Color Authoring for Motion Graphics Video</h3>
<p>BEST_PAPER</p>
<p>Authors: Yinghou Wang, Xinyu Shi, Jian Zhao, Yun Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147118">Link</a></p>
<p>Abstract: Motion graphic (MG) videos are effective and compelling for presenting complex concepts through animated visuals; and colors are important to convey desired emotions, maintain visual continuity, and signal narrative transitions. However, current video color authoring workflows are fragmented, lacking contextual previews, hindering rapid theme adjustments, and not aligning with designers’ progressive authoring flows. To bridge this gap, we introduce Piet, the first tool tailored for MG video color authoring. Piet features an interactive palette to visually represent color distributions, support controllable focus levels, and enable quick theme probing via grouped color shifts. We interviewed 6 domain experts to identify the frustrations in current tools and inform the design of Piet. An in-lab user study with 13 expert designers showed that Piet effectively simplified the MG video color authoring and reduced the friction in creative color theme exploration.</p>
<h2>Creative Professionals and AI A</h2>
<h3>Unlocking Creator-AI Synergy: Challenges, Requirements, and Design Opportunities in AI-Powered Short-Form Video Production</h3>
<p>Authors: Hajun Kim, Jini Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147507">Link</a></p>
<p>Abstract: The emergence of AI-Powered Short-Form Video Generators (ASVG) has showcased the potential to streamline production time and foster creative ideas. Despite their widespread adoption, research has underexplored ASVG, especially from creators’ perspectives. To evaluate the role of ASVG as creator-centered collaborators, we conducted mixed-method research: (1) interviews (N = 17) and (2) a participatory design workshop (N = 12) with short-form video creators. In our interviews, we investigated creators’ production process and challenges in creating short-form videos. In participatory workshops, short-form video creators envisioned AI-powered video tools, addressing their requirements and AI collaboration perceptions. Our findings indicate ASVGs can provide various advantages including inspiration, swift access to video sources, and automated highlight generation. To put things in perspective, we also underscore concerns arising from AI collaboration, including potential creator identity dilution, reduced creative output, and information bubble. We also discuss design considerations when designing ASVG to retain their creative values.</p>
<h3>ReelFramer: Human-AI Co-Creation for News-to-Video Translation</h3>
<p>Authors: Kevin Crowston, Mark Hansen, Sitong Wang, Lydia Chilton, Jeffrey Nickerson, Samia Menon, Dingzeyu Li, Keren Henderson, Tao Long</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147933">Link</a></p>
<p>Abstract: Short videos on social media are the dominant way young people consume content. News outlets aim to reach audiences through news reels---short videos conveying news---but struggle to translate traditional journalistic formats into short, entertaining videos. To translate news into social media reels, we support journalists in reframing the narrative. In literature, narrative framing is a high-level structure that shapes the overall presentation of a story. We identified three narrative framings for reels that adapt social media norms but preserve news value, each with a different balance of information and entertainment. We introduce ReelFramer, a human-AI co-creative system that helps journalists translate print articles into scripts and storyboards. ReelFramer supports exploring multiple narrative framings to find one appropriate to the story. AI suggests foundational narrative details, including characters, plot, setting, and key information. ReelFramer also supports visual framing; AI suggests character and visual detail designs before generating a full storyboard. Our studies show that narrative framing introduces the necessary diversity to translate various articles into reels, and establishing foundational details helps generate scripts that are more relevant and coherent. We also discuss the benefits of using narrative framing and foundational details in content retargeting.</p>
<h3>Understanding Nonlinear Collaboration between Human and AI Agents: A Co-design Framework for Creative Design</h3>
<p>Authors: Haotian Li, Weiwei Cui, Junxiu Tang, Tan Tang, Renzhong Li, Jiayi Zhou, Yingcai Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148154">Link</a></p>
<p>Abstract: Creative design is a nonlinear process where designers generate diverse ideas in the pursuit of an open-ended goal and converge towards consensus through iterative remixing.</p>
<p>In contrast, AI-powered design tools often employ a linear sequence of incremental and precise instructions to approximate design objectives.</p>
<p>Such operations violate customary creative design practices and thus hinder AI agents' ability to complete creative design tasks.</p>
<p>To explore better human-AI co-design tools, we first summarize human designers’ practices through a formative study with 12 design experts.</p>
<p>Taking graphic design as a representative scenario, we formulate a nonlinear human-AI co-design framework and develop a proof-of-concept prototype, OptiMuse. </p>
<p>We evaluate OptiMuse and validate the nonlinear framework through a comparative study.</p>
<p>We notice a subconscious change in people's attitudes towards AI agents, shifting from perceiving them as mere executors to regarding them as opinionated colleagues. </p>
<p>This shift effectively fostered the exploration and reflection processes of individual designers.</p>
<h3>PlantoGraphy: Incorporating Iterative Design Process into Generative Artificial Intelligence for Landscape Rendering</h3>
<p>Authors: Haichuan Lin, Wei Zeng, Chuanzhang Chen, Rong Huang, Kang Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147560">Link</a></p>
<p>Abstract: Landscape renderings are realistic images of landscape sites, allowing stakeholders to perceive better and evaluate design ideas. While recent advances in Generative Artificial Intelligence (GAI) enable automated generation of landscape renderings, the end-to-end methods are not compatible with common design processes, leading to insufficient alignment with design idealizations and limited cohesion of iterative landscape design. Informed by a formative study for comprehending design requirements, we present PlantoGraphy, an iterative design system that allows for interactive configuration of GAI models to accommodate human-centered design practice. A two-stage pipeline is incorporated: first, the concretization module transforms conceptual ideas into concrete scene layouts with a domain-oriented large language model; and second, the illustration</p>
<p>module converts scene layouts into realistic landscape renderings with a layout-guided diffusion model fine-tuned through Low-Rank Adaptation. PlantoGraphy has undergone a series of performance evaluations and user studies, demonstrating its effectiveness in landscape rendering generation and the high recognition of its interactive functionality.</p>
<h3>Fashioning Creative Expertise with Generative AI:  Graphical Interfaces for Design Space Exploration Better Support Ideation Than Text Prompts</h3>
<p>Authors: Thiemo Wambsganss, Richard Davis, Tanja Käser, Kevin Gonyop Kim, Wei Jiang, Pierre Dillenbourg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147024">Link</a></p>
<p>Abstract: This paper investigates the potential impact of deep generative models on the work of creative professionals. We argue that current generative modeling tools lack critical features that would make them useful creativity support tools, and introduce our own tool, generative.fashion, which was designed with theoretical principles of design space exploration in mind. Through qualitative studies with fashion design apprentices, we demonstrate how generative.fashion supported both divergent and convergent thinking, and compare it with a state-of-the-art text-based interface using Stable Diffusion. In general, the apprentices preferred generative.fashion, citing the features explicitly designed to support ideation. In two follow-up studies, we provide quantitative results that support and expand on these insights. We conclude that text-only prompts in existing models restrict creative exploration, especially for novices. Our work demonstrates that interfaces which are theoretically aligned with principles of design space exploration are essential for unlocking the full creative potential of generative AI.</p>
<h2>Creative Professionals and AI B</h2>
<h3>LumiMood: A Creativity Support Tool for Designing the Mood of a 3D Scene</h3>
<p>Authors: SeungJun Kim, Seungju Kim, Jeongseok Oh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148271">Link</a></p>
<p>Abstract: The aesthetic design of 3D scenes in game content enhances players' experience by inducing desired emotions. Creating emotionally engaging scenes involves designing low-level features, such as color distribution, contrast, and brightness. This study presents LumiMood, an AI-driven creativity support tool (CST) that automatically adjusts lighting and post-processing to create moods for 3D scenes. LumiMood supports designers by synthesizing reference images, creating mood templates, and providing intermediate design steps. Our formative study with 10 designers identified distinct challenges in mood design based on the participants' experience levels. A user study involving 40 designers revealed that using LumiMood benefits the designers by streamlining workflow, improving precision, and increasing mood intention accuracy. Results indicate that LumiMood supports clarifying mood concepts and improves interpretation of lighting and post-processing, thus resolving the challenges. We observe the effect of template based designing and discuss considerable factors for AI-driven CSTs for users with varying levels of experiences.</p>
<h3>C2Ideas: Supporting Creative Interior Color Design Ideation with a Large Language Model</h3>
<p>Authors: Hao Cui, Yihan Hou, Wei Zeng, Lei WANG, Manling YANG, Jie Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147389">Link</a></p>
<p>Abstract: Interior color design is a creative process that endeavors to allocate colors to furniture and other elements within an interior space. While much research focuses on generating realistic interior designs, these automated approaches often misalign with user intention and disregard design rationales. Informed by a need-finding preliminary study, we develop C2Ideas, an innovative system for designers to creatively ideate color schemes enabled by an intent-aligned and domain-oriented large language model. C2Ideas integrates a three-stage process: Idea Prompting stage distills user intentions into color linguistic prompts; Word-Color Association stage transforms the prompts into semantically and stylistically coherent color schemes; and Interior Coloring stage assigns colors to interior elements complying with design principles. We also develop an interactive interface that enables flexible user refinement and interpretable reasoning. C2Ideas has undergone a series of indoor cases and user studies, demonstrating its effectiveness and high recognition of interactive functionality by designers.</p>
<h3>TypeDance: Creating Semantic Typographic Logos from Image through Personalized Generation</h3>
<p>Authors: Wei Zeng, Liangwei Wang, Xiaojuan Ma, Shishi Xiao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146619">Link</a></p>
<p>Abstract: Semantic typographic logos harmoniously blend typeface and imagery to represent semantic concepts while maintaining legibility. Conventional methods using spatial composition and shape substitution are hindered by the conflicting requirement for achieving seamless spatial fusion between geometrically dissimilar typefaces and semantics. While recent advances made AI generation of semantic typography possible, the end-to-end approaches exclude designer involvement and disregard personalized design. This paper presents TypeDance, an AI-assisted tool incorporating design rationales with the generative model for personalized semantic typographic logo design. It leverages combinable design priors extracted from uploaded image exemplars and supports type-imagery mapping at various structural granularity, achieving diverse aesthetic designs with flexible control. Additionally, we instantiate a comprehensive design workflow in TypeDance, including ideation, selection, generation, evaluation, and iteration. A two-task user evaluation, including imitation and creation, confirmed the usability of TypeDance in design across different usage scenarios.</p>
<h3>When Teams Embrace AI: Human Collaboration Strategies in Generative Prompting in a Creative Design Task</h3>
<p>Authors: Ziyi Qiu, Yuanning Han, JIALE CHENG, RAY LC</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147669">Link</a></p>
<p>Abstract: Studies of Generative AI (GenAI)-assisted creative workflows have focused on individuals overcoming challenges of prompting to produce what they envisioned. When designers work in teams, how do collaboration and prompting influence each other, and how do users perceive generative AI and their collaborators during the co-prompting process? We engaged students with design or performance backgrounds, and little exposure to GenAI, to work in pairs with GenAI to create stage designs based on a creative theme. We found two patterns of collaborative prompting focused on generating story descriptions first, or visual imagery first. GenAI tools helped participants build consensus in the task, and allowed for discussion of the prompting strategies. Participants perceived GenAI as efficient tools rather than true collaborators, suggesting that human partners reduced the reliance on their use. This work highlights the importance of human-human collaboration when working with GenAI tools, suggesting systems that take advantage of shared human expertise in the prompting process.</p>
<h3>Is Resistance Futile?: Early Career Game Developers, Generative AI, and Ethical Skepticism</h3>
<p>Authors: Josiah Boucher, Yunus Telliel, Gillian Smith</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146874">Link</a></p>
<p>Abstract: This paper presents a study that examines developer perceptions and usage of generative AI (GAI) in a summer professional development program for game development interns focused on mobile game design. GAI applications are in common usage worldwide, yet the impacts of this technology in game development remain relatively underexplored. Through a qualitative study using ethnographic interviews and participatory observation, this paper explores how GAI impacted the workflows, creative processes, and professional identities of early career game developers. We present a case of GAI integration that was not a straightforward adoption. Focusing on the interns' resistance, negotiation, and reimagining, we show that the interns were actively developing a new professional culture both with and against generative AI. For the interns, their ethical commitments to fellow game developers and the future of their profession were as important as their practical concerns about usability, utility, and efficacy of GAI tools.</p>
<h2>Data Visualization: Charts</h2>
<h3>Do You See What I See? A Qualitative Study Eliciting High-Level Visualization Comprehension</h3>
<p>Authors: Danielle Szafir, Zhehao Wang, Arran Zeyu Wang, Paul Rosen, Jennifer Adorno, Ghulam Jilani Quadri</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146696">Link</a></p>
<p>Abstract: Designers often create visualizations to achieve specific high-level analytical or communication goals. These goals require people to naturally extract complex, contextualized, and interconnected patterns in data. While limited prior work has studied general high-level interpretation, prevailing perceptual studies of visualization effectiveness primarily focus on isolated, predefined, low-level tasks, such as estimating statistical quantities. This study more holistically explores visualization interpretation to examine the alignment between designers' communicative goals and what their audience sees in a visualization, which we refer to as their comprehension. We found that statistics people effectively estimate from visualizations in classical graphical perception studies may differ from the patterns people intuitively comprehend in a visualization. We conducted a qualitative study on three types of visualizations---line graphs, bar graphs, and scatterplots---to investigate the high-level patterns people naturally draw from a visualization. Participants described a series of graphs using natural language and think-aloud protocols. We found that comprehension varies with a range of factors, including graph complexity and data distribution. Specifically, 1) a visualization's stated objective often does not align with people's comprehension, 2) results from traditional experiments may not predict the knowledge people build with a graph, and 3) chart type alone is insufficient to predict the information people extract from a graph. Our study confirms the importance of defining visualization effectiveness from multiple perspectives to assess and inform visualization practices.</p>
<h3>Effects of Point Size and Opacity Adjustments in Scatterplots</h3>
<p>Authors: Gabriel Strain, Caroline Jay, Andrew J. Stewart, Paul Warren</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147175">Link</a></p>
<p>Abstract: Systematically changing the size and opacity of points on scatterplots can be used to induce more accurate perceptions of correlation by viewers. Evidence points to the mechanisms behind these effects being similar, so one may expect their combination to be additive regarding their effects on correlation estimation. We present a fully-reproducible study in which we combine techniques for influencing correlation perception to show that in reality, effects of changing point size and opacity interact in a non-additive fashion. We show that there is a great deal of scope for using visual features to change</p>
<p>viewers’ perceptions of data visualizations. Additionally, we use our results to further interrogate the perceptual mechanisms at play when changing point size and opacity in scatterplots.</p>
<h3>Spatial Audio-Enhanced Multimodal Graph Rendering for Efficient Data Trend Learning on Touchscreen Devices</h3>
<p>Authors: Jennifer Tennison, Nicholas Giudice, Medhani Kalal, Wilfredo Robinson Moore, Jenna Gorlewicz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146668">Link</a></p>
<p>Abstract: Touchscreen-based rendering of graphics using vibrations, sonification, and text-to-speech is a promising approach for nonvisual access to graphical information, but extracting trends from complex data representations nonvisually is challenging. This work presents the design of a multimodal feedback scheme with integrated spatial audio for the exploration of histograms and scatter plots on touchscreens. We detail the hardware employed and the algorithms used to control vibrations and sonification adjustments through the change of pitch and directional stereo output. We conducted formative testing with 5 blind or visually impaired participants, and results illustrate that spatial audio has the potential to increase the identification of trends in the data, at the expense of a skewed mental representation of the graph. This design work and pilot study are critical to the iterative, human-centered approach of rendering multimodal graphics on touchscreens and contribute a new scheme for efficiently capturing data trends in complex data representations.</p>
<h3>VisTorch: Interacting with Situated Visualizations using Handheld Projectors</h3>
<p>Authors: Huaishu Peng, Biswaksen Patnaik, Niklas Elmqvist</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147315">Link</a></p>
<p>Abstract: Spatial data is best analyzed in situ, but existing mixed reality technologies can be bulky, expensive, or unsuitable for collaboration. We present VisTorch: a handheld device for projected situated analytics consisting of a pico-projector, a multi-spectrum camera, and a touch surface. VisTorch enables viewing charts situated in physical space by simply pointing the device at a surface to reveal visualizations in that location. We evaluated the approach using both a user study and an expert review. In the former, we asked 20 participants to first organize charts in space and then refer to these charts to answer questions. We observed three spatial and one temporal pattern in participant analyses. In the latter, four experts---a museum designer, a statistical software developer, a theater designer, and an environmental educator---utilized VisTorch to derive practical scenarios. Results from our study showcase the utility of situated visualizations for memory and recall.</p>
<h3>To Cut or Not To Cut? A Systematic Exploration of Y-Axis Truncation</h3>
<p>Authors: Matthew Kay, Sheng Long</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147733">Link</a></p>
<p>Abstract: Y-axis truncation is a well-known, much-debated visualization practice. Our work complements existing empirical work by providing a systematic analysis of y-axis truncation on grouped bar charts. Drawing upon theoretical frameworks such as Algebraic Visualization Design, we examine how structure-preserving modifications to visualization affect user performance by systematically dividing the space of possible truncations according to their monotonicity and the type of relations in the underlying data. Our results demonstrate that for comparing and estimating the difference between the lengths of two bars, truncating the y-axis does not affect task performance. For comparing or estimating the relative growth between two bars, truncating monotonically has similar performance to no truncation, while truncating non-monotonically is very likely to impair performance. We discuss possible extensions of our work and recommendations for y-axis truncation. </p>
<p>All supplementary materials are available at https://osf.io/k4hjd/?view_only=008b087fc3d94be7ba0ce7aea95012a7. </p>
<h2>Data Visualization: Geospatial and Multimodal</h2>
<h3>DeepSee: Multidimensional Visualizations of Seabed Ecosystems</h3>
<p>Authors: Eric Martin, Rebecca Wipfler, Hillary Mushkin, Maggie Hendrie, Noah Deutsch, John Magyar, Victoria Orphan, Sergio Parra, Scott Davidoff, Alex Endert, Jennifer Paduan, David W. Caress, Haley Sapers, Daniel Utter, Malika Khurana, Adam Coscia, Santiago Lombeyda</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146725">Link</a></p>
<p>Abstract: Scientists studying deep ocean microbial ecosystems use limited numbers of sediment samples collected from the seafloor to characterize important life-sustaining biogeochemical cycles in the environment. Yet conducting fieldwork to sample these extreme remote environments is both expensive and time consuming, requiring tools that enable scientists to explore the sampling history of field sites and predict where taking new samples is likely to maximize scientific return. We conducted a collaborative, user-centered design study with a team of scientific researchers to develop DeepSee, an interactive data workspace that visualizes 2D and 3D interpolations of biogeochemical and microbial processes in context together with sediment sampling history overlaid on 2D seafloor maps. Based on a field deployment and qualitative interviews, we found that DeepSee increased the scientific return from limited sample sizes, catalyzed new research workflows, reduced long-term costs of sharing data, and supported teamwork and communication between team members with diverse research goals.</p>
<h3>SalienTime: User-driven Selection of Salient Time Steps for Large-Scale Geospatial Data Visualization</h3>
<p>Authors: Huayuan Ye, Changbo Wang, Chenhui Li, Haiwen Huang, Juntong Chen, Zhong Peng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147827">Link</a></p>
<p>Abstract: The voluminous nature of geospatial temporal data from physical monitors and simulation models poses challenges to efficient data access, often resulting in cumbersome temporal selection experiences in web-based data portals. Thus, selecting a subset of time steps for prioritized visualization and pre-loading is highly desirable. Addressing this issue, this paper establishes a multifaceted definition of salient time steps via extensive need-finding studies with domain experts to understand their workflows. Building on this, we propose a novel approach that leverages autoencoders and dynamic programming to facilitate user-driven temporal selections. Structural features, statistical variations, and distance penalties are incorporated to make more flexible selections. User-specified priorities, spatial regions, and aggregations are used to combine different perspectives. We design and implement a web-based interface to enable efficient and context-aware selection of time steps and evaluate its efficacy and usability through case studies, quantitative evaluations, and expert interviews.</p>
<h3>Data Cubes in Hand: A Design Space of Tangible Cubes for Visualizing 3D Spatio-Temporal Data in Mixed Reality</h3>
<p>Authors: Luyan Jiang, Haonan Yao, Hai-Ning Liang, Nan Xiang, Shuqi He, Yue Li, Kaiwen Li, Lingyun Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146834">Link</a></p>
<p>Abstract: Tangible interfaces in mixed reality (MR) environments allow for intuitive data interactions. Tangible cubes, with their rich interaction affordances, high maneuverability, and stable structure, are particularly well-suited for exploring multi-dimensional data types. However, the design potential of these cubes is underexplored. This study introduces a design space for tangible cubes in MR, focusing on interaction space, visualization space, sizes, and multiplicity. Using spatio-temporal data, we explored the interaction affordances of these cubes in a workshop (N=24). We identified unique interactions like rotating, tapping, and stacking, which are linked to augmented reality (AR) visualization commands. Integrating user-identified interactions, we created a design space for tangible-cube interactions and visualization. A prototype visualizing global health spending with small cubes was developed and evaluated, supporting both individual and combined cube manipulation. This research enhances our grasp of tangible interaction in MR, offering insights for future design and application in diverse data contexts.</p>
<h3>Understanding Reader Takeaways in Thematic Maps Under Varying Text, Detail, and Spatial Autocorrelation</h3>
<p>Authors: Fan Lei, Ross Maciejewski, Michelle Mancenido, Arlen Fan, Alan MacEachren</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148161">Link</a></p>
<p>Abstract: Maps are crucial in conveying geospatial data in diverse contexts such as news and scientific reports. This research, utilizing thematic maps, probes deeper into the underexplored intersection of text framing and map types in influencing map interpretation. In this work, we conducted experiments to evaluate how textual detail and semantic content variations affect the quality of insights derived from map examination. We also explored the influence of explanatory annotations across different map types (e.g., choropleth, hexbin, isarithmic), base map details, and changing levels of spatial autocorrelation in the data. From two online experiments with $N=103$ participants, we found that annotations, their specific attributes, and map type used to present the data significantly shape the quality of takeaways. Notably, we found that the effectiveness of annotations hinges on their contextual integration. These findings offer valuable guidance to the visualization community for crafting impactful thematic geospatial representations.</p>
<h3>MAIDR: Making Statistical Visualizations Accessible with Multimodal Data Representation</h3>
<p>Authors: Yilin Xia, Bongshin Lee, JooYoung Seo, Sean McCurry, Yu Jun Yam</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146802">Link</a></p>
<p>Abstract: This paper investigates new data exploration experiences that enable blind users to interact with statistical data visualizations---bar plots, heat maps, box plots, and scatter plots---leveraging multimodal data representations. In addition to sonification and textual descriptions that are commonly employed by existing accessible visualizations, our MAIDR (multimodal access and interactive data representation) system incorporates two additional modalities (braille and review) that offer complementary benefits. It also provides blind users with the autonomy and control to interactively access and understand data visualizations. In a user study involving 11 blind participants, we found the MAIDR system facilitated the accurate interpretation of statistical visualizations. Participants exhibited a range of strategies in combining multiple modalities, influenced by their past interactions and experiences with data visualizations. This work accentuates the overlooked potential of combining refreshable tactile representation with other modalities and elevates the discussion on the importance of user autonomy when designing accessible data visualizations.</p>
<h2>Dementia Care</h2>
<h3>Evolving Presentation of Self: The Influence of Dementia Communication Challenges on Everyday Interactions</h3>
<p>Authors: Yvon Ruitenburg, Panos Markopoulos, Wijnand IJsselsteijn, Minha Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147523">Link</a></p>
<p>Abstract: Communication can become challenging for people with dementia due to language, speech, discourse, and memory impairments. Although recent developments in Human-Computer Interaction have addressed some of these communication challenges, little is known about how they affect the self-presentation of people with dementia in everyday interactions. To understand this connection, we conducted interviews with sixteen people with dementia, six spouses, and fourteen formal caregivers. Our qualitative data revealed that people with dementia's presentation of competence, politeness, engagement, and reality are altered by communication challenges, which can impact their self-esteem, interactions, and relationships. Our study highlights the need for developing technologies that can enhance mutual understanding and acceptance of people with dementia's evolving presentation of self. Additionally, policy changes are required to reduce the stigma associated with communication challenges to foster social inclusion.</p>
<h3>Mnemosyne - Supporting Reminiscence for Individuals with Dementia in Residential Care Settings</h3>
<p>Authors: Peter Shaw, Andrea Baumann, Ludwig Trotter, Nigel Davies, Sarah Clinch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147516">Link</a></p>
<p>Abstract: Reminiscence is known to play an important part in helping to mitigate the effects of dementia. Within the HCI community, work has typically focused on supporting reminiscence at an individual or social level but less attention has been given to supporting reminiscence in residential care settings. This lack of research became particularly apparent during the COVID pandemic when traditional forms of reminiscence involving physical artefacts and face-to-face interactions became especially challenging. In this paper we report on the design, development and evaluation of a reminiscence system, deployed in a residential care home over a two-year-period that included the pandemic. Mnemosyne comprises a pervasive display network and a browser-based application whose adoption and use we explored using a mixed methods approach. Our findings offer insights that will help shape the development and evaluation of future systems, particularly those that use pervasive displays to support unsupervised reminiscence.</p>
<h3>Technology-Mediated Non-pharmacological Interventions for Dementia: Needs for and Challenges in Professional, Personalized and Multi-Stakeholder Collaborative Interventions</h3>
<p>BEST_PAPER</p>
<p>Authors: JUNYAN MAO, Yuling Sun, Xiaojuan Ma, Xin Tong, Zhennan Yi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146988">Link</a></p>
<p>Abstract: Designing and using technologies to support Non-Pharmacological Interventions (NPI) for People with Dementia (PwD) has drawn increasing attention in HCI, with the potential expectations of higher user engagement and positive outcomes. Yet, technologies for NPI can only be valuable if practitioners successfully incorporate them into their ongoing intervention practices beyond a limited research period. Currently, we know little about how practitioners experience and perceive these technologies in practical NPI for PwD. </p>
<p>In this paper, we investigate this question through observations of five in-person NPI activities and interviews with 11 therapists and 5 caregivers. Our findings elaborate the practical NPI workflow process and characteristics, and practitioners’ attitudes, experiences, and perceptions to technology-mediated NPI in practice. </p>
<p>Generally, our participants emphasized practical NPI is a complex and professional practice, needing fine-grained, personalized evaluation and planning, and the practical executing process is situated, and multi-stakeholder collaborative. Yet, existing technologies often fail to consider these specific characteristics, which leads to limitations in practical effectiveness or sustainable use. Drawing on our findings, we discuss the possible implications for designing more useful and practical NPI intervention technologies. </p>
<h3>Family Caregiver Experiences of Using a Mobile App for Music-based Training to Support Dementia Care</h3>
<p>Authors: Tanara Vieira Sousa, Ryan Kelly, Nicola T. Lautenschlager, Zara Thompson, Amit Lampit, Jeanette Tamplin, Felicity Baker, Dianna Vidas, Jenny Waycott, Lars Kulik</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147009">Link</a></p>
<p>Abstract: Family caregivers of people living with dementia need easy-to-access strategies to manage changing care needs. Music therapy is valuable for supporting dementia care, but not always accessible. Technologies could potentially facilitate accessible, home-based music therapy support, but need to be carefully evaluated. We conducted an 8-week field trial of a prototype mobile application, MATCH, with caregivers and people living with dementia. MATCH contains training videos and suggested playlists showing how to use music for specific care needs. MATCH, and music streaming broadly, enabled caregivers to add new strategies to their care repertoire, addressing a range of care needs and enhancing the care relationship. To make MATCH work, however, caregivers needed to fit it into complex care environments and existing technologies. We argue that digital therapeutic tools need to be adopted by caregivers to fit their individual contexts, and this can challenge assumptions about how therapeutic tools will work in practice.</p>
<h3>Design Opportunities for Care Transitions in Dementia: Understanding Informal Caregivers' Experiences Through a Practice-Informed Approach</h3>
<p>Authors: Maudy Gosen, Wijnand IJsselsteijn, Maarten Houben, Rens Brankaert, Veerle Van Overloop</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147643">Link</a></p>
<p>Abstract: The transition from home to formal residential care is described as stressful and emotionally difficult for people with dementia and their informal caregivers. While HCI research investigated how technology supports people with dementia at home or in formal care, there still is a need to understand how technology can support care transitions. This paper presents a practice-informed approach to gather insights collaboratively between care professionals and HCI researchers. We interviewed 42 informal caregivers of people with dementia to uncover their experiences before, during, and after care transitions. Our findings reveal how informal caregivers were: 1) navigating hurdles of information on care transitions, 2) caught up in the evolving challenges of informal caregiving, and 3) shifting from uncertainty in decision-making to acceptance of admission. Next, we formulate six design opportunities to support transitions in dementia care and encourage HCI researchers to pursue a practice-informed approach to address societal challenges in dementia.</p>
<h2>Digital Wellbeing A</h2>
<h3>Real-World Winds: Micro Challenges to Promote Balance Post Smartphone Overload</h3>
<p>Authors: Sven Mayer, Nađa Terzimehić, Sarah Aragon-Hahner, Julia Huber</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146849">Link</a></p>
<p>Abstract: We present and evaluate the concept of winds -- micro challenges to be done in the physical world post-smartphone overload, to encourage exiting the digital smartphone tunnel and promote refreshing breaks from the digital realm. Whereas digital detox solutions are unsustainable in everyday life, current everyday interventions such as screen time reminders or app blockers can induce negative feelings in users. We hypothesize that winds, delivered by our mobile app Real-World Wind, promote balance between the user’s physical and digital activities, as well as engagement with the intervention. RWW tracks users’ smartphone use behavior and distributes winds of five categories upon overload pattern detection. We evaluated the effectiveness of RWW in a week-long field study with 25 participants. Our findings show that winds foster a fun and engaging experience, and significantly promote balance between the digital and physical world post-smartphone overload. We discuss implications for future technology overload interventions. </p>
<h3>StayFocused: Examining the Effects of Reflective Prompts and Chatbot Support on Compulsive Smartphone Use</h3>
<p>Authors: Yuhan Luo, Minhui Liang, Zhuoyang LI, RAY LC</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148192">Link</a></p>
<p>Abstract: Amidst the increasingly prevalent smartphone addiction, we introduce StayFocused, a mobile app to help people focus on their tasks at hand by reducing compulsive smartphone use. Besides guiding people to set focus sessions for non-screen time, we incorporated reflective prompts probing individuals' phone-checking intentions whenever they check their phones and a chatbot to deliver these prompts. To examine the effects of the reflective prompts and the chatbot support, we designed three versions of StayFocused: baseline, reflection, and reflection-chatbot, and conducted a stage-based between-subjects study with 36 college students over five weeks. We found that participants who received the reflective prompts were able to focus longer and resist distractions, and those with chatbot support seemed to better maintain their smartphone use reduction. By highlighting how participants reflected on their focus session activities and their preferences for the chatbot, we discuss the implications of designing persuasive conversational interfaces to reduce unintended behaviors.</p>
<h3>Attention Receipts: Utilizing the Materiality of Receipts to Improve Screen-time Reflection on YouTube</h3>
<p>Authors: Anup Sathya, Ken Nakagaki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147812">Link</a></p>
<p>Abstract: YouTube remains a site of problematic persuasive media consumption, often overriding the goals of users when on the platform. In resistance, we present Attention Receipts - artifacts that materialize the cost of being persuaded by the engagement driven design of YouTube. We design and build a browser plugin and a receipt printer that helps users critically reflect upon their time spent watching videos on YouTube. In a 3 week field-deployment with 6 participants, we evaluate how the materiality of the receipt and their agency in the reflection process affect both the quality of reflection and the time spent consuming media. We find that the materiality of the receipts positively influences time spent consuming internet media and that users were split on having agency over when and how they reflect upon their screen-time. We conclude with design recommendations for domestic artifacts that utilize materiality to reveal the effects of persuasive technology. </p>
<h3>A Longitudinal In-the-Wild Investigation of Design Frictions to Prevent Smartphone Overuse</h3>
<p>Authors: Luke Haliburton, Frederik Riedel, Nađa Terzimehić, Albrecht Schmidt, David Grüning</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147365">Link</a></p>
<p>Abstract: Smartphone overuse is hyper-prevalent in society, and developing tools to prevent this overuse has become a focus of HCI. However, there is a lack of work investigating smartphone overuse interventions over the long term. We collected usage data from N=1,039 users of one sec over an average of 13.4 weeks and qualitative insights from 249 of the users through an online survey. We found that users overwhelmingly choose to target Social Media apps. We found that the short design frictions introduced by one sec effectively reduce how often users attempt to open target apps and lead to more intentional app-openings over time. Additionally, we found that users take periodic breaks from one sec interventions, and quickly rebound from a pattern of overuse when returning from breaks. Overall, we contribute findings from a longitudinal investigation of design frictions in the wild and identify usage patterns from real users in practice.</p>
<h3>InteractOut: Leveraging Interaction Proxies as Input Manipulation Strategies for Reducing Smartphone Overuse</h3>
<p>Authors: Tao Lu, Anhong Guo, Tianying Zhang, Hongxiao Zheng, Xuhai "Orson" Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147313">Link</a></p>
<p>Abstract: Smartphone overuse poses risks to people's physical and mental health. However, current intervention techniques mainly focus on explicitly changing screen content (i.e., output) and often fail to persistently reduce smartphone overuse due to being over-restrictive or over-flexible. We present the design and implementation of InteractOut, a suite of implicit input manipulation techniques that leverage interaction proxies to weakly inhibit the natural execution of common user gestures on mobile devices. We present a design space for input manipulations and demonstrate 8 Android implementations of input interventions. We first conducted a pilot lab study (N=30) to evaluate the usability of these interventions. Based on the results, we then performed a 5-week within-subject field experiment (N=42) to evaluate InteractOut in real-world scenarios. Compared to the traditional and common timed lockout technique, InteractOut significantly reduced the usage time by an additional 15.6% and opening frequency by 16.5% on participant-selected target apps. InteractOut also achieved a 25.3% higher user acceptance rate, and resulted in less frustration and better user experience according to participants' subjective feedback. InteractOut demonstrates a new direction for smartphone overuse intervention and serves as a strong complementary set of techniques with existing methods.</p>
<h2>Digital Wellbeing B</h2>
<h3>Time2Stop: Adaptive and Explainable Human-AI Loop for Smartphone Overuse Intervention</h3>
<p>Authors: Yukang Yan, Yuntao Wang, Anind Dey, Marzyeh Ghassemi, Han Xiao, Yuanchun Shi, Adiba Orzikulova, Zhipeng Li, Xuhai "Orson" Xu, Sung-Ju Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146643">Link</a></p>
<p>Abstract: Despite a rich history of investigating smartphone overuse intervention techniques, AI-based just-in-time adaptive intervention (JITAI) methods for overuse reduction are lacking. We develop Time2Stop, an intelligent, adaptive, and explainable JITAI system that leverages machine learning to identify optimal intervention timings, introduces interventions with transparent AI explanations, and collects user feedback to establish a human-AI loop and adapt the intervention model over time. We conducted an 8-week field experiment (N=71) to evaluate the effectiveness of both the adaptation and explanation aspects of Time2Stop. Our results indicate that our adaptive models significantly outperform the baseline methods on intervention accuracy (&gt;32.8% relatively) and receptivity (&gt;8.0%). In addition, incorporating explanations further enhances the effectiveness by 53.8% and 11.4% on accuracy and receptivity, respectively. Moreover, Time2Stop significantly reduces overuse, decreasing app visit frequency by 7.0∼8.9%. Our subjective data also echoed these quantitative measures. Participants preferred the adaptive interventions and rated the system highly on intervention time accuracy, effectiveness, and level of trust. We envision our work can inspire future research on JITAI systems with a human-AI loop to evolve with users.</p>
<h3>“I finally felt I had the tools to control these urges”: Empowering Students to Achieve Their Device Use Goals With the Reduce Digital Distraction Workshop</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Kasper Hornbæk, Petr Slovak, Maureen Freed, Nigel Shadbolt, Lize Alberts, Kai Lukoff, Max Van Kleek, Hannah Andrews, Michael Inzlicht, Guido Makransky, Laura Csuka, Ulrik Lyngs, Victoria Oldemburgo de Mello, Claudine Tinsman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147658">Link</a></p>
<p>Abstract: Digital self-control tools (DSCTs) help people control their time and attention on digital devices, using interventions like distraction blocking or usage tracking. Most studies of DSCTs' effectiveness have focused on whether a single intervention reduces time spent on a single device. In reality, people may require combinations of DSCTs to achieve more subjective goals across multiple devices. We studied how DSCTs can address individual needs of university students (n = 280), using a workshop where students reflect on their goals before exploring relevant tools. At 1-3 month follow-ups, 95\% of respondents still used at least one type of DSCT, typically applied across multiple devices, and there was substantial variation in the tool combinations chosen. We observed a large increase in self-reported digital self-control, suggesting that providing a space to articulate goals and self-select appropriate DSCTs is a powerful way to support people who struggle to self-regulate digital device use.</p>
<h3>MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention</h3>
<p>Authors: Ruolan Wu, Xiaole Pan, Ningning Zhang, Yuanchun Shi, Li Chen, Yue Fu, Qiaolei Jiang, Yujia Liu, Yuhan Wang, Chun Yu, Xuhai "Orson" Xu, Zhi Zheng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146884">Link</a></p>
<p>Abstract: Problematic smartphone use negatively affects physical and mental health. Despite the wide range of prior research, existing persuasive techniques are not flexible enough to provide dynamic persuasion content based on users’ physical contexts and mental states. We first conducted a Wizard-of-Oz study (N=12) and an interview study (N=10) to summarize the mental states behind problematic smartphone use: boredom, stress, and inertia. This informs our design of four persuasion strategies: understanding, comforting, evoking, and scaffolding habits. We leveraged large language models (LLMs) to enable the automatic and dynamic generation of effective persuasion content. We developed MindShift, a novel LLM-powered problematic smartphone use intervention technique. MindShift takes users’ in-the-moment app usage behaviors, physical contexts, mental states, goals &amp; habits as input, and generates personalized and dynamic persuasive content with appropriate persuasion strategies. We conducted a 5-week field experiment (N=25) to compare MindShift with its simplified version (remove mental states) and baseline techniques (fixed reminder). The results show that MindShift improves intervention acceptance rates by 4.7-22.5% and reduces smartphone usage duration by 7.4-9.8%. Moreover, users have a significant drop in smartphone addiction scale scores and a rise in self-efficacy scale scores. Our study sheds light on the potential of leveraging LLMs for context-aware persuasion in other behavior change domains.</p>
<h3>“You Can Find a Part of my Life in Every Single App”: An Interview Study of What Makes Smartphone Applications Special to Their Users</h3>
<p>Authors: Kasper Hornbæk, Mikael B. Skov, Olga Iarygina, Ulrik Lyngs</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148169">Link</a></p>
<p>Abstract: In the 1979 book "The Meaning of Things'' Csikszentmihalyi and Rochberg-Halton studied people's perception of the significance of things in the home. They emphasized how things influence the self, and vice versa. We propose that their method and analytical framework can help to understand the analogous question for smartphones: Why are some apps special to users? Using the framework, we conduct and analyze 60 interviews with people aged 21 to 41; with participants' consent, we made the anonymized transcripts publicly available. The analysis of the interviews shows that participants find apps special because they are convenient, support personal goals and social communication, help them remember, and serve emotional functions. Participants report that their identity is intertwined with certain apps, even if they are annoying or cause dependency. Importantly, we also find that participants actively regulate their use of apps through their organization and particular use strategies.</p>
<h3>Navigating User-System Gaps: Understanding User-Interactions in User-Centric Context-Aware Systems for Digital Well-being Intervention</h3>
<p>Authors: Uichin Lee, Inyeop Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147725">Link</a></p>
<p>Abstract: In this paper, we investigate the challenges users face with a user-centric context-aware intervention system. Users often face gaps when the system's responses do not align with their goals and intentions. We explore these gaps through a prototype system that enables users to specify context-action intervention rules as they desire. We conducted a lab study to understand how users perceive and cope with gaps while translating their intentions as rules, revealing that users experience context-mapping and context-recognition uncertainties (instant evaluation cycle). We also performed a field study to explore how users perceive gaps and make adaptations of rules when the operation of specified rules in real-world settings (delayed evaluation cycle). This research highlights the dynamic nature of user interaction with context-aware systems and suggests the potential of such systems in supporting digital well-being. It provides insights into user adaptation processes and offers guidance for designing user-centric context-aware applications.</p>
<h2>Education and AI A</h2>
<h3>From Primary Education to Premium Workforce: Drawing on K-12 Approaches for Developing AI Literacy</h3>
<p>Authors: Ole Sejer Iversen, Magnus Høholt Kaspersen, Christian Dindler, Karl-Emil Bilstrup, Peter Dalsgaard, Marianne Graves Petersen, Line Musaeus</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147388">Link</a></p>
<p>Abstract: Advances in artificial intelligence present a need for fostering AI literacy in workplaces. While there is a lack of research on how this can be achieved, there are documented successful approaches in child-computer interaction (CCI), albeit aimed at K-12 education. We present an in-vivo explorative case study of how CCI approaches can be adopted for adult professionals via a full-day workshop developed in collaboration with a trade union to upskill workers. Analyzing data from pre- and post-surveys, a follow-up survey, and materials produced by participants (n=53), we demonstrate how this increased participants’ knowledge of AI while their self-efficacy and empowerment did not improve. This is similar to findings from K-12 education, pointing to self-efficacy and empowerment as major challenges for AI literacy across sectors. We discuss the role of ambassadorships and professional organizations in addressing these issues, and indicate research directions for the CHI community.</p>
<h3>More than Model Documentation: Uncovering Teachers' Bespoke Information Needs for Informed Classroom Integration of ChatGPT</h3>
<p>Authors: Hariharan Subramonyam, Mei Tan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147621">Link</a></p>
<p>Abstract: ChatGPT has entered classrooms, circumventing typical training and vetting procedures. Unlike other educational technologies, it placed teachers in direct contact with the versatility of generative AI. Consequently, teachers are urgently tasked to assess its capabilities to inform their use of ChatGPT. However, it is unclear what support teachers have and need and whether existing documentation, such as model cards, provides adequate direction for educators in this new paradigm. By interviewing 22 middle- and high-school ELA and Social Studies teachers, we connect the discourse on AI transparency and documentation with educational technology integration, highlighting the information needs of teachers. Our findings reveal that teachers confront significant information gaps, lacking clarity on exploring ChatGPT's capabilities for bespoke learning tasks and ensuring its fit with the needs of diverse learners. As a solution, we propose a framework for interactive model documentation that empowers teachers to navigate the interplay between pedagogical and technical knowledge. </p>
<h3>The Promise and Peril of ChatGPT in Higher Education: Opportunities, Challenges, and Design Implications</h3>
<p>Authors: Daehwan Ahn, Hyanghee Park</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147256">Link</a></p>
<p>Abstract: A growing number of students in higher education are using ChatGPT for various educational purposes, ranging from seeking information to writing essays. Although many universities have officially banned the use of ChatGPT because of its potential harm and unintended consequences, it is still important to uncover how students leverage ChatGPT for learning, what challenges emerge, and how we can make better use of ChatGPT in higher education. Thus, we conducted focus group workshops and a series of participatory design sessions with thirty students who have actively interacted with ChatGPT for one semester in university and with other five stakeholders (e.g., professors, AI experts). Based on these, this paper identifies real opportunities and challenges of utilizing and designing ChatGPT for higher education.</p>
<h3>Teaching artificial intelligence in extracurricular contexts through narrative-based learnersourcing</h3>
<p>Authors: Bansharee Ireen, Sophia Moore, Elizabeth Murnane, Grigory Artazyan, Winston Iskandar, Dylan Moore</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147257">Link</a></p>
<p>Abstract: Collaborative technology provides powerful opportunities to engage young people in active learning experiences that are inclusive, immersive, and personally meaningful. In particular, interactive narratives have proven to be effective scaffolds for learning, and learnersourcing has emerged as a promising student-driven approach to enable personalized education and quality control at-scale. We introduce the first synthesis of these ideas in the context of teaching artificial intelligence (AI), which is now seen as a critical component of 21st-century education. Specifically, we explore the design of a narrative-based learnersourcing platform where engagement is centered around a learner-made choose-your-own-adventure story. In grounding our approach, we draw from pedagogical literature, digital storytelling, and recent work on learnersourcing. We report on our iterative, learner-centered design process as well as our study findings that demonstrate the platform’s positive effects on knowledge gains, interest in AI concepts, and the overall user experience of narrative-based learnersourcing technology.</p>
<h3>ml-machine.org: Infrastructuring a Research Product to Disseminate AI Literacy in Education</h3>
<p>Authors: Niels Olof Bouvin, Magnus Høholt Kaspersen, Karl-Emil Bilstrup, Marianne Graves Petersen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148135">Link</a></p>
<p>Abstract: ml-machine.org is a web- and micro:bit-based educational tool for building machine learning models designed to enable more widespread teaching of AI literacy in secondary education. It has been designed as a research product in collaboration with partners from the educational sector, including the Danish Broadcasting Corporation and the Micro:bit Educational Foundation. ml-machine.org currently has more than 5000 unique users and is used in schools and teacher training. It is publicly available and promoted on the broadcasting corporation's platforms. We describe the two-year process of developing and disseminating ml-machine.org. Based on interviews with partners and educators, we report on how ml-machine.org supports inquiry into the adoption and appropriation of such educational tools. We also provide insights on working with formal education infrastructures in order to scale and integrate a research product into teacher practices. Based on these experiences, we propose infrastructure as a novel quality of research products.</p>
<h2>Ethics of Digital Technologies A</h2>
<h3>BLIP: Facilitating the Exploration of Undesirable Consequences of Digital Technologies</h3>
<p>Authors: Katharina Reinecke, Rock Pang, Sebastin Santy, Rene Just</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146666">Link</a></p>
<p>Abstract: Digital technologies have positively transformed society, but they have also led to undesirable consequences not anticipated at the time of design or development. We posit that insights into past undesirable consequences can help researchers and practitioners gain awareness and anticipate potential adverse effects. To test this assumption, we introduce BLIP, a system that extracts real-world undesirable consequences of technology from online articles, summarizes and categorizes them, and presents them in an interactive, web-based interface. In two user studies with 15 researchers in various computer science disciplines, we found that BLIP substantially increased the number and diversity of undesirable consequences they could list in comparison to relying on prior knowledge or searching online. Moreover, BLIP helped them identify undesirable consequences relevant to their ongoing projects, made them aware of undesirable consequences they “had never considered,” and inspired them to reflect on their own experiences with technology.</p>
<h3>Perceptions of Fairness in Technology-Mediated Marketplaces</h3>
<p>Authors: Coye Cheshire, Andrew Chong, Ji Su Yoo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147651">Link</a></p>
<p>Abstract: Consumers increasingly interact with workers through technology-mediated marketplaces (TMMs)—environments where third-party companies manage interactions, control information, and constrain behavioral choices. We argue that opacity in how TMMs operate can make it difficult for consumers to judge what is fair when interacting with other economic actors. To better understand how consumers perceive and act on fairness in TMMs, we examine the practice of tipping—a consumer behavior in the United States that is strongly associated with assessments of fairness. Through interviews with consumers, we find three distinct ways that consumers discuss fairness in tipping in third-party food delivery: fairness as supporting a living wage, fairness as reciprocity, and fairness in distribution of payments. We discuss how TMMs codify economic interactions and change consumers’ social meaning of a tip, how consumers perceive an obligation to tip drivers differently in TMMs, and how TMMs alter information consumers use to determine accountability.</p>
<h3>STILE: Exploring and Debugging Social Biases in Pre-trained Text Representations</h3>
<p>Authors: Samia Kabir, Lixiang Li, Tianyi Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147326">Link</a></p>
<p>Abstract: The recent success of Natural Language Processing (NLP) relies heavily on pre-trained text representations such as word embeddings. However, pre-trained text representations may exhibit social biases and stereotypes, e.g., disproportionately associating gender with occupations. Though prior work presented various bias detection algorithms, they are limited to pre-defined biases and lack effective interaction support. In this work, we propose STILE, an interactive system that supports mixed-initiative bias discovery and debugging in pre-trained text representations. STILE provides users the flexibility to interactively define and customize biases to detect based on their interests. Furthermore, it provides a bird’s-eye view of detected biases in a Chord diagram and allows users to dive into the training data to investigate how a bias was developed. Our lab study and expert review confirm the usefulness and usability of STILE as an effective aid in identifying and understanding biases in pre-trained text representations.</p>
<h3>An Ontology of Dark Patterns Knowledge: Foundations, Definitions, and a Pathway for Shared Knowledge-Building</h3>
<p>Authors: Thomas Mildner, Nataliia Bielova, Colin Gray, Cristiana Teixeira Santos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147221">Link</a></p>
<p>Abstract: Deceptive and coercive design practices are increasingly used by companies to extract profit, harvest data, and limit consumer choice. Dark patterns represent the most common contemporary amalgamation of these problematic practices, connecting designers, technologists, scholars, regulators, and legal professionals in transdisciplinary dialogue. However, a lack of universally accepted definitions across the academic, legislative, practitioner, and regulatory space has likely limited the impact that scholarship on dark patterns might have in supporting sanctions and evolved design practices. In this paper, we seek to support the development of a shared language of dark patterns, harmonizing ten existing regulatory and academic taxonomies of dark patterns and proposing a three-level ontology with standardized definitions for 64 synthesized dark pattern types across low-, meso-, and high-level patterns. We illustrate how this ontology can support translational research and regulatory action, including transdisciplinary pathways to extend our initial types through new empirical work across application and technology domains.</p>
<h3>Beyond Dark Patterns: A Concept-Based Framework for Ethical Software Design</h3>
<p>Authors: Jonathan Zong, Daniel Jackson, Evan Caragay, Katherine Xiong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147293">Link</a></p>
<p>Abstract: Current dark pattern research tells designers what not to do, but how do they know what to do? In contrast to prior approaches that focus on patterns to avoid and their underlying principles, we present a framework grounded in positive expected behavior against which deviations can be judged. To articulate this expected behavior, we use concepts—abstract units of functionality that compose applications. We define a design as dark when its concepts violate users' expectations, and benefit the application provider at the user's expense. Though user expectations can differ, users tend to develop common expectations as they encounter the same concepts across multiple applications, which we can record in a concept catalog as standard concepts. We evaluate our framework and concept catalog through three studies, illustrating their ability to describe existing dark patterns, evaluate nuanced designs, and document common application functionality. </p>
<h2>Evaluating AI Technologies A</h2>
<h3>Are We Asking the Right Questions?: Designing for Community Stakeholders’ Interactions with AI in Policing</h3>
<p>Authors: Devansh Saxena, Joseph Chudzik, Md Romael Haque, Katy Weathington, Shion Guha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147789">Link</a></p>
<p>Abstract: Research into recidivism risk prediction in the criminal justice system has garnered significant attention from HCI, critical algorithm studies, and the emerging field of human-AI decision-making. This study focuses on algorithmic crime mapping, a prevalent yet underexplored form of algorithmic decision support (ADS) in this context. We conducted experiments and follow-up interviews with 60 participants, including community members, technical experts, and law enforcement agents (LEAs), to explore how lived experiences, technical knowledge, and domain expertise shape interactions with the ADS, impacting human-AI decision-making. Surprisingly, we found that domain experts (LEAs) often exhibited anchoring bias, readily accepting and engaging with the first crime map presented to them. Conversely, community members and technical experts were more inclined to engage with the tool, adjust controls, and generate different maps. Our findings highlight that all three stakeholders were able to provide critical feedback regarding AI design and use - community members questioned the core motivation of the tool, technical experts drew attention to the elastic nature of data science practice, and LEAs suggested redesign pathways such that the tool could complement their domain expertise.</p>
<h3>Human-LLM Collaborative Annotation Through Effective Verification of LLM Labels</h3>
<p>Authors: Sajjadur Rahman, Hannah Kim, Kushan Mitra, Xinru Wang, Zhengjie Miao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147019">Link</a></p>
<p>Abstract: Large language models (LLMs) have shown remarkable performance across various natural language processing (NLP) tasks, indicating their significant potential as data annotators. Although LLM-generated annotations are more cost-effective and efficient to obtain, they are often erroneous for complex or domain-specific tasks and may introduce bias when compared to human annotations. Therefore, instead of completely replacing human annotators with LLMs, we need to leverage the strengths of both LLMs and humans to ensure the accuracy and reliability of annotations. This paper presents a multi-step human-LLM collaborative approach where (1) LLMs generate labels and provide explanations, (2) a verifier assesses the quality of LLM-generated labels, and (3) human annotators re-annotate a subset of labels with lower verification scores. To facilitate human-LLM collaboration, we make use of LLM's ability to rationalize its decisions. LLM-generated explanations can provide additional information to the verifier model as well as help humans better understand LLM labels. We demonstrate that our verifier is able to identify potentially incorrect LLM labels for human re-annotation. Furthermore, we investigate the impact of presenting LLM labels and explanations on human re-annotation through crowdsourced studies.</p>
<h3>"AI enhances our performance, I have no doubt this one will do the same": The Placebo effect is robust to negative descriptions of AI</h3>
<p>Authors: Agnes Kloft, Steeven Villa, Robin Welsch, Thomas Kosch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148294">Link</a></p>
<p>Abstract: Heightened AI expectations facilitate performance in human-AI interactions through placebo effects. While lowering expectations to control for placebo effects is advisable, overly negative expectations could induce nocebo effects. In a letter discrimination task, we informed participants that an AI would either increase or decrease their performance by adapting the interface, when in reality, no AI was present in any condition. A Bayesian analysis showed that participants had high expectations and performed descriptively better irrespective of the AI description when a sham-AI was present. Using cognitive modeling, we could trace this advantage back to participants gathering more information. A replication study verified that negative AI descriptions do not alter expectations, suggesting that performance expectations with AI are biased and robust to negative verbal descriptions. We discuss the impact of user expectations on AI interactions and evaluation.</p>
<h3>An Evaluation of Situational Autonomy for Human-AI Collaboration in a Shared Workspace Setting</h3>
<p>Authors: Frank Jäkel, Dirk Balfanz, Dorothea Koert, Janik Schöpper, Vildan Salikutluk, Katrin Scheuermann, Eric Frodl, Franziska Herbert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147227">Link</a></p>
<p>Abstract: Designing interactions for human-AI teams (HATs) can be challenging due to an AI agent's potential autonomy. Previous work suggests that higher autonomy does not always improve team performance, and situation-dependent autonomy adaptation might be beneficial. However, there is a lack of systematic empirical evaluations of such autonomy adaptation in human-AI interaction. Therefore, we propose a cooperative task in a simulated shared workspace to investigate effects of fixed levels of AI autonomy and situation-dependent autonomy adaptation on team performance and user satisfaction. We derive adaptation rules for AI autonomy from previous work and a pilot study. We implement these rule for our main experiment and find that team performance was best when humans collaborated with an agent adjusting its autonomy based on the situation. Additionally, users rated this agent highest in terms of perceived intelligence. From these results, we discuss the influence of varying autonomy degrees on HATs in shared workspaces.</p>
<h3>Evaluating the Utility of Conformal Prediction Sets for AI-Advised Image Labeling</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Negar Kamali, Jessica Hullman, Angelos Chatzimparmpas, Dongping Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146876">Link</a></p>
<p>Abstract: As deep neural networks are more commonly deployed in high-stakes domains, their black-box nature makes uncertainty quantification challenging. We investigate the effects of presenting conformal prediction sets---a distribution-free class of methods for generating prediction sets with specified coverage---to express uncertainty in AI-advised decision-making. Through a large online experiment, we compare the utility of conformal prediction sets to displays of Top-$1$ and Top-$k$ predictions for AI-advised image labeling. In a pre-registered analysis, we find that the utility of prediction sets for accuracy varies with the difficulty of the task: while they result in accuracy on par with or less than Top-$1$ and Top-$k$ displays for easy images, prediction sets excel at assisting humans in labeling out-of-distribution (OOD) images, especially when the set size is small. Our results empirically pinpoint practical challenges of conformal prediction sets and provide implications on how to incorporate them for real-world decision-making.</p>
<h2>Eye and Face</h2>
<h3>EyeEcho: Continuous and Low-power Facial Expression Tracking on Glasses</h3>
<p>Authors: Francois Guimbretiere, Ke Li, Boao Chen, Mose Sakashita, Cheng Zhang, Ruidong Zhang, Siyuan Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146746">Link</a></p>
<p>Abstract: In this paper, we introduce EyeEcho, a minimally-obtrusive acoustic sensing system designed to enable glasses to continuously monitor facial expressions. It utilizes two pairs of speakers and microphones mounted on glasses, to emit encoded inaudible acoustic signals directed towards the face, capturing subtle skin deformations associated with facial expressions. The reflected signals are processed through a customized machine-learning pipeline to estimate full facial movements. EyeEcho samples at 83.3 Hz with a relatively low power consumption of 167 mW. Our user study involving 12 participants demonstrates that, with just four minutes of training data, EyeEcho achieves highly accurate tracking performance across different real-world scenarios, including sitting, walking, and after remounting the devices. Additionally, a semi-in-the-wild study involving 10 participants further validates EyeEcho's performance in naturalistic scenarios while participants engage in various daily activities. Finally, we showcase EyeEcho's potential to be deployed on a commercial-off-the-shelf (COTS) smartphone, offering real-time facial expression tracking.</p>
<h3>Uncovering and Addressing Blink-Related Challenges in Using Eye Tracking for Interactive Systems</h3>
<p>Authors: Henrike Weingärtner, Sven Mayer, Jesse Grootjen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147069">Link</a></p>
<p>Abstract: Currently, interactive systems use physiological sensing to enable advanced functionalities. While eye tracking is a promising means to understand the user, eye tracking data inherently suffers from missing data due to blinks, which may result in reduced system performance. We conducted a literature review to understand how researchers deal with this issue. We uncovered that researchers often implemented their use-case-specific pipeline to overcome the issue, ranging from ignoring missing data to artificial interpolation. With these first insights, we run a large-scale analysis on 11 publicly available datasets to understand the impact of the various approaches on data quality and accuracy. By this, we highlight the pitfalls in data processing and which methods work best. Based on our results, we provide guidelines for handling eye tracking data for interactive systems. Further, we propose a standard data processing pipeline that allows researchers and practitioners to pre-process and standardize their data efficiently.</p>
<h3>MELDER: The Design and Evaluation of a Real-time Silent Speech Recognizer for Mobile Devices</h3>
<p>Authors: Laxmi Pandey, Ahmed Arif</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146951">Link</a></p>
<p>Abstract: Silent speech is unaffected by ambient noise, increases accessibility, and enhances privacy and security. Yet current silent speech recognizers operate in a phrase-in/phrase-out manner, thus are slow, error prone, and impractical for mobile devices. We present MELDER, a Mobile Lip Reader that operates in real-time by splitting the input video into smaller temporal segments to process them individually. An experiment revealed that this substantially improves computation time, making it suitable for mobile devices. We further optimize the model for everyday use by exploiting the knowledge from a high-resource vocabulary using a transfer learning model. We then compare MELDER in both stationary and mobile settings with two state-of-the-art silent speech recognizers, where MELDER demonstrated superior overall performance. Finally, we compare two visual feedback methods of MELDER with the visual feedback method of Google Assistant. The outcomes shed light on how these proposed feedback methods influence users' perceptions of the model's performance.</p>
<h3>ReHEarSSE: Recognizing Hidden-in-the-Ear Silently Spelled Expressions</h3>
<p>Authors: Yuntao Wang, Ken Christofferson, Yifei Chen, Alex Mariakakis, Kaoru Sezaki, Xuefu Dong, Yuuki Nishiyama</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147342">Link</a></p>
<p>Abstract: Silent speech interaction (SSI) allows users to discreetly input text without using their hands. Existing wearable SSI systems typically require custom devices and are limited to a small lexicon, limiting their utility to a small set of command words. This work proposes ReHearSSE, an earbud-based ultrasonic SSI system capable of generalizing to words that do not appear in its training dataset, providing support for nearly an entire dictionary's worth of words. As a user silently spells words, ReHearSSE uses autoregressive features to identify subtle changes in ear canal shape. ReHearSSE infers words using a deep learning model trained to optimize connectionist temporal classification (CTC) loss with an intermediate embedding that accounts for different letters and transitions between them. We find that ReHearSSE recognizes 100 unseen words with an accuracy of 89.3%.</p>
<h3>Watch Your Mouth: Silent Speech Recognition with Depth Sensing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yang Zhang, Jun Rekimoto, Zixiong Su, Xue Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147350">Link</a></p>
<p>Abstract: Silent speech recognition is a promising technology that decodes human speech without requiring audio signals, enabling private human-computer interactions. In this paper, we propose Watch Your Mouth, a novel method that leverages depth sensing to enable accurate silent speech recognition. By leveraging depth information, our method provides unique resilience against environmental factors such as variations in lighting and device orientations, while further addressing privacy concerns by eliminating the need for sensitive RGB data. We started by building a deep-learning model that locates lips using depth data. We then designed a deep learning pipeline to efficiently learn from point clouds and translate lip movements into commands and sentences. We evaluated our technique and found it effective across diverse sensor locations: On-Head, On-Wrist, and In-Environment. Watch Your Mouth outperformed the state-of-the-art RGB-based method, demonstrating its potential as an accurate and reliable input technique.</p>
<h2>Fabrication: 3D Printing A</h2>
<h3>SolderlessPCB: Reusing Electronic Components in PCB Prototyping through Detachable 3D Printed Housings</h3>
<p>Authors: Huaishu Peng, Jiasheng Li, Zining Zhang, Zeyu Yan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146974">Link</a></p>
<p>Abstract: The iterative prototyping process for printed circuit boards (PCBs) frequently employs surface-mounted device (SMD) components, which are often discarded rather than reused due to the challenges associated with desoldering, leading to unnecessary electronic waste. This paper introduces SolderlessPCB, a collection of techniques for solder-free PCB prototyping, specifically designed to promote the recycling and reuse of electronic components. Central to this approach are custom 3D-printable housings that allow SMD components to be mounted onto PCBs without soldering. We detail the design of SolderlessPCB and the experiments conducted to evaluate its design parameters, electrical performance, and durability. To illustrate the potential for reusing SMD components with SolderlessPCB, we discuss two scenarios: the reuse of components from earlier design iterations and from obsolete prototypes. We also provide examples demonstrating that SolderlessPCB can handle high-current applications and is suitable for high-speed data transmission. The paper concludes by discussing the limitations of our approach and suggesting future directions to overcome these challenges.</p>
<h3>The Effect of Orientation on the Readability and Comfort of 3D-Printed Braille</h3>
<p>Authors: Tarik Crnovrsanin, Laura South, Eduardo Puerta, Cody Dunne</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147955">Link</a></p>
<p>Abstract: Fused Deposition Modeling (FDM) is a low-cost method of 3D printing that involves stacking horizontal layers of plastic.</p>
<p>FDM is used to produce tactile graphics and interfaces for people with visual impairments. </p>
<p>Unfortunately, the print orientation can alter the structure and quality of braille and text. </p>
<p>The difference between printing braille vertically and horizontally has been documented.</p>
<p>However, we found no comprehensive study of these angles or the angles in between, nor any study providing a quantitative and qualitative user evaluation.</p>
<p>We conducted two mixed-methods studies to evaluate the performance of braille printed at different angles.</p>
<p>We measured reading time and subjective preference and performed a thematic analysis of participants' responses.</p>
<p>Our participants were faster using and preferred 75\degree\ and vertical braille over horizontal braille.</p>
<p>These results provide makers with guidelines for creating models with readable 3D-printed braille.</p>
<h3>SketchPath: Using Digital Drawing to Integrate the Gestural Qualities of Craft in CAM-Based Clay 3D Printing</h3>
<p>BEST_PAPER</p>
<p>Authors: Devon Frost, Eun-Ha Paek, Jennifer Jacobs, Raina Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148134">Link</a></p>
<p>Abstract: This paper presents the design and outcomes of SketchPath, a system that uses hand-drawn toolpaths to design for clay 3D printing. Drawing, as a direct manipulation technique, allows artists to design with the expressiveness of CAM-based tools without needing to work with a numerical system or constrained system. SketchPath works to provide artists with direct control over the outcomes of their form by not abstracting away machine operations or constraining the kinds of artifacts that can be produced. Artifacts produced with SketchPath emerge at a unique intersection of manual qualities and machine precision, creating works that blend handmade and machine aesthetics. In interactions with our system, ceramicists without a background in CAD/CAM were able to produce more complex forms with limited training, suggesting the future of CAM-based fabrication design can take on a wider range of modalities.  </p>
<h3>Throwing Out Conventions: Reimagining Craft-Centered CNC Tool Design through the Digital Pottery Wheel</h3>
<p>BEST_PAPER</p>
<p>Authors: Ilan Moyer, Devon Frost, Sam Bourgault, Jennifer Jacobs</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147769">Link</a></p>
<p>Abstract: Skilled potters use manual tools with direct material engagement. In contrast, the design of clay 3D printers and workflows reinforces industrial CNC manufacturing conventions. To understand how digital fabrication can serve skilled craft practitioners, we ask: how might clay 3D printing function if it had evolved from traditional pottery tools? To examine this question, we created the Digital Pottery Wheel (DPW), a throwing wheel with 3D printing capabilities. The DPW consists of a polar mechanical architecture that looks and functions like a pottery wheel while supporting 3D printing and a real-time modular control system that blends automated and manual control. We worked with ceramicists to develop interactions that include printing onto thrown forms, throwing to manipulate printed forms, and integrating manual control, recording, and playback to re-execute manually produced forms. We demonstrate how using a physical metaphor to guide digital fabrication machine design results in new products, workflows, and perceptions.</p>
<h3>3D Printing Locally Activated Visual-Displays Embedded in 3D Objects via Electrically Conductive and Thermochromic Materials</h3>
<p>Authors: Ryo Suzuki, Andrea Bianchi, Kongpyung (Justin) Moon, Zofia Marciniak</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147413">Link</a></p>
<p>Abstract: 3D printed displays promise to create unique visual interfaces for physical objects. However, current methods for creating 3D printed displays either require specialized post-fabrication processes (e.g., electroluminescence spray and silicon casting) or function as passive elements that simply react to environmental factors (e.g., body and air temperature). These passive displays offer limited control over when, where, and how the colors change. In this paper, we introduce ThermoPixels, a method for designing and 3D printing actively controlled and visually rich thermochromic displays that can be embedded in arbitrary geometries. We investigate the color-changing and thermal properties of thermochromic and conductive filaments. Based on these insights, we designed ThermoPixels and an accompanying software tool that allows embedding ThermoPixels in arbitrary 3D geometries, creating displays of various shapes and sizes (flat, curved, or matrix displays) or displays that embed textures, multiple colors, or that are flexible. </p>
<h2>Finance and Money</h2>
<h3>Shortchanged: Uncovering and Analyzing Intimate Partner Financial Abuse in Consumer Complaints</h3>
<p>Authors: Vineeth Ravi, Rosanna Bellini, Kevin Lee, Jessica Staddon, Arkaprabha Bhattacharya</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148177">Link</a></p>
<p>Abstract: Digital financial services can introduce new digital-safety risks for users, particularly survivors of intimate partner financial abuse (IPFA). To offer improved support for such users, a comprehensive understanding of their support needs and the barriers they face to redress by financial institutions is essential. Drawing from a dataset of 2.7 million customer complaints, we implement a bespoke workflow that utilizes language-modeling techniques and expert human review to identify complaints describing IPFA. Our mixed-method analysis provides insight into the most common digital financial products involved in these attacks, and the barriers consumers report encountering when doing so. Our contributions are twofold; we offer the first human-labeled dataset for this overlooked harm and provide practical implications for technical practice, research, and design for better supporting and protecting survivors of IPFA.</p>
<h3>Stranger Danger? Investor Behavior and Incentives on Cryptocurrency Copy-Trading Platforms</h3>
<p>Authors: Daisuke Kawai, Kyle Soska, Nicolas Christin, Bryan Routledge, Ariel Zetlin-Jones</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148232">Link</a></p>
<p>Abstract: Several large financial trading platforms have recently begun implementing ``copy trading,'' a process by which a leader allows copiers to automatically mirror their trades in exchange for a share of the profits realized. While it has been shown in many contexts that platform design considerably influences user choices---users tend to disproportionately trust rankings presented to them---we would expect that here, copiers exercise due diligence given the money at stake, typically USD 500--2\,000 or more. We perform a quantitative analysis of two major cryptocurrency copy-trading platforms, with different default leader ranking algorithms. One of these platforms additionally changed the information displayed during our study. In all cases, we show that the platform UI significantly influences copiers' decisions. Besides being sub-optimal, this influence is problematic as rankings are often easily gameable by unscrupulous leaders who prey on novice copiers, and they create perverse incentives for all platform users.</p>
<h3>Supportive Fintech for Individuals with Bipolar Disorder: Financial Data Sharing Preferences for Longitudinal Care Management</h3>
<p>Authors: Mark Matthews, Johnna Blair, Erika F. H. Saunders, Jeff Brozena, Saeed Abdullah, Dahlia Mukherjee, Thomas Richardson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147609">Link</a></p>
<p>Abstract: Financial stability is a key challenge for individuals living with bipolar disorder (BD). Symptomatic periods in BD are associated with poor financial decision-making, contributing to a negative cycle of worsening symptoms and an increased risk of bankruptcy. There has been an increased focus on designing supportive financial technologies (fintech) to address varying and intermittent needs across different stages of BD. However, little is known about this population’s expectations and privacy preferences related to financial data sharing for longitudinal care management. To address this knowledge gap, we have deployed a factorial vignette survey using the Contextual Integrity framework. Our data from individuals with BD (N=480) shows that they are open to sharing financial data for long term care management. We have also identified significant differences in sharing preferences across age, gender, and diagnostic subtype. We discuss the implications of these findings in designing equitable fintech to support this marginalized community.</p>
<h3>Trading as Gambling: Social Investing and Financial Risks on the r/WallStreetBets subreddit</h3>
<p>Authors: Sam Moradzadeh, Xinning Gui, Yubo Kou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147259">Link</a></p>
<p>Abstract: Financial trading has become commonplace, involving the purchase and sale of securities such as stocks and bonds. While HCI research has investigated people’s financial literacy and decision-making and how to design for it, little is known as to how people form financial conversations on social media. To answer this question, we used a grounded theory approach to analyzing financial conversations in the YOLO (‘you only live once’) posts on the r/WallStreetBets subreddit (WSB), one of today’s largest financial online communities. We describe how WSB's discursive culture portrays its gambling-like, high-risk trading by likening trading to gambling, celebrating it, and normalizing financial risk-taking. We discuss the rise of social investing, including how individual investors’ affective relationships encourage their outsized risk-taking, as well as reflect on its looming financial risks, especially to already marginalized groups. Lastly, we propose implications for design and policymaking.</p>
<h3>"Don't put all your eggs in one basket": How Cryptocurrency Users Choose and Secure Their Wallets</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Tanusree Sharma, Sauvik Das, Yang Wang, Yaman Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148179">Link</a></p>
<p>Abstract: Cryptocurrency wallets come in various forms, each with unique usability and security features. Through interviews with 24 users, we explore reasons for selecting wallets in different contexts. Participants opt for smart contract wallets to simplify key management, leveraging social interactions. However, they prefer personal devices over individuals as guardians to avoid social cybersecurity concerns in managing guardian relationships. When engaging in high-stakes or complex transactions, they often choose browser-based wallets, leveraging third-party security extensions. For simpler transactions, they prefer the convenience of mobile wallets. Many participants avoid hardware wallets due to usability issues and security concerns with respect to key recovery service provided by manufacturer and phishing attacks. Social networks play a dual role: participants seek security advice from friends, but also express security concerns in soliciting this help. We offer novel insights into how and why users adopt specific wallets. We also discuss design recommendations for future wallet technologies based on our findings.</p>
<h2>Hand Interaction</h2>
<h3>EITPose: Wearable and Practical Electrical Impedance Tomography for Continuous Hand Pose Estimation</h3>
<p>Authors: Alexander Kyu, Mayank Goel, Hongyu Mao, Karan Ahuja, Junyi Zhu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147181">Link</a></p>
<p>Abstract: Real-time hand pose estimation has a wide range of applications spanning gaming, robotics, and human-computer interaction. In this paper, we introduce EITPose, a wrist-worn, continuous 3D hand pose estimation approach that uses eight electrodes positioned around the forearm to model its interior impedance distribution during pose articulation. Unlike wrist-worn systems relying on cameras, EITPose has a slim profile (12 mm thick sensing strap) and is power-efficient (consuming only 0.3 W of power), making it an excellent candidate for integration into consumer electronic devices. In a user study involving 22 participants, EITPose achieves with a within-session mean per joint positional error of 11.06 mm. Its camera-free design prioritizes user privacy, yet it maintains cross-session and cross-user accuracy levels comparable to camera-based wrist-worn systems, thus making EITPose a promising technology for practical hand pose estimation.</p>
<h3>EchoWrist: Continuous Hand Pose Tracking and Hand-Object Interaction Recognition Using Low-Power Active Acoustic Sensing On a Wristband</h3>
<p>Authors: Chi-Jung Lee, Sicheng Yin, Francois Guimbretiere, Ke Li, Tianhong Yu, Oliver Lopez, Vipin Gunda, Devansh Agarwal, Mose Sakashita, Cheng Zhang, James Kim, Ruidong Zhang, Boao Dong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147046">Link</a></p>
<p>Abstract: Our hands serve as a fundamental means of interaction with the world around us. Therefore, understanding hand poses and interaction contexts is critical for human-computer interaction (HCI). We present EchoWrist, a low-power wristband that continuously estimates 3D hand poses and recognizes hand-object interactions using active acoustic sensing. EchoWrist is equipped with two speakers emitting inaudible sound waves toward the hand. These sound waves interact with the hand and its surroundings through reflections and diffractions, carrying rich information about the hand's shape and the objects it interacts with. The information captured by the two microphones goes through a deep learning inference system that recovers hand poses and identifies various everyday hand activities. Results from the two 12-participant user studies show that EchoWrist is effective and efficient at tracking 3D hand poses and recognizing hand-object interactions. Operating at 57.9 mW, EchoWrist can continuously reconstruct 20 3D hand joints with MJEDE of 4.81 mm and recognize 12 naturalistic hand-object interactions with 97.6% accuracy.</p>
<h3>Single-handed Folding Interactions with a Modified Clamshell Flip Phone</h3>
<p>Authors: Antony Albert Raj Irudayaraj, Yen-Ting Yeh, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147358">Link</a></p>
<p>Abstract: We explore and evaluate single-handed folding interactions suitable for “modified clamshell flip phones” with a full screen touch display that folds in half along the short dimension. Three categories of interactions are identified: only-fold, touch-enhanced fold, and fold-enhanced touch; in which gestures are created using fold direction, fold magnitude, and touch position. A prototype evaluation device is built to resemble clamshell flip phones, but with a modified hinge and spring system to enable folding in both directions. A study investigates performance and preference for 30 fold gestures to discover which are most promising. To demonstrate how folding interactions could be incorporated into flip phone interfaces, applications such as map browsing, text editing, and menu shortcuts are described.</p>
<h3>Emotion Embodied: Unveiling the Expressive Potential of Single-Hand Gestures</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Kening Zhu, Shannon Santosa, Junnan Yu, Yuhan Luo, Yichen Wan, Minhui Liang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146626">Link</a></p>
<p>Abstract: Hand gestures are widely used in daily life for expressing emotions, yet gesture input is not part of existing emotion tracking systems. To seek a practical and effortless way of using gestures to inform emotions, we explore the relationships between gestural features and commonly experienced emotions by focusing on single-hand gestures that are easy to perform and capture. First, we collected 756 gestures (in photo and video pairs) from 63 participants who expressed different emotions in a survey, and then interviewed 11 of them to understand their gesture-forming rationales. We found that the valence and arousal level of the expressed emotions significantly correlated with participants' finger-pointing direction and their gesture strength, and synthesized four channels through which participants externalized their expressions with gestures. Reflecting on the findings, we discuss how emotions can be characterized and contextualized with gestural cues and implications for designing multimodal emotion tracking systems and beyond.</p>
<h3>Hand Gesture Recognition for Blind Users by Tracking 3D Gesture Trajectory</h3>
<p>Authors: Aruna Balasubramanian, IV Ramakrishnan, Xiaojun Bi, Prerna Khanna, Shubham Jain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148204">Link</a></p>
<p>Abstract: Hand gestures provide an alternate interaction modality for blind users and can be supported using commodity smartwatches without requiring specialized sensors. The enabling technology is an accurate gesture recognition algorithm, but almost all algorithms are designed for sighted users. Our study shows that blind user gestures are considerably different from sighted users, rendering current recognition algorithms unsuitable. Blind user gestures have high inter-user variance, making learning gesture patterns difficult without large-scale training data. Instead, we design a gesture recognition algorithm that works on a 3D representation of the gesture trajectory, capturing motion in free space. Our insight is to extract a micro-movement in the gesture that is user-invariant and use this micro-movement for gesture classification. To this end, we develop an ensemble classifier that combines image classification with geometric properties of the gesture. Our evaluation demonstrates a 92% classification accuracy, surpassing the next best state-of-the-art which has an accuracy of 82%. </p>
<h2>Health and AI A</h2>
<h3>``It Is a Moving Process'': Understanding the Evolution of Explainability Needs of Clinicians in Pulmonary Medicine</h3>
<p>Authors: Agathe Balayn, Jiwon Jung, Rembrandt Oltmans, Jie Yang, Lorenzo Corti, Marlies Wijsenbeek</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147566">Link</a></p>
<p>Abstract: Clinicians increasingly pay attention to Artificial Intelligence (AI) to improve the quality and timeliness of their services. There are converging opinions on the need for Explainable AI (XAI) in healthcare. However, prior work considers explanations as stationary entities with no account for the temporal dynamics of patient care. In this work, we involve 16 Idiopathic Pulmonary Fibrosis (IPF) clinicians from a European university medical centre and investigate their evolving uses and purposes for explainability throughout patient care. By applying a patient journey map for IPF, we elucidate clinicians' informational needs, how human agency and patient-specific conditions can influence the interaction with XAI systems, and the content, delivery, and relevance of explanations over time. We discuss implications for integrating XAI in clinical contexts and more broadly how explainability is defined and evaluated. Furthermore, we reflect on the role of medical education in addressing epistemic challenges related to AI literacy.</p>
<h3>Understanding the Impact of Long-Term Memory on Self-Disclosure with Large Language Model-Driven Chatbots for Public Health Intervention</h3>
<p>Authors: Yuin Jeong, Eunkyung Jo, SoHyun Park, Young-Ho Kim, Daniel Epstein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148244">Link</a></p>
<p>Abstract: Recent large language models (LLMs) offer the potential to support public health monitoring by facilitating health disclosure through open-ended conversations but rarely preserve the knowledge gained about individuals across repeated interactions. Augmenting LLMs with long-term memory (LTM) presents an opportunity to improve engagement and self-disclosure, but we lack an understanding of how LTM impacts people's interaction with LLM-driven chatbots in public health interventions. We examine the case of CareCall—an LLM-driven voice chatbot with LTM—through the analysis of 1,252 call logs and interviews with nine users. We found that LTM enhanced health disclosure and fostered positive perceptions of the chatbot by offering familiarity. However, we also observed challenges in promoting self-disclosure through LTM, particularly around addressing chronic health conditions and privacy concerns. We discuss considerations for LTM integration in LLM-driven chatbots for public health monitoring, including carefully deciding what topics need to be remembered in light of public health goals.  </p>
<h3>Advancing Patient-Centered Shared Decision-Making with AI Systems for Older Adult Cancer Patients</h3>
<p>Authors: Robert Riter, Yuexing Hao, Zeyu Liu, Saleh Kalantari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148222">Link</a></p>
<p>Abstract: Shared decision making (SDM) plays a vital role in clinical practice guidelines, fostering enduring therapeutic communication and patient-clinician relationships. Previous research indicates that active patient participation in decision-making improves satisfaction and treatment outcomes. However, medical decision-making can be intricate and multifaceted. To help make SDM more accessible, we designed a patient-centered Artificial Intelligence (AI) SDM system for older adult cancer patients who lack high health literacy to become more involved in the clinical decision-making process and to improve comprehension toward treatment outcomes. We conducted a pilot feasibility study through 12 preliminary interviews followed by 25 usability testing interviews after the system development, with older adult cancer survivors and clinicians. Results indicated promise in the AI system's ability to enhance SDM, providing personalized healthcare experiences and education for cancer patients. Clinician responses also provided useful suggestions for SDM’s new design and research opportunities in mitigating medical errors and improving clinical efficiency.</p>
<h3>Beyond the Waiting Room: Patient's Perspectives on the Conversational Nuances of Pre-Consultation Chatbots</h3>
<p>Authors: Khai Truong, Brenna Li, Noah Crampton, Alex Mariakakis, Ofek Gross, Saba Tauseef, Mamta Kapoor, Mohit Jain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147742">Link</a></p>
<p>Abstract: Pre-consultation serves as a critical information exchange between healthcare providers and patients, streamlining visits and supporting patient-centered care. Human-led pre-consultations offer many benefits, yet they require significant time and energy from clinical staff. In this work, we identify design goals for pre-consultation chatbots given their potential to carry out human-like conversations and autonomously adapt their line of questioning. We conducted a study with 33 walk-in clinic patients to elicit design considerations for pre-consultation chatbots. Participants were exposed to one of two study conditions: an LLM-powered AI agent and a Wizard-of-Oz agent simulated by medical professionals. Our study found that both conditions were equally well-received and demonstrated comparable conversational capabilities. However, the extent of the follow-up questions and the amount of empathy impacted the chatbot's perceived thoroughness and sincerity. Patients also highlighted the importance of setting expectations for the chatbot before and after the pre-consultation experience.</p>
<h3>How Much Decision Power Should (A)I Have?: Investigating Patients’ Preferences Towards AI Autonomy in Healthcare Decision Making</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Niko Vegt, Marina Bos-de Vos, Valentijn Visch, Dajung Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146903">Link</a></p>
<p>Abstract: Despite the growing potential of artificial intelligence (AI) in improving clinical decision making, patients' perspectives on the use of AI for their care decision making are underexplored. In this paper, we investigate patients’ preferences towards the autonomy of AI in assisting healthcare decision making. We conducted interviews and an online survey using an interactive narrative and speculative AI prototypes to elicit participants’ preferred choices of using AI in a pregnancy care context. The analysis of the interviews and in-story responses reveals that patients’ preferences for AI autonomy vary per person and context, and may change over time. This finding suggests the need for involving patients in defining and reassessing the appropriate level of AI assistance for healthcare decision making. Departing from these varied preferences for AI autonomy, we discuss implications for incorporating patient-centeredness in designing AI-powered healthcare decision making.</p>
<h2>Health and AI B</h2>
<h3>The Illusion of Empathy? Notes on Displays of Emotion in Human-Computer Interaction</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Malte Jung, Andrea Cuadra, James Landay, Nicola Dell, Deborah Estrin, Lynn Stein, Maria Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147950">Link</a></p>
<p>Abstract: From ELIZA to Alexa, Conversational Agents (CAs) have been deliberately designed to elicit or project empathy. Although empathy can help technology better serve human needs, it can also be deceptive and potentially exploitative. In this work, we characterize empathy in interactions with CAs, highlighting the importance of distinguishing evocations of empathy between two humans from ones between a human and a CA. To this end, we systematically prompt CAs backed by large language models (LLMs) to display empathy while conversing with, or about, 65 distinct human identities, and also compare how different LLMs display or model empathy. We find that CAs make value judgments about certain identities, and can be encouraging of identities related to harmful ideologies (e.g., Nazism and xenophobia). Moreover, a computational approach to understanding empathy reveals that despite their ability to display empathy, CAs do poorly when interpreting and exploring a user's experience, contrasting with their human counterparts.</p>
<h3>Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis</h3>
<p>Authors: Bingsheng Yao, Jeffrey Caterino, Shao Zhang, Jianing Yu, Lace Padilla, Ping Zhang, Yuxuan Lu, Dakuo Wang, Changchang Yin, Xuhai "Orson" Xu, Melanie Tory</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147992">Link</a></p>
<p>Abstract: Today's AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that \system enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.</p>
<h3>Leveraging Prompt-Based Large Language Models: Predicting Pandemic Health Decisions and Outcomes Through Social Media Language</h3>
<p>Authors: Eugenia Rho, Valerie Reyna, Uma Sushmitha Gunturi, Xiaohan Ding, Buse Carik</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147157">Link</a></p>
<p>Abstract: We introduce a multi-step reasoning framework using prompt-based LLMs to examine the relationship between social media language patterns and trends in national health outcomes. Grounded in fuzzy-trace theory, which emphasizes the importance of “gists” of causal coherence in effective health communication, we introduce Role-Based Incremental Coaching (RBIC), a prompt-based LLM framework, to identify gists at-scale. Using RBIC, we systematically extract gists from subreddit discussions opposing COVID-19 health measures (Study 1). We then track how these gists evolve across key events (Study 2) and assess their influence on online engagement (Study 3). Finally, we investigate how the volume of gists is associated with national health trends like vaccine uptake and hospitalizations (Study 4). Our work is the first to empirically link social media linguistic patterns to real-world public health trends, highlighting the potential of prompt-based LLMs in identifying critical online discussion patterns that can form the basis of public health communication strategies.</p>
<h3>Multimodal Healthcare AI: Identifying and Designing Clinically Relevant Vision-Language Applications for Radiology</h3>
<p>Authors: Shruthi Bannur, Daniel Coelho de Castro, Fernando Pérez-García, Stephen Harris, Matthew Lungren, Hannah Richardson, Stephanie Hyland, Kenza Bouzid, Anja Thieme, Joseph Jacob, Aditya Nori, Mercy Ranjit, Maria Teodora Wetscherek, Pratik Ghosh, Junaid Bajwa, Javier Alvarez-Valle, Ozan Oktay, Anton Schwaighofer, Nur Yildirim, Harshita Sharma, Mark Pinnock</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146624">Link</a></p>
<p>Abstract: Recent advances in AI combine large language models (LLMs) with vision encoders that bring forward unprecedented technical capabilities to leverage for a wide range of healthcare applications. Focusing on the domain of radiology, vision-language models (VLMs) achieve good performance results for tasks such as generating radiology findings based on a patient's medical image, or answering visual questions (e.g., ``Where are the nodules in this chest X-ray?''). However, the clinical utility of potential applications of these capabilities is currently underexplored. We engaged in an iterative, multidisciplinary design process to envision clinically relevant VLM interactions, and co-designed four VLM use concepts: Draft Report Generation, Augmented Report Review, Visual Search and Querying, and Patient Imaging History Highlights. We studied these concepts with 13 radiologists and clinicians who assessed the VLM concepts as valuable, yet articulated many design considerations. Reflecting on our findings, we discuss implications for integrating VLM capabilities in radiology, and for healthcare AI more generally.</p>
<h3>Human-Algorithmic Interaction Using a Large Language Model-Augmented Artificial Intelligence Clinical Decision Support System</h3>
<p>Authors: Ambrose Wong, Dennis Shung, Jasjeet Sekhon, Yuan Pu, Allen Hsiao, Loren Laine, Leigh Evans, Terika McCall, Kisung You, Rene Kizilcec, Mauro Giuffre, Niroop Rajashekar, Sunny Chung, Yeo Eun Shin, Colleen Chan, Theo Saarinen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147431">Link</a></p>
<p>Abstract: Integration of artificial intelligence (AI) into clinical decision support systems (CDSS) poses a socio-technological challenge that is impacted by usability, trust, and human-computer interaction (HCI). AI-CDSS interventions have shown limited benefit in clinical outcomes, which may be due to insufficient understanding of how health-care providers interact with AI systems. Large language models (LLMs) have the potential to enhance AI-CDSS, but haven't been studied in either simulated or real-world clinical scenarios. We present findings from a randomized controlled trial deploying AI-CDSS for the management of upper gastrointestinal bleeding (UGIB) with and without an LLM interface within realistic clinical simulations for physician and medical student participants. We find evidence that LLM augmentation improves ease-of-use, that LLM-generated responses with citations improve trust, and HCI varies based on clinical expertise. Qualitative themes from interviews suggest the perception of LLM-augmented AI-CDSS as a team-member used to confirm initial clinical intuitions and help evaluate borderline decisions. </p>
<h2>Health and Care Practices</h2>
<h3>Designing Communication Feedback Systems To Reduce Healthcare Providers’ Implicit Biases In Patient Encounters</h3>
<p>Authors: Reggie Casanova-Perez, Janice Sabin, Nadir Weibel, Manas Satish Bedmutha, Harshini Ramaswamy, Wanda Pratt, Andrea Hartzler, Brian Wood, Emily Bascom, Kelly Tobar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147797">Link</a></p>
<p>Abstract: Healthcare providers’ implicit bias, based on patients’ physical characteristics and perceived identities, negatively impacts healthcare access, care quality, and outcomes. Feedback tools are needed to help providers identify and learn from their biases. To incorporate providers’ perspectives on the most effective ways to present such feedback, we conducted semi-structured design critique sessions with 24 primary care providers. We found that providers seek feedback designed with transparent metrics indicating the quality of their communication with a patient and trends in communication patterns across visits. Based on these metrics and trends, providers want this feedback presented in a dashboard paired with actionable, personalized tips about how to improve their communication behaviors. Our study provides new insights for interactive systems to help mitigate the impact of implicit biases in patient-provider communication. New systems that build upon these insights could support providers in making healthcare more equitable, particularly for patients from marginalized communities.</p>
<h3>Perceived Empathy of Technology Scale (PETS): Measuring Empathy of Systems Toward the User</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jonathan Rupp, Sven Mayer, Matthias Schmidmaier, Darina Cvetanova</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146760">Link</a></p>
<p>Abstract: Affective computing improves rapidly, allowing systems to process human emotions. This enables systems such as conversational agents or social robots to show empathy toward users. While there are various established methods to measure the empathy of humans, there is no reliable and validated instrument to quantify the perceived empathy of interactive systems. Thus, we developed the Perceived Empathy of Technology Scale (PETS) to assess and compare how empathic users perceive technology. We followed a standardized multi-phase process of developing and validating scales. In total, we invited 30 experts for item generation, 324 participants for item selection, and 396 additional participants for scale validation. We developed our scale using 22 scenarios with opposing empathy levels, ensuring the scale is universally applicable. This resulted in the PETS, a 10-item, 2-factor scale. The PETS allows designers and researchers to evaluate and compare the perceived empathy of interactive systems rapidly.</p>
<h3>Designing for Caregiver-facing Values Elicitation Tools</h3>
<p>BEST_PAPER</p>
<p>Authors: Charisse Foo, Gerald Huat Choon Koh, Sajeban Antonyrex, Pin Sym Foong, Natasha Ureyang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146676">Link</a></p>
<p>Abstract: In serious illness contexts, caregivers are often tasked to make values-based decisions for patients without decision-making capacity. However, most existing values elicitation tools are designed for patient use, which might not address caregivers’ unique needs. In this study, we developed five low-fidelity prototypes as probes to explore the design requirements for caregiver-facing values elicitation tools with 12 caregivers. Our findings indicate that caregivers need more support in reconciling various conceptions of patient values and their own values. Caregivers wanted to use the tools to build consensus among family members, but may prefer to use the online tool on their own rather than share the interface with other caregivers. Lastly, there is a prevalent lack of understanding of the importance of values in decision-making. From these insights, we draw some implications for the design of online tools for caregiver-facing values elicitation.</p>
<h3>Hospital Employee Experiences Caring for Patients in Smart Patient Rooms</h3>
<p>Authors: Jason Wiese, Joshua Dawson, Eden Fisher</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147343">Link</a></p>
<p>Abstract: Smart hospital patient rooms integrate smart devices for digital control of both entertainment (e.g., television and sound system) and the environment (e.g., lights, blinds, and temperature). While primarily designed to enhance the patient experience, this technology also impacts the hospital employees who work in these patient rooms. This study explores hospital employee experiences with smart patient rooms. We conducted 23 interviews with rehabilitation healthcare professionals, including nurses, doctors, psychologists, and occupational, physical, and speech therapists, to understand their perspectives on working in smart patient rooms. Drawn from thematic analysis of the interviews, our findings offer insights into employees' current use of the technology, the benefits and drawbacks they encounter, and their suggestions for improving the technology. These findings shed light on the complex problem of building smart patient rooms that simultaneously support the needs of multiple stakeholders, including patients and employees; they also point to important considerations for future designs.</p>
<h3>Investigating Why Clinicians Deviate from Standards of Care: Liberating Patients from Mechanical Ventilation in the ICU</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Gursimran Chawla, Jeremy Kahn, Susanna Zlotnikov, Leigh Bukowski, James McCann, John Zimmerman, Aradhana Venkat, Jennifer Kim, Nur Yildirim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147846">Link</a></p>
<p>Abstract: Clinical practice guidelines, care pathways, and protocols are designed to support evidence-based practices for clinicians; however, their adoption remains a challenge. We set out to investigate why clinicians deviate from the "Wake Up and Breathe" protocol, an evidence-based guideline for liberating patients from mechanical ventilation in the intensive care unit (ICU). We conducted over 40 hours of direct observations of live clinical workflows, 17 interviews with frontline care providers, and 4 co-design workshops at three different medical intensive care units. Our findings indicate that unlike prior literature suggests, disagreement with the protocol is not a substantial barrier to adoption. Instead, the uncertainty surrounding the application of the protocol for individual patients leads clinicians to deprioritize adoption in favor of tasks where they have high certainty. Reflecting on these insights, we identify opportunities for technical systems to help clinicians in effectively executing the protocol and discuss future directions for HCI research to support the integration of protocols into clinical practice in complex, team-based healthcare settings.</p>
<h2>Healthcare Training</h2>
<h3>Looking Together ≠ Seeing the Same Thing: Understanding Surgeons' Visual Needs During Intra-operative Coordination and Instruction</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Natalie Mateju, Michael Kemp, Xu Wang, Xinyue Chen, Jingying Wang, Vitaliy Popov, Gurjit Sandhu, Taylor Kantor</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146738">Link</a></p>
<p>Abstract: Shared gaze visualizations have been found to enhance collaboration and communication outcomes in diverse HCI subfields including collaborative work and learning. Given the importance of gaze in surgery operations, especially when a surgeon trainer and trainee need to coordinate their actions, research on the use of gaze to facilitate intra-operative coordination and instruction has been limited and shows mixed implications. We performed a field observation of 8 surgeries and an interview study with 14 surgeons to understand their visual needs during operations, informing ways to leverage and augment gaze to enhance intra-operative coordination and instruction.  We found that trainees have varying needs in receiving visual guidance which are often unfulfilled by the trainers’ instructions. It is critical for surgeons to control the timing of the gaze-based visualizations and effectively interpret gaze data. We suggest overlay technologies, e.g., gaze-based summaries and depth sensing, to augment raw gaze in support of surgical coordination and instruction. </p>
<h3>Surgment: Segmentation-enabled Semantic Search and Creation of Visual Question and Feedback to Support Video-Based Surgery Learning</h3>
<p>Authors: Tandis Soltani, Xu Wang, Haoran Tang, Jingying Wang, Vitaliy Popov, Taylor Kantor</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147894">Link</a></p>
<p>Abstract: Videos are prominent learning materials to prepare surgical trainees before they enter the operating room (OR). In this work, we explore techniques to enrich the video-based surgery learning experience. We propose Surgment, a system that helps expert surgeons create exercises with feedback based on surgery recordings. Surgment is powered by a few-shot-learning-based pipeline (SegGPT+SAM) to segment surgery scenes, achieving an accuracy of 92\%. The segmentation pipeline enables functionalities to create visual questions and feedback desired by surgeons from a formative study. Surgment enables surgeons to 1) retrieve frames of interest through sketches, and 2) design exercises that target specific anatomical components and offer visual feedback. In an evaluation study with 11 surgeons, participants applauded the search-by-sketch approach for identifying frames of interest and found the resulting image-based questions and feedback to be of high educational value.</p>
<h3>MR Microsurgical Suture Training System with Level-Appropriate Support</h3>
<p>Authors: Hideki Koike, Shio Miyafuji, Yusuke Kojima, Taichi Kin, Yuka Tashiro, Takeo Igarashi, Satoshi Kiyofuji</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147989">Link</a></p>
<p>Abstract: The integration of advanced technologies in healthcare necessitates the development of systems accommodating the daily routines in medical practices. Neurosurgeons, in particular, require extensive practice in microsurgical suturing in the long term, even in the busy routine of a medical practice. This study collaboratively developed a Mixed Reality system with neurosurgeons to support self-training in microscopic suturing. Based on the neurosurgeons' opinions, we implemented a level-appropriate microsurgical suture training system. For novices, the system offers shadow-matching training to support the practice of precise movements under the high-sensitivity environment of the microscope. For intermediates, it provides a real-time feedback system, which allows users to practice attention to details. Evaluation involved testing the novice system on students with no medical background and the intermediate system on neurosurgery residents. The effectiveness of the system was demonstrated through the experimental results and subsequent discussion.</p>
<h3>Facilitating Virtual Reality Integration in Medical Education: A Case Study of Acceptability and Learning Impact in Childbirth Delivery Training</h3>
<p>Authors: Shengdong Zhao, Abhiram Kanneganti, Gosavi Arundhati Tushar, Eng Tat Khoo, Chang Liu, Felicia Tan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147754">Link</a></p>
<p>Abstract: Advancements in Virtual Reality (VR) technology have opened new frontiers in medical education, igniting interest among medical educators to incorporate it into mainstream curriculum, complementing traditional training modalities such as manikin training. Despite numerous VR simulators on the market, their uptake in medical education remains limited. This paper explores the acceptability and educational effectiveness of VR in the context of vaginal childbirth delivery training, with the simulator providing a walkthrough for the second and third stages of labour, contrasting it with established manikin-based methods. We conducted a large-scale empirical study with 117 medical students, revealing a significant 24.9% improvement in knowledge scores when using VR as compared to manikin. However, VR received significantly lower self-reported feasibility scores in Confidence, Usability, Enjoyment, Feedback and Presence, indicating low acceptance. The study provides critical insights into the relationship between technological innovation and educational impact, guiding future integration of VR into medical training curricula.</p>
<h3>"I'd be watching him contour till 10 o'clock at night'': Understanding Tensions between Teaching Methods and Learning Needs in Healthcare Apprenticeship</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Nadir Weibel, James D. Murphy, Kexin Cheng, Chen Chen, Matin Yarmand</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147449">Link</a></p>
<p>Abstract: Apprenticeship is the predominant method for transferring specialized medical skills, yet the inter-dynamics between faculty and residents, including methods of feedback exchange are under-explored. We specifically investigate contouring: outlining tumors in preparation for radiotherapy, a critical skill that when performed subpar, severely degrades patient survival. Interviews and design-thinking workshops (N = four faculty; six residents) revealed misalignment between teaching methods and residents who desired timely, relevant, and diverse feedback. We further discuss reasons: overlapping learning content and strategies to ease tensions between clinical and teaching duties, and lack of support for exchange of cognitive processes. The follow-up survey study (N = 67 practitioners from 31 countries), which contained annotation and sketching tasks, provided diverse perspective over effective feedback elements. We lastly present sociotechnical implications in supporting faculty's teaching duties and learners' cognitive models, such as systematically leveraging senior learners in providing case-based guidance and supporting double-sided flow of cognitive information via in-situ video snippets.</p>
<h2>Human-Robot Interaction A</h2>
<h3>A Robot Jumping the Queue: Expectations About Politeness and Power During Conflicts in Everyday Human-Robot Encounters</h3>
<p>Authors: Sam Thellman, Philipp Hock, Tom Ziemke, Linda Miller, Franziska Babel, Robin Welsch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147417">Link</a></p>
<p>Abstract: Increasing encounters between people and autonomous service robots may lead to conflicts due to mismatches between human expectations and robot behaviour. This interactive online study (N = 335) investigated human-robot interactions at an elevator, focusing on the effect of communication and behavioural expectations on participants' acceptance and compliance. Participants evaluated a humanoid delivery robot primed as either submissive or assertive. The robot either matched or violated these expectations by using a command or appeal to ask for priority and then entering either first or waiting for the next ride. The results highlight that robots are less accepted if they violate expectations by entering first or using a command. Interactions were more effective if participants expected an assertive robot which then asked politely for priority and entered first. The findings emphasize the importance of power expectations in human-robot conflicts for the robot's evaluation and effectiveness in everyday situations.</p>
<h3>I feel being there, they feel being together: Exploring How Telepresence Robots Facilitate Long-Distance Family Communication</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Bongwon Suh, Hajin Lim, Joonhwan Lee, Jiyeon Seo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147312">Link</a></p>
<p>Abstract: Many families often live geographically apart from each other due to work, education, or marriage. Therefore, long-distance families frequently use computer-mediated communication (CMC) tools to stay connected. While CMC tools have significantly improved family communication, they cannot fully mediate social presence. To examine the potential of telepresence robots for improving long-distance family communication, we conducted a two-week qualitative in situ study involving eight families. We analyzed recorded videos of their family interactions and conducted pre- and post-deployment interviews. Our findings highlight telepresence robots' potential as family communication tools, enabling immersive, natural, and dynamic interactions through physical embodiment and autonomy. Particularly, we identified five categories of family interaction mediated by telepresence robots: engaging in multi-party family communication, exploring home, restoring family routines, providing support, and having joint physical activities. Based on our findings, we present design guidelines for leveraging telepresence robots as effective family communication tools. </p>
<h3>PepperPose: Full-Body Pose Estimation with a Companion Robot</h3>
<p>Authors: Siqi Zheng, Yuntao Wang, Chongyang Wang, Tin Lun Lam, Yuanchun Shi, Lingxiao Zhong, Yuan Gao, Chen Liang, Chun Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146730">Link</a></p>
<p>Abstract: Accurate full-body pose estimation across diverse actions in a user-friendly and location-agnostic manner paves the way for interactive applications in realms like sports, fitness, and healthcare. This task becomes challenging in real-world scenarios due to factors like the user's dynamic positioning, the diversity of actions, and the varying acceptability of the pose-capturing system. In this context, we present PepperPose, a novel companion robot system tailored for optimized pose estimation. Unlike traditional methods, PepperPose actively tracks the user and refines its viewpoint, facilitating enhanced pose accuracy across different locations and actions. This allows users to enjoy a seamless action-sensing experience. Our evaluation, involving 30 participants undertaking daily functioning and exercise actions in a home-like space, underscores the robot's promising capabilities. Moreover, we demonstrate the opportunities that PepperPose presents for human-robot interaction, its current limitations, and future developments.</p>
<h3>Giving Robots a Voice: Human-in-the-Loop Voice Creation and open-ended Labeling</h3>
<p>Authors: Pol van Rijn, Nori Jacoby, Kathrin Janowski, Katharina Weitz, Silvan Mertes, Elisabeth André</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147115">Link</a></p>
<p>Abstract: Speech is a natural interface for humans to interact with robots. Yet, aligning a robot's voice to its appearance is challenging due to the rich vocabulary of both modalities. Previous research has explored a few labels to describe robots and tested them on a limited number of robots and existing voices. Here, we develop a robot-voice creation tool followed by large-scale behavioral human experiments (N=2,505). First, participants collectively tune robotic voices to match 175 robot images using an adaptive human-in-the-loop pipeline. Then, participants describe their impression of the robot or their matched voice using another human-in-the-loop paradigm for open-ended labeling. The elicited taxonomy is then used to rate robot attributes and to predict the best voice for an unseen robot. We offer a web interface to aid engineers in customizing robot voices, demonstrating the synergy between cognitive science and machine learning for engineering tools.</p>
<h2>Human-Robot Interaction B</h2>
<h3>Robot-Assisted Decision-Making: Unveiling the Role of Uncertainty Visualisation and Embodiment</h3>
<p>Authors: Saumya Pareek, Wafa Johal, Jorge Goncalves, Sarah Schömbs</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146811">Link</a></p>
<p>Abstract: Robots are embodied agents that act under several sources of uncertainty. When assisting humans in a collaborative task, robots need to communicate their uncertainty to help inform decisions. In this study, we examine the use of visualising a robot’s uncertainty in a high-stakes assisted decision-making task. In particular, we explore how different modalities of uncertainty visualisations (graphical display vs. the robot’s embodied behaviour) and confidence levels (low, high, 100%) conveyed by a robot affect the human decision-making and perception during a collaborative task. Our results show that these visualisations significantly impact how participants arrive to their decision as well as how they perceive the robot’s transparency across the different confidence levels. We highlight potential trade-offs and offer implications for robot-assisted decision-making. Our work contributes empirical insights on how humans make use of uncertainty visualisations conveyed by a robot in a critical robot-assisted decision-making scenario.</p>
<h3>Trash in Motion: Emergent Interactions with a Robotic Trashcan</h3>
<p>Authors: Barry Brown, Wendy Ju, Ilan Mandel, Fanjun Bu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146631">Link</a></p>
<p>Abstract: The introduction of robots in public spaces raises many questions concerning emergent interactions with robots. In this paper, we use video analysis to study two robotic trashcans deployed in a busy city square. We focus on the movement-based practices that emerged between the robot, the robot operators, and the inhabitants of the square. These practices spanned ways of attracting the robot and disposing of trash, the robot 'asking' for trash, 'demonstrations' by those in the square, as well as passersby in the square navigating around and in coordination with the robots. In discussion, we document these 'spontaneous simple sequential systematics' - interactions that were systematic (they had an order), sequential (they had parts that happened one at a time), simple (in that they could be understood and copied by an observer) and spontaneous (they could be produced with no prompting or training). Building on this we discuss how we might think of robotic motion as a design space, along with HCI contributions to urban robotics.</p>
<h3>Investigating Effect of Altered Auditory Feedback on Self-Representation, Subjective Operator Experience, and Task Performance in Teleoperation of a Social Robot</h3>
<p>Authors: Nami Ogawa, Jun Baba, Junya Nakanishi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147866">Link</a></p>
<p>Abstract: Teleoperating social robots requires operators to ``speak as the robot,'' as local users would favor robots whose appearance and voice match.</p>
<p>This study focuses on real-time altered auditory feedback (AAF), a method to transform the acoustic traits of one's speech and provide feedback to the speaker, to transform the operator's self-representation toward ``becoming the robot.''</p>
<p>To explore whether AAF with voice transformation (VT) matched to the robot's appearance can influence the operator's self-representation and ease the task, we experimented with three conditions: no VT (No-VT), only VT (VT-only), and VT with AAF (VT-AAF), where participants teleoperated a robot to verbally serve real passersby at a bakery.</p>
<p>The questionnaire results demonstrate that VT-AAF changed the participants' self-representation to match the robot's character and improved participants' subjective teleoperating experience, while task performance and implicit measures of self-representation were not significantly affected.</p>
<p>Notably, 87\% of the participants preferred VT-AAF the most. </p>
<h3>The Adaptive Architectural Layout: How the Control of a Semi-Autonomous Mobile Robotic Partition was Shared to Mediate the Environmental Demands and Resources of an Open-Plan Office</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Andrew Vande Moere, Alex Binh Vinh Duc Nguyen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146791">Link</a></p>
<p>Abstract: A typical open-plan office layout is unable to optimally host multiple collocated work activities, personal needs, and situational events, as its space exerts a range of environmental demands  on workers in terms of maintaining their acoustic, visual or privacy comfort. As we hypothesise that these demands could be coped by optimising the environmental resources of the architectural layout, we deployed a mobile robotic partition that autonomously manoeuvres between predetermined locations. During a five-weeks in-the-wild study within a real-world open-plan office, we studied how 13 workers adopted four distinct adaptation strategies when sharing the spatiotemporal control of the robotic partition. Based on their logged and self-reported reasoning, we present six initiation regulating factors that determine the appropriateness of each adaptation strategy. This study thus contributes to how future human-building interaction could autonomously improve the experience, comfort, performance, and even the health and wellbeing of multiple workers that share the same workplace.</p>
<h3>From Agent Autonomy to Casual Collaboration: A Design Investigation on Help-Seeking Urban Robots</h3>
<p>Authors: Martin Tomitsch, Marius Hoggenmüller, Xinyan Yu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148163">Link</a></p>
<p>Abstract: As intelligent agents transition from controlled to uncontrolled environments, they face challenges that sometimes exceed their operational capabilities. In many scenarios, they rely on assistance from bystanders to overcome those challenges. </p>
<p>Using robots that get stuck in urban settings as an example, we investigate how agents can prompt bystanders into providing assistance. We conducted four focus group sessions with 17 participants that involved bodystorming, where participants assumed the role of robots and bystander pedestrians in role-playing activities. Generating insights from both assumed robot and bystander perspectives, we were able to identify potential non-verbal help-seeking strategies (i.e., addressing bystanders, cueing intentions, and displaying emotions) and factors shaping the assistive behaviours of bystanders. </p>
<p>Drawing on these findings, we offer design considerations for help-seeking urban robots and other agents operating in uncontrolled environments to foster casual collaboration, encompass expressiveness, align with agent social categories, and curate appropriate incentives.</p>
<h2>Human-Robot Interaction C</h2>
<h3>Impact of Multi-Robot Presence and Anthropomorphism on Human Cognition and Emotion</h3>
<p>Authors: Jiadi Luo, Lawrence Kim, Veronika Domova</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147559">Link</a></p>
<p>Abstract: Exploring how robots impact human cognition and emotions has become increasingly important as robots gradually become ubiquitous in our lives. In this study, we investigate the impact of robotic presence on human cognition and emotion by examining various robot parameters such as anthropomorphism, number of robots, and multi-robot motion patterns. 16 participants completed two cognitive tasks in the presence of anthropomorphic and non-anthropomorphic robots, alone, and with a human nearby. The non-anthropomorphic robot conditions were further varied in the number of robots and their motion patterns. We find that increasing the number of non-anthropomorphic robots generally leads to slower performance, but coordinated patterned motions can lower the completion time compared to random movements. An anthropomorphic robot induces an increased level of feelings of being judged compared to a non-anthropomorphic robot. These findings provide preliminary insights into how designers or users can purposefully integrate robots into our environment by understanding the effects of anthropomorphism, number of robots, and multi-robot motion patterns on human cognition and emotion.</p>
<h3>Join Me Here if You Will: Investigating Embodiment and Politeness Behaviors When Joining Small Groups of Humans, Robots, and Virtual Characters</h3>
<p>Authors: Iolanda Leite, Sahba Zojaji, Christopher Peters, Andrii Matviienko</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147171">Link</a></p>
<p>Abstract: Politeness and embodiment are pivotal elements in human-agent interactions. While many previous works advocate the positive role of embodiment in enhancing these interactions, it remains unclear how embodiment and politeness affect individuals joining groups. In this paper, we explore how politeness behaviors (verbal and nonverbal) exhibited by three distinct embodiments (humans, robots, and virtual characters) influence individuals' decisions to join a group of two agents in a controlled experiment (N=54). We assessed agent effectiveness regarding persuasiveness, perceived politeness, and participants' trajectories when joining the group. We found that embodiment does not significantly impact agent persuasiveness and perceived politeness, but politeness does. Direct and explicit politeness strategies have a higher success rate in persuading participants to join the group at the furthest side. Lastly, participants adhered to social norms when joining at the furthest side, maintained a greater physical distance from humans, chose longer paths, and walked faster when interacting with humans.</p>
<h3>Designing Multispecies Worlds for Robots, Cats, and Humans</h3>
<p>BEST_PAPER</p>
<p>Authors: Eike Schneiders, Matt Adams, Nick Tandavanitj, Victor Ngo, Clara Mancini, Alan Chamberlain, Steven Benford, Simon Castle-Green, Joel Fischer, Ju Row Farr</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147577">Link</a></p>
<p>Abstract: We reflect on the design of a multispecies world centred around a bespoke enclosure in which three cats and a robot arm coexist for six hours a day during a twelve-day installation as part of an artist-led project. In this paper, we present the project's design process, encompassing various interconnected components, including the cats, the robot and its autonomous systems, the custom end-effectors and robot attachments, the diverse roles of the humans-in-the-loop, and the custom-designed enclosure. Subsequently, we provide a detailed account of key moments during the deployment and discuss the design implications for future multispecies systems. Specifically, we argue that designing the technology and its interactions is not sufficient, but that it is equally important to consider the design of the `world' in which the technology operates. Finally, we highlight the necessity of human involvement in areas such as breakdown recovery, animal welfare, and their role as audience.</p>
<h3>Towards Robotic Companions: Understanding Handler-Guide Dog Interactions for Informed Guide Dog Robot Design</h3>
<p>BEST_PAPER</p>
<p>Authors: Sunghoon Lee, Hochul Hwang, Nicholas Giudice, Donghyun Kim, Joydeep Biswas, Hee-Tae Jung</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147890">Link</a></p>
<p>Abstract: Dog guides are favored by blind and low-vision (BLV) individuals for their ability to enhance independence and confidence by reducing safety concerns and increasing navigation efficiency compared to traditional mobility aids. However, only a relatively small proportion of BLV people work with dog guides due to their limited availability and associated maintenance responsibilities. There is considerable recent interest in addressing this challenge by developing legged guide dog robots. This study was designed to determine critical aspects of the handler-guide dog interaction and better understand handler needs to inform guide dog robot development. We conducted semi-structured interviews and observation sessions with 23 dog guide handlers and 5 trainers. Thematic analysis revealed critical limitations in guide dog work, desired personalization in handler-guide dog interaction, and important perspectives on future guide dog robots. Grounded on these findings, we discuss pivotal design insights for guide dog robots aimed for adoption within the BLV community. </p>
<h2>Inter- and Cross-Species Interactions</h2>
<h3>No More Angry Birds: Investigating Touchscreen Ergonomics to Improve Tablet-Based Enrichment for Parrots</h3>
<p>Authors: Rebecca Kleinberger, Ilyena Hirskyj-Douglas, Jennifer Cunha, Megan McMahon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148084">Link</a></p>
<p>Abstract: Touchscreen devices, ubiquitous in humans' day-to-day lives, offer a promising avenue for animal enrichment. With advanced cognitive abilities, keen visual perception, and adeptness to engage with capacitive screens using dexterous tongues, parrots are uniquely positioned to benefit from this technology. Additionally, pet parrots often lack appropriate stimuli, supporting the need for inexpensive solutions using off-the-shelf devices. However, the current human-centric interaction design standards of tablet applications do not optimally cater to the tactile affordances and ergonomic needs of parrots. To address this, we conducted a study with 20 pet parrots, examining their tactile interactions with touchscreens and evaluating the applicability of existing HCI interaction models. Our research highlights key ergonomic characteristics unique to parrots, which include pronounced multi-tap behavior, a critical size threshold for touch targets, and greater effectiveness of larger targets over closer proximity. Based on these insights, we propose guidelines for tablet-based enrichment systems for companion parrots.</p>
<h3>Ellie Talks About the Weather: Toward Evaluating the Expressive and Enrichment Potential of a Tablet-Based Speech Board in a single Goffin’s Cockatoo</h3>
<p>Authors: Rebecca Kleinberger, Jennifer Cunha, Nikhil Singh, Megan McMahon, Lily Stella, Hao Jin, Corinne Renguette</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147963">Link</a></p>
<p>Abstract: Augmentative and alternative communication devices (AACs) are designed to assist humans with complex communication needs. Recently, AAC use has been reported in non-human animals. Such tools may potentially provide enrichment and increase interspecies connection. However, there is no evaluation framework and little data available to assess AAC potential. Here, we examine seven months of a single parrot’s sustained use of a tablet-based AAC totaling 129 sessions within 190 days. After devising a coding schema, we propose a framework to explore the expressive potential and enrichment value for the parrot. Our results suggest that the choice of destination words cannot be simply explained based on random selection or icon location alone, and 92\% of corroborable selections are validated by behaviors. The parrot interactions also appear significantly skewed toward social and cognitive enrichment. This work is a first step toward assessment of AAC use for parrot enrichment. </p>
<h3>Call of the Wild Web: Comparing Parrot Engagement in Live vs. Pre-Recorded Video Calls</h3>
<p>Authors: Rebecca Kleinberger, Ilyena Hirskyj-Douglas, Jennifer Cunha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147943">Link</a></p>
<p>Abstract: The concept of the animal Internet has flourished, with many conceptualisations proceeding from the premise that connecting animals online may enrich their social life. Yet we remain unaware of how -- or even whether -- online interactions (either live or with pre-recorded material) might affect how animals engage with other animals. We implemented a system for parrots to trigger live video calls with other birds or playback from a pre-recorded video call. The goal was to identify differences in engagement and behaviours. Over a six-month study, parrots triggered significantly more live calls and engaged longer in that setting relative to the playback condition, while the animals' caregivers found greater value in the latter but preferred the live alternative for the birds under their care. The results begin to question what animals make of online remote connections, putting forward considerations as to how the internet can affect animals' experiences. </p>
<h3>Uncovering Lemur Cross-Species Usage of an Interactive Audio Device In Zoos</h3>
<p>Authors: Ilyena Hirskyj-Douglas, Vilma Kankaanpää, Fay Clark</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147810">Link</a></p>
<p>Abstract: Computer technology for animals is typically oriented toward isolated individuals, seldom attending to such group-living factors as accommodating differences between individuals. To address this shortcoming of research and practice, the authors designed and developed an audio-based system that lets lemurs in group accommodation voluntarily trigger audio via a novel device dubbed LemurLounge and listen to it on their own. This interactive system was deployed for 14 lemurs, of three species (black-and-white, brown, and ring-tailed), in their normal habitat. The device's presence clearly influenced lemurs' visits to the relevant portion of the enclosure. Alongside a general preference for audio over silence, assessment of individual- and species-level differences revealed significant differences at both levels, though no particular sound type (rainfall, traffic, either upbeat or relaxing music, or white noise) was favoured. The findings and design work highlight the need for customisable and adaptive computer technology for animals living in group settings, with important implications for lemurs and other primates, humans included.</p>
<h3>Charting Ethical Tensions in Multispecies Technology Research through Beneficiary-Epistemology Space</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Pepita Barnard Stringer, Ayse Kucukyilmaz, Eike Schneiders, Matt Adams, Guido Salimbeni, Nick Tandavanitj, Victor Ngo, Clara Mancini, Alan Chamberlain, Steven Benford, Simon Castle-Green, Joel Fischer, Ju Row Farr</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147025">Link</a></p>
<p>Abstract: While ethical challenges are widely discussed in HCI, far less is reported about the ethical processes that researchers routinely navigate. We reflect on a multispecies project that negotiated an especially complex ethical approval process. Cat Royale was an artist-led exploration of creating an artwork to engage audiences in exploring trust in autonomous systems. The artwork took the form of a robot that played with three cats. Gaining ethical approval required an extensive dialogue with three Institutional Review Boards (IRBs) covering computer science, veterinary science and animal welfare, raising tensions around the welfare of the cats, perceived benefits and appropriate methods, and reputational risk to the University. To reveal these tensions we introduce beneficiary-epistemology space, that makes explicit who benefits from research (humans or animals) and underlying epistemologies. Positioning projects and IRBs in this space can help clarify tensions and highlight opportunities to recruit additional expertise.</p>
<h2>Perception and Input in Immersive Environments</h2>
<h3>Big or Small, It’s All in Your Head: Visuo-Haptic Illusion of Size-Change Using Finger-Repositioning</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Andrea Bianchi, Mike Sinclair, Eyal Ofek, Myung Jin Kim, Michel Pahud</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147073">Link</a></p>
<p>Abstract: Haptic perception of physical sizes increases the realism and immersion in Virtual Reality (VR). Prior work rendered sizes by exerting pressure on the user’s fingertips or employing tangible, shape-changing devices. These interfaces are constrained by the physical shapes they can assume, making it challenging to simulate objects growing larger or smaller than the perceived size of the interface. Motivated by literature on pseudo-haptics describing the strong influence of visuals over haptic perception, this work investigates modulating the perception of size beyond this range. We developed a fixed-sized VR controller leveraging finger-repositioning to create a visuo-haptic illusion of dynamic size-change of handheld virtual objects. Through two user studies, we found that with an accompanying size-changing visual context, users can perceive virtual object sizes up to 44.2% smaller to 160.4%larger than the perceived size of the device. Without the accompanying visuals, a constant size (141.4% of device size) was perceived.</p>
<h3>STMG: A Machine Learning Microgesture Recognition System for Supporting Thumb-Based VR/AR Input</h3>
<p>Authors: Moshe Ben-Zacharia, Necati Cihan Camgöz, Shugao Ma, Eric Sauser, Andrei Marin, Yubo Zhang, Ayush Bhargava, Robert Wang, Chengde Wan, Yujun Cai, Fedor Kovalev, Ken Koh, Shannon Hoople, Mariel Sanchez-Rodriguez, Marcos Nunes-Ueno, Kenrick Kin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146737">Link</a></p>
<p>Abstract: AR/VR devices have started to adopt hand tracking, in lieu of controllers, to support user interaction. However, today's hand input rely primarily on one gesture: pinch. Moreover, current mappings of hand motion to use cases like VR locomotion and content scrolling involve more complex and larger arm motions than joystick or trackpad usage. STMG increases the gesture space by recognizing additional small thumb-based microgestures from skeletal tracking running on a headset. We take a machine learning approach and achieve a 95.1% recognition accuracy across seven thumb gestures performed on the index finger surface: four directional thumb swipes (left, right, forward, backward), thumb tap, and fingertip pinch start and pinch end. We detail the components to our machine learning pipeline and highlight our design decisions and lessons learned in producing a well generalized model. We then demonstrate how these microgestures simplify and reduce arm motions for hand-based locomotion and scrolling interactions.</p>
<h3>Beyond the Blink: Investigating Combined Saccadic &amp; Blink-Suppressed Hand Redirection in Virtual Reality</h3>
<p>Authors: Oscar Ariza, André Zenner, Chiara Karr, Antonio Krüger, Martin Feick</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147392">Link</a></p>
<p>Abstract: In pursuit of hand redirection techniques that are ever more tailored to human perception, we propose the first algorithm for hand redirection in virtual reality that makes use of saccades, i.e., fast ballistic eye movements that are accompanied by the perceptual phenomenon of change blindness. Our technique combines the previously proposed approaches of gradual hand warping and blink-suppressed hand redirection with the novel approach of saccadic redirection in one unified yet simple algorithm. We compare three variants of the proposed Saccadic &amp; Blink-Suppressed Hand Redirection (SBHR) technique with the conventional approach to redirection in a psychophysical study (N=25). Our results highlight the great potential of our proposed technique for comfortable redirection by showing that SBHR allows for significantly greater magnitudes of unnoticeable redirection while being perceived as significantly less intrusive and less noticeable than commonly employed techniques that only use gradual hand warping.</p>
<h3>TriPad: Touch Input in AR on Ordinary Surfaces with Hand Tracking Only</h3>
<p>Authors: Caroline Appert, Stéphanie Rey, Camille Dupré, Emmanuel Pietriga, Houssem Saidi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147490">Link</a></p>
<p>Abstract: TriPad enables opportunistic touch interaction in Augmented Reality using hand tracking only. Users declare the surface they want to appropriate with a simple hand tap gesture. They can then use this surface at will for direct and indirect touch input. TriPad only involves analyzing hand movements and postures, without the need for additional instrumentation, scene understanding or machine learning. TriPad thus works on a variety of flat surfaces, including glass. It also ensures low computational overhead on devices that typically have a limited power budget. We describe the approach, and report on two user studies. The first study demonstrates the robustness of TriPad's hand movement interpreter on different surface materials. The second study compares TriPad against direct mid-air AR input techniques on both discrete and continuous tasks and with different surface orientations. TriPad achieves a better speed-accuracy trade-off overall, improves comfort and minimizes fatigue.</p>
<h3>Flicker Augmentations: Rapid Brightness Modulation for Real-World Visual Guidance using Augmented Reality</h3>
<p>Authors: Kasper Hornbæk, Jonathan Sutton, Tobias Langlotz, Alexander Plopski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147292">Link</a></p>
<p>Abstract: Providing attention guidance, such as assisting in search tasks, is a prominent use for Augmented Reality.  Typically, this is achieved by graphically overlaying geometrical shapes such as arrows. However, providing visual guidance can cause side effects such as attention tunnelling or scene occlusions, and introduce additional visual clutter. Alternatively, visual guidance can adjust saliency but this comes with different challenges such as hardware requirements and environment dependent parameters. In this work we advocate for using flicker as an alternative for real-world guidance using Augmented Reality. We provide evidence for the effectiveness of flicker from two user studies. The first compared flicker against alternative approaches in a highly controlled setting, demonstrating efficacy (N = 28). The second investigated flicker in a practical task, demonstrating feasibility with higher ecological validity (N = 20). Finally, our discussion highlights the opportunities and challenges when using flicker to provide real-world visual guidance using Augmented Reality.</p>
<h2>Learning with AI</h2>
<h3>The Metacognitive Demands and Opportunities of Generative AI</h3>
<p>BEST_PAPER</p>
<p>Authors: Lev Tankelevitch, Auste Simkute, Ava Scott, Advait Sarkar, Viktor Kewenig, Abigail Sellen, Sean Rintel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147504">Link</a></p>
<p>Abstract: Generative AI (GenAI) systems offer unprecedented opportunities for transforming professional and personal work, yet present challenges around prompting, evaluating and relying on outputs, and optimizing workflows. We argue that metacognition—the psychological ability to monitor and control one’s thoughts and behavior—offers a valuable lens to understand and design for these usability challenges. Drawing on research in psychology and cognitive science, and recent GenAI user studies, we illustrate how GenAI systems impose metacognitive demands on users, requiring a high degree of metacognitive monitoring and control. We propose these demands could be addressed by integrating metacognitive support strategies into GenAI systems, and by designing GenAI systems to reduce their metacognitive demand by targeting explainability and customizability. Metacognition offers a coherent framework for understanding the usability challenges posed by GenAI, and provides novel research and design directions to advance human-AI interaction.</p>
<h3>BIDTrainer: An LLMs-driven Education Tool for Enhancing the Understanding and Reasoning in Bio-inspired Design</h3>
<p>Authors: Peter Childs, Zebin Cai, Liuqing Chen, Zhaojun Jiang, Lingyun Sun, Haoyu Zuo, Duowei Xia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147876">Link</a></p>
<p>Abstract: Bio-inspired design (BID) fosters innovative solutions in engineering by drawing inspiration from biology. Learning BID is crucial for developing multidisciplinary innovation skills of designers and engineers. While current BID education has attempted to enhance learners' understanding and analogical reasoning skills in BID, it often relies much on teachers' expertise. When learners turn to learn independently through some educational tools, there are challenges in understanding and reasoning practice in such complex multidisciplinary environment, as well as evaluating learning outcomes comprehensively. Addressing these challenges, we introduce a Large Language Models (LLMs)-driven BID education method based on a structured ontology, as well as three strategies: enhancing understanding through LLMs-enpowered "learning by asking", assisting reasoning by providing hints and feedback, and assessing learning outcomes through benchmarking against existing BID knowledge. Implementing the method, we developed BIDTrainer, an interactive BID education tool. User studies indicate that learners using BIDTrainer understood BID cases better, reason faster with higher interactivity than the baseline, and BIDTrainer assessed the learning outcomes consistent with experts.</p>
<h3>Teachers, Parents, and Students' perspectives on Integrating Generative AI into Elementary Literacy Education</h3>
<p>Authors: Xiaofei Zhou, Kylie Peppler, Shenshen Han, Zhenyao Cai, Richard Ko, Seth Corrigan, Ariel Han</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147607">Link</a></p>
<p>Abstract: The viral launch of new generative AI (GAI) systems, such as ChatGPT and Text-to-Image (TTL) generators, sparked questions about how they can be effectively incorporated into writing education. However, it is still unclear how teachers, parents, and students perceive and suspect GAI systems in elementary school settings. We conducted a workshop with twelve families (parent-child dyads) with children ages 8-12 and interviewed sixteen teachers in order to understand each stakeholder's perspectives and opinions on GAI systems for learning and teaching writing. We found that the GAI systems could be beneficial in generating adaptable teaching materials for teachers, enhancing ideation, and providing students with personalized, timely feedback. However, there are concerns over authorship, students’ agency in learning, and uncertainty concerning bias and misinformation. In this article, we discuss design strategies to mitigate these constraints by implementing an adults-oversight system, balancing AI-role allocation, and facilitating customization to enhance students’ agency over writing projects.</p>
<h3>Teaching Middle Schoolers about the Privacy Threats of Tracking and Pervasive Personalization: A Classroom Intervention Using Design-Based Research</h3>
<p>Authors: Philip Nelson, Kyra Derrick, Khushbu Singh, Nicole Bannister, Mehtab Iqbal, Sushmita Khan, Oluwafemi Osho, Kelly Caine, Bart Knijnenburg, Emily Sidnam-Mauch, Lingyuan Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146762">Link</a></p>
<p>Abstract: With the pervasive and evolving use of tracking and AI to make inferences about online platform users, it has become imperative for adolescents---a key demographic using such platforms---to develop a deep understanding of these practices to protect their privacy. Traditionally, K-12 cybersecurity education has largely been confined to extracurricular activities, limiting underrepresented students' access. To resolve this shortcoming, we partnered with a rural-identifying middle school to deliver AI-related privacy education in classrooms. Using Design-Based Research methodology, we identified students' AI-related privacy learning needs and developed six education modules. This paper focuses on the design, classroom implementation, and evaluation of module #2, covering the privacy threats of Tracking and Pervasive Personalization (TaPP). Student assessment outcomes show they developed transferable foundational knowledge of the privacy implications of tracking and personalization after participating in the TaPP module. Our findings demonstrate the benefits of integrating AI-related privacy education into existing K-12 curricula.</p>
<h3>Putting Things into Context: Generative AI-Enabled Context Personalization for Vocabulary Learning Improves Learning Motivation</h3>
<p>Authors: Pat Pataranutaporn, Yaoli Mao, Pattie Maes, Valdemar Danry, Joanne Leong, Florian Perteneder</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147682">Link</a></p>
<p>Abstract: Fostering students' interests in learning is considered to have many positive downstream effects. Large language models have opened up new horizons for generating content tuned to one's interests, yet it is unclear in what ways and to what extent this customization could have positive effects on learning. To explore this novel dimension, we conducted a between-subjects online study (n=272) featuring different variations of a generative AI vocabulary learning app that enables users to personalize their learning examples. Participants were randomly assigned to control (sentence sourced from pre-existing text) or experimental conditions (generated sentence or short story based on users’ text input). While we did not observe a difference in learning performance between the conditions, the analysis revealed that generative AI-driven context personalization positively affected learning motivation. We discuss how these results relate to previous findings and underscore their significance for the emerging field of using generative AI for personalized learning.  </p>
<h2>Menstrual Tracking and Health</h2>
<h3>Understanding Cultural and Religious Values Relating to Awareness of Women’s Intimate Health among Arab Muslims</h3>
<p>Authors: Latifa Al Naimi, Mirela Alistar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147619">Link</a></p>
<p>Abstract: Women’s intimate health is a historically stigmatized topic in many cultures. Arab and Muslim values such as privacy and modesty can influence the extent to which members of these communities seek information or help regarding their intimate health. However, Eurocentric approaches to design and research for these groups only yield resistance due to their challenging of core values. We explore prior work in women's health in HCI and cultural models to design for an underrepresented group in HCI research. Through interviews conducted with 16 participants who identified as Arab Muslims, we investigated attitudes, cultural and religious values, and backgrounds relating to awareness of women’s intimate health issues. Our thematic analysis identified shared experiences in learning about women’s intimate health and ways in which Arab culture and Islam synchronize or diverge. We contribute cultural and religious elements to consider in research methodology and design for Arab and Muslim communities. </p>
<h3>"Islamically, I am not on my period": A Study of Menstrual Tracking in Muslim Women in the US</h3>
<p>Authors: James Clawson, Pallavi Panchpor, Zaidat Ibrahim, Novia Nurain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147294">Link</a></p>
<p>Abstract: The widespread adoption of menstrual tracking applications has garnered much attention with recent research focusing on inclusive design. However, existing literature has yet to explore the impact of religious practices on menstrual tracking behavior. We investigate the menstrual tracking practices of Muslim women of faith in the United States, a population whose personal reproductive health behaviors are deeply influenced by their faith, values, and religious laws We conducted a three-phase study consisting of preliminary surveys (N=133), semi-structured interviews (N=20), and a post-Roe v. Wade survey (N=77). We highlight motivations for tracking and uncover this overlooked population's challenges as they engage with menstrual tracking technologies. We reveal an intimate connection between menstrual tracking and religious practices. We uncover challenges from engaging with existing menstrual-tracking applications and contribute design recommendations for accommodating faith in the design of health-tracking technologies. We amplify a call to action for the HCI community to reduce the "othering" of under-represented populations and to better support the inclusive design of technologies that center religious identities and values for individuals of faith.</p>
<h3>Tracking During Ramadan: Examining the Intersection of Menstrual and Religious Tracking Practices Among Muslim Women in the United States</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: James Clawson, Zaidat Ibrahim, Novia Nurain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147054">Link</a></p>
<p>Abstract: Personal Informatics (PI) tools are crucial in helping individuals monitor their physical health, mental health, and overall well-being. Many Muslim women use multiple PI tools to support their religious and spiritual well-being alongside their health. We investigate the religious and health-tracking practices of Muslim women living in the United States during the month of Ramadan. We conducted a month-long diary study and semi-structured interviews with nine (9) Muslim women observing Ramadan. Through this research, we uncover their motivations for tracking, discover the complex interplay between their social roles and religious practices, and identify conflicts arising from competing objectives (tracking their spiritual and physical health). Our findings contribute insights into the inclusive design of Personal Informatics tools tailored to the needs of Muslim women of faith and provide a call to the research community to expand tracking technologies to include aspects that support religious health and wellness. We discuss design considerations for supporting Muslim women during Ramadan and beyond.</p>
<h3>Functional Design Requirements to Facilitate Menstrual Health Data Exploration</h3>
<p>Authors: Khai Truong, Brenna Li, Alex Mariakakis, Georgianna Lin, Minh Le, Pierre-William Lessard, Fanny Chevalier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147625">Link</a></p>
<p>Abstract: Menstrual trackers currently lack the affordances required to help individuals achieve their goals beyond menstrual event predictions and symptom logging. Taking an initial step towards this aspiration, we propose, validate, and refine five functional design requirements for future interface designs that facilitate menstrual data exploration. We interviewed 30 individuals who menstruate and collected their feedback on the practical application of these requirements. To elicit ideas and impressions, we designed two proof-of-concept interfaces to use as design probes with similar core functionalities but different presentations of phase timing predictions and signal arrangement. Our analysis revealed participants' feedback regarding the presentation of predictions for menstrual-related events, the visualization of future signal patterns, personalization abilities for viewing signals relevant to their menstrual experience, the availability of resources to understand the underlying biological connections between signals, and the ability to compare multiple cycles side-by-side with context.</p>
<h3>My Data, My Choice, My Insights: Women's Requirements when Collecting, Interpreting and Sharing their Personal Health Data</h3>
<p>Authors: Susanna Spoerl, Susanne Boll, Sophie Grimme, Marion Koelle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148283">Link</a></p>
<p>Abstract: HCI research has been instrumental in enabling self-directed health tracking. Despite a plethora of devices and data, however, users' views of their own health are often fragmented. This is a problem for women's health, where physical and mental observations and symptoms are strongly intertwined. An integrated view throughout different life stages could help to better understand these connections, facilitate symptom alleviation through life-style changes, and support timely diagnosis: currently, women's health issues often go under-researched and under-diagnosed. To capture the needs and worries of self-directed tracking, interpreting and sharing women's health data, we held workshops with 28 women. Drawing upon feminist methods, we conducted a Reflexive Thematic Analysis to identify six central themes that ground opportunities and challenges for life-long, self-directed tracking of intimate data. These themes inform the design of tools for data collection, analysis and sharing that empower women to better understand their bodies and demand adequate health services.</p>
<h2>Mental Health A</h2>
<h3>Supporting Cognitive Reappraisal With Digital Technology: A Content Analysis and Scoping Review of Challenges, Interventions, and Future Directions</h3>
<p>Authors: Alissa Antle, Petr Slovak, Alexandra Kitson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148296">Link</a></p>
<p>Abstract: Cognitive reappraisal (CR) is a critical emotion regulation skill that is strongly associated with mental well-being outcomes. While CR has been well theorized psychologically and many therapeutic approaches exist, CR remains one of the toughest skills to learn and develop. We explore the design space of using technologically-mediated CR supports through a dual approach. First, we draw on a content analysis of 30 therapeutic manuals combined with five clinician interviews to understand existing CR processes and challenges in therapeutic settings. Second, we compare the identified challenges with a scoping review of 42 HCI papers on technologically-mediated CR interventions. This allowed us to identify trends and gaps in a field where digital health innovations are critically needed; and suggest four design opportunities that warrant further exploration. Together, our work contributes theoretically-derived future research opportunities, and provides researchers with concrete guidance to explore these important design spaces.</p>
<h3>Multi-stakeholder Perspectives on Mental Health Screening Tools for Children</h3>
<p>Authors: Tauhidur Rahman, Deepak Ganesan, Adam Grabell, Lynnea Mayorga, Adrelys Mateo Santana, Manasa Kalanadhabhatta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147792">Link</a></p>
<p>Abstract: Pediatric mental health is a growing concern around the world, affecting children's social-emotional development and increasing the risk of poor behavioral outcomes later in life. However, obtaining a behavioral diagnosis in early childhood is challenging due to lack of access to resources, low parental mental health literacy, and children's dependence on several stakeholders to coordinate care for them. While app-based, at-home screening tools could offer a scalable and convenient diagnostic solution for families, stakeholder perspectives on their utility and usability remain to be examined. This work reports on a survey of child mental health practitioners and interviews with parents to illustrate existing barriers to care that stakeholders encounter, the perceived benefits of app-based screening tools in meeting their needs, and the challenges in scaling up these tools. We identify where stakeholders agree or disagree, delineate key design tensions, and provide recommendations for the development of future screening technologies.</p>
<h3>HCI Contributions in Mental Health: A Modular Framework to Guide Psychosocial Intervention Design</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Petr Slovak, Sean Munson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148036">Link</a></p>
<p>Abstract: Many people prefer psychosocial interventions for mental health care or other concerns, but these interventions are often complex and unavailable in settings where people seek care. Intervention designers use technology to improve user experience or reach of interventions, and HCI researchers have made many contributions toward this goal. Both HCI and mental health researchers must navigate tensions between innovating on and adhering to the theories of change that guide intervention design. In this paper, we propose a framework that describes design briefs and evaluation approaches for HCI contributions at the scopes of capabilities, components, intervention systems, and intervention implementations. We show how theories of change (from mental health) can be translated into design briefs (in HCI), and that these translations can bridge and coordinate efforts across fields. It is our hope that this framework can support researchers in motivating, planning, conducting, and communicating work that advances psychosocial intervention design. </p>
<h3>“Can you be with that feeling?”: Extending Design Strategies for Interoceptive Awareness for the Context of Mental Health</h3>
<p>Authors: A. Jess Williams, Petr Slovak, MacKenzie D. A. Robertson, Phoebe Staab</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146761">Link</a></p>
<p>Abstract: Awareness of internal sensations, or interoceptive awareness (IA) is a topic of interest spanning multiple disciplines. In psychology, several therapeutic frameworks which cultivate IA have emerged. Meanwhile, HCI designers have developed novel approaches to IA across diverse contexts and design goals. These HCI strategies may hold value for mental health, however, it's unclear to what degree designerly IA techniques match or contrast with those used in therapeutic settings. We seek to address this gap in two parts. First, we offer a set of design opportunities based on IA practices used in HCI and findings from interviews with 22 counselors. Second, we share context-specific insights from a 5-week probe study involving 24 young women with nonclinical disordered eating behaviors, which are linked to interoceptive deficits. Together, the design opportunities and probe study findings provide guidance and highlight open questions regarding the design of technology-mediated IA support for mental health.</p>
<h3>''I Call Upon a Friend'': Virtual Reality-Based Supports for Cognitive Reappraisal Identified through Co-designing with Adolescents</h3>
<p>Authors: Artun Cimensel, Alissa Antle, Ashu Adhikari, Alexandra Kitson, Kenneth Karthik, Sadhbh Kenny, Melissa Chan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147702">Link</a></p>
<p>Abstract: Virtual reality (VR) offers great promise to expand delivery models for therapeutic interventions to help adolescents develop adaptive emotion regulation skills. Cognitive reappraisal (CR) is an emotion regulation skill that involves changing your thinking to improve your emotional state. However, adolescents face developmental and implementation barriers to do CR successfully. To better understand adolescents' (15-18 years) lived experience of CR challenges and how they envision VR could support their skills learning and transfer to everyday life, we ran three co-design workshops (N=69). Our research weaves together the workshop findings with prior literature to identify directions for future VR-based CR interventions. From our study results, we generated design strategies leveraging best practices of existing research: embedded and embodied scaffolds, providing different points of view, and externalizing the inner self. To illustrate these strategies in practice, we show how each would work in a challenging emotional scenario identified by adolescents.</p>
<h2>Mental Health and AI</h2>
<h3>Patient Perspectives on AI-Driven Predictions of Schizophrenia Relapses: Understanding Concerns and Opportunities for Self-Care and Treatment</h3>
<p>Authors: Viet Cuong Nguyen, Munmun De Choudhury, Dong Whi Yoo, Hayoung Woo, Kaylee Kruzan, Gregory Abowd, Michael L. Birnbaum, Jennifer Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147243">Link</a></p>
<p>Abstract: Early detection and intervention for relapse is important in the treatment of schizophrenia spectrum disorders. Researchers have developed AI models to predict relapse from patient-contributed data like social media. However, these models face challenges, including misalignment with practice and ethical issues related to transparency, accountability, and potential harm. Furthermore, how patients who have recovered from schizophrenia view these AI models has been underexplored. To address this gap, we first conducted semi-structured interviews with 28 patients and reflexive thematic analysis, which revealed a disconnect between AI predictions and patient experience, and the importance of the social aspect of relapse detection. In response, we developed a prototype that used patients' Facebook data to predict relapse. Feedback from seven patients highlighted the potential for AI to foster collaboration between patients and their support systems, and to encourage self-reflection. Our work provides insights into human-AI interaction and suggests ways to empower people with schizophrenia.</p>
<h3>Understanding Human-AI Collaboration in Music Therapy Through Co-Design with Therapists</h3>
<p>Authors: Jingjing Sun, Jingyi Yang, Jiangtao Gong, Guyue Zhou, Yucheng Jin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146901">Link</a></p>
<p>Abstract: The rapid development of musical AI technologies has expanded the creative potential of various musical activities, ranging from music style transformation to music generation. However, little research has investigated how musical AIs can support music therapists, who urgently need new technology support. This study used a mixed method, including semi-structured interviews and a participatory design approach. By collaborating with music therapists, we explored design opportunities for musical AIs in music therapy. We presented the co-design outcomes involving the integration of musical AIs into a music therapy process, which was developed from a theoretical framework rooted in emotion-focused therapy. After that, we concluded the benefits and concerns surrounding music AIs from the perspective of music therapists. Based on our findings, we discussed the opportunities and design implications for applying musical AIs to music therapy. Our work offers valuable insights for developing human-AI collaborative music systems in therapy involving complex procedures and specific requirements.</p>
<h3>Simulating Emotions With an Integrated Computational Model of Appraisal and Reinforcement Learning</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jussi Jokinen, Bernhard Hilpert, Jiayi Zhang, Joost Broekens</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147014">Link</a></p>
<p>Abstract: Predicting users' emotional states during interaction is a long-standing goal of affective computing. However, traditional methods based on sensory data alone fall short due to the interplay between users' latent cognitive states and emotional responses. To address this, we introduce a computational cognitive model that simulates emotion as a continuous process, rather than a static state, during interactive episodes. This model integrates cognitive-emotional appraisal mechanisms with computational rationality, utilizing value predictions from reinforcement learning. Experiments with human participants demonstrate the model's ability to predict and explain the emergence of emotions such as happiness, boredom, and irritation during interactions. Our approach opens the possibility of designing interactive systems that adapt to users' emotional states, thereby improving user experience and engagement. This work also deepens our understanding of the potential of modeling the relationship between reward processing, reinforcement learning, goal-directed behavior, and appraisal.</p>
<h3>Facilitating Self-Guided Mental Health Interventions Through Human-Language Model Interaction: A Case Study of Cognitive Restructuring</h3>
<p>Authors: Tim Althoff, Kevin Rushton, Theresa Nguyen, Inna Lin, Ashish Sharma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147699">Link</a></p>
<p>Abstract: Self-guided mental health interventions, such as "do-it-yourself" tools to learn and practice coping strategies, show great promise to improve access to mental health care. However, these interventions are often cognitively demanding and emotionally triggering, creating accessibility barriers that limit their wide-scale implementation and adoption. In this paper, we study how human-language model interaction can support self-guided mental health interventions. We take cognitive restructuring, an evidence-based therapeutic technique to overcome negative thinking, as a case study. In an IRB-approved randomized field study on a large mental health website with 15,531 participants, we design and evaluate a system that uses language models to support people through various steps of cognitive restructuring. Our findings reveal that our system positively impacts emotional intensity for 67% of participants and helps 65% overcome negative thoughts. Although adolescents report relatively worse outcomes, we find that tailored interventions that simplify language model generations improve overall effectiveness and equity.</p>
<h3>Seeking in Cycles: How Users Leverage Personal Information Ecosystems to Find Mental Health Information</h3>
<p>Authors: Abhishek Roy, Ashlee Milton, Rebecca Umbach, Stevie Chancellor, Juan Maestre</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146836">Link</a></p>
<p>Abstract: Information is crucial to how people understand their mental health and well-being, and many turn to online sources found through search engines and social media. We present an interview study (n = 17) of participants who use online platforms to seek information about their mental illnesses. Participants use their personal information ecosystems in a cyclical process to find information. This cycle is driven by the adoption of new information and questioning the credibility of information. Privacy concerns fueled by perceptions of stigma and platform design also influence their information-seeking decisions. Our work proposes theoretical implications for social computing and information retrieval on information seeking in users' personal information ecosystems. We offer design implications to support users in navigating personal information ecosystems to find mental health information.</p>
<h2>Mindfulness and Goals</h2>
<h3>Fragmented Moments, Balanced Choices: How Do People Make Use of Their Waiting Time?</h3>
<p>Authors: Jian Zheng, Ge Gao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147136">Link</a></p>
<p>Abstract: Everyone spends some time waiting every day. HCI research has developed tools for boosting productivity while waiting. However, little is known about how people naturally spend their waiting time. We conducted an experience sampling study with 21 working adults who used a mobile app to report their daily waiting time activities over two weeks. The aim of this study is to understand the activities people do while waiting and the effect of situational factors. We found that participants spent about 60% of their waiting time on leisure activities, 20% on productive activities, and 20% on maintenance activities. These choices are sensitive to situational factors, including accessible device, location, and certain routines of the day. Our study complements previous ones by demonstrating that people purpose waiting time for various goals beyond productivity and to maintain work-life balance. Our findings shed light on future empirical research and system design for time management.</p>
<h3>Mindful Scroll: An Infinite Scroll Abstract Colouring App for Mindfulness</h3>
<p>Authors: Craig Kaplan, Saralin Zassman, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147867">Link</a></p>
<p>Abstract: We design and evaluate Mindful Scroll, a mobile application for mindfulness that encourages a slow and deliberate approach to colouring. The app renders an infinite scroll of generated geometric tilings that reveal pseudo-random colour palettes and fill effects when coloured using a finger or pen. A five-day study (N=28) evaluated the efficacy of the app in reducing anxiety and enhancing mindfulness. The results indicate that the app is capable of promoting a greater sense of mindfulness over time and produced similar results across several measures compared to traditional structured colouring and existing mindfulness-based mobile applications. All participants expressed a desire to use the app again, with a majority stating they felt more mindful after the study.</p>
<h3>My Voice as a Daily Reminder: Self-Voice Alarm for Daily Goal Achievement</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jieun Kim, Hayeon Song</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146620">Link</a></p>
<p>Abstract: Sticking to daily plans is essential for achieving life goals but challenging in reality. This study presents a self-voice alarm as a novel daily goal reminder. Based on the strong literature on the psychological effects of self-voice, we developed a voice alarm system that reminds users of daily tasks to support their consistent task completion. Over the course of 14 days, participants (N = 63) were asked to complete daily vocabulary tasks when reminded by an alarm (i.e., self-voice vs. other-voice vs. beep sound alarm). The self-voice alarm elicited higher alertness and uncomfortable feelings while fostering more days of task completion and repetition compared to the beep sound alarm. Both self-voice and other-voice alarms increased users’ perceived usefulness of the alarm system. Leveraging both quantitative and qualitative approaches, we provide a practical guideline for designing voice alarm systems that will foster users’ behavioral changes to achieve daily goals.</p>
<h3>Leveraging Idle Games to Incentivize Intermittent and Frequent Practice of Deep Breathing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Book Sadprasid, Scott Bateman, Anne Mei, Alex Mariakakis, Fanny Chevalier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147724">Link</a></p>
<p>Abstract: The need for frequent and brief practice in deep breathing presents challenges in maintaining motivation and consistency.</p>
<p>While persuasive technologies have been shown to improve engagement in therapeutic exercises, there is a lack of insight into specific motivational strategies for such intermittent activities. We investigate how idle games can incentivize behaviors like deep breathing and identify specific mechanics for fostering an optimal practice cycle. We illustrate this approach in a game called \textit{BreathPurr-suade}. After validating the physiological efficacy of the embedded breathing guide, our four-week study revealed idle games are more effective in maintaining deep breathing adherence than a standard breathing guide. Our work highlights the capacity of idle games to foster deep breathing, revealing their efficacy in subtle persuasive game designs that encourage intermittent therapeutic practices.</p>
<h3>Stairway to Heaven: A Gamified VR Journey for Breath Awareness</h3>
<p>Authors: Giovanni Troiano, Joseph Schwab, Hamid Ghaednia, Caleb Myers, Amir Abdollahi, Nathan Miner, Casper Harteveld, Mehmet Kosa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147670">Link</a></p>
<p>Abstract: Gamification and virtual reality (VR) are increasingly being explored for their potential to enhance mindful practices and well-being. We further explore the potential of gamification and VR for breath awareness and mindfulness, and contribute Stairway to Heaven, a VR artifact that combines gamification with respiratory sensor biofeedback to cultivate mindful awareness of breathing. In our mixed-method study with 21 participants, we evaluated the usability and effectiveness of our artifact in promoting breathing frequencies between 4 and 10 breaths per minute (BPM). We integrate breath-driven teleportation as a virtual locomotion technique (VLT) using respiratory biofeedback to gamify progression through a virtual wilderness. Additionally, we supplement our design with a mindfulness audio guide. The results of our user study showcase the potential of combining actionable gamification and VR, guided mindfulness, and breath-driven VLT to foster slow breathing self-regulation successfully.</p>
<h2>Participatory AI</h2>
<h3>How Do Analysts Understand and Verify AI-Assisted Data Analyses?</h3>
<p>Authors: Ruoxi Shang, Steven Drucker, Tim Althoff, Ken Gu, Chenglong Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148040">Link</a></p>
<p>Abstract: Data analysis is challenging as it requires synthesizing domain knowledge, statistical expertise, and programming skills. Assistants powered by large language models (LLMs), such as ChatGPT, can assist analysts by translating natural language instructions into code. However, AI-assistant responses and analysis code can be misaligned with the analyst's intent or be seemingly correct but lead to incorrect conclusions. Therefore, validating AI assistance is crucial and challenging. Here, we explore how analysts understand and verify the correctness of AI-generated analyses. To observe analysts in diverse verification approaches, we develop a design probe equipped with natural language explanations, code, visualizations, and interactive data tables with common data operations. Through a qualitative user study (n=22) using this probe, we uncover common behaviors within verification workflows and how analysts' programming, analysis, and tool backgrounds reflect these behaviors. Additionally, we provide recommendations for analysts and highlight opportunities for designers to improve future AI-assistant experiences.</p>
<h3>From Fitting Participation to Forging Relationships: The Art of Participatory ML</h3>
<p>Authors: Alexandra Zafiroglu, Ned Cooper</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148266">Link</a></p>
<p>Abstract: Participatory machine learning (ML) encourages the inclusion of end users and people affected by ML systems in design and development processes. We interviewed 18 participation brokers—individuals who facilitate such inclusion and transform the products of participants' labour into inputs for an ML artefact or system—across a range of organisational settings and project locations. Our findings demonstrate the inherent challenges of integrating messy contextual information generated through participation with the structured data formats required by ML workflows and the uneven power dynamics in project contexts. We advocate for evolution in the role of brokers to more equitably balance value generated in Participatory ML projects for design and development teams with value created for participants. To move beyond 'fitting' participation to existing processes and empower participants to envision alternative futures through ML, brokers must become educators and advocates for end users, while attending to frustration and dissent from indirect stakeholders.</p>
<h3>Explaining It Your Way - Findings from a Co-Creative Design Workshop on Designing XAI Applications with AI End-Users from the Public Sector</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ceenu George, Maris Männiste, Katharina Weitz, Ruben Schlagowski, Elisabeth André</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148130">Link</a></p>
<p>Abstract: Human-Centered AI prioritizes end-users' needs like transparency and usability. This is vital for applications that affect people's everyday lives, such as social assessment tasks in the public sector. This paper discusses our pioneering effort to involve public sector AI users in XAI application design through a co-creative workshop with unemployment consultants from Estonia. The workshop's objectives were identifying user needs and creating novel XAI interfaces for the used AI system. As a result of our user-centered design approach, consultants were able to develop AI interface prototypes that would support them in creating success stories for their clients by getting detailed feedback and suggestions. We present a discussion on the value of co-creative design methods with end-users working in the public sector to improve AI application design and provide a summary of recommendations for practitioners and researchers working on AI systems in the public sector. </p>
<h3>Generative AI in the Wild: Prospects, Challenges, and Strategies</h3>
<p>Authors: Ting Wang, Yuan Sun, Eunchae Jang, Fenglong Ma</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146627">Link</a></p>
<p>Abstract: Propelled by their remarkable capabilities to generate novel and engaging content, Generative Artificial Intelligence (GenAI) technologies are disrupting traditional workflows in many industries. While prior research has examined GenAI from a techno-centric perspective, there is still a lack of understanding about how users perceive and utilize GenAI in real-world scenarios. To bridge this gap, we conducted semi-structured interviews with (N = 18) GenAI users in creative industries, investigating the human-GenAI co-creation process within a holistic LUA (Learning, Using and Assessing) framework. Our study uncovered an intriguingly complex landscape: Prospects -- GenAI greatly fosters the co-creation between human expertise and GenAI capabilities, profoundly transforming creative workflows; Challenges -- Meanwhile, users face substantial uncertainties and complexities arising from resource availability, tool usability, and regulatory compliance; Strategies -- In response, users actively devise various strategies to overcome many of such challenges. Our study reveals key implications for the design of future GenAI tools. </p>
<h3>The Situate AI Guidebook: Co-Designing a Toolkit to Support Multi-Stakeholder, Early-stage Deliberations Around Public Sector AI Proposals</h3>
<p>Authors: Kenneth Holstein, Anna Kawakami, Haiyi Zhu, Amanda Coston, Hoda Heidari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147906">Link</a></p>
<p>Abstract: Public sector agencies are rapidly deploying AI systems to augment or automate critical decisions in real-world contexts like child welfare, criminal justice, and public health. </p>
<p>A growing body of work documents how these AI systems often fail to improve services in practice. These failures can often be traced to decisions made during the early stages of AI ideation and design, such as problem formulation. However, today, we lack systematic processes to support effective, early-stage decision-making about whether and under what conditions to move forward with a proposed AI project. To understand how to scaffold such processes in real-world settings, we worked with public sector agency leaders, AI developers, frontline workers, and community advocates across four public sector agencies and three community advocacy groups in the United States. Through an iterative co-design process, we created the Situate AI Guidebook: a structured process centered around a set of deliberation questions to scaffold conversations around (1) goals and intended use or a proposed AI system, (2) societal and legal considerations, (3) data and modeling constraints, and (4) organizational governance factors. We discuss how the guidebook's design is informed by participants’ challenges, needs, and desires for improved deliberation processes. We further elaborate on implications for designing responsible AI toolkits in collaboration with public sector agency stakeholders and opportunities for future work to expand upon the guidebook. This design approach can be more broadly adopted to support the co-creation of responsible AI toolkits that scaffold key decision-making processes surrounding the use of AI in the public sector and beyond.</p>
<h2>Privacy &amp; Boundaries</h2>
<h3>Under the (neighbor)hood: Hyperlocal Surveillance on Nextdoor</h3>
<p>Authors: Madiha Zahrah Choksi, Travis Lloyd, Marianne Aubin Le Quere, James Grimmelmann, Ruojia Tao, Mor Naaman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147901">Link</a></p>
<p>Abstract: This paper examines the tensions between neighborhood gentrification and community surveillance posts on Nextdoor, a hyperlocal social media platform for neighborhoods. We created a privacy-preserving pipeline to gather research data from public Nextdoor posts in Atlanta, Georgia and filtered these to a dataset of 1,537 community surveillance posts. We developed a qualitative codebook to label observed patterns of community surveillance, and deploy a large language model to tag these posts at scale. Ultimately, we present an extensible and empirically-tested typology of the modes of community surveillance that occur on hyperlocal platforms. We find a complex relationship between community surveillance posts and neighborhood gentrification, which indicates that publicly disclosing information about perceived outsiders, especially for petty crimes, is most prevalent in gentrifying neighborhoods. Our empirical evidence inform critical perspectives which posit that community surveillance on platforms like Nextdoor can exclude and marginalize minoritized populations, particularly in gentrifying neighborhoods. Our findings carry broader implications for hyperlocal social platforms and their potential to amplify and exacerbate social tensions and exclusion.</p>
<h3>What You Experience is What We Collect: User Experience Based Fine-Grained Permissions for Everyday Augmented Reality</h3>
<p>Authors: Melvin Abraham, Mohamed Khamis, Mark McGill</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146684">Link</a></p>
<p>Abstract: Everyday Augmented Reality (AR) headsets pose significant privacy risks, potentially allowing prolonged sensitive data collection of both users and bystanders (e.g. members of the public). While users control data access through permissions, current AR systems inherit smartphone permission prompts, which may be less appropriate for all-day AR. This constrains informed choices and risks over-privileged access to sensors. We propose (N=20) a novel AR permission control system that allows better-informed privacy decisions and evaluate it using five mock application contexts. Our system's novelty lies in enabling users to experience the varying impacts of permission levels on not only a) privacy, but also b) application functionality. This empowers users to better understand what data an application depends on and how its functionalities are impacted by limiting said data. Participants found that our method allows for making better informed privacy decisions, and deemed it more transparent and trustworthy than state-of-the-art AR and smartphone permission systems taken from Android and iOS. Our results offer insights into new and necessary AR permission systems, improving user understanding and control over data access.</p>
<h3>“I Don’t Want to Become a Number’’: Examining Different Stakeholder Perspectives on a Video-Based Monitoring System for Senior Care with Inherent Privacy Protection (by Design).</h3>
<p>Authors: Tamara Mujirishvili, Kooshan Hashemifard, Francisco Florez-Revuelta, Pau Climent-Pérez, Anton Fedosov</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146872">Link</a></p>
<p>Abstract: Active and Assisted Living (AAL) technologies aim to enhance the quality of life of older adults and promote successful aging. While video-based AAL solutions offer rich capabilities for better healthcare management in older age, they pose significant privacy risks. To mitigate the risks, we developed a video-based monitoring system that incorporates different privacy-preserving filters. We deployed the system in one assistive technology center and conducted a qualitative study with older adults and other stakeholders involved in care provision. Our study demonstrates diverse users’ perceptions and experiences with video-monitoring technology and offers valuable insights for the system’s further development. The findings unpack the privacy-versus-safety trade-off inherent in video-based technologies and discuss how the privacy-preserving mechanisms within the system mitigate privacy-related concerns. The study also identifies varying stakeholder perspectives towards the system in general and highlights potential avenues for developing video-based monitoring technologies in the AAL context.</p>
<h3>Bring Privacy To The Table: Interactive Negotiation for Privacy Settings of Shared Sensing Devices</h3>
<p>Authors: Haozhe Zhou, Mayank Goel, Yuvraj Agarwal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147351">Link</a></p>
<p>Abstract: To address privacy concerns with the Internet of Things (IoT) devices, researchers have proposed enhancements in data collection transparency and user control. However, managing privacy preferences for shared devices with multiple stakeholders remains challenging. We introduced ThingPoll, a system that helps users negotiate privacy configurations for IoT devices in shared settings. We designed ThingPoll by observing twelve participants verbally negotiating privacy preferences, from which we identified potentially successful and inefficient negotiation patterns. ThingPoll bootstraps a preference model from a custom crowdsourced privacy preferences dataset. During negotiations, ThingPoll strategically scaffolds the process by eliciting users’ privacy preferences, providing helpful contexts, and suggesting feasible configuration options. We evaluated ThingPoll with 30 participants negotiating the privacy settings of 4 devices. Using ThingPoll, participants reached an agreement in 97.5% of scenarios within an average of 3.27 minutes. Participants reported high overall satisfaction of 83.3% with ThingPoll as compared to baseline approaches.</p>
<h3>What to the Muslim is Internet search: Digital Borders as Barriers to Information</h3>
<p>Authors: Sucheta Ghoshal, Lubna Razaq</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147363">Link</a></p>
<p>Abstract: In today's digital age, searching for information online is considered a ubiquitous task that can be accomplished in just a few moments using various web-based technologies. Yet, information seeking has geopolitical burdens for users who are racialized and marginalized by the nation-state and other structures of power. In our paper, we conducted a qualitative interview study with 15 Muslim participants, mostly of South Asian origin, living in the US with varying citizenship or (non)immigration status about their information needs and concerns around privacy as a Muslim, and the resulting restrictive patterns of information seeking on various Internet platforms. We argue that our findings on the barriers faced and strategies employed by Muslim residents toward information access suggest a broader pattern of digital manifestations of border imperialism. We posit that HCI researchers should pay attention to how "digital borders" have epistemic implications for people marginalized by geopolitical boundaries.</p>
<h2>Privacy for Safer Web and Apps</h2>
<h3>“That’s Kind of Sus(picious)”: The Comprehensiveness of Mental Health Application Users’ Privacy and Security Concerns</h3>
<p>Authors: Rachael Kang, Helena M. Mentis, Yi Xuan Khoo, Tera L. Reynolds</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146698">Link</a></p>
<p>Abstract: With the increasing usage of mental health applications (MHAs), there is growing concern regarding their data privacy practices. Analyzing 437 user reviews from 83 apps, we outline users’ predominant privacy and security concerns with currently available apps. We then compare those concerns to criteria from two prominent app evaluation websites -- Privacy Not Included and One Mind PsyberGuide. Our findings show that MHA users have myriad data privacy and security concerns including a user's control over their own data, but these concerns do not often overlap with those of experts from evaluation websites who focus more on issues such as required password strength. We highlight this disconnect and propose solutions in how the mental health care ecosystem can provide better guidance to MHA users and experts from the fields of privacy and security and mental health technology in choosing and evaluating, respectively, potentially useful mental health apps. </p>
<h3>Websites Need Your Permission Too -- User Sentiment and Decision-Making on Web Permission Prompts in Desktop Chrome</h3>
<p>Authors: Marian Harbach</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147321">Link</a></p>
<p>Abstract: The web utilizes permission prompts to moderate access to certain capabilities. We present the first investigation of user behavior and sentiment of this security and privacy measure on the web, using 28 days of telemetry data from more than 100M Chrome installations on desktop platforms and experience sampling responses from 25,706 Chrome users. Based on this data, we find that ignoring and dismissing permission prompts are most common for geolocation and notifications. Permission prompts are perceived as more annoying and interrupting when they are not allowed, and most respondents cite a rational reason for the decision they took. Our data also supports that the perceived availability of contextual information from the requesting website is associated with allowing access to a requested capability. More usable permission controls could facilitate adoption of best practices that address several of the identified challenges; and ultimately could lead to better user experiences and a safer web.</p>
<h3>PriviAware: Exploring Data Visualization and Dynamic Privacy Control Support for Data Collection in Mobile Sensing Research</h3>
<p>Authors: Yugyeong Jung, Uichin Lee, Hei Yiu Law, Seolyeong Bae, Hyunsoo Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148313">Link</a></p>
<p>Abstract: With increased interest in leveraging personal data collected from 24/7 mobile sensing for digital healthcare research, supporting user-friendly consent to data collection for user privacy has also become important. This work proposes \emph{PriviAware}, a mobile app that promotes flexible user consent to data collection with data exploration and contextual filters that enable users to turn off data collection based on time and places that are considered privacy-sensitive. We conducted a user study (N = 58) to explore how users leverage data exploration and contextual filter functions to explore and manage their data and whether our system design helped users mitigate their privacy concerns. Our findings indicate that offering fine-grained control is a promising approach to raising users’ privacy awareness under the dynamic nature of the pervasive sensing context. We provide practical privacy-by-design guidelines for mobile sensing research.</p>
<h3>Privacy of Default Apps in Apple’s Mobile Ecosystem</h3>
<p>Authors: Janne Lindqvist, Amel Bourdoucen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147013">Link</a></p>
<p>Abstract: Users need to configure default apps when they first start using their devices. The privacy configurations of these apps do not always match what users think they have initially enabled. We first explored the privacy configurations of eight default apps Safari, Siri, Family Sharing, iMessage, FaceTime, Location Services, Find My and Touch ID. We discovered serious issues with the documentation of these apps. Based on this, we studied users' experiences with an interview study (N=15). We show that: the instructions of setting privacy configurations of default apps are vague and lack required steps; users were unable to disable default apps from accessing their personal information; users assumed they were being tracked by some default apps; default apps may cause tensions in family relationships because of information sharing. Our results illuminate on the privacy and security implications of configuring the privacy of default apps and how users understand the mobile ecosystem.</p>
<h3>Measuring Compliance with the California Consumer Privacy Act Over Space and Time</h3>
<p>Authors: Van Tran, Aarushi Mehrotra, Lior Strahilevitz, Marshini Chetty, Nick Feamster, Jens Frankenreiter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147035">Link</a></p>
<p>Abstract: The widespread sharing of consumers' personal information with third parties </p>
<pre><code>raises significant privacy concerns. The California Consumer Privacy Act (CCPA)

mandates that online businesses offer consumers the option to opt out of the sale

and sharing of personal information. Our study
</code></pre>
<p>automatically tracking the presence of the opt-out link longitudinally across multiple </p>
<pre><code>states after the California Privacy Rights Act (CPRA) went into effect. We categorize

websites based on whether they are subject to CCPA and investigate cases of potential

non-compliance. We find a number of websites that implement the opt-out link early and

across all examined states but also find a significant number of CCPA-subject websites

that fail to offer any opt-out methods even when CCPA is in effect. Our findings can

shed light on how websites are reacting to the CCPA and identify potential gaps in

compliance and opt-out method designs that hinder consumers from exercising CCPA opt-out

rights.
</code></pre>
<h2>Privacy and Deepfake</h2>
<h3>Non-Consensual Synthetic Intimate Imagery: Prevalence, Attitudes, and Knowledge in 10 Countries</h3>
<p>Authors: Nicola Henry, Rebecca Umbach, Colleen Berryessa, Gemma Beard</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148314">Link</a></p>
<p>Abstract: Deepfake technologies have become ubiquitous, <code>democratizing'' the ability to manipulate photos and videos. One popular use of deepfake technology is the creation of sexually explicit content, which can then be posted and shared widely on the internet. Drawing on a survey of over 16,000 respondents in 10 different countries, this article examines attitudes and behaviors related to</code>deepfake pornography'' as a specific form of non-consensual synthetic intimate imagery (NSII). Our study found that deepfake pornography behaviors were considered harmful by respondents, despite nascent societal awareness. Regarding the prevalence of deepfake pornography victimization and perpetration, 2.2% of all respondents indicated personal victimization, and 1.8% all of respondents indicated perpetration behaviors. Respondents from countries with specific legislation still reported perpetration and victimization experiences, suggesting NSII laws are inadequate to deter perpetration. Approaches to prevent and reduce harms may include digital literacy education, as well as enforced platform policies, practices, and tools which better detect, prevent, and respond to NSII content. </p>
<h3>It's Trying Too Hard To Look Real: Deepfake Moderation Mistakes and Identity-Based Bias</h3>
<p>Authors: Collins Munyendo, Gang Wang, Jaron Mink, Kurt Hugenberg, Tadayoshi Kohno, Elissa Redmiles, Miranda Wei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147959">Link</a></p>
<p>Abstract: Online platforms employ manual human moderation to distinguish human-created social media profiles from deepfake-generated ones. Biased misclassification of real profiles as artificial can harm general users as well as specific identity groups; however, no work has yet systematically investigated such mistakes and biases. We conducted a user study (n=695) that investigates how 1) the identity of the profile, 2) whether the moderator shares that identity, and 3) components of a profile shown affect the perceived artificiality of the profile. We find statistically significant biases in people's moderation of LinkedIn profiles based on all three factors. Further, upon examining how moderators make decisions, we find they rely on mental models of AI and attackers, as well as typicality expectations (how they think the world works). The latter includes reliance on race/gender stereotypes. Based on our findings, we synthesize recommendations for the design of moderation interfaces, moderation teams, and security training.</p>
<h3>Examining Human Perception of Generative Content Replacement in Image Privacy Protection</h3>
<p>Authors: Koji Yatani, Shitao Fang, Anran Xu, Simo Hosio, Huan Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148241">Link</a></p>
<p>Abstract: The richness of the information in photos can often threaten privacy, thus image editing methods are often employed for privacy protection. Existing image privacy protection techniques, like blurring, often struggle to maintain the balance between robust privacy protection and preserving image usability. To address this, we introduce a generative content replacement (GCR) method in image privacy protection, which seamlessly substitutes privacy-threatening contents with similar and realistic substitutes, using state-of-the-art generative techniques. Compared with four prevalent image protection methods, GCR consistently exhibited low detectability, making the detection of edits remarkably challenging. GCR also performed reasonably well in hindering the identification of specific content and managed to sustain the image's narrative and visual harmony. This research serves as a pilot study and encourages further innovation on GCR and the development of tools that enable human-in-the-loop image privacy protection using approaches similar to GCR.</p>
<h3>Dungeons &amp; Deepfakes: Using scenario-based role-play to study journalists' behavior towards using AI-based verification tools for video content</h3>
<p>Authors: Matthew Wright, Yijing Kelly Wu, Andrea Hickerson, Saniat Sohrawardi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146663">Link</a></p>
<p>Abstract: The evolving landscape of manipulated media, including the threat of deepfakes, has made information verification a daunting challenge for journalists. Technologists have developed tools to detect deepfakes, but these tools can sometimes yield inaccurate results, raising concerns about inadvertently disseminating manipulated content as authentic news. This study examines the impact of unreliable deepfake detection tools on information verification. We conducted role-playing exercises with 24 US journalists, immersing them in complex breaking-news scenarios where determining authenticity was challenging. Through these exercises, we explored questions regarding journalists' investigative processes, use of a deepfake detection tool, and decisions on when and what to publish. Our findings reveal that journalists are diligent in verifying information, but sometimes rely too heavily on results from deepfake detection tools. We argue for more cautious release of such tools, accompanied by proper training for users to mitigate the risk of unintentionally propagating manipulated content as real news.</p>
<h3>Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks</h3>
<p>BEST_PAPER</p>
<p>Authors: Hao-Ping (Hank) Lee, Sauvik Das, Thomas Serban von Davier, Jodi Forlizzi, Yu-Ju Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146930">Link</a></p>
<p>Abstract: Privacy is a key principle for developing ethical AI technologies, but how does including AI technologies in products and services change privacy risks?</p>
<p>We constructed a taxonomy of AI privacy risks by analyzing 321 documented AI privacy incidents.</p>
<p>We codified how the unique capabilities and requirements of AI technologies described in those incidents generated new privacy risks, exacerbated known ones, or otherwise did not meaningfully alter the risk.</p>
<p>We present 12 high-level privacy risks that AI technologies either newly created (e.g., exposure risks from deepfake pornography) or exacerbated (e.g., surveillance risks from collecting training data).</p>
<p>One upshot of our work is that incorporating AI technologies into a product can alter the privacy risks it entails.</p>
<p>Yet, current approaches to privacy-preserving AI/ML (e.g., federated learning, differential privacy, checklists) only address a subset of the privacy risks arising from the capabilities and data requirements of AI.</p>
<h2>Reflection and Regulation for Wellbeing</h2>
<h3>“I feel like he’s looking in the computer world to be social, but I can’t trust his judgement”: Reimagining Parental Control for Children with ASD</h3>
<p>Authors: Prakriti Dumaru, Mahdi Nasrullah Al-Ameen, Audrey Flood, Bryson Hackler</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147979">Link</a></p>
<p>Abstract: Children with Autism Spectrum Disorder (ASD) often seek comfort from devices (e.g., smartphones) to deal with social overstimulation. However, such reliance exposes them to inappropriate digital content and increases susceptibility to mimicry and social vulnerability. Thus, parents having children with ASD encounter unique challenges in regulating their device usage, which are little addressed in the existing literature on parental mediation. As we begin to address this gap, we designed low-fidelity prototypes centered around open communication and self-regulation, which we refined based on the feedback from six ASD experts in two focus groups. We evaluated updated designs (presented in form of storyboards) through semi-structured interviews with 25 parents whose children with ASD (aged below 14) are active Internet users. Our study joins the body of work on parental mediation; our findings provide insights into inclusive parental control tools for children with ASD, and offer guidelines for future research in these directions.</p>
<h3>Supporting Experiential Learning in People with Gestational Diabetes Mellitus</h3>
<p>Authors: Chia-Fang Chung, Clara Caldeira, Zaidat Ibrahim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147011">Link</a></p>
<p>Abstract: Managing Gestational Diabetes Mellitus (GDM) is a significant challenge for pregnant individuals. Constant self-monitoring, emotional burden, and the short and long-term implications of GDM make the overall pregnancy experience challenging for these individuals, requiring action, learning, and lifestyle adjustment to manage the pregnancy properly. Prior literature on GDM mostly focuses on the medical and health management of the condition. However, pregnant individuals with GDM often must actively learn and adapt lifestyle strategies quickly without much support. Through semi-structured interviews with 13 pregnant individuals diagnosed with GDM, we investigate how these individuals experience, explore, learn, and reflect on ways to live with and manage GDM. Using Kolb's Learning Theory to analyze and structure our findings, we built on pregnant individuals' concrete lived experiences and uncovered the challenges as they navigate the GDM journey, managing their changing relationship with food and supporting emotional well-being while living with an often stigmatized condition in an at-risk pregnancy. Our study contributes to the discussion on the design opportunities to facilitate experiential learning of pregnant individuals' journey.</p>
<h3>Momentary Stressor Logging and Reflective Visualizations: Implications for Stress Management with Wearables</h3>
<p>Authors: Mithun Saha, Nasir Ali, David M. Almeida, Santosh Kumar, Anandatirtha Nandugudi, Shahin Samiei, Timothy Hnat, Sameer Neupane</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148091">Link</a></p>
<p>Abstract: Commercial wearables from Fitbit, Garmin, and Whoop have recently introduced real-time notifications based on detecting changes in physiological responses indicating potential stress. In this paper, we investigate how these new capabilities can be leveraged to improve stress management. We developed a smartwatch app, a smartphone app, and a cloud service, and conducted a 100-day field study with 122 participants who received prompts triggered by physiological responses several times a day. They were asked whether they were stressed, and if so, to log the most likely stressor. Each week, participants received new visualizations of their data to self-reflect on patterns and trends. Participants reported better awareness of their stressors, and self-initiating fourteen kinds of behavioral changes to reduce stress in their daily lives. Repeated self-reports over 14 weeks showed reductions in both stress intensity (in 26,521 momentary ratings) and stress frequency (in 1,057 weekly surveys).</p>
<h3>From Disorientation to Harmony: Autoethnographic Insights into Transformative Videogame Experiences</h3>
<p>BEST_PAPER</p>
<p>Authors: Jaakko Väkevä, Elisa Mekler, Janne Lindqvist</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147641">Link</a></p>
<p>Abstract: Videogames can transform the perspectives and attitudes of players. Prior discussion on this transformative potential has typically been limited to non-entertainment videogames with explicit transformational goals. However, recreational gaming appears to hold considerable potential for igniting deeply personal experiences of profound transformation in players. Towards understanding this phenomenon, we conducted an explorative autoethnographic study. For this, the first author played five narrative-driven videogames while collecting self-observational and self-reflective data of his experience during and outside gameplay. Our findings offer intimate insights into the trajectory and emotional qualities of personally meaningful and transformative videogame experiences. For example, we found that gameplay experiences that were initially perceived as bewildering or disorienting could evolve into more harmonious experiences laden with personal meaning. This shift in experience developed through different forms of subsequent re-engagement with initially discrepant game encounters.</p>
<h3>New Understandings of Loss: Examining the Role of Reflective Technology Within Bereavement and Meaning-Making</h3>
<p>Authors: Chia-Fang Chung, Colin LeFevre</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147535">Link</a></p>
<p>Abstract: Bereavement causes unique challenges, and bereaved individuals can benefit from support during their grieving process. Grief theory emphasizes the importance of reflection during bereavement, and HCI has established that reflective technology can support well-being. However, it remains unclear how to provide bereavement support with reflective technology. We build on constructivist grief psychotherapies to investigate bereavement meaning-making as a focus for reflective technology. We study meaning-making in the context of the digital game GRIS, due to digital games' alignment with meaning-making. To understand the progression of meaning-making experiences, we conducted a qualitative diary and interview study: 11 bereaved individuals were interviewed on their bereavement experiences, played and completed diaries on GRIS, and were interviewed on their experiences engaging in meaning-making while playing. From these findings, we propose design recommendations for reflective technology to engage with individualized bereavement experiences, embed user agency within reflections, and focus on novel and anti-nihilistic reflections.</p>
<h2>Research Methods and Tools B</h2>
<h3>"To Click or not to Click": Back to Basic for Experience Sampling for Office Well-being in Shared Office Spaces</h3>
<p>Authors: Steven Houben, Hans Brombacher, Steven Vos, Dimitra Dritsa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147147">Link</a></p>
<p>Abstract: Sensors in offices mainly measure environmental data, missing qualitative insights into office workers' perceptions. This opens the opportunity for active individual participation in data collection. To promote reflection on office well-being while overcoming experience sampling challenges in terms of privacy, notification, and display overload, and in-the-moment data collection, we developed Click-IO. Click-IO is a tangible, privacy-sensitive, mobile experience sampling tool that collects contextual information. We evaluated Click-IO for 20-days. The system enabled real-time reflections for office workers, promoting self-awareness of their environment and well-being. Its non-digital design ensured privacy-sensitive feedback collection, while its mobility facilitated in-the-moment feedback. Based on our findings, we identify design recommendations for the development of mobile experience sampling tools. Moreover, the integration of contextual data with environmental sensor data presented a more comprehensive understanding of individuals' experiences. This research contributes to the development of experience sampling tools and sensor integration for understanding office well-being.</p>
<h3>Who is "I"?: Subjectivity and  Ethnography in HCI</h3>
<p>Authors: Heidi Biggs, Tejaswini Joshi, Jeffrey Bardzell, Shaowen Bardzell</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147561">Link</a></p>
<p>Abstract: HCI research applies ethnographic methods to understand and represent practices that involve the use of interactive systems. A subdomain of this work is interpretivist ethnography, which positions the researcher’s perspectival view [37] as central to ethnographic research and its epistemic contribution.  Given this we ask: How might ethnographic researchers in HCI surface the meaning-making role of their subjectivities in research? We reflect on our prior ethnographic fieldwork on small-scale sustainable farms in Indianapolis, Indiana to bring the ethnographic “I” into focus by articulating our reflections as “impressionist tales'' [64:101-124]. We ground this pursuit in sociologist Andrea Doucet’s concept of “gossamer walls” to surface researcher’s three reflexive relationships 1) with herself; 2) with participants; and 3) with her epistemic communities [34]. We build on and contribute to postmodern ethnography in HCI to clarify the epistemic virtues and methodological best practices of a more unapologetically subjective ethnographic practice in HCI.</p>
<h3>Understanding fraudulence in online qualitative studies: From the researcher's perspective</h3>
<p>Authors: Chia-Fang Chung, Chun-Han Ariel Wang, Seung Wan Ha, Kay Connelly, Aswati Panicker, Yuxing Wu, Katie Siek, Zaidat Ibrahim, Novia Nurain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147323">Link</a></p>
<p>Abstract: Researchers are increasingly facilitating qualitative research studies online. While this has made research more accessible for participation, there have been notable encounters with “fraudulent” participants. By fraudulent, we refer to individuals who are deceptive about meeting the inclusion criteria, their identity, or experiences. Fraudulent participants have generated new challenges for researchers who have to interact 1:1 with these individuals, face ethical dilemmas on appropriate next steps, diagnose and prevent the issue from happening again, and deal with their own identity as a scholar. In this study, we interview 16 HCI researchers to understand and learn from their experiences. We contribute: (1) an understanding of how HCI qualitative researchers deal with fraudulent participants; (2) a guide for qualitative HCI researchers on how to handle fraudulence; and (3) a reflection on how the HCI research community might better improve our science and training efforts.</p>
<h3>Did You Misclick? Reversing 5-Point Satisfaction Scales Causes Unintended Responses</h3>
<p>Authors: Martin Pielot</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147691">Link</a></p>
<p>Abstract: When fielding satisfaction questions, survey platforms offer the option to randomly reverse the response options. In this paper, we provide evidence that the use of this option leads to biased results. In Study 1, we show that reversing vertically oriented response options leads to significantly lower satisfaction ratings – from 90 to 82 percent in our case. Study 2 had survey respondents verify their response and found that on a reversed scale, the very-dissatisfied option was selected unintentionally in about half of the cases. The cause, shown by Study 3, is that survey respondents expect the positive option at the top and do not always pay sufficient attention to the question, combined with the similar spelling of satisfied and dissatisfied. To prevent unintentional responses from biasing the results, we recommend keeping the positive option at the top in vertically-oriented scales with visually-similar endpoint labels.</p>
<h3>Towards Estimating Missing Emotion Self-reports Leveraging User Similarity: A Multi-task Learning Approach</h3>
<p>Authors: Surjya Ghosh, Sougata Sen, Salma Mandi, Bivas Mitra, Pradipta De</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148276">Link</a></p>
<p>Abstract: The Experience Sampling Method (ESM) is widely used to collect emotion self-reports to train machine learning models for emotion inference. However, as ESM studies are time-consuming and burdensome, participants often withdraw in between. This unplanned withdrawal compels the researchers to discard the dropout participants’ data, significantly impacting the quality and quantity of the self-reports. To address this problem, we leverage only the self-reporting similarity across participants (unlike prior works that apply different machine learning approaches on additional modalities) for missing self-report estimation. In specific, we propose a Multi-task Learning (MTL) framework, MUSE, that constructs the missing self-reports of the dropout participants. We evaluate MUSE in two in-the-wild studies (N1=24, N2=30) of 6-week and 8-week duration, during which the participants reported four emotions (happy, sad, stressed, relaxed) using a smartphone application. The evaluation reveals that MUSE estimates the missing emotion self-reports with an average AUCROC of 84% (Study I) and 82% (Study II). A follow-up evaluation of MUSE for an emotion inference (downstream) task reveals no significant difference in emotion inference performance when estimated self-reports are used. These findings underscore the utility of MUSE in estimating missing self-reports in ESM studies and the applicability of MUSE for downstream tasks (e.g., emotion inference).</p>
<h2>Security Systems</h2>
<h3>Is a Trustmark and QR Code Enough? The Effect of IoT Security and Privacy Label Information Complexity on Consumer Comprehension and Behavior</h3>
<p>Authors: Xinran Li, Lorrie Cranor, Dillon Shu, Hamsini Ravishankar, Yuvraj Agarwal, Claire Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146756">Link</a></p>
<p>Abstract: The U.S. Government is developing a package label to help consumers access reliable security and privacy information about Internet of Things (IoT) devices when making purchase decisions. The label will include the U.S. Cyber Trust Mark, a QR code to scan for more details, and potentially additional information. To examine how label information complexity and educational interventions affect comprehension of security and privacy attributes and label QR code use, we conducted an online survey with 518 IoT purchasers. We examined participants' comprehension and preferences for three labels of varying complexities, with and without an educational intervention. Participants favored and correctly utilized the two higher-complexity labels, showing a special interest in the privacy-relevant content. Furthermore, while the educational intervention improved understanding of the QR code’s purpose, it had a modest effect on QR scanning behavior. We highlight clear design and policy directions for creating and deploying IoT security and privacy labels.</p>
<h3>I see an IC: A Mixed-Methods Approach to Study Human Problem-Solving Processes in Hardware Reverse Engineering</h3>
<p>Authors: Markus Weber, René Walendy, Steffen Becker, Carina Wiesen, Christof Paar, Nikol Rummel, Malte Elson, Jingjie Li, Younghyun Kim, Kassem Fawaz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146998">Link</a></p>
<p>Abstract: Trust in digital systems depends on secure hardware, often assured through Hardware Reverse Engineering (HRE). This work develops methods for investigating human problem-solving processes in HRE, an underexplored yet critical aspect. Since reverse engineers rely heavily on visual information, eye tracking holds promise for studying their cognitive processes. To gain further insights, we additionally employ verbal thought protocols during and immediately after HRE tasks: Concurrent and Retrospective Think Aloud. We evaluate the combination of eye tracking and Think Aloud with 41 participants in an HRE simulation. Eye tracking accurately identifies fixations on individual circuit elements and highlights critical components. Based on two use cases, we demonstrate that eye tracking and TA can complement each other to improve data quality. Our methodological insights can inform future studies in HRE, a specific setting of human-computer interaction, and in other problem-solving settings involving misleading or missing information.</p>
<h3>Mental Models, Expectations and Implications of Client-Side Scanning: An Interview Study with Experts</h3>
<p>Authors: Sascha Fahl, Adrian Dabrowski, Divyanshu Bhardwaj, Katharina Krombholz, Carolyn Guthoff</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147543">Link</a></p>
<p>Abstract: Client-Side Scanning (CSS) is discussed as a potential solution to contain the dissemination of child sexual abuse material (CSAM). A significant challenge associated with this debate is that stakeholders have different interpretations of the capabilities and frontiers of the concept and its varying implementations. In this paper, we explore stakeholders' understandings of the technology and the expectations and potential implications in the context of CSAM by conducting and analyzing 28 semi-structured interviews with a diverse sample of experts. We identified mental models of CSS and the expected challenges. Our results show that CSS is often a preferred solution in the child sexual abuse debate due to the lack of an alternative. Our findings illustrate the importance of further interdisciplinary discussions to define and comprehend the impact of CSS usage on society, particularly vulnerable groups such as children. </p>
<h3>VeriSMS: A Message Verification System for Inclusive Patient Outreach against Phishing Attacks</h3>
<p>Authors: Chenkai Wang, Jonathan Handler, Gang Wang, Cody Zevnik, Hadjer Benkraouda, Zhuofan Jia, Roopa Foulger, Nicholas Heuermann</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148268">Link</a></p>
<p>Abstract: Patient outreach enables timely communication between patients and healthcare providers but is vulnerable to phishing/spoofing attacks. In this paper, we work with a U.S.-based healthcare provider to design an inclusive method to address this threat. We present VeriSMS which allows patients to call a voice agent to verify whether the received (sensitive) messages are indeed sent by their healthcare provider. We design the system to be inclusive: it is accessible to patients who only have access to SMS and phone call capabilities. We perform a two-part user study to refine the system design (N=15) and confirm users can correctly understand the system and use it to identify spoofed/phishing messages (N=35). A key insight from our study is to not exclusively optimize for strong security but to tailor the designs based on user habits. Our result confirms the effectiveness and usability of VeriSMS and its ability to significantly increase adversaries' costs. </p>
<h3>SkullID: Through-Skull Sound Conduction based Authentication for Smartglasses</h3>
<p>Authors: HongMin Kim, Iljoo Kim, Ian Oakley, Eunyong Cheon, Bum Jun Kwon, Hyejin Shin, Jun Ho Huh, Choong-Hoon Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146810">Link</a></p>
<p>Abstract: This paper investigates the use of through-skull sound conduction to authenticate smartglass users. We mount a surface transducer on the right mastoid process to play cue signals and capture skull-transformed audio responses through contact microphones on various skull locations. We use the resultant bio-acoustic information as classification features. In an initial single-session study (N=25), we achieved mean Equal Error Rates (EERs) of 5.68% and 7.95% with microphones on the brow and left mastoid process. Combining the two signals substantially improves performance (to 2.35% EER). A subsequent multi-session study (N=30) demonstrates EERs are maintained over three recalls and, additionally, shows robustness to donning variations and background noise (achieving 2.72% EER). In a follow-up usability study over one week, participants report high levels of usability (as expressed by SUS scores) and that only modest workload is required to authenticate. Finally, a security analysis demonstrates the system's robustness to spoofing and imitation attacks.</p>
<h2>Social Support for Wellbeing</h2>
<h3>Saharaline: A Collective Social Support Intervention for Teachers in Low-Income Indian Schools</h3>
<p>Authors: Rama Adithya Varanasi, Nicola Dell, Aditya Vashistha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147521">Link</a></p>
<p>Abstract: This paper presents Saharaline, an intervention designed to provide collective social support for teachers in low-income schools. Implemented as a WhatsApp-based helpline, Saharaline enables teachers to reach out for personalized, long-term assistance with a wide range of problems and stressors, including pedagogical, technological, and emotional challenges. Depending on the support needed, teachers' requests are routed to appropriate domain experts--- staff employed by educational non-profit organizations who understand teachers' on-the-ground realities---who offer localized and contextualized assistance. Via a three-month exploratory deployment with 28 teachers in India, we show how Saharaline's design enabled a collective of diverse education experts to craft and deliver localized solutions that teachers could incorporate into their practice. We conclude by reflecting on the efficacy of our intervention in low-resource work contexts and provide recommendations to enhance collective social support interventions similar to Saharaline.</p>
<h3>Machine and Human Understanding of Empathy in Online Peer Support: A Cognitive Behavioral Approach</h3>
<p>Authors: Zainab Iftikhar, Sara Syed, Jeff Huang, Amy Xiao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146964">Link</a></p>
<p>Abstract: Online peer support provides space for individuals to connect with others and seek support. However, while empathy is critical for effective support, studies have found that highly empathetic support on these platforms can be rare. Using data from online peer support platforms, we conducted a mixed-methods analysis to study the factors that lead to support seekers’ perceived empathy. We found that CBT techniques like active listening and reflective restatements, along with fostering a space for exploration, increase perceived empathy, whereas rigid adherence to structure, misalignment of concerns, and lack of emotional validation can contribute to low perceived empathy. In addition, despite the high levels of empathy reported by most support seekers (85%), computational models reported low averaged empathy (1.69/6). Lastly, we propose that empathy is not a quantifiable metric and that future algorithmic empathy measurements require human perspectives.</p>
<h3>"Butt call me once you get a chance to chat &#128578;" : Designing Persuasive Reminders for Veterans to Facilitate Peer-Mentor Support</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: SHEIKH AHAMED, Robert Curry, Md Romael Haque, Praveen Madiraju, Sabirat Rubya, Natalie Baker, Zeno Franco, OTIS WINSTEAD</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146845">Link</a></p>
<p>Abstract: US military veterans (USMVs) are a vulnerable population with an elevated risk of mental health issues and suicide. Peer support, especially through mobile technology, has proven effective in addressing mental health related challenges, but ensuring long-term engagement remains a concern. This study explores the opportunity of designing persuasive technology, particularly persuasive reminders, to enhance engagement in peer support interventions for veterans. We followed community-based participatory research with ten veterans to identify specific peer support processes that can benefit from persuasive reminders and to uncover the underlying community values and needs to guide design. The findings emphasize the importance of designing reminders that focus on personalized strategies, effective delivery of success stories, understanding motivation levels, careful language selection, actionable reminders, and mutual accountability. The study advocates context-specific design and highlights the need for a broader user-centered persuasion design perspective to cater to veterans' unique needs.</p>
<h3>Transitioning Towards a Proactive Practice: A Longitudinal Field Study on the Implementation of a ML System in Adult Social Care</h3>
<p>Authors: Marina Jirotka, Lars Kunze, Tyler Reinmund</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147484">Link</a></p>
<p>Abstract: Politicians and care associations advocate for the use of machine learning (ML) systems to improve the delivery of adult social services. Yet, guidance on how to implement ML systems remains limited and research indicates that future implementation efforts are likely to encounter difficulties. We aim to enhance the understanding of ML system implementations by conducting a longitudinal field study with a team responsible for deploying a ML system within an adult social services department. The ML system implementation represented a cross-organisational effort to facilitate the department’s transition to a proactive practice. Throughout this process, stakeholders adapted to numerous challenges in real-time. This study makes three contributions. First, we provide a description of how ML systems are implemented and highlight practical challenges. Second, we illustrate the utility of HCI knowledge in designing workflows for ML-assisted preventative care programmes. Finally, we provide recommendations for future deployments of ML systems in social care.</p>
<h3>The Sound of Support: Gendered Voice Agent as Support to Minority Teammates in Gender-Imbalanced Team</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Angel Hsing-Chi Hwang, Andrea Stevenson Won</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148275">Link</a></p>
<p>Abstract: The present work explores the potential of leveraging a teamwork agent's identity --  signaled through its gendered voice -- to support marginalized individuals in gender-imbalanced teams. In a mixed design experiment (N = 178), participants were randomly assigned to work with a female and a male voice agent in either a female-dominated or male-dominated team. Results show the presence of a same-gender voice agent is particularly beneficial to the performance of marginalized female members, such that they would contribute more ideas and talk more when a female agent was present. Conversely, marginalized male members became more talkative but were less focused on the teamwork tasks at hand when working with a male-sounding agent. The findings of the present experiment support existing literature on the effect of social presence in gender-imbalanced teams, such that gendered agents serve similar benefits as human teammates of the same gender identities. However, the effect of agents' presence remains limited when participants have experienced severe marginalization in the past. Based on findings from the present study, we discuss relevant design implications and avenues for future research.</p>
<h2>Universal Accessibility A</h2>
<h3>Exploring Mobile Device Accessibility: Challenges, Insights, and Recommendations for Evaluation Methodologies</h3>
<p>Authors: Carlos Duarte, Letícia Seixas Pereira, Maria Matos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146754">Link</a></p>
<p>Abstract: With the ubiquitous use of mobile applications, it is paramount that they are accessible, so they can empower all users, including those with different needs. Determining if an app is accessible implies conducting an accessibility evaluation. While accessibility evaluations have been thoroughly studied in the web domain, there are still many open questions when evaluating mobile applications. This paper investigates mobile accessibility evaluation methodologies. We conducted four studies, including an examination of accessibility reports from European Member-states, interviews with accessibility experts, manual evaluations, and usability tests involving users. Our investigations have uncovered significant limitations in current evaluation methods, suggesting that the absence of authoritative guidelines and standards, similar to what exists for the web, but tailored specifically to mobile devices, hampers the effectiveness of accessibility evaluation and monitoring activities. Based on our findings, we present a set of recommendations aimed at improving the evaluation methodologies for assessing mobile applications’ accessibility.</p>
<h3>Human I/O: Towards a Unified Approach to Detecting Situational Impairments</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jiahao Li, Ruofei Du, Xiang 'Anthony' Chen, David Kim, Xingyu Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148270">Link</a></p>
<p>Abstract: Situationally Induced Impairments and Disabilities (SIIDs) can significantly hinder user experience in contexts such as poor lighting, noise, and multi-tasking. While prior research has introduced algorithms and systems to address these impairments, they predominantly cater to specific tasks or environments and fail to accommodate the diverse and dynamic nature of SIIDs. We introduce Human I/O, a unified approach to detecting a wide range of SIIDs by gauging the availability of human input/output channels. Leveraging egocentric vision, multimodal sensing and reasoning with large language models, Human I/O achieves a 0.22 mean absolute error and a 82% accuracy in availability prediction across 60 in-the-wild egocentric video recordings in 32 different scenarios. Furthermore, while the core focus of our work is on the detection of SIIDs rather than the creation of adaptive user interfaces, we showcase the efficacy of our prototype via a user study with 10 participants. Findings suggest that Human I/O significantly reduces effort and improves user experience in the presence of SIIDs, paving the way for more adaptive and accessible interactive systems in the future.</p>
<h3>AXNav: Replaying Accessibility Tests from Natural Language</h3>
<p>Authors: Ruijia Cheng, Amanda Swearngin, Yue Jiang, Maryam Taeb, Eldon Schoop, Jeffrey Nichols</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147260">Link</a></p>
<p>Abstract: Developers and quality assurance testers often rely on manual testing to test accessibility features throughout the product lifecycle. Unfortunately, manual testing can be tedious, often has an overwhelming scope, and can be difficult to schedule amongst other development milestones. Recently, Large Language Models (LLMs) have been used for a variety of tasks including automation of UIs. However, to our knowledge, no one has yet explored the use of LLMs in controlling assistive technologies for the purposes of supporting accessibility testing. In this paper, we explore the requirements of a natural language based accessibility testing workflow, starting with a formative study. From this we build a system that takes a manual accessibility test instruction in natural language (e.g., "Search for a show in VoiceOver") as input and uses an LLM combined with pixel-based UI Understanding models to execute the test and produce a chaptered, navigable video. In each video, to help QA testers, we apply heuristics to detect and flag accessibility issues (e.g., Text size not increasing with Large Text enabled, VoiceOver navigation loops). We evaluate this system through a 10-participant user study with accessibility QA professionals who indicated that the tool would be very useful in their current work and performed tests similarly to how they would manually test the features. The study also reveals insights for future work on using LLMs for accessibility testing.</p>
<h3>AccessLens: Auto-detecting Inaccessibility of Everyday Objects</h3>
<p>Authors: Qian Lu, Nahyun Kwon, Muhammad Hasham Qazi, Jeeeun Kim, Joanne Liu, Changhoon Oh, Shu Kong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147903">Link</a></p>
<p>Abstract: In our increasingly diverse society, everyday physical interfaces often present barriers, impacting individuals across various contexts. This oversight, from small cabinet knobs to identical wall switches that can pose different contextual challenges, highlights an imperative need for solutions. Leveraging low-cost 3D-printed augmentations such as knob magnifiers and tactile labels seems promising, yet the process of discovering unrecognized barriers remains challenging because disability is context-dependent. We introduce AccessLens, an end-to-end system designed to identify inaccessible interfaces in daily objects, and recommend 3D-printable augmentations for accessibility enhancement. Our approach involves training a detector using the novel AccessDB dataset designed to automatically recognize 21 distinct Inaccessibility Classes (e.g., bar-small and round-rotate) within 6 common object categories (e.g., handle and knob). AccessMeta serves as a robust way to build a comprehensive dictionary linking these accessibility classes to open-source 3D augmentation designs. Experiments demonstrate our detector's performance in detecting inaccessible objects.</p>
<h3>A Systematic Review of Ability-diverse Collaboration through Ability-based Lens in HCI</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Lan Xiao, Tigmanshu Bhatnagar, Maryam Bandukda, Michael Sedlmair, Katrin Angerbauer, Weiyue Lin, Catherine Holloway</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147798">Link</a></p>
<p>Abstract: In a world where diversity is increasingly recognised and celebrated, it is important for HCI to embrace the evolving methods and theories for technologies to reflect the diversity of its users and be ability-centric. Interdependence Theory, an example of this evolution, highlights the interpersonal relationships between humans and technologies and how technologies should be designed to meet shared goals and outcomes for people, regardless of their abilities. This necessitates a contemporary understanding of "ability-diverse collaboration," which motivated this review. In this review, we offer an analysis of 117 papers sourced from the ACM Digital Library spanning the last two decades. We contribute (1) a unified taxonomy and the Ability-Diverse Collaboration Framework, (2) a reflective discussion and mapping of the current design space, and (3) future research opportunities and challenges. Finally, we have released our data and analysis tool to encourage the HCI research community to contribute to this ongoing effort.</p>
<h2>User Studies on Large Language Models</h2>
<h3>The Effects of Perceived AI Use On Content Perceptions</h3>
<p>Authors: Irene Rae</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147441">Link</a></p>
<p>Abstract: There is a potential future where the content created by a human and an AI are indistinguishable. In this future, if you can't tell the difference, does it matter?  We conducted a 3 (Assigned creator: human, human with AI assistance, AI) by 4 (Context: news, travel, health, and jokes) mixed-design experiment where participants evaluated human-written content that was presented as created by a human, a human with AI assistance, or an AI.  We found that participants felt more negatively about the content creator and were less satisfied when they thought AI was used, but assigned creator had no effect on content judgments.  We also identified five interpretations for how participants thought AI use affected the content creation process.  Our work suggests that informing users about AI use may not have the intended effect of helping consumers make content judgments and may instead damage the relationship between creators and followers.</p>
<h3>DirectGPT: A Direct Manipulation Interface to Interact with Large Language Models</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Sylvain Malacria, Géry Casiez, Damien Masson, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146635">Link</a></p>
<p>Abstract: We characterize and demonstrate how the principles of direct manipulation can improve interaction with large language models. This includes: continuous representation of generated objects of interest; reuse of prompt syntax in a toolbar of commands; manipulable outputs to compose or control the effect of prompts; and undo mechanisms. This idea is exemplified in DirectGPT, a user interface layer on top of ChatGPT that works by transforming direct manipulation actions to engineered prompts. A study shows participants were 50% faster and relied on 50% fewer and 72% shorter prompts to edit text, code, and vector images compared to baseline ChatGPT. Our work contributes a validated approach to integrate LLMs into traditional software using direct manipulation. Data, code, and demo available at https://osf.io/3wt6s.</p>
<h3>From Text to Self: Users’ Perception of AIMC Tools on Interpersonal Communication and Self</h3>
<p>BEST_PAPER</p>
<p>Authors: Sami Foell, Alexis Hiniker, Yue Fu, Xuhai "Orson" Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146970">Link</a></p>
<p>Abstract: In the rapidly evolving landscape of AI-mediated communication (AIMC), tools powered by Large Language Models (LLMs) are becoming integral to interpersonal communication. Employing a mixed-methods approach, we conducted a one-week diary and interview study to explore users’ perceptions of these tools’ ability to: 1) support interpersonal communication in the short-term, and 2) lead to potential long-term effects. Our findings indicate that participants view AIMC support favorably, citing benefits such as increased communication confidence, finding precise language to express their thoughts, and navigating linguistic and cultural barriers. However, our findings also show current limitations of AIMC tools, including verbosity, unnatural responses, and excessive emotional intensity. These shortcomings are further exacerbated by user concerns about inauthenticity and potential overreliance on the technology. We identify four key communication spaces delineated by communication stakes (high or low) and relationship dynamics (formal or informal) that differentially predict users’ attitudes toward AIMC tools. Specifically, participants report that these tools are more suitable for communicating in formal relationships than informal ones and more beneficial in high-stakes than low-stakes communication.</p>
<h3>Farsight: Fostering Responsible AI Awareness During AI Application Prototyping</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Michael Terry, Michael Madaio, Zijie Wang, Lauren Wilcox, Chinmay Kulkarni</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146993">Link</a></p>
<p>Abstract: Prompt-based interfaces for Large Language Models (LLMs) have made prototyping and building AI-powered applications easier than ever before. However, identifying potential harms that may arise from AI applications remains a challenge, particularly during prompt-based prototyping. To address this, we present Farsight, a novel in situ interactive tool that helps people identify potential harms from the AI applications they are prototyping. Based on a user's prompt, Farsight highlights news articles about relevant AI incidents and allows users to explore and edit LLM-generated use cases, stakeholders, and harms. We report design insights from a co-design study with 10 AI prototypers and findings from a user study with 42 AI prototypers. After using Farsight, AI prototypers in our user study are better able to independently identify potential harms associated with a prompt and find our tool more useful and usable than existing resources. Their qualitative feedback also highlights that Farsight encourages them to focus on end-users and think beyond immediate harms. We discuss these findings and reflect on their implications for designing AI prototyping experiences that meaningfully engage with AI harms. Farsight is publicly accessible at: https://pair-code.github.io/farsight.</p>
<h3>“As an AI language model, I cannot”: Investigating LLM Denials of User Requests</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Niels van Berkel, Joel Wester, Henning Pohl, Tim Schrills</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148063">Link</a></p>
<p>Abstract: Users ask large language models (LLMs) to help with their homework, for lifestyle advice, or for support in making challenging decisions. Yet LLMs are often unable to fulfil these requests, either as a result of their technical inabilities or policies restricting their responses. To investigate the effect of LLMs denying user requests, we evaluate participants' perceptions of different denial styles. We compare specific denial styles (baseline, factual, diverting, and opinionated) across two studies, respectively focusing on LLM's technical limitations and their social policy restrictions. Our results indicate significant differences in users' perceptions of the denials between the denial styles. The baseline denial, which provided participants with brief denials without any motivation, was rated significantly higher on frustration and significantly lower on usefulness, appropriateness, and relevance. In contrast, we found that participants generally appreciated the diverting denial style. We provide design recommendations for LLM denials that better meet peoples' denial expectations.</p>
<h2>Visualization and Sonification</h2>
<h3>Glanceable Data Visualizations for Older Adults: Establishing Thresholds and Examining Disparities Between Age Groups</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yujie Gong, Petra Isenberg, Ali Sarvghad, Tanja Blascheck, Zack While</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148143">Link</a></p>
<p>Abstract: We present results of a replication study on smartwatch visualizations with adults aged 65 and older. The older adult population is rising globally, coinciding with their increasing interest in using small wearable devices, such as smartwatches, to track and view data. Smartwatches, however, pose challenges to this population: fonts and visualizations are often small and meant to be seen at a glance. How concise design on smartwatches interacts with aging-related changes in perception and cognition, however, is not well understood. We replicate a study that investigated how visualization type and number of data points affect glanceable perception. We observe strong evidence of differences for participants aged 75 and older, sparking interesting questions regarding the study of visualization and older adults. We discuss first steps toward better understanding and supporting an older population of smartwatch wearers and reflect on our experiences working with this population. Supplementary materials are available at \url{https://osf.io/7x4hq/}.</p>
<h3>DynaVis: Dynamically Synthesized UI Widgets for Visualization Editing</h3>
<p>BEST_PAPER</p>
<p>Authors: Priyan Vaithilingam, Jeevana Priya Inala, Elena Glassman, Chenglong Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148267">Link</a></p>
<p>Abstract: Users often rely on GUIs to edit and interact with visualizations - a daunting task due to the large space of editing options. As a result, users are either overwhelmed by a complex UI or constrained by a custom UI with a tailored, fixed subset of options with limited editing flexibility. Natural Language Interfaces (NLIs) are emerging as a feasible alternative for users to specify edits. However, NLIs forgo the advantages of traditional GUI: the ability to explore and repeat edits and see instant visual feedback.</p>
<p>We introduce DynaVis, which blends natural language and dynamically synthesized UI widgets. As the user describes an editing task in natural language, DynaVis performs the edit and synthesizes a persistent widget that the user can interact with to make further modifications. Study participants (n=24) preferred \tool over the NLI-only interface citing ease of further edits and editing confidence due to immediate visual feedback.</p>
<h3>Graph4GUI: Graph Neural Networks for Representing Graphical User Interfaces</h3>
<p>Authors: Yue Jiang, Vikas Garg, Changkong Zhou, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146736">Link</a></p>
<p>Abstract: Present-day graphical user interfaces (GUIs) exhibit diverse arrangements of text, graphics, and interactive elements such as buttons and menus, but representations of GUIs have not kept up. They do not encapsulate both semantic and visuo-spatial relationships among elements. To seize machine learning's potential for GUIs more efficiently, Graph4GUI exploits graph neural networks to capture individual elements' properties and their semantic-visuo-spatial constraints in a layout. The learned representation demonstrated its effectiveness in multiple tasks, especially generating designs in a challenging GUI autocompletion task, which involved predicting the positions of remaining unplaced elements in a partially completed GUI. The new model's suggestions showed alignment and visual appeal superior to the baseline method and received higher subjective ratings for preference. Furthermore, we demonstrate the practical benefits and efficiency advantages designers perceive when utilizing our model as an autocompletion plug-in.</p>
<h3>Erie: A Declarative Grammar for Data Sonification</h3>
<p>Authors: Yea-Seul Kim, Jessica Hullman, Hyeok Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148059">Link</a></p>
<p>Abstract: Data sonification—mapping data variables to auditory variables, such as pitch or volume—is used for data accessibility, scientific exploration, and data-driven art (e.g., museum exhibitions) among others. While a substantial amount of research has been made on effective and intuitive sonification design, software support is not commensurate, limiting researchers from fully exploring its capabilities. We contribute Erie, a declarative grammar for data sonification, that enables abstractly expressing auditory mappings. Erie supports specifying extensible tone designs (e.g., periodic wave, sampling, frequency/amplitude modulation synthesizers), various encoding channels, auditory legends, and composition options like sequencing and overlaying. Using standard Web Audio and Web Speech APIs, we provide an Erie compiler for web environments. We demonstrate the expressiveness and feasibility of Erie by replicating research prototypes presented by prior work and provide a sonification design gallery. We discuss future steps to extend Erie toward other audio computing environments and support interactive data sonification.</p>
<h3>“It is hard to remove from my eye”: Design Makeup Residue Visualization System for Chinese Traditional Opera (Xiqu) Performers</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zeyu Xiong, Mingming Fan, Chenqing Zhu, Shihan Fu, Xiaojuan Ma, Yanying Zhu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146861">Link</a></p>
<p>Abstract: Chinese traditional opera (Xiqu) performers often experience skin problems due to the long-term use of heavy-metal-laden face paints. To explore the current skincare challenges encountered by Xiqu performers, we conducted an online survey (N=136) and semi-structured interviews (N=15) as a formative study. We found that incomplete makeup removal is the leading cause of human-induced skin problems, especially the difficulty in removing eye makeup. Therefore, we proposed EyeVis, a prototype that can visualize the residual eye makeup and record the time make-up was worn by Xiqu performers. We conducted a 7-day deployment study (N=12) to evaluate EyeVis. Results indicate that EyeVis helps to increase Xiqu performers' awareness about removing makeup, as well as boosting their confidence and security in skincare. Overall, this work also provides implications for studying the work of people who wear makeup on a daily basis, and helps to promote and preserve the intangible cultural heritage of practitioners.</p>
<h2>Wellbeing and Eating: Nutrition and Weight</h2>
<h3>FoodCensor: Promoting Mindful Digital Food Content Consumption for People with Eating Disorders</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Subin Park, Sujin Han, Ryuhaerang Choi, Sung-Ju Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146779">Link</a></p>
<p>Abstract: Digital food content’s popularity is underscored by recent studies revealing its addictive nature and association with disordered eating. Notably, individuals with eating disorders exhibit a positive correlation between their digital food content consumption and disordered eating behaviors. Based on these findings, we introduce FoodCensor, an intervention designed to empower individuals with eating disorders to make informed, conscious, and health-oriented digital food content consumption decisions. FoodCensor (i) monitors and hides passively exposed food content on smartphones and personal computers, and (ii) prompts reflective questions for users when they spontaneously search for food content. We deployed FoodCensor to people with binge eating disorder or bulimia (n=22) for three weeks. Our user study reveals that FoodCensor fostered self-awareness and self-reflection about unconscious digital food content consumption habits, enabling them to adopt healthier behaviors consciously. Furthermore, we discuss design implications for promoting healthier digital content consumption practices for vulnerable populations to specific content types.</p>
<h3>Integrating Expertise in LLMs: Crafting a Customized Nutrition Assistant with Refined Template Instructions</h3>
<p>Authors: Ronald Metoyer, Heather Eicher-Miller, Brianna Wimer, Annalisa Szymanski, Oghenemaro Anuyah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147537">Link</a></p>
<p>Abstract: Large Language Models (LLMs) have the potential to contribute to the fields of nutrition and dietetics in generating food product explanations that facilitate informed food selections. However, the extent to which these models offer effective and accurate information remains unverified. In collaboration with registered dietitians (RDs), we evaluate the strengths and weaknesses of LLMs in providing accurate and personalized nutrition information. Through a mixed-methods approach, RDs validated GPT-4 outputs at various levels of prompt specificity, which led to the development of design guidelines used to prompt LLMs for nutrition information. We tested these guidelines by creating a GPT prototype, The Food Product Nutrition Assistant, tailored for food product explanations. This prototype was refined and evaluated in focus groups with RDs. We find that the implementation of these dietitian-reviewed template instructions enhance the generation of detailed food product descriptions and tailored nutrition information.</p>
<h3>Beyond Static Labels: Unpacking Nutrition Comprehension in the Digital Age</h3>
<p>Authors: Ronald Metoyer, Brianna Wimer, Annalisa Szymanski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148140">Link</a></p>
<p>Abstract: Understanding nutrition labels remains challenging for consumers; however, digital shopping environments offer opportunities to explore how interactive nutrition labels may be used to enhance comprehension. We conducted an A/B study with 24 participants, comparing their ability to interpret and apply nutrition information using conventional, static labels versus interactive labels. We evaluated interactive nutrition labels' impact through quantitative metrics and qualitative insights from interviews and think-aloud sessions. Our findings reveal a statistically significant improvement in assessing nutrient amounts and interpreting numerical information when users engage with interactive labels. These results underscore the potential interactivity has on promoting public understanding of nutritional content and highlight opportunities for refinement. Based on our findings, we propose new design directions and discuss technology's role in making nutrition labels more effective for decision-making and nutrition education.</p>
<h3>Investigating Contextual Notifications to Drive Self-Monitoring in mHealth Apps for Weight Maintenance</h3>
<p>Authors: Meena Shankar, Jaime Ruiz, Xuanpu Zhang, Oluwatomisin Obajemu, Yu-Peng Chen, Lisa Anthony, Kathryn Ross, Julia Woodward, Dinank Bista, Ishvina Singh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148173">Link</a></p>
<p>Abstract: Mobile health applications for weight maintenance offer self-monitoring as a tool to empower users to achieve health goals (e.g., losing weight); yet maintaining consistent self-monitoring over time proves challenging for users. These apps use push notifications to help increase users’ app engagement and reduce long-term attrition, but they are often ignored by users due to appearing at inopportune moments. Therefore, we analyzed whether delivering push notifications based on time alone or also considering user context (e.g., current activity) affected users’ engagement in a weight maintenance app, in a 4-week in-the-wild study with 30 participants. We found no difference in participants’ overall (across the day) self-monitoring frequency between the two conditions, but in the context-based condition, participants responded faster and more frequently to notifications, and logged their data more timely (as eating/exercising occurs). Our work informs the design of notifications in weight maintenance apps to improve their efficacy in promoting self-monitoring.</p>
<h3>Predicting early user churn in a public digital weight loss intervention</h3>
<p>Authors: Elgar Fleisch, Robert Jakob, Tobias Kowatsch, Nils Lepper</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148260">Link</a></p>
<p>Abstract: Digital health interventions (DHIs) offer promising solutions to the rising global challenges of noncommunicable diseases by promoting behavior change, improving health outcomes, and reducing healthcare costs. However, high churn rates are a concern with DHIs, with many users disengaging before achieving desired outcomes. Churn prediction can help DHI providers identify and retain at-risk users, enhancing the efficacy of DHIs. We analyzed churn prediction models for a weight loss app using various machine learning algorithms on data from 1,283 users and 310,845 event logs. The best-performing model, a random forest model that only used daily login counts, achieved an F1 score of 0.87 on day 7 and identified an average of 93% of churned users during the week-long trial. Notably, higher-dimensional models performed better at low false positive rate thresholds. Our findings suggest that user churn can be forecasted using engagement data, aiding in timely personalized strategies and better health results.</p>
<h2>Wellbeing and Mental Health B</h2>
<h3>DeepStress: Supporting Stressful Context Sensemaking in Personal Informatics Systems Using a Quasi-experimental Approach</h3>
<p>Authors: Uichin Lee, Sangjun Park, Gyuwon Jung</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147710">Link</a></p>
<p>Abstract: Personal informatics (PI) systems are widely used in various domains such as mental health to provide insights from self-tracking data for behavior change. Users are highly interested in examining relationships from the self-tracking data, but identifying causality is still considered challenging. In this study, we design DeepStress, a PI system that helps users analyze contextual factors causally related to stress. DeepStress leverages a quasi-experimental approach to address potential biases related to confounding factors. To explore the user experience of DeepStress, we conducted a user study and a follow-up diary study using participants' own self-tracking data collected for 6 weeks. Our results show that DeepStress helps users consider multiple contexts when investigating causalities and use the results to manage their stress in everyday life. We discuss design implications for causality support in PI systems.</p>
<h3>Maintaining Continuing Bonds in Bereavement: A Participatory Design Process of Be.side</h3>
<p>Authors: Jieun Kim, Giulia Barbareschi, Daisuke Uriu, Youichi Kamiyama, Kouta Minamizawa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146846">Link</a></p>
<p>Abstract: During the grieving process, physical objects often serve as catalysts for remembering and honouring the relationship with departed loved ones. Leveraging a participatory design approach, we created Be.side, a fully customisable multi-modal artefact that incorporates scent, sound, and heartbeat stimulation and acts as a touch-point between the deceased and the bereaved. We conducted a four-week study with three participants to understand how the artefact, continuously attuned to each participant, helped to continue bonds with the deceased. Our results show that Be.side’s bespoke elements helped participants to evoke memories of the deceased. Participants created personalised rituals for remembrance. They sustained bonds by not only interacting with Be.side but also participating in the research. Finally, highlighting that remembrance can both provide comfort and deepen sadness, we discuss future design considerations.</p>
<h3>"I'm gonna KMS": From Imminent Risk to Youth Joking about Suicide and Self-Harm via Social Media</h3>
<p>Authors: Munmun De Choudhury, Sarvech Qadir, Ashwaq Alsoubai, Naima Samreen Ali, Pamela Wisniewski, Afsaneh Razi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147067">Link</a></p>
<p>Abstract: Recent increases in self-harm and suicide rates among youth have coincided with prevalent social media use; therefore, making these sensitive topics of critical importance to the HCI research community. We analyzed 1,224 direct message conversations (DMs) from 151 young Instagram users (ages 13-21), who engaged in private conversations using self-harm and suicide-related language. We found that youth discussed their personal experiences, including imminent thoughts of suicide and/or self-harm, as well as their past attempts and recovery. They gossiped about others, including complaining about triggering content and coercive threats of self-harm and suicide but also tried to intervene when a friend was in danger. Most of the conversations involved suicide or self-harm language that did not indicate the intent to harm but instead used hyperbolical language or humor. Our results shed light on youth perceptions, norms, and experiences of self-harm and suicide to inform future efforts towards risk detection and prevention.</p>
<h3>EmoEden: Applying Generative Artificial Intelligence to Emotional Learning for Children with High-Function Autism</h3>
<p>Authors: Wenkai Chen, Yu Cai, Yao Du, Liuqing Chen, Yilin Tang, Lingyun Sun, Ziyu Chen, Fan Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146914">Link</a></p>
<p>Abstract: Children with high-functioning autism (HFA) often face challenges in emotional recognition and expression, leading to emotional distress and social difficulties. Conversational agents developed for HFA children in previous studies show limitations in children’s learning effectiveness due to the conversational agents’ inability to dynamically generate personalized and contextual content. Recent advanced generative Artificial Intelligence techniques, with the capability to generate substantial diverse and high-quality texts and visual content, offer an opportunity for personalized assistance in emotional learning for HFA children. Based on the findings of our formative study, we integrated large language models and text-to-image models to develop a tool named EmoEden supporting children with HFA. Over a 22-day study involving six HFA children, it is observed that EmoEden effectively engaged children and improved their emotional recognition and expression abilities. Additionally, we identified the advantages and potential risks of applying generative AI to assist HFA children in emotional learning.</p>
<h3>“This app said I had severe depression, and now I don’t know what to do”: the unintentional harms of mental health applications</h3>
<p>BEST_PAPER</p>
<p>Authors: Rachael Kang, Tera L. Reynolds</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147719">Link</a></p>
<p>Abstract: A growing market for mental health applications and increasing evidence for the efficacy of these applications have made apps a popular mode of mental healthcare delivery. However, given the gravity of mental illnesses, the potential harms of using these applications must be continually investigated. In this study, we conducted a thematic analysis using user-comments left on depression self-management applications. We analyzed 6,253 reviews from thirty-six, systematically selected apps from the Google Play and Apple App stores. We identified four themes regarding the potential, unintentional harms caused by these applications. This study uniquely contributes to the literature by examining the reported harms to users caused by depression self-management apps and contextualizing them in an ethical framework. We provide recommendations to developers for creating ethical depression self-management apps and resources for practitioners and consumers to aid in screening apps.</p>
<h2>Writing and AI A</h2>
<h3>MindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients' Journaling</h3>
<p>Authors: Hwajung Hong, Chanmo Yang, Hyun AH Kim, Su-woo Lee, Seolyeong Bae, Taewan Kim, Young-Ho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147830">Link</a></p>
<p>Abstract: Large Language Models (LLMs) offer promising opportunities in mental health domains, although their inherent complexity and low controllability elicit concern regarding their applicability in clinical settings. We present MindfulDiary, an LLM-driven journaling app that helps psychiatric patients document daily experiences through conversation. Designed in collaboration with mental health professionals, MindfulDiary takes a state-based approach to safely comply with the experts' guidelines while carrying on free-form conversations. Through a four-week field study involving 28 patients with major depressive disorder and five psychiatrists, we examined how MindfulDiary facilitates patients' journaling practice and clinical care. The study revealed that MindfulDiary supported patients in consistently enriching their daily records and helped clinicians better empathize with their patients through an understanding of their thoughts and daily contexts. Drawing on these findings, we discuss the implications of leveraging LLMs in the mental health domain, bridging the technical feasibility and their integration into clinical settings.</p>
<h3>Shaping Human-AI Collaboration: Varied Scaffolding Levels in Co-writing with Language Models</h3>
<p>Authors: Shaochun Zheng, Somayeh Molaei, Lionel Robert, Paramveer Dhillon, Maximilian Golub, Jiaqi Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147385">Link</a></p>
<p>Abstract: Advances in language modeling have paved the way for novel human-AI co-writing experiences. This paper explores how varying levels of scaffolding from large language models (LLMs) shape the co-writing process. Employing a within-subjects field experiment with a Latin square design, we asked participants (N=131) to respond to argumentative writing prompts under three randomly sequenced conditions: no AI assistance (control), next-sentence suggestions (low scaffolding), and next-paragraph suggestions (high scaffolding). Our findings reveal a U-shaped impact of scaffolding on writing quality and productivity (words/time). While low scaffolding did not significantly improve writing quality or productivity, high scaffolding led to significant improvements, especially benefiting non-regular writers and less tech-savvy users. No significant cognitive burden was observed while using the scaffolded writing tools, but a moderate decrease in text ownership and satisfaction was noted. Our results have broad implications for the design of AI-powered writing tools, including the need for personalized scaffolding mechanisms.</p>
<h3>The HaLLMark Effect: Supporting Provenance and Transparent Use of Large Language Models in Writing with Interactive Visualization</h3>
<p>Authors: Cecilia Shelton, Md Naimul Hoque, Kari Kraus, Bhavya Ghai, Tasfia Mashiat, Fanny Chevalier, Niklas Elmqvist</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147129">Link</a></p>
<p>Abstract: The use of Large Language Models (LLMs) for writing has sparked controversy both among readers and writers. On one hand, writers are concerned that LLMs will deprive them of agency and ownership, and readers are concerned about spending their time on text generated by soulless machines. On the other hand, AI-assistance can improve writing as long as writers can conform to publisher policies, and as long as readers can be assured that a text has been verified by a human. We argue that a system that captures the provenance of interaction with an LLM can help writers retain their agency, conform to policies, and communicate their use of AI to publishers and readers transparently. Thus we propose HaLLMark, a tool for visualizing the writer's interaction with the LLM. We evaluated HaLLMark with 13 creative writers, and found that it helped them retain a sense of control and ownership of the text.</p>
<h3>ABScribe: Rapid Exploration &amp; Organization of Multiple Writing Variations in Human-AI Co-Writing Tasks using Large Language Models</h3>
<p>Authors: Kashish Mittal, Joseph Williams, Tovi Grossman, Anastasia Kuzminykh, Peter Dushniku, Ilya Musabirov, Nathan Laundry, Michael Liut, Zhi Yuan "Michael" Yu, Mohi Reza</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148096">Link</a></p>
<p>Abstract: Exploring alternative ideas by rewriting text is integral to the writing process. State-of-the-art Large Language Models (LLMs) can simplify writing variation generation. However, current interfaces pose challenges for simultaneous consideration of multiple variations: creating new variations without overwriting text can be difficult, and pasting them sequentially can clutter documents, increasing workload and disrupting writers' flow. To tackle this, we present ABScribe, an interface that supports rapid, yet visually structured, exploration and organization of writing variations in human-AI co-writing tasks. With ABScribe, users can swiftly modify variations using LLM prompts, which are auto-converted into reusable buttons. Variations are stored adjacently within text fields for rapid in-place comparisons using mouse-over interactions on a popup toolbar. Our user study with 12 writers shows that ABScribe significantly reduces task workload (d = 1.20, p &lt; 0.001), enhances user perceptions of the revision process (d = 2.41, p &lt; 0.001) compared to a popular baseline workflow, and provides insights into how writers explore variations using LLMs.</p>
<h2>Writing and AI B</h2>
<h3>Writer-Defined AI Personas for On-Demand Feedback Generation</h3>
<p>Authors: Hendrik Heuer, Daniel Buschek, Florian Lehmann, Tim Zindulka, Karim Benharrak</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147111">Link</a></p>
<p>Abstract: Compelling writing is tailored to its audience. This is challenging, as writers may struggle to empathize with readers, get feedback in time, or gain access to the target group. We propose a concept that generates on-demand feedback, based on writer-defined AI personas of any target audience. We explore this concept with a prototype (using GPT-3.5) in two user studies (N=5 and N=11): Writers appreciated the concept and strategically used personas for getting different perspectives. The feedback was seen as helpful and inspired revisions of text and personas, although it was often verbose and unspecific. We discuss the impact of on-demand feedback, the limited representativity of contemporary AI systems, and further ideas for defining AI personas. This work contributes to the vision of supporting writers with AI by expanding the socio-technical perspective in AI tool design: To empower creators, we also need to keep in mind their relationship to an audience.</p>
<h3>Intelligent Support Engages Writers Through Relevant Cognitive Processes</h3>
<p>Authors: Thiemo Wambsganss, Andreas Göldi, Seyed Parsa Neshaei, Roman Rietsche</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147114">Link</a></p>
<p>Abstract: Student peer review writing is prevalent and important in education for fostering critical thinking and learning motivation. However, it often entails challenges such as high effort and writer's block. Leaving students unsupported may thus diminish the efficacy of the process. Large Language Models (LLMs) offer a potential remedy, but their utility hinges on user-centered design. Guided by design-determining constructs from the Cognitive Process Theory of Writing, we developed an intelligent writing support tool to alleviate these challenges, aiding 1) ideation and 2) evaluation. A randomized experiment (n=120) confirmed users were less inclined to utilize the tool's intelligent features when offered pre-supplied ideas or evaluations, validating our approach. Moreover, students engaged not less but more with their writing if support was available, indicating an enhanced experience. Our research illuminates design choices for enhancing LLM-based tools' usability and user experience, specifically optimizing intelligent writing support tools to facilitate student peer review.</p>
<h3>The Value, Benefits, and Concerns of Generative AI-Powered Assistance in Writing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jing Peng, Chen Liang, Ming Yin, Zhuoyan Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147288">Link</a></p>
<p>Abstract: Recent advances in generative AI technologies like large language models raise both excitement and concerns about the future of human-AI co-creation in writing. To unpack people’s attitude towards and experience with generative AI-powered writing assistants, in this paper, we conduct an experiment to understand whether and how much value people attach to AI assistance, and how the incorporation of AI assistance in writing workflows changes people’s writing perceptions and performance. Our results suggest that people are willing to forgo financial payments to receive writing assistance from AI, especially if AI can provide direct content generation assistance and the writing task is highly creative. Generative AI-powered assistance is found to offer benefits in increasing people’s productivity and confidence in writing. However, direct content generation assistance offered by AI also comes with risks, including decreasing people’s sense of accountability and diversity in writing. We conclude by discussing the implications of our findings.</p>
<h3>Rambler: Supporting Writing With Speech via LLM-Assisted Gist Manipulation</h3>
<p>Authors: Can Liu, J.D. Zamfirescu-Pereira, Sauhard Jain, Susan Lin, Shumin Zhai, Bjoern Hartmann, Matthew Lee, Michael Xuelin Huang, Jeremy Warner, Shanqing Cai, Piyawat Lertvittayakumjorn</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147240">Link</a></p>
<p>Abstract: Dictation enables efficient text input on mobile devices. However, writing with speech can produce disfluent, wordy, and incoherent text and thus requires heavy post-processing. This paper presents Rambler, an LLM-powered graphical user interface that supports gist-level manipulation of dictated text with two main sets of functions: gist extraction and macro revision. Gist extraction generates keywords and summaries as anchors to support the review and interaction with spoken text. LLM-assisted macro revisions allow users to respeak, split, merge, and transform dictated text without specifying precise editing locations. Together they pave the way for interactive dictation and revision that help close gaps between spontaneously spoken words and well-structured writing. In a comparative study with 12 participants performing verbal composition tasks, \tool outperformed the baseline of a speech-to-text editor + ChatGPT, as it better facilitates iterative revisions with enhanced user control over the content while supporting surprisingly diverse user strategies.</p>
<h2>Writing, Sketching and AI</h2>
<h3>Neural Canvas: Supporting Scenic Design Prototyping by Integrating 3D Sketching and Generative AI</h3>
<p>Authors: Jiawen Cheng, Zeyu Wang, Yifei Shen, Mingming Fan, Chutian Jiang, Yulin Shen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147583">Link</a></p>
<p>Abstract: We propose Neural Canvas, a lightweight 3D platform that integrates sketching and a collection of generative AI models to facilitate scenic design prototyping. Compared with traditional 3D tools, sketching in a 3D environment helps designers quickly express spatial ideas, but it does not facilitate the rapid prototyping of scene appearance or atmosphere. Neural Canvas integrates generative AI models into a 3D sketching interface and incorporates four types of projection operations to facilitate 2D-to-3D content creation. Our user study shows that Neural Canvas is an effective creativity support tool, enabling users to rapidly explore visual ideas and iterate 3D scenic designs. It also expedites the creative process for both novices and artists who wish to leverage generative AI technology, resulting in attractive and detailed 3D designs created more efficiently than using traditional modeling tools or individual generative AI platforms.</p>
<h3>A Design Space for Intelligent and Interactive Writing Assistants</h3>
<p>Authors: Pao Siangliulue, Simon Buckingham Shum, Sherol Chen, Thiemo Wambsganss, Disha Shrivastava, Madiha Zahrah Choksi, Roy Pea, Subhashini Venugopalan, Sitong Wang, Eugenia Rho, Hua Shen, Antoine Bosselut, John Chung, Avinash Bhat, Tal August, Jessi Stark, Joonsuk Park, Joseph Chee Chang, Senjuti Dutta, Max Kreminski, David Zhou, Zejiang Shen, Lila Shroff, Yewon Kim, Daniel Buschek, Agnia Sergeyuk, Katy Gero, Antonette Shibani, Md Naimul Hoque, Vipul Raheja, Seyed Parsa Neshaei, Sarah Sterman, Emad Alghamdi, Jin L.C. Guo, Mina Lee, Simon Knight</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146994">Link</a></p>
<p>Abstract: In our era of rapid technological advancement, the research landscape for writing assistants has become increasingly fragmented across various research communities. We seek to address this challenge by proposing a design space as a structured way to examine and explore the multidimensional space of intelligent and interactive writing assistants. Through community collaboration, we explore five aspects of writing assistants: task, user, technology, interaction, and ecosystem. Within each aspect, we define dimensions and codes by systematically reviewing 115 papers while leveraging the expertise of researchers in various disciplines. Our design space aims to offer researchers and designers a practical tool to navigate, comprehend, and compare the various possibilities of writing assistants, and aid in the design of new writing assistants.</p>
<h3>The Impact of Sketch-guided vs. Prompt-guided 3D Generative AIs on the Design Exploration Process</h3>
<p>Authors: Sergio Bromberg, Tae Hee Jo, Seonghoon Ban, Kyungwon Yun, Kyung Hoon Hyun, Seung Won Lee, Jiin Choi, Semin Jin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148240">Link</a></p>
<p>Abstract: Various modalities have emerged in the field of 3D generative AI (GenAI) to enhance design outcomes.  While some designers find inspiration in prompts to guide their design options, others prefer sketching to embody creative visions. Nonetheless, the impact of the different modalities of 3D GenAI on the design process remains largely unexplored. This study examines the utilization of prompt- and sketch-guided modalities within the design process by conducting linkography and workflow analyses with 12 designers. The results revealed that prompts played a pivotal role in stimulating initial ideation, whereas sketches played a crucial role in embodying design ideas. This investigation highlights the distinct contributions of these modalities at different phases of the design process, suggesting the potential for a more refined and synergistic collaboration between humans and AI. By elucidating the diverse functions of sketches and prompts, we propose prospective directions for the UX framework of the 3D GenAI.</p>
<h3>CreativeConnect: Supporting Reference Recombination for Graphic Design Ideation with Generative AI</h3>
<p>Authors: Jeongeon Park, John Chung, DaEun Choi, Sumin Hong, Juho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147936">Link</a></p>
<p>Abstract: Graphic designers often get inspiration through the recombination of references. Our formative study (N=6) reveals that graphic designers focus on conceptual keywords during this process, and want support for discovering the keywords, expanding them, and exploring diverse recombination options of them, while still having room for designers' creativity. We propose CreativeConnect, a system with generative AI pipelines that helps users discover useful elements from the reference image using keywords, recommends relevant keywords, generates diverse recombination options with user-selected keywords, and shows recombinations as sketches with text descriptions. Our user study (N=16) showed that CreativeConnect helped users discover keywords from the reference and generate multiple ideas based on them, ultimately helping users produce more design ideas with higher self-reported creativity compared to the baseline system without generative pipelines. While CreativeConnect was shown effective in ideation, we discussed how CreativeConnect can be extended to support other types of tasks in creativity support.</p>
<h2>Children and Adults Online Safety</h2>
<h3>"Pikachu would electrocute people who are misbehaving": Expert, Guardian and Child Perspectives on Automated Embodied Moderators for Safeguarding Children in Social Virtual Reality</h3>
<p>Authors: Cristina Fiani, Mohamed Khamis, Shaun Macdonald, Mark McGill, Robin Bretin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147166">Link</a></p>
<p>Abstract: Automated embodied moderation has the potential to create safer spaces for children in social VR, providing a protective figure that takes action to mitigate harmful interactions. However, little is known about how such moderation should be employed in practice. </p>
<p>Through interviews with 16 experts in online child safety and psychology, and workshops with 8 guardians and 13 children, we contribute a comprehensive overview of how Automated Embodied Moderators (AEMs) can safeguard children in social VR. </p>
<p>We explore perceived concerns, benefits and preferences across the stakeholder groups and gather first-of-their-kind recommendations and reflections around AEM design. </p>
<p>The results stress the need to adapt AEMs to children, whether victims or harassers, based on age and development, emphasising empowerment, psychological impact and humans/guardians-in-the-loop. Our work provokes new participatory design-led directions to consider in the development of AEMs for children in social VR taking child, guardian, and expert insights into account. </p>
<h3>Tricky vs. Transparent: Towards an Ecologically Valid and Safe Approach for Evaluating Online Safety Nudges for Teens</h3>
<p>Authors: Zainab Agha, Ruyuan Wan, Jinkyung Park, Yiwei Wang, Dominic DiFranzo, Naima Samreen Ali, Pamela Wisniewski, Karla Badillo-Urquiola</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147274">Link</a></p>
<p>Abstract: HCI research has been at the forefront of designing interventions for protecting teens online; yet, how can we test and evaluate these solutions without endangering the youth we aim to protect? Towards this goal, we conducted focus groups with 20 teens to inform the design of a social media simulation platform and study for evaluating online safety nudges co-designed with teens. Participants evaluated risk scenarios, personas, platform features, and our research design to provide insight regarding the ecological validity of these artifacts. Teens expected risk scenarios to be subtle and tricky, while also higher in risk to be believable. The teens iterated on the nudges to prioritize risk prevention without reducing autonomy, risk coping, and community accountability. For the simulation, teens recommended using transparency with some deceit to balance realism and respect for participants. Our meta-level research provides a teen-centered action plan to evaluate online safety interventions safely and effectively.</p>
<h3>Systemization of Knowledge (SoK): Creating a Research Agenda for Human-Centered Real-Time Risk Detection on Social Media Platforms</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jinkyung Park, Sarvech Qadir, Ashwaq Alsoubai, Pamela Wisniewski, Afsaneh Razi, Gianluca Stringhini</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147468">Link</a></p>
<p>Abstract: Accurate real-time risk identification is vital to protecting social media users from online harm, which has driven research towards advancements in machine learning (ML). While strides have been made regarding the computational facets of algorithms for "real-time'' risk detection, such research has not yet evaluated these advancements through a human-centered lens. To this end, we conducted a systematic literature review of 53 peer-reviewed articles on real-time risk detection on social media. Real-time detection was mainly operationalized as "early'' detection after-the-fact based on pre-defined chunks of data and evaluated based on standard performance metrics, such as timeliness. We identified several human-centered opportunities for advancing current algorithms, such as integrating human insight in feature selection, algorithms' improvement considering human behavior, and utilizing human evaluations. This work serves as a critical call-to-action for the HCI and ML communities to work together to protect social media users before, during, and after exposure to risks.</p>
<h3>"I Know I'm Being Observed:" Video Interventions to Educate Users about Targeted Advertising on Facebook</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Rhea Vengurlekar, Trevor Jones, Xinru Page, Stephanie Morales, Brian Smith, Norman Su, Yun-Chieh Tsai, Garrett Smith, Rachel George, Mainack Mondal, Josh Bedwell, Bart Knijnenburg, Sarah Carson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147986">Link</a></p>
<p>Abstract: Recent work explores how to educate and encourage users to protect their online privacy. We tested the efficacy of short videos for educating users about targeted advertising on Facebook. We designed a video that utilized an emotional appeal to explain risks associated with targeted advertising (fear appeal), and which demonstrated how to use the associated ad privacy settings (digital literacy). We also designed a version of this video which additionally showed the viewer their personal Facebook ad profile, facilitating personal reflection on how they are currently being profiled (reflective learning). We conducted an experiment (n = 127) in which participants watched a randomly assigned video and measured the impact over the following 10 weeks. We found that these videos significantly increased user engagement with Facebook advertising preferences, especially for those who viewed the reflective learning content. However, those who only watched the fear appeal content were more likely to disengage with Facebook as a whole. </p>
<h3>Sharenting on TikTok: Exploring Parental Sharing Behaviors and the Discourse Around Children's Online Privacy</h3>
<p>Authors: Sophie Stephenson, Christopher Page, Franziska Roesner, Apu Kapadia, Miranda Wei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147746">Link</a></p>
<p>Abstract: Since the inception of social media, parents have been sharing information about their children online. Unfortunately, this ``sharenting'' can expose children to several online and offline risks. Although researchers have studied sharenting on multiple platforms, sharenting on short-form video platforms like TikTok---where posts can contain detailed information, spread quickly, and spark considerable engagement---is understudied. Thus, we provide a targeted exploration of sharenting on TikTok. We analyzed 328 TikTok videos that demonstrate sharenting and 438 videos where TikTok creators discuss sharenting norms. Our results indicate that sharenting on TikTok indeed creates several risks for children, not only within individual posts but also in broader patterns of sharenting that arise when parents repeatedly use children to generate viral content. At the same time, creators voiced sharenting concerns and boundaries that reflect what has been observed on other platforms, indicating the presence of cross-platform norms. Promisingly, we observed that TikTok users are engaging in thoughtful conversations around sharenting and beginning to shift norms toward safer sharenting. We offer concrete suggestions for designers and platforms based on our findings.</p>
<h2>Creativity Tools</h2>
<h3>EyeGuide &amp; EyeConGuide: Gaze-based Visual Guides to Improve 3D Sketching Systems</h3>
<p>Authors: Wolfgang Stuerzlinger, Zeynep Ecem Gelmez, Rumeysa Turkmen, Mayra Barrera Machuca, Paul Asente, Anil Ufuk Batmaz, Mine Sarac, Ken Pfeuffer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147653">Link</a></p>
<p>Abstract: Visual guides help to align strokes and raise accuracy in Virtual Reality (VR) sketching tools. Automatic guides that appear at relevant sketching areas are convenient to have for a seamless sketching with a guide. We explore  guides that exploit eye-tracking to render them adaptive to the user's visual attention. EyeGuide and EyeConGuide cause visual grid fragments to appear spatially close to the user's intended sketches, based on the information of the user's eye-gaze direction and the 3D position of the hand. Here we evaluated the techniques in two user studies across simple and complex sketching objectives in VR. The results show that gaze-based guides have a positive effect on sketching accuracy, perceived usability and preference over manual activation in the tested tasks. Our research contributes to integrating gaze-contingent techniques for  assistive guides and presents important insights into multimodal design applications in VR.</p>
<h3>Formulating or Fixating: Effects of Examples on Problem Solving Vary as a Function of Example Presentation Interface Design</h3>
<p>Authors: Mark Fuge, Joel Chan, Zijian Ding, Eesh Kamrah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147454">Link</a></p>
<p>Abstract: Interactive systems that facilitate exposure to examples can augment problem solving performance. However designers of such systems are often faced with many practical design decisions about how users will interact with examples, with little clear theoretical guidance. To understand how example interaction design choices affect whether/how people benefit from examples, we conducted an experiment where 182 participants worked on a controlled analog to an exploratory creativity task, with access to examples of varying diversity and presentation interfaces. Task performance was worse when examples were presented in a list, compared to contextualized in the exploration space or shown in a dropdown list. Example lists were associated with more fixation, whereas contextualized examples were associated with using examples to formulate a model of the problem space to guide exploration. We discuss implications of these results for a theoretical framework that maps design choices to fundamental psychological mechanisms of creative inspiration from examples.</p>
<h3>GenQuery: Supporting Expressive Visual Search with Generative Models</h3>
<p>Authors: DaEun Choi, Tae Soo Kim, Juho Kim, Kihoon Son, Young-Ho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148274">Link</a></p>
<p>Abstract: Designers rely on visual search to explore and develop ideas in early design stages. However, designers can struggle to identify suitable text queries to initiate a search or to discover images for similarity-based search that can adequately express their intent. We propose GenQuery, a novel system that integrates generative models into the visual search process. GenQuery can automatically elaborate on users' queries and surface concrete search directions when users only have abstract ideas. To support precise expression of search intents, the system enables users to generatively modify images and use these in similarity-based search. In a comparative user study (N=16), designers felt that they could more accurately express their intents and find more satisfactory outcomes with GenQuery compared to a tool without generative features. Furthermore, the unpredictability of generations allowed participants to uncover more diverse outcomes. By supporting both convergence and divergence, GenQuery led to a more creative experience.</p>
<h3>Inkeraction: An Interaction Modality Powered by Ink Recognition and Synthesis</h3>
<p>Authors: Tayeb Karim, Lei Shi, Philippe Gervais, Palash Nandy, Rob Mickle, Mathangi Venkatesan, Mike Cleron, Ashwin Ganti, David Robishaw, Chris Melancon, Rachel Campbell, Maria Cirimele, Pedro Gonnet, Andrii Maksai, Angad Singh, Xiaoyu Iris Qu, Chelsey Fleming, Kirsten Climer, Claudiu Musat, Peggy Chi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147672">Link</a></p>
<p>Abstract: Ink is a powerful medium for note-taking and creativity tasks. Multi-touch devices and stylus input have enabled digital ink to be editable and searchable. To extend the capabilities of digital ink, we introduce Inkeraction, an interaction modality powered by ink recognition and synthesis. Inkeraction segments and classifies digital ink objects (e.g., handwriting and sketches), identifies relationships between them, and generates strokes in different writing styles. Inkeraction reshapes the design space for digital ink by enabling features that include: (1) assisting users to manipulate ink objects, (2) providing word-processor features such as spell checking, (3) automating repetitive writing tasks such as transcribing, and (4) bridging with generative models' features such as brainstorming. Feedback from two user studies with a total of 22 participants demonstrated that Inkeraction supported writing activities by enabling participants to write faster with fewer steps and achieve better writing quality.</p>
<h3>Personalizing Products with Stylized Head Portraits for Self-Expression</h3>
<p>Authors: Shengqi Dang, Yang Shi, Nan Cao, Nanxuan Zhao, Yechun Peng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147814">Link</a></p>
<p>Abstract: Personalizing products aesthetically or functionally can help users increase personal relevance and support self-expression. However, using non-abstract personal data such as head portraits for product personalization has been understudied. While recent advances in Artificial Intelligence have enabled generating stylized head portraits, these images also raise concerns about lack of control, artificiality, and ethics, which potentially limit their broader use. In this work, we present PicMe, a design support tool that converts user face photos into stylized head portraits as vector graphics that can be used to personalize products. To enable style transfer, PicMe leverages a deep-learning-based algorithm trained on an extended open-source illustration dataset of characters in a cartoonish and minimalistic style. We evaluated PicMe through two experiments and a user study. The results of our evaluation showed that PicMe can help create personalized head portraits that support self-expression.</p>
<h2>Ethics of Digital Technologies B</h2>
<h3>Fighting Malicious Designs: Towards Visual Countermeasures Against Dark Patterns</h3>
<p>Authors: Jan Borchers, René Röpke, René Schäfer, Sarah Sahabi, Paul Preuschoff</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147553">Link</a></p>
<p>Abstract: Dark patterns are malicious UI design strategies that nudge users towards decisions going against their best interests. To create technical countermeasures against them, dark patterns must be automatically detectable. While researchers have devised algorithms to detect some patterns automatically, there has only been little work to use obtained results to technically counter the effects of dark patterns when users face them on their devices.</p>
<p>To address this, we tested three visual countermeasures against 13 common dark patterns in an interactive lab study. The countermeasures we tested either (a) highlighted and explained the manipulation, (b) hid it from the user, or (c) let the user switch between the original view and the hidden version. From our data, we were able to extract multiple clusters of dark patterns where participants preferred specific countermeasures for similar reasons. To support creating effective countermeasures, we discuss our findings with a recent ontology of dark patterns.</p>
<h3>A Scoping Study of Evaluation Practices for Responsible AI Tools: Steps Towards Effectiveness Evaluations</h3>
<p>Authors: Glen Berman, Michael Madaio, Nitesh Goyal</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147656">Link</a></p>
<p>Abstract: Responsible design of AI systems is a shared goal across HCI and AI communities. Responsible AI (RAI) tools have been developed to support practitioners to identify, assess, and mitigate ethical issues during AI development. These tools take many forms (e.g., design playbooks, software toolkits, documentation protocols). However, research suggests that use of RAI tools is shaped by organizational contexts, raising questions about how effective such tools are in practice. To better understand how RAI tools are—and might be—evaluated, we conducted a qualitative analysis of 37 publications that discuss evaluations of RAI tools. We find that most evaluations focus on usability, while questions of tools’ effectiveness in changing AI development are sidelined. While usability evaluations are an important approach to evaluate RAI tools, we draw on evaluation approaches from other fields to highlight developer- and community-level steps to support evaluations of RAI tools’ effectiveness in shaping AI development practices and outcomes.</p>
<h3>Searching for the Non-Consequential: Dialectical Activities in HCI and the Limits of Computers</h3>
<p>Authors: Haoqi Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147571">Link</a></p>
<p>Abstract: This paper examines the pervasiveness of consequentialist thinking in human-computer interaction (HCI), and forefronts the value of non-consequential, dialectical activities in human life. Dialectical activities are human endeavors in which the value of the activity is intrinsic to itself, including being a good friend or parent, engaging in art-making or music-making, conducting research, and so on. I argue that computers—the ultimate consequentialist machinery for reliably transforming inputs into outputs—cannot be the be-all and end-all for promoting human values rooted in dialectical activities. I examine how HCI as a field of study might reconcile the consequentialist machines we have with the dialectical activities we value, and propose computational ecosystems as a vision for HCI that makes proper space for dialectical activities.</p>
<h3>Building an Ethics-Focused Action Plan: Roles, Process Moves, and Trajectories</h3>
<p>Authors: Ziqing Li, Brookley Rigsbee, Matthew Will, Shruthi Sai Chivukula, Aayushi Bharadwaj, Janna Johns, Ambika R Menon, Thomas Carlock, Anne Pivonka, Colin Gray, Ike Obi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147804">Link</a></p>
<p>Abstract: Design and technology practitioners are increasingly aware of the ethical impact of their work practices, desiring tools to support their ethical awareness across a range of contexts. In this paper, we report on findings from a series of six co-creation workshops with 26 technology and design practitioners that supported their creation of a bespoke ethics-focused action plan. Using a qualitative content analysis and thematic analysis approach, we identified a range of roles and process moves that practitioners and design students with professional experience employed and illustrate the interplay of these elements that impacted the creation of their action plan and revealed aspects of their ethical design complexity. We conclude with implications for supporting ethics in socio-technical practice and opportunities for the further development of methods that support ethical engagement and are resonant with the realities of practice.</p>
<h3>Staying at the Roach Motel: Cross-Country Analysis of Manipulative Subscription and Cancellation Flows</h3>
<p>Authors: Ashley Sheil, David Malone, Raphael Gellert, Hanna Schraffenberger, Gunes Acar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147230">Link</a></p>
<p>Abstract: Subscribing to online services is typically a straightforward process, but cancelling them can be arduous and confusing --- causing many to resign and continue paying for services they no longer use. Making the cancellation process intentionally difficult is recognized as a dark pattern called Roach Motel.</p>
<p>This paper characterizes the subscription and cancellation flows of popular news websites from four different countries and discusses them in the context of recent regulatory changes.</p>
<p>We study the design features that make it difficult to cancel a subscription and find several cancellation flows that feature intentional barriers, such as forcing users to call a representative or type in a phrase.</p>
<p>Further, we find many subscription flows that do not adequately inform users about recurring charges.</p>
<p>Our results point to a growing need for effective regulation of designs that trick, coerce, or manipulate users into paying for subscriptions they do not want.</p>
<h2>Supporting Children and Teens Socialization</h2>
<h3>From Adolescents' Eyes: Assessing an Indicator-Based Intervention to Combat Misinformation on TikTok</h3>
<p>Authors: Franziska Schneider, Tom Biselli, Katrin Hartwig, Christian Reuter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147187">Link</a></p>
<p>Abstract: Misinformation poses a recurrent challenge for video-sharing platforms (VSPs) like TikTok. Obtaining user perspectives on digital interventions addressing the need for transparency (e.g., through indicators) is essential.</p>
<p>This article offers a thorough examination of the comprehensibility, usefulness, and limitations of an indicator-based intervention from an adolescents' perspective.</p>
<p>This study (N=39; aged 13-16 years) comprised two qualitative steps: (1) focus group discussions and (2) think-aloud sessions, where participants engaged with a smartphone-app for TikTok.</p>
<p>The results offer new insights into how video-based indicators can assist adolescents' assessments. The intervention received positive feedback, especially for its transparency, and could be applicable to new content. This paper sheds light on how adolescents are expected to be experts while also being prone to video-based misinformation, with limited understanding of an intervention's limitations. </p>
<p>By adopting teenagers' perspectives, we contribute to HCI research and provide new insights into the chances and limitations of interventions for VSPs.</p>
<h3>For Me or Not for Me? The Ease With Which Teens Navigate Accurate and Inaccurate Personalized Social Media Content</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Nora McDonald, John Seberger, Afsaneh Razi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146940">Link</a></p>
<p>Abstract: Social media apps present personalized content to users. Such content is often described as "for you,'' raising questions about the relationship between users' sense of "self'' and the "you'' that is represented. Answering such questions is pressing in the case of teen users whose identities are still forming. Thus we ask, "What do teens think about the relationship between personalized content and their sense of self?'' We interviewed teens aged 13 to 17 (n = 15) about their experiences with personalized content on  social media. Participants so routinely saw themselves accurately reflected in personalized content that they noted the occasional inaccuracy with surprise, while simply scrolling past it. Our findings point to: the normalization of data doubles in the form of personalized content; and teens' indifference to inaccuracies presented by such data doubles.</p>
<h3>Wrist-bound Guanxi, Jiazu, and Kuolie: Unpacking Chinese Adolescent Smartwatch-Mediated Socialization</h3>
<p>Authors: Zhicong Lu, Lanjing Liu, Chao Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148286">Link</a></p>
<p>Abstract: Adolescent peer relationships, essential for their development, are increasingly mediated by digital technologies. As this trend continues, wearable devices, especially smartwatches tailored for adolescents, is reshaping their socialization. In China, smartwatches like XTC have gained wide popularity, introducing unique features such as "Bump-to-Connect'' and exclusive social platforms. Nonetheless, how these devices influence adolescents' peer experience remains unknown. Addressing this, we interviewed 18 Chinese adolescents (age: 11---16), discovering a smartwatch-mediated social ecosystem. Our findings highlight the ice-breaking role of smartwatches in friendship initiation and their use for secret messaging with local peers. Within the online smartwatch community, peer status is determined by likes and visibility, leading to diverse pursuit activities (eg., chu guanxi, jiazu,  kuolie) and negative social dynamics. We discuss the core affordances of smartwatches and Chinese cultural factors that influence adolescent social behavior, and offer implications for designing future wearables that responsibly and safely support adolescent socialization.</p>
<h3>ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events</h3>
<p>Authors: Chanmo Yang, Woosuk Seo, Young-Ho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148027">Link</a></p>
<p>Abstract: Children typically learn to identify and express their emotions by sharing stories and feelings with others, particularly family members. However, it is challenging for parents or siblings to have effective emotion communication with children since children are still developing their communication skills. We present ChaCha, a chatbot that encourages and guides children to share personal events and associated emotions. ChaCha combines a state machine and large language models (LLMs) to keep the dialogue on track while carrying on free-form conversations. Through an exploratory study with 20 children (aged 8-12), we examine how ChaCha prompts children to share personal events and guides them to describe associated emotions. Participants perceived ChaCha as a close friend and shared their stories on various topics, such as family trips and personal achievements. Based on the findings, we discuss opportunities for leveraging LLMs to design child-friendly chatbots to support children in sharing emotions.</p>
<h3>‘A Teaspoon of Authenticity’: Exploring How Young Adults BeReal on Social Media</h3>
<p>Authors: Priya Kumar, Ananya Reddy</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148046">Link</a></p>
<p>Abstract: BeReal is the latest social media platform to tout itself as a more authentic space for connection. The app notifies users at a random time each day and gives users two minutes to post an image from their smartphone’s front- and back-facing cameras. While prior work has theorized authenticity on social media and studied how various user populations enact authenticity, more research is needed to understand whether and how specific design features afford authenticity. We conducted a walkthrough of the BeReal app and interviewed 31 young adults about their experiences on BeReal. We found that participants approached authenticity in two ways—as extemporaneous interaction and as comprehensive self-presentation—and that BeReal harnesses the affordances of visibility, editability, availability, and persistence in a way that enables the former more than the latter. Based on our findings, we offer four recommendations for designers and researchers who seek to support authenticity online.</p>
<h2>Online Communities: Engagement A</h2>
<h3>Message in a Bottle: Investigating Bioart Installations as a Transdisciplinary Means of Community Engagement</h3>
<p>Authors: Lydia Stamato, Hasan Mahmud Prottoy, Erin Higgins, Lisa Scheifele, Foad Hamidi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147439">Link</a></p>
<p>Abstract: As exploration of living media, biology, and biotechnology advances HCI, researchers call attention to implications for ethics. We respond with a qualitative study of audience engagement with multimedia bioart installation. Bioart comprises a transdisciplinary practice that brings diverse perspectives in art, science, and technology into dialogue and engages audiences. Understanding a bioart exemplar, Raaz, as disrupting habitual modes of being, we investigate audience experiences in three contexts, elaborating transdisciplinary community engagement that takes seriously living media and biotechnology and informs HCI broadly through vital authenticity, performative reflection, empowered critique, distributed expertise, and revealed dynamics. We discuss how transdisciplinary community engagement functions as a mode of inquiry and design that supports inclusive liminal experiences.</p>
<h3>Analyzing User Engagement with TikTok's Short Format Video Recommendations using Data Donations</h3>
<p>Authors: Angelica Goetzen, Savvas Zannettou, Oshrat Ayalon, Olivia Nemes-Nemeth, Franziska Roesner, Krishna P. Gummadi, Elissa Redmiles</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147650">Link</a></p>
<p>Abstract: Short-format videos have exploded on platforms like TikTok, Instagram, and YouTube. Despite this, the research community lacks large-scale empirical studies into how people engage with short-format videos and the role of recommendation systems that offer endless streams of such content.  In this work, we analyze user engagement on TikTok using data we collect via a data donation system that allows TikTok users to donate their data. We recruited 347 TikTok users and collected 9.2M TikTok video recommendations they received. By analyzing user engagement, we find that the average daily usage time increases over the users' lifetime while the user attention remains stable at around 45%. We also find that users like more videos uploaded by people they follow than those recommended by people they do not follow. Our study offers valuable insights into how users engage with short-format videos on TikTok and lessons learned from designing a data donation system.</p>
<h3>Mapping the Design Space of Teachable Social Media Feed Experiences</h3>
<p>Authors: K. J. Kevin Feng, Xander Koo, David McDonald, Amy Zhang, Lawrence Tan, Amy Bruckman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147899">Link</a></p>
<p>Abstract: Social media feeds are deeply personal spaces that reflect individual values and preferences. However, top-down, platform-wide content algorithms can reduce users' sense of agency and fail to account for nuanced experiences and values. Drawing on the paradigm of interactive machine teaching (IMT), an interaction framework for non-expert algorithmic adaptation, we map out a design space for \textit{teachable social media feed experiences} to empower agential, personalized feed curation. To do so, we conducted a think-aloud study (N=24) featuring four social media platforms---Instagram, Mastodon, TikTok, and Twitter---to understand key signals users leveraged to determine the value of a post in their feed. We synthesized users' signals into taxonomies that, when combined with user interviews, inform five design principles that extend IMT into the social media setting. We finally embodied our principles into three feed designs that we present as sensitizing concepts for teachable feed experiences moving forward.</p>
<h3>How Founder Motivations, Goals, and Actions Influence Early Trajectories of Online Communities</h3>
<p>Authors: Sanjay Kairam, Jeremy Foote</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147364">Link</a></p>
<p>Abstract: Online communities offer their members various benefits, such as information access, social and emotional support, and entertainment. Despite the important role that founders play in shaping communities, prior research has focused primarily on what drives users to participate and contribute; the motivations and goals of founders remain underexplored. To uncover how and why online communities get started, we present findings from a survey of 951 recent founders of Reddit communities. We find that topical interest is the most common motivation for community creation, followed by motivations to exchange information, connect with others, and self-promote. Founders have heterogeneous goals for their nascent communities, but they tend to privilege community quality and engagement over sheer growth. Differences in founders' early attitudes towards their communities help predict not only the community-building actions that they pursue, but also the ability of their communities to attract visitors, contributors, and subscribers over the first 28 days. We end with a discussion of the implications for researchers, designers, and founders of online communities.</p>
<h3>“I Prefer Regular Visitors to Answer My Questions”: Users’ Desired Experiential Background of Contributors for Location-based Crowdsourcing Platform</h3>
<p>Authors: Chia-Yi Lee, Fang-Yu Lin, Yi-Ting Ho, Grace Yu-Chun Yen, Yao-Kuang Chen, Pei-Hua Tsai, Yung-Ju Chang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147015">Link</a></p>
<p>Abstract: This three-phase study explores the experiential background of contributors to platforms that provide crowdsourced location-related information. Initially, we utilized interviews to understand users' expectations for location-related information and the contributors’ experiential background they believe would enhance this information's utility. We then deployed a survey to identify the top eight sought-after location-information types and their perceived characteristics. Then the concluding online scenario-based study provided quantitative evidence about the interrelationships of eight types of location-related information, ten crucial quality attributes, and aspects of the contributors' experiential background believed to enhance the utility of the descriptions they provide. Notably, although certain experiential background aspects were deemed universally advantageous across all information types, unique connections were identified among specific information types and distinct experiential background aspects seen as augmenting the contributor's descriptions' utility. These insights underline the importance of location-based crowdsourcing platforms incorporating contributors’ experiential background when assigning tasks.</p>
<h2>Evaluating AI Technologies B</h2>
<h3>Listening to the Voices: Describing Ethical Caveats of Conversational User Interfaces According to Experts and Frequent Users</h3>
<p>Authors: John Sloan, Gian-Luca Savino, Jasmin Niess, Thomas Mildner, Rainer Malaka, Nina Wenig, Leigh Clark, Anna-Maria Meck, Marion Bartl, Diego Garaialde, Philip Doyle, Orla Cooney</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147969">Link</a></p>
<p>Abstract: Advances in natural language processing and understanding have led to a rapid growth in the popularity of conversational user interfaces (CUIs). While CUIs introduce novel benefits, they also yield risks that may exploit people's trust. Although research looking at unethical design deployed through graphical user interfaces (GUIs) established a thorough taxonomy of so-called dark patterns, there is a need for an equally in-depth understanding in the context of CUIs. Addressing this gap, we interviewed 27 participants from three cohorts: researchers, practitioners, and frequent users of CUIs. Applying thematic analysis, we develop five themes reflecting each cohort's insights about ethical design challenges and introduce the CUI Expectation Cycle, bridging system capabilities and user expectations while respecting each theme's ethical caveats. This research aims to inform future work to consider ethical constraints while adopting a human-centred approach.</p>
<h3>EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria</h3>
<p>Authors: Jamin Shin, Tae Soo Kim, Juho Kim, Young-Ho Kim, Yoonjoo Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147201">Link</a></p>
<p>Abstract: By simply composing prompts, developers can prototype novel generative applications with Large Language Models (LLMs). To refine prototypes into products, however, developers must iteratively revise prompts by evaluating outputs to diagnose weaknesses. Formative interviews (N=8) revealed that developers invest significant effort in manually evaluating outputs as they assess context-specific and subjective criteria. We present EvalLM, an interactive system for iteratively refining prompts by evaluating multiple outputs on user-defined criteria. By describing criteria in natural language, users can employ the system's LLM-based evaluator to get an overview of where prompts excel or fail, and improve these based on the evaluator's feedback. A comparative study (N=12) showed that EvalLM, when compared to manual evaluation, helped participants compose more diverse criteria, examine twice as many outputs, and reach satisfactory prompts with 59% fewer revisions. Beyond prompts, our work can be extended to augment model evaluation and alignment in specific application contexts.</p>
<h3>Understanding Choice Independence and Error Types in Human-AI Collaboration</h3>
<p>Authors: Abhinav Sharma, Ujwal Gadiraju, Alexander Erlei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147055">Link</a></p>
<p>Abstract: The ability to make appropriate delegation decisions is an important prerequisite of effective human-AI collaboration. Recent work, however, has shown that people struggle to evaluate AI systems in the presence of forecasting errors, falling well short of relying on AI systems appropriately. We use a pre-registered crowdsourcing study ($N=611$) to extend this literature by two underexplored crucial features of human AI decision-making: \textit{choice independence} and \textit{error type}. Subjects in our study repeatedly complete two prediction tasks and choose which predictions they want to delegate to an AI system. For one task, subjects receive a decision heuristic that allows them to make informed and relatively accurate predictions. The second task is substantially harder to solve, and subjects must come up with their own decision rule. We systematically vary the AI system's performance such that it either provides the best possible prediction for both tasks or only for one of the two. Our results demonstrate that people systematically violate choice independence by taking the AI's performance in an unrelated second task into account. Humans who delegate predictions to a superior AI in their own expertise domain significantly reduce appropriate reliance when the model makes systematic errors in a complementary expertise domain. In contrast, humans who delegate predictions to a superior AI in a complementary expertise domain significantly increase appropriate reliance when the model systematically errs in the human expertise domain. Furthermore, we show that humans differentiate between error types and that this effect is conditional on the considered expertise domain. This is the first empirical exploration of choice independence and error types in the context of human-AI collaboration. Our results have broad and important implications for the future design, deployment, and appropriate application of AI systems.  </p>
<h3>ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Martin Wattenberg, Priyan Vaithilingam, Chelse Swoopes, Ian Arawjo, Elena Glassman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147701">Link</a></p>
<p>Abstract: Evaluating outputs of large language models (LLMs) is challenging, requiring making—and making sense of—many responses. Yet tools that go beyond basic prompting tend to require knowledge of programming APIs, focus on narrow domains, or are closed-source. We present ChainForge, an open-source visual toolkit for prompt engineering and on-demand hypothesis testing of text generation LLMs. ChainForge provides a graphical interface for comparison of responses across models and prompt variations. Our system was designed to support three tasks: model selection, prompt template design, and hypothesis testing (e.g., auditing). We released ChainForge early in its development and iterated on its design with academics and online users. Through in-lab and interview studies, we find that a range of people could use ChainForge to investigate hypotheses that matter to them, including in real-world settings. We identify three modes of prompt engineering and LLM hypothesis testing: opportunistic exploration, limited evaluation, and iterative refinement.</p>
<h3>CloChat: Understanding How People Customize, Interact, and Experience Personas in Large Language Models</h3>
<p>Authors: DaEun Han, Hyeon Jeon, Jinwook Seo, Changhoon Oh, Juhye Ha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147362">Link</a></p>
<p>Abstract: Large language models (LLMs) have facilitated significant strides in generating conversational agents, enabling seamless, contextually relevant dialogues across diverse topics. However, the existing LLM-driven conversational agents have fixed personalities and functionalities, limiting their adaptability to individual user needs. Creating personalized agent personas with distinct expertise or traits can address this issue. Nonetheless, we lack knowledge of how people customize and interact with agent personas. In this research, we investigated how users customize agent personas and their impact on interaction quality, diversity, and dynamics. To this end, we developed CloChat, an interface supporting easy and accurate customization of agent personas in LLMs. We conducted a study comparing how participants interact with CloChat and ChatGPT. The results indicate that participants formed emotional bonds with the customized agents, engaged in more dynamic dialogues, and showed interest in sustaining interactions. These findings contribute to design implications for future systems with conversational agents using LLMs.</p>
<h2>Politics of Datasets</h2>
<h3>The Cadaver in the Machine: The Social Practices of Measurement and Validation in Motion Capture Technology</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mona Sloane, Hauke Sandhaus, Abigail Jacobs, Emanuel Moss, Emma Harvey</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147039">Link</a></p>
<p>Abstract: Motion capture systems, used across various domains, make body representations concrete through technical processes. We argue that the measurement of bodies and the validation of measurements for motion capture systems can be understood as social practices. By analyzing the findings of a systematic literature review (N=278) through the lens of social practice theory, we show how these practices, and their varying attention to errors, become ingrained in motion capture design and innovation over time. Moreover, we show how contemporary motion capture systems perpetuate assumptions about human bodies and their movements. We suggest that social practices of measurement and validation are ubiquitous in the development of data- and sensor-driven systems more broadly, and provide this work as a basis for investigating hidden design assumptions and their potential negative consequences in human-computer interaction.</p>
<h3>Aligning Data with the Goals of an Organization and Its Workers: Designing Data Labeling for Social Service Case Notes</h3>
<p>Authors: Whitney Nelson, Apoorva Gondimalla, Kenneth Fleischmann, Govind Joshi, Eunsol Choi, Sherri Greenberg, Varshinee Sreekanth, Stephen Slota, Min Kyung Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148090">Link</a></p>
<p>Abstract: The challenges of data collection in nonprofits for performance and funding reports are well-established in HCI research. Few studies, however, delve into improving the data collection process. Our study proposes ideas to improve data collection by exploring challenges that social workers experience when labeling their case notes. Through collaboration with an organization that provides intensive case management to those experiencing homelessness in the U.S., we conducted interviews with caseworkers and held design sessions where caseworkers, managers, and program analysts examined storyboarded ideas to improve data labeling. Our findings suggest several design ideas on how data labeling practices can be improved: Aligning labeling with caseworker goals, enabling shared control on data label design for a comprehensive portrayal of caseworker contributions, improving the synthesis of qualitative and quantitative data, and making labeling user-friendly. We contribute design implications for data labeling to better support multiple stakeholder goals in social service contexts.</p>
<h3>The ``Colonial Impulse" of Natural Language Processing: An Audit of Bengali Sentiment Analysis Tools and Their Identity-based Biases</h3>
<p>Authors: Jed Brubaker, Bryan Semaan, Shion Guha, Dipto Das</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146683">Link</a></p>
<p>Abstract: While colonization has sociohistorically impacted people's identities across various dimensions, those colonial values and biases continue to be perpetuated by sociotechnical systems. One category of sociotechnical systems--sentiment analysis tools--can also perpetuate colonial values and bias, yet less attention has been paid to how such tools may be complicit in perpetuating coloniality, although they are often used to guide various practices (e.g., content moderation). In this paper, we explore potential bias in sentiment analysis tools in the context of Bengali communities who have experienced and continue to experience the impacts of colonialism. Drawing on identity categories most impacted by colonialism amongst local Bengali communities, we focused our analytic attention on gender, religion, and nationality. We conducted an algorithmic audit of all sentiment analysis tools for Bengali, available on the Python package index (PyPI) and GitHub. Despite similar semantic content and structure, our analyses showed that in addition to inconsistencies in output from different tools, Bengali sentiment analysis tools exhibit bias between different identity categories and respond differently to different ways of identity expression. Connecting our findings with colonially shaped sociocultural structures of Bengali communities, we discuss the implications of downstream bias of sentiment analysis tools.</p>
<h3>Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM</h3>
<p>Authors: Jeffrey Heer, Michael Bernstein, James Landay, Janice Teoh, Michelle Lam</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147161">Link</a></p>
<p>Abstract: Data analysts have long sought to turn unstructured text data into meaningful concepts. Though common, topic modeling and clustering focus on lower-level keywords and require significant interpretative work. We introduce concept induction, a computational process that instead produces high-level concepts, defined by explicit inclusion criteria, from unstructured text. For a dataset of toxic online comments, where a state-of-the-art BERTopic model outputs “women, power, female,” concept induction produces high-level concepts such as “Criticism of traditional gender roles” and “Dismissal of women's concerns.” We present LLooM, a concept induction algorithm that leverages large language models to iteratively synthesize sampled text and propose human-interpretable concepts of increasing generality. We then instantiate LLooM in a mixed-initiative text analysis tool, enabling analysts to shift their attention from interpreting topics to engaging in theory-driven analysis. Through technical evaluations and four analysis scenarios ranging from literature review to content moderation, we find that LLooM’s concepts improve upon the prior art of topic models in terms of quality and data coverage. In expert case studies, LLooM helped researchers to uncover new insights even from familiar datasets, for example by suggesting a previously unnoticed concept of attacks on out-party stances in a political social media dataset.</p>
<h3>Situating Datasets: Making Public Eviction Data Actionable for Housing Justice</h3>
<p>Authors: Grace Guo, Katsuki Chan, Jordan Taylor, Carl DiSalvo, Elora Raymond, Anh-Ton Tran</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148020">Link</a></p>
<p>Abstract: Activists, governments, and academics regularly advocate for more open data. But how is data made open, and for whom is it made useful and usable? In this paper, we investigate and describe the work of making eviction data open to tenant organizers. We do this through an ethnographic description of ongoing work with a local housing activist organization. This work combines observation, direct participation in data work, and creating media artifacts, specifically digital maps. Our interpretation is grounded in D’Ignazio and Klein’s Data Feminism, emphasizing standpoint theory. Through our analysis and discussion, we highlight how shifting positionalities from data intermediaries to data accomplices affects the design of data sets and maps. We provide HCI scholars with three design implications when situating data for grassroots organizers: becoming a domain beginner, striving for data actionability, and evaluating our design artifacts by the social relations they sustain rather than just their technical efficacy.</p>
<h2>Touch, Gesture and Posture</h2>
<h3>CRTypist: Simulating Touchscreen Typing Behavior via Computational Rationality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jussi Jokinen, Yujun Zhu, Aditya Acharya, Shumin Zhai, Danqing Shi, Aini Putkonen, Antti Oulasvirta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147836">Link</a></p>
<p>Abstract: Touchscreen typing requires coordinating the fingers and visual attention for button-pressing, proofreading, and error correction. Computational models need to account for the associated fast pace, coordination issues, and closed-loop nature of this control problem, which is further complicated by the immense variety of keyboards and users. The paper introduces CRTypist, which generates human-like typing behavior. Its key feature is a reformulation of the supervisory control problem, with the visual attention and motor system being controlled with reference to a working memory representation tracking the text typed thus far. Movement policy is assumed to asymptotically approach optimal performance in line with cognitive and design-related bounds. This flexible model works directly from pixels, without requiring hand-crafted feature engineering for keyboards. It aligns with human data in terms of movements and performance, covers individual differences, and can generalize to diverse keyboard designs. Though limited to skilled typists, the model generates useful estimates of the typing performance achievable under various conditions.</p>
<h3>WheelPose: Data Synthesis Techniques to Improve Pose Estimation Performance on Wheelchair Users</h3>
<p>Authors: Yang Zhang, William Huang, Siyou Pei, Sam Ghahremani</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148072">Link</a></p>
<p>Abstract: Existing pose estimation models perform poorly on wheelchair users due to a lack of representation in training data. We present a data synthesis pipeline to address this disparity in data collection and subsequently improve pose estimation performance for wheelchair users. Our configurable pipeline generates synthetic data of wheelchair users using motion capture data and motion generation outputs simulated in the Unity game engine. We validated our pipeline by conducting a human evaluation, investigating perceived realism, diversity, and an AI performance evaluation on a set of synthetic datasets from our pipeline that synthesized different backgrounds, models, and postures. We found our generated datasets were perceived as realistic by human evaluators, had more diversity than existing image datasets, and had improved person detection and pose estimation performance when fine-tuned on existing pose estimation models. Through this work, we hope to create a foothold for future efforts in tackling the inclusiveness of AI in a data-centric and human-centric manner with the data synthesis techniques demonstrated in this work. Finally, for future works to extend upon, we open source all code in this research and provide a fully configurable Unity Environment used to generate our datasets. In the case of any models we are unable to share due to redistribution and licensing policies, we provide detailed instructions on how to source and replace said models. All materials can be found at https://github.com/hilab-open-source/wheelpose.</p>
<h3>Sitting Posture Recognition and Feedback: A Literature Review</h3>
<p>Authors: Christian Krauter, Michael Sedlmair, Sven Mayer, Alexander Achberger, Katrin Angerbauer, Aimée Sousa Calepso</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147428">Link</a></p>
<p>Abstract: Extensive sitting is unhealthy; thus, countermeasures are needed to react to the ongoing trend toward more prolonged sitting. A variety of studies and guidelines have long addressed the question of how we can improve our sitting habits. Nevertheless, sitting time is still increasing. Here, smart devices can provide a general overview of sitting habits for more nuanced feedback on the user's sitting posture. Based on a literature review (N=223), including publications from engineering, computer science, medical sciences, electronics, and more, our work guides developers of posture systems. There is a large variety of approaches, with pressure-sensing hardware and visual feedback being the most prominent. We found factors like environment, cost, privacy concerns, portability, and accuracy important for deciding hardware and feedback types. Further, one should consider the user's capabilities, preferences, and tasks. Regarding user studies for sitting posture feedback, there is a need for better comparability and for investigating long-term effects. </p>
<h3>iPose: Interactive Human Pose Reconstruction from Video</h3>
<p>Authors: Li-Yi Wei, Jingyuan Liu, Takeo Igarashi, Ariel Shamir</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146911">Link</a></p>
<p>Abstract: Reconstructing 3D human poses from video has wide applications, such as character animation and sports analysis. Automatic 3D pose reconstruction methods have demonstrated promising results, but failure cases can still appear due to the diversity of human actions, capturing conditions, and depth ambiguities. Thus, manual intervention remains indispensable, which can be time-consuming and require professional skills. We thus present iPose, an interactive tool that facilitates intuitive human pose reconstruction from a given video. Our tool incorporates both human perception in specifying pose appearance to achieve controllability, and video frame processing algorithms to achieve precision and automation. A user manipulates the projection of a 3D pose via 2D operations on top of video frames, and the 3D poses are updated correspondingly while satisfying both kinematic and video frame constraints. The pose updates are propagated temporally to reduce user workload. We evaluate the effectiveness of iPose with a user study on the 3DPW dataset and expert interviews.</p>
<h2>Governance and Public Policies</h2>
<h3>Data Probes as Boundary Objects for Technology Policy Design: Demystifying Technology for Policymakers and Aligning Stakeholder Objectives in Rideshare Gig Work</h3>
<p>Authors: Alexander Boltz, Angie Zhang, Veena Dubal, Rocita Rana, Min Kyung Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146997">Link</a></p>
<p>Abstract: Despite the evidence of harm that technology can inflict, commensurate policymaking to hold tech platforms accountable still lags. This is pertinent to app-based gig workers, where unregulated algorithms continue to dictate their work, often with little human recourse. While past HCI literature has investigated workers’ experiences under algorithmic management and how to design interventions, rarely are the perspectives of stakeholders who inform or craft policy sought. To bridge this, we propose using data probes---interactive visualizations of workers’ data that show the impact of technology practices on people---exploring them in 12 semi-structured interviews with policy informers, (driver-)organizers, litigators, and a lawmaker in the rideshare space. We show how data probes act as boundary objects to assist stakeholder interactions, demystify technology for policymakers, and support worker collective action. We discuss the potential for data probes as training tools for policymakers, and considerations around data access and worker risks when using data probes. </p>
<h3>In Dice We Trust: Uncertainty Displays for Maintaining Trust in Election Forecasts Over Time</h3>
<p>BEST_PAPER</p>
<p>Authors: Matthew Kay, Fumeng Yang, Nicholas Diakopoulos, Erik Nisbet, Chloe Mortenson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147247">Link</a></p>
<p>Abstract: Trust in high-profile election forecasts influences the public’s confidence in democratic processes and electoral integrity. Yet, maintaining trust after unexpected outcomes like the 2016 U.S. presidential election is a significant challenge. Our work confronts this challenge through three experiments that gauge trust in election forecasts. We generate simulated U.S. presidential election forecasts, vary win probabilities and outcomes, and present them to participants in a professional-looking website interface. In this website interface, we explore (1) four different uncertainty displays, (2) a technique for subjective probability correction, and (3) visual calibration that depicts an outcome with its forecast distribution. Our quantitative results suggest that text summaries and quantile dotplots engender the highest trust over time, with observable partisan differences. The probability correction and calibration show small-to-null effects on average. Complemented by our qualitative results, we provide design recommendations for conveying U.S. presidential election forecasts and discuss long-term trust in uncertainty communication. We provide preregistration, code, data, model files, and videos at https://doi.org/10.17605/OSF.IO/923E7.</p>
<h3>V-FRAMER: Visualization Framework for Mitigating Reasoning Errors in Public Policy</h3>
<p>Authors: Matthew Kay, Lily Ge, Steven Franconeri, Peter Cheng, Matthew Easterday, Evanthia Dimara</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147167">Link</a></p>
<p>Abstract: Existing data visualization design guidelines focus primarily on constructing grammatically-correct visualizations that faithfully convey the values and relationships in the underlying data. However, a designer may create a grammatically-correct visualization that still leaves audiences susceptible to reasoning misleaders, e.g. by failing to normalize data or using unrepresentative samples. Reasoning misleaders are especially pernicious when presenting public policy data, where data-driven decisions can affect public health, safety, and economic development. Through textual analysis, a formative evaluation, and iterative design with 19 policy communicators, we construct an actionable visualization design framework, V-FRAMER, that effectively synthesizes ways of mitigating reasoning misleaders. We discuss important design considerations for frameworks like V-FRAMER, including using concrete examples to help designers understand reasoning misleaders, and using a hierarchical structure to support example-based accessing. We further describe V-FRAMER's congruence with current practice and how practitioners might integrate the framework into their existing workflows. Related materials available at: https://osf.io/q3uta/.</p>
<h3>Affective Design: The Influence of Facebook Reactions on the Emotional Expression of the 114th US Congress</h3>
<p>Authors: Jacob Erickson, Bei Yan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147668">Link</a></p>
<p>Abstract: Political communication is critical for democracy, but polarized emotions in communication may make careful deliberation difficult. Much of modern political communication occurs on social media, which may exacerbate these challenges. This study examines how the design of social media features impact political communication. We examined how the introduction of Facebook Reactions influenced the posts of the 114th US Congress on the platform. We start by analyzing the emotional content of posts, finding that politicians generally increased their usage of negative emotions in their posts after the feature's launch. Further analysis showed that increased user engagement preceded the rise in negative emotions, suggesting that politicians were making adjustments based on user feedback. Our results show that the design features of social media can shape online political communication.</p>
<h3>Watching the Election Sausage Get Made: How Data Journalists Visualize the Vote Counting Process in U.S. Elections</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Matthew Kay, Mandi Cai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146972">Link</a></p>
<p>Abstract: Election results in the United States are visualized online in real time by news outlets as vote counting persists over days or weeks. They are a massive public-facing exercise in managing audience understanding of uncertainty in partial data, breaking news web traffic records as the public seeks information about winners. We categorize designs of real-time election results from 19 U.S. news outlets and election results providers for the 2020 and 2022 general elections to create a visual vocabulary of live results. We then use this vocabulary to guide interviews with data journalists who worked on these designs to understand their design goals and challenges. Tying these conversations back to our visual vocabulary, we map out how communication goals like balancing certainty and uncertainty in the journey towards finding out winners, alongside challenges like determining thresholds at which information is shown, manifest in the designs displayed.</p>
<h2>Supporting Communities</h2>
<h3>Pika: Empowering Non-Programmers to Author Executable Governance Policies in Online Communities</h3>
<p>Authors: Leijie Wang, Julija Rukanskaitė, Amy Zhang, Nicholas Vincent</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146949">Link</a></p>
<p>Abstract: Internet users have formed a wide array of online communities with diverse community goals and nuanced norms. However, most online platforms only offer a limited set of governance models in their software infrastructure and leave little room for customization. Consequently, technical proficiency becomes a prerequisite for online communities to build governance policies in code, excluding non-programmers from participation in designing community governance. In this paper, we present Pika, a system that empowers non-programmers to author a wide range of executable governance policies. At its core, Pika incorporates a declarative language that decomposes governance policies into modular components, thereby facilitating expressive policy authoring through a user-friendly, form-based web interface. Our user studies with 10 non-programmers and 7 programmers show that Pika can empower non-programmers to author policies approximately 2.5 times faster than programmers who author in code. We also provide insights about Pika's expressivity in supporting diverse policies online communities want.</p>
<h3>Do We Run How We Say We Run? Formalization and Practice of Governance in OSS Communities</h3>
<p>Authors: Curtis Atkisson, Mahasweta Chakraborti, Vladimir Filkov, Ştefan Stănciulescu, Seth Frey</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147289">Link</a></p>
<p>Abstract: Open Source Software (OSS) communities often resist regulation typical of traditional organizations. Yet formal governance systems are being increasingly adopted among communities, particularly through non-profit project-sponsoring foundations. Our study looks at the Apache Software Foundation Incubator program and 208 of the projects it has supported. We assemble a scalable, semantic pipeline to discover and analyze the governance behavior of projects from their mailing lists. We then investigate the relationship of such behavior to what the formal policies prescribe, through their own governance priorities and how their members internalize them. Our findings indicate that a greater amount of policy over a governed topic doesn't elicit more governed activity on that topic, but does predict greater internalization by community members. Moreover, alignment of community operations with foundation governance, be it dedicating their governance focus or adopting policy along topics seeing greater policy-making, has limited association with project outcomes.</p>
<h3>Third-Party Developers and Tool Development For Community Management on Live Streaming Platform Twitch</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: He Zhang, Jie Cai, John Carroll, Ya-Fang Lin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147232">Link</a></p>
<p>Abstract: Community management is critical for stakeholders to collaboratively build and sustain communities with socio-technical support. However, most of the existing research has mainly focused on the community members and the platform, with little attention given to the developers who act as intermediaries between the platform and community members and develop tools to support community management.  This study focuses on third-party developers (TPDs) for the live streaming platform Twitch and explores their tool development practices. Using a mixed method with in-depth qualitative analysis, we found that TPDs maintain complex relationships with different stakeholders (streamers, viewers, platform, professional developers), and the multi-layered policy restricts their agency regarding idea innovation and tool development. We argue that HCI research should shift its focus from tool users to tool developers with regard to community management. We propose designs to support closer collaboration between TPDS and the platform and professional developers and streamline TPDs' development process with unified toolkits and policy documentation.</p>
<h3>“I was able to give her the confidence”: Reciprocal Capacity Building in a Community-based Program for Digital Engagement</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jeanette Szomstein, Tawanna Dillahunt, Lutalo Sanifu, Julie Hui, Christie Baer, Kristin Seefeldt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146613">Link</a></p>
<p>Abstract: Assets-based approaches emphasize the importance of leveraging and building upon community strengths. We describe how a community-based digital capacity building program, Community Tech Workers (CTW), addresses the goals of assets-based development by hiring local residents and students to serve as tech support personnel for underserved minority small business owners in a Midwest city. Through interviews and observations, we examine how reciprocal relationships between tech workers and small business owners are critical to the success and sustainability of the program. We find that tech workers and business owners mutually benefit by 1) building confidence in technology together, 2) having business owners provide reciprocal guidance in professional development, and 3) fostering mutual appreciation and commitment to community development. We conclude by introducing the concept of reciprocal capacity building to HCI and discussing how it provides a potentially more equitable approach to community-based interventions.</p>
<h3>In Between Users and Developers: Serendipitous Connections and Intermediaries in Volunteer-Driven Open-Source Software Development</h3>
<p>Authors: Volker Wulf, Dave Randall, Yannick Bollmann, Lea Katharina Michel, Vasilis Ntouros, Leonie Jahn, Philip Engelbutzeder</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148224">Link</a></p>
<p>Abstract: Technology plays a pivotal role in driving transformation through grassroots movements, which operate on a local scale while embracing a global perspective on sustainability. Consequently, research emerged within Sustainable HCI, aiming to derive design principles that can empower these movements to scale their impact. However, a notable gap exists in contributions when addressing scalability of large free and open-source software (FOSS) projects. </p>
<p>This paper aims to present our endeavors as action-oriented researchers with the voluntary-driven Foodsharing.de movement, focusing on a local community, the open-source developers and their connections. Within a community of 585,000 users and only a few developers that is dedicated to save and share surplus food, we explore the concepts of ‘intermediary experience’. We also introduce the notion of ‘serendipitous connections’, highlighting the unintentional yet beneficial associations that can arise from the collaboration between developers and users.</p>
<h2>AI and Interaction Design</h2>
<h3>(Un)making AI Magic: A Design Taxonomy</h3>
<p>Authors: Maria Luce Lupetti, Dave Murray-Rust</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147268">Link</a></p>
<p>Abstract: This paper examines the role that enchantment plays in the design of AI things by constructing a taxonomy of design approaches that increase or decrease the perception of magic and enchantment. We start from the design discourse surrounding recent developments in AI technologies, highlighting specific interaction qualities such as algorithmic uncertainties and errors and articulating relations to the rhetoric of magic and supernatural thinking. Through analyzing and reflecting upon 52 students' design projects from two editions of a Master course in design and AI, we identify seven design principles and unpack the effects of each in terms of enchantment and disenchantment. We conclude by articulating ways in which this taxonomy can be approached and appropriated by design/HCI practitioners, especially to support exploration and reflexivity.</p>
<h3>AI-Assisted Causal Pathway Diagram for Human-Centered Design</h3>
<p>Authors: Predrag Klasnja, Rosemary Meza, Donghoon Shin, Gary Hsieh, Lucas Colusso, Ruican Zhong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147483">Link</a></p>
<p>Abstract: This paper explores the integration of causal pathway diagrams (CPD) into human-centered design (HCD), investigating how these diagrams can enhance the early stages of the design process. A dedicated CPD plugin for the online collaborative whiteboard platform Miro was developed to streamline diagram creation and offer real-time AI-driven guidance. Through a user study with designers ($N=20$), we found that CPD's branching and its emphasis on causal connections supported both divergent and convergent processes during design. CPD can also facilitate communication among stakeholders. Additionally, we found our plugin significantly reduces designers' cognitive workload and increases their creativity during brainstorming, highlighting the implications of AI-assisted tools in supporting creative work and evidence-based designs.</p>
<h3>VAL: Interactive Task Learning with GPT Dialog Parsing</h3>
<p>Authors: Christopher MacLellan, Lane Lawley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148061">Link</a></p>
<p>Abstract: Machine learning often requires millions of examples to produce static, black-box models. In contrast, interactive task learning (ITL) emphasizes incremental knowledge acquisition from limited instruction provided by humans in modalities such as natural language. However, ITL systems often suffer from brittle, error-prone language parsing, which limits their usability. Large language models (LLMs) are resistant to brittleness but are not interpretable and cannot learn incrementally. We present VAL, an ITL system with a new philosophy for LLM/symbolic integration. By using LLMs only for specific tasks—such as predicate and argument selection—within an algorithmic framework, VAL reaps the benefits of LLMs to support interactive learning of hierarchical task knowledge from natural language. Acquired knowledge is human interpretable and generalizes to support execution of novel tasks without additional training. We studied users' interactions with VAL in a video game setting, finding that most users could successfully teach VAL using language they felt was natural.</p>
<h3>Jigsaw: Supporting Designers to Prototype Multimodal Applications by Chaining AI Foundation Models</h3>
<p>Authors: David Chuan-En Lin, Nikolas Martelaro</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147352">Link</a></p>
<p>Abstract: Recent advancements in AI foundation models have made it possible for them to be utilized off-the-shelf for creative tasks, including ideating design concepts or generating visual prototypes. However, integrating these models into the creative process can be challenging as they often exist as standalone applications tailored to specific tasks. To address this challenge, we introduce Jigsaw, a prototype system that employs puzzle pieces as metaphors to represent foundation models. Jigsaw allows designers to combine different foundation model capabilities across various modalities by assembling compatible puzzle pieces. To inform the design of Jigsaw, we interviewed ten designers and distilled design goals. In a user study, we showed that Jigsaw enhanced designers' understanding of available foundation model capabilities, provided guidance on combining capabilities across different modalities and tasks, and served as a canvas to support design exploration, prototyping, and documentation.</p>
<h3>Enhancing UX Evaluation Through Collaboration with Conversational AI Assistants: Effects of Proactive Dialogue and Timing</h3>
<p>Authors: Emily Kuang, Minghao Li, Kristen Shinohara, Mingming Fan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147731">Link</a></p>
<p>Abstract: Usability testing is vital for enhancing the user experience (UX) of interactive systems. However, analyzing test videos is complex and resource-intensive. Recent AI advancements have spurred exploration into human-AI collaboration for UX analysis, particularly through natural language. Unlike user-initiated dialogue, our study investigated the potential of proactive conversational assistants to aid UX evaluators through automatic suggestions at three distinct times: before, in sync with, and after potential usability problems. We conducted a hybrid Wizard-of-Oz study involving 24 UX evaluators, using ChatGPT to generate automatic problem suggestions and a human actor to respond to impromptu questions. While timing did not significantly impact analytic performance, suggestions appearing after potential problems were preferred, enhancing trust and efficiency. Participants found the automatic suggestions useful, but they collectively identified more than twice as many problems, underscoring the irreplaceable role of human expertise. Our findings also offer insights into future human-AI collaborative tools for UX evaluation.</p>
<h2>AI and UI Design</h2>
<h3>SimUser: Generating Usability Feedback by Simulating Various Users Interacting with Mobile Applications</h3>
<p>Authors: Shi Chen, Hanfei Zhu, Yuping Jin, Suqi Lou, Zhenghua Pan, Lingyun Sun, Wei Xiang, Xinli Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148321">Link</a></p>
<p>Abstract: The conflict between the rapid iteration demand of prototyping and the time-consuming nature of user tests has led researchers to adopt AI methods to identify usability issues. However, these AI-driven methods concentrate on evaluating the feasibility of a system, while often overlooking the influence of specified user characteristics and usage contexts. Our work proposes a tool named SimUser based on large language models (LLMs) with the Chain-of-Thought structure and user modeling method. It generates usability feedback by simulating the interaction between users and applications, which is influenced by user characteristics and contextual factors. The empirical study (48 human users and 21 designers) validated that in the context of a simple smartwatch interface, SimUser could generate heuristic usability feedback with the similarity varying from 35.7% to 100% according to the user groups and usability category. Our work provides insights into simulating users by LLM to improve future design activities.</p>
<h3>Generating Automatic Feedback on UI Mockups with Large Language Models</h3>
<p>Authors: Peitong Duan, Yang Li, Bjoern Hartmann, Jeremy Warner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146712">Link</a></p>
<p>Abstract: Feedback on user interface (UI) mockups is crucial in design. However, human feedback is not always readily available. We explore the potential of using large language models for automatic feedback. Specifically, we focus on \changes{applying GPT-4 to automate heuristic evaluation}, which currently entails a human expert assessing a UI’s compliance with a set of design guidelines. We implemented a Figma plugin that takes in a UI design and a set of written heuristics, and renders automatically-generated feedback as constructive suggestions. We assessed performance on 51 UIs using three sets of guidelines, compared GPT-4-generated design suggestions with those from human experts, and conducted a study with 12 expert designers to understand fit with existing practice. We found that GPT-4-based feedback is useful for catching subtle errors, improving text, and considering UI semantics, but feedback also decreased in utility over iterations. Participants described several uses for this plugin despite its imperfect suggestions.</p>
<h3>MUD: Towards a Large-Scale and Noise-Filtered UI Dataset for Modern Style UI Modeling</h3>
<p>Authors: Chunyang Chen, Sidong Feng, Suyu Ma, David Kong, Han Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147307">Link</a></p>
<p>Abstract: The importance of computational modeling of mobile user interfaces (UIs) is undeniable. However, these require a high-quality UI dataset. Existing datasets are often outdated, collected years ago, and are frequently noisy with mismatches in their visual representation. This presents challenges in modeling UI understanding in the wild. This paper introduces a novel approach to automatically mine UI data from Android apps, leveraging Large Language Models (LLMs) to mimic human-like exploration. To ensure dataset quality, we employ the best practices in UI noise filtering and incorporate human annotation as a final validation step. Our results demonstrate the effectiveness of LLMs-enhanced app exploration in mining more meaningful UIs, resulting in a large dataset MUD of 18k human-annotated UIs from 3.3k apps. We highlight the usefulness of MUD in two common UI modeling tasks: element detection and UI retrieval, showcasing its potential to establish a foundation for future research into high-quality, modern UIs.</p>
<h3>Surveyor: Facilitating Discovery Within Video Games for Blind and Low Vision Players</h3>
<p>Authors: Peize Song, Hanxiu 'Hazel' Zhu, Jizhong Wang, Brian Smith, Vishnu Nair</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147935">Link</a></p>
<p>Abstract: Video games are increasingly accessible to blind and low vision (BLV) players, yet many aspects remain inaccessible. One aspect is the joy players feel when they explore environments and make new discoveries, which is integral to many games. Sighted players experience discovery by surveying environments and identifying unexplored areas. Current accessibility tools, however, guide BLV players directly to items and places, robbing them of that experience. Thus, a crucial challenge is to develop navigation assistance tools that also foster exploration and discovery. To address this challenge, we propose the concept of exploration assistance in games and design Surveyor, an in-game exploration assistance tool that enhances discovery by tracking where BLV players look and highlighting unexplored areas. We designed Surveyor using insights from a formative study and compared Surveyor's effectiveness to approaches found in existing accessible games. Our findings reveal implications for facilitating richer play experiences for BLV users within games.</p>
<h3>OmniActions: Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs</h3>
<p>Authors: Jiahao Li, Tovi Grossman, Stephanie Santosa, Michelle Li, Yan Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147206">Link</a></p>
<p>Abstract: The progression to "Pervasive Augmented Reality" envisions easy access to multimodal information continuously. However, in many everyday scenarios, users are occupied physically, cognitively or socially. This may increase the friction to act upon the multimodal information that users encounter in the world. To reduce such friction, future interactive interfaces should intelligently provide quick access to digital actions based on users' context. To explore the range of possible digital actions, we conducted a diary study that required participants to capture and share the media that they intended to perform actions on (e.g., images or audio), along with their desired actions and other contextual information. Using this data, we generated a holistic design space of digital follow-up actions that could be performed in response to different types of multimodal sensory inputs. We then designed \codename, a pipeline powered by large language models (LLMs) that processes multimodal sensory inputs and predicts follow-up actions on the target information grounded in the derived design space. Using the empirical data collected in the diary study, we performed quantitative evaluations on three variations of LLM techniques (intent classification, in-context learning and finetuning) and identified the most effective technique for our task. Additionally, as an instantiation of the pipeline, we developed an interactive prototype and reported preliminary user feedback about how people perceive and react to the action predictions and its errors. </p>
<h2>AI for Researchers</h2>
<h3>Know Your Audience: The benefits and pitfalls of generating plain language summaries beyond the "general" audience</h3>
<p>Authors: Noah A. Smith, Tal August, Katharina Reinecke, Kyle Lo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147146">Link</a></p>
<p>Abstract: Language models (LMs) show promise as tools for communicating science to the general public by simplifying and summarizing complex language. Because models can be prompted to generate text for a specific audience (e.g., college-educated adults), LMs might be used to create multiple versions of plain language summaries for people with different familiarities of scientific topics. However, it is not clear what the benefits and pitfalls of adaptive plain language are. When is simplifying necessary, what are the costs in doing so, and do these costs differ for readers with different background knowledge? Through three within-subjects studies in which we surface summaries for different envisioned audiences to participants of different backgrounds, we found that while simpler text led to the best reading experience for readers with little to no familiarity in a topic, high familiarity readers tended to ignore certain details in overly plain summaries (e.g., study limitations). Our work provides methods and guidance on ways of adapting plain language summaries beyond the single "general" audience. </p>
<h3>Evaluating Large Language Models on Academic Literature Understanding and Review: An Empirical Study among Early-stage Scholars</h3>
<p>Authors: Song Yan, Zuyuan Wang, Jiyao Wang, Haolong Hu, Youyu Sheng, Dengbo He</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147471">Link</a></p>
<p>Abstract: The rapid advancement of large language models (LLMs) such as ChatGPT makes LLM-based academic tools possible. However, little research has empirically evaluated how scholars perform different types of academic tasks with LLMs. Through an empirical study followed by a semi-structured interview, we assessed 48 early-stage scholars’ performance in conducting core academic activities (i.e., paper reading and literature reviews) under different levels of time pressure. Before conducting the tasks, participants received different training programs regarding the limitations and capabilities of the LLMs. After completing the tasks, participants completed an interview. Quantitative data regarding the influence of time pressure, task type, and training program on participants' performance in academic tasks was analyzed. Semi-structured interviews provided additional information on the influential factors of task performance, participants' perceptions of LLMs, and concerns about integrating LLMs into academic workflows. The findings can guide more appropriate usage and design of LLM-based tools in assisting academic work.</p>
<h3>Understanding the Role of Large Language Models in Personalizing and Scaffolding Strategies to Combat Academic Procrastination</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Joseph Williams, Alex Mariakakis, Anastasia Kuzminykh, Yuchen Zeng, Minyi Ma, Syed Ishtiaque Ahmed, Michael Liut, Rachel Kornfield, Dana Kulzhabayeva, Sarah Yi Xu, Mary Czerwinski, Ananya Bhattacharjee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148128">Link</a></p>
<p>Abstract: Traditional interventions for academic procrastination often fail to capture the nuanced, individual-specific factors that underlie them. Large language models (LLMs) hold immense potential for addressing this gap by permitting open-ended inputs, including the ability to customize interventions to individuals' unique needs. However, user expectations and potential limitations of LLMs in this context remain underexplored. To address this, we conducted interviews and focus group discussions with 15 university students and 6 experts, during which a technology probe for generating personalized advice for managing procrastination was presented. Our results highlight the necessity for LLMs to provide structured, deadline-oriented steps and enhanced user support mechanisms. Additionally, our results surface the need for an adaptive approach to questioning based on factors like busyness. These findings offer crucial design implications for the development of LLM-based tools for managing procrastination while cautioning the use of LLMs for therapeutic guidance.</p>
<h3>From Paper to Card: Transforming Design Implications with Generative AI</h3>
<p>Authors: Lucy Wang, Donghoon Shin, Gary Hsieh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147713">Link</a></p>
<p>Abstract: Communicating design implications is common within the HCI community when publishing academic papers, yet these papers are rarely read and used by designers. One solution is to use design cards as a form of translational resource that communicates valuable insights from papers in a more digestible and accessible format to assist in design processes. However, creating design cards can be time-consuming, and authors may lack the resources/know-how to produce cards. Through an iterative design process, we built a system that helps create design cards from academic papers using an LLM and text-to-image model. Our evaluation with designers (N=21) and authors of selected papers (N=12) revealed that designers perceived the design implications from our design cards as more inspiring and generative, compared to reading original paper texts, and the authors viewed our system as an effective way of communicating their design implications. We also propose future enhancements for AI-generated design cards.</p>
<h3>CollabCoder: A Lower-barrier, Rigorous Workflow for Inductive Collaborative Qualitative Analysis with Large Language Models</h3>
<p>Authors: Simon Perrault, Toby Li, Yuchen Guo, Tianqin Zhang, Gionnieve Lim, Zheng Zhang, Jie Gao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147401">Link</a></p>
<p>Abstract: Collaborative Qualitative Analysis (CQA) can enhance qualitative analysis rigor and depth by incorporating varied viewpoints. Nevertheless, ensuring a rigorous CQA procedure itself can be both complex and costly. To lower this bar, we take a theoretical perspective to design a one-stop, end-to-end workflow, CollabCoder, that integrates Large Language Models (LLMs) into key inductive CQA stages. In the independent open coding phase, CollabCoder offers AI-generated code suggestions and records decision-making data. During the iterative discussion phase, it promotes mutual understanding by sharing this data within the coding team and using quantitative metrics to identify coding (dis)agreements, aiding in consensus-building. In the codebook development phase, CollabCoder provides primary code group suggestions, lightening the workload of developing a codebook from scratch. A 16-user evaluation confirmed the effectiveness of CollabCoder, demonstrating its advantages over the existing CQA platform. All related materials of CollabCoder, including code and further extensions, will be included in: https://gaojie058.github.io/CollabCoder/.</p>
<h2>Assistive Technologies for Neurodiversity</h2>
<h3>Designing Scaffolding Strategies for Conversational Agents in Dialog Task of Neurocognitive Disorders Screening</h3>
<p>Authors: Dongjie Yang, Danxuan LIANG, Junze Li, Helen Meng, YUHANG ZENG, Xiaojuan Ma, Jiaxiong Hu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147967">Link</a></p>
<p>Abstract: Regular screening is critical for individuals at risk of neurocognitive disorders (NCDs) to receive early intervention. </p>
<p>Conversational agents (CAs) have been adopted to administer dialog-based NCD screening tests for their scalability compared to human-administered tests. </p>
<p>However, unique communication skills are required for CAs during NCD screening, e.g., clinicians often apply scaffolding to ensure subjects’ understanding of and engagement in screening tests. </p>
<p>Based on scaffolding theories and analysis of clinicians' practices from human-administered test recordings, we designed a scaffolding framework for the CA. </p>
<p>In an exploratory wizard-of-Oz study, the CA empowered by ChatGPT administered tasks in the Grocery Shopping Dialog Task with 15 participants (10 diagnosed with NCDs). </p>
<p>Clinical experts verified the quality of the CA's scaffolding and we explored its effects on task understanding of the participants.</p>
<p>Moreover, we proposed implications for the future design of CAs that enable scaffolding for scalable NCD screening.</p>
<h3>Unlock Life with a Chat(GPT): Integrating Conversational AI with Large Language Models into Everyday Lives of Autistic Individuals</h3>
<p>Authors: Hwajung Hong, Sung-In Kim, Dasom Choi, Sunok Lee, Kyungah Lee, Sangsu Lee, Hee Jeong Yoo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146853">Link</a></p>
<p>Abstract: Autistic individuals often draw on insights from their supportive networks to develop self-help life strategies ranging from everyday chores to social activities. However, human resources may not always be immediately available. Recently emerging conversational agents (CAs) that leverage large language models (LLMs) have the potential to serve as powerful information-seeking tools, facilitating autistic individuals to tackle daily concerns independently. This study explored the opportunities and challenges of LLM-driven CAs in empowering autistic individuals through focus group interviews and workshops (N=14). We found that autistic individuals expected LLM-driven CAs to offer a non-judgmental space, encouraging them to approach day-to-day issues proactively. However, they raised issues regarding critically digesting the CA responses and disclosing their autistic characteristics. Based on these findings, we propose approaches that place autistic individuals at the center of shaping the meaning and role of LLM-driven CAs in their lives, while preserving their unique needs and characteristics.</p>
<h3>An Emotion Translator: Speculative Design By Neurodiverse Dyads</h3>
<p>Authors: Jaime Snyder, Annuska Zolyomi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148281">Link</a></p>
<p>Abstract: For autistic individuals, navigating social and emotional interactions can be complex, often involving disproportionately high cognitive labor in contrast to neurotypical conversation partners. Through a novel approach to speculative co-design, autistic adults explored affective imaginaries --- imagined futuristic technology interventions --- to probe a provocative question: What if technology could translate emotions like it can translate spoken language? The resulting speculative prototype for an image-enabled emotion translator chat application included: (1) a visual system for representing personalized emotion taxonomies, and (2) a  Wizard of Oz implementation of these taxonomies in a low-fidelity chat application. Although wary of technology that purports to understand emotions, autistic participants saw value in being able to deploy visual emotion taxonomies during chats with neurotypical conversation partners. This work shows that affective technology should enable users to: (1) curate encodings of emotions used in system artifacts, (2) enhance interactive emotional understanding, and (3) have agency over how and when to use emotion features.</p>
<h3>From Letterboards to Holograms: Advancing Assistive Technology for Nonspeaking Autistic Individuals with the HoloBoard</h3>
<p>Authors: Vikram Jaswal, Lorans Alabood, Travis Dow, Diwakar Krishnamurthy, Kaylyn Feeley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147346">Link</a></p>
<p>Abstract: About one-third of autistic individuals are nonspeaking, i.e., they cannot use speech to convey their thoughts reliably. Many in this population communicate via spelling, a process in which they point to letters on a letterboard held upright in their field of view by a trained Communication and Regulation Partner (CRP). This paper focuses on transitioning such individuals to more independent, digital spelling that requires less support from the CRP, a goal most nonspeakers we consulted with desire. To enable this transition, we followed an approach that mimics an environment familiar to the nonspeaker and that harnesses the skills they already possess from physical letterboard training. Using this approach, we developed HoloBoard, a system that allows a nonspeaker, their CRP, and others, e.g., researchers, to share a common Augmented Reality (AR) environment containing a virtual letterboard. We configured the system to offer a brief (less than 10 minutes, on average) training module with graduated spelling tasks on the virtual letterboard. In a study involving 23 participants, 16 completed the entire module. These participants were able to spell words on the virtual letterboard without the CRP holding that board, an outcome we had not expected. When offered the opportunity to continue interacting with the virtual letterboard after the training module, 14 performed more complicated tasks than we had anticipated, spelling full sentences, or even offering feedback on the HoloBoard using solely the virtual board. Furthermore, five of these participants used the system solo, i.e., with the CRP and researchers absent from the virtual environment. These results suggest that training with the HoloBoard can lay the foundation for more independent communication, providing new social and educational opportunities for this marginalized population.</p>
<h3>Are Robots Ready to Deliver Autism Inclusion?: A Critical Review</h3>
<p>Authors: Imani Munyaka, Raunak Mondal, Naba Rizvi, Andrew Begel, Mya Bolds, William Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147238">Link</a></p>
<p>Abstract: The marginalization of autistic people in our society today is multi-faceted as it includes violence that is both physical and ideological in nature. It is rooted in the dehumanization, infantilization, and masculinization of autistic people and pervasive even in contemporary research studies that continue to echo ableist ideologies from the past. In this work, we identify how HRI research reproduces systemic social inequalities and explain how they align with historical misrepresentations, and other systemic barriers. We analyzed 142 papers focusing on HRI and autism published between 2016 and 2022. We critique these studies through a mixed-methods analysis of their definition of autism, study designs, participant recruitment, and results. Our findings indicate that HRI research stigmatizes autism in three dimensions - 1) the pathologization of autism, 2) gender and age-based essentialism, and 3) power imbalances. Our work uncovered that about 90% of HRI research during the timeline explored excluded the perspectives of autistic people, particularly those from understudied groups. We recommend broadening the inclusion of autistic people, considering research objectives beyond clinical use, and diversifying collaborations, foundational works considered, &amp; participant demographics for more inclusive future work.</p>
<h2>Body, Avatars, and Interaction in Immersive Realities</h2>
<h3>Your Avatar Seems Hesitant to Share About Yourself: How People Perceive Others' Avatars in the Transparent System</h3>
<p>Authors: Huisung Kwon, Ki Joon Kim, Hyemin Park, Yeonju Jang, Taenyun Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146653">Link</a></p>
<p>Abstract: In avatar-mediated communications, users often cannot identify how others' avatars are created, which is one of the important information they need to evaluate others. Thus, we tested a social virtual world that is transparent about others' avatar-creation methods and investigated how knowing about others' avatar-creation methods shapes users' perceptions of others and their self-disclosure. We conducted a 2x2 mixed-design experiment with system design (nontransparent vs. transparent system) as a between-subjects and avatar-creation method (customized vs. personalized avatar) as a within-subjects variable with 60 participants. The results revealed that personalized avatars in the transparent system were viewed less positively than customized avatars in the transparent system or avatars in the nontransparent system. These avatars appeared less comfortable and honest in their self-disclosure and less competent. Interestingly, avatars in the nontransparent system attracted more followers. Our results suggest being cautious when creating a social virtual world that discloses the avatar-creation process.</p>
<h3>CamTroller: An Auxiliary Tool for Controlling Your Avatar in PC Games Using Natural Motion Mapping</h3>
<p>Authors: Yuqian Wang, Junjian CHEN, Yan Luximon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147378">Link</a></p>
<p>Abstract: Natural motion mapping enhances the gaming experience by reducing the cognitive burden and increasing immersion. However, many players still use the keyboard and mouse in recent commercial PC games. To solve the conflict between complex avatar motion and the limited interaction system, we introduced CamTroller, an auxiliary tool for commercial one-to-one avatar mapping PC games following the concept of a natural user interface. To validate this concept, we selected PUBG  as the application scenario and developed a proof-of-concept system to help players achieve a better experience by naturally mapping selected human motions to the avatars in games through an RGB webcam. A within-subject study with 18 non-professional players practiced common operation (Basic), professional player’s operation (Pro), and CamTroller. Results showed that the performance of CamTroller was as good as the Pro and significantly higher than Basic. Also, the subjective evaluation showed that CamTroller achieved significantly higher intuitiveness than Basic and Pro.</p>
<h3>Stretch your reach: Studying Self-Avatar and Controller Misalignment in Virtual Reality Interaction</h3>
<p>Authors: Nuria Pelechano, Jose Luis Ponton, Alejandro Beacco, Reza Keshavarz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147486">Link</a></p>
<p>Abstract: Immersive Virtual Reality typically requires a head-mounted display (HMD) to visualize the environment and hand-held controllers to interact with the virtual objects. Recently, many applications display full-body avatars to represent the user and animate the arms to follow the controllers. Embodiment is higher when the self-avatar movements align correctly with the user. However, having a full-body self-avatar following the user's movements can be challenging due to the disparities between the virtual body and the user's body. This can lead to misalignments in the hand position that can be noticeable when interacting with virtual objects. In this work, we propose five different interaction modes to allow the user to interact with virtual objects despite the self-avatar and controller misalignment and study their influence on embodiment, proprioception, preference, and task performance. We modify aspects such as whether the virtual controllers are rendered, whether controllers are rendered in their real physical location or attached to the user's hand, and whether stretching the avatar arms to always reach the real controllers. We evaluate the interaction modes both quantitatively (performance metrics) and qualitatively (embodiment, proprioception, and user preference questionnaires). Our results show that the stretching arms solution, which provides body continuity and guarantees that the virtual hands or controllers are in the correct location, offers the best results in embodiment, user preference, proprioception, and performance. Also, rendering the controller does not have an effect on either embodiment or user preference. </p>
<h3>Virtual Body Swapping: A VR-Based Approach to Embodied Third-Person Self-Processing in Mind-Body Therapy</h3>
<p>Authors: Nina Döllinger, Carolin Wienrich, Mario Botsch, Erik Wolf, David Mal, Sebastian Keppler, Johann Habakuk Israel, Marc Latoschik</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146675">Link</a></p>
<p>Abstract: Virtual reality (VR) offers various opportunities for innovative therapeutic approaches, especially regarding self-related mind-body interventions.</p>
<p>We introduce a VR body swap system enabling multiple users to swap their perspectives and appearances and evaluate its effects on virtual sense of embodiment (SoE) and perception- and cognition-based self-related processes.</p>
<p>In a self-compassion-framed scenario, twenty participants embodied their personalized, photorealistic avatar, swapped bodies with an unfamiliar peer, and reported their SoE, interoceptive awareness (perception), and self-compassion (cognition). Participants' experiences differed between bottom-up and top-down processes. Regarding SoE, their agency and self-location shifted to the swap avatar, while their top-down self-identification remained with their personalized avatar. Further, the experience positively affected interoceptive awareness but not self-compassion. Our outcomes offer novel insights into the SoE in a multiple-embodiment scenario and highlight the need to differentiate between the different processes in intervention design. They raise concerns and requirements for future research on avatar-based mind-body interventions.</p>
<h3>"I Shot the Interviewer!": The Effects of In-VR Interviews on Participant Feedback and Rapport</h3>
<p>Authors: Nadia Pantidi, Jacob Young, Jennifer Ferreira</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146913">Link</a></p>
<p>Abstract: The integration of questionnaires into virtual reality experiences has recently been proposed as a way to reduce the potential biases introduced through the negative effects of leaving VR, however there has been little attention paid to how qualitative interviews could similarly be integrated into the virtual world for the purposes of user evaluation. In this paper we explore how conducting interviews within the virtual environment may affect the outcome of the evaluation and the relationship between participant and interviewer, and how this may differ with and without visual representation of the interviewer through use of an avatar. We conclude that in-VR interviews are a valid and promising method of data collection for user evaluation with similar data quality to in-person interviews, but that the interviewer should have a visual presence in the environment to maintain their relationship with the participant and the perceived realism of the environment.</p>
<h2>Children and Family A</h2>
<h3>LegacySphere: Facilitating Intergenerational Communication Through Perspective-Taking and Storytelling in Embodied VR</h3>
<p>Authors: Dongwook Yoon, Chenxinran Shen, Joanna McGrenere</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147857">Link</a></p>
<p>Abstract: Intergenerational communication can enhance well-being and family cohesion, but stereotypes and low empathy can be barriers to achieving effective communication.</p>
<p>VR perspective-taking is a potential approach that is known to enhance understanding and empathy toward others by allowing a user to take another's viewpoint. In this study, we introduce LegacySphere, a novel VR perspective-taking experience leveraging the combination of embodiment, role-play, and storytelling. To explore LegacySphere's design and impact, we conducted an observational study involving five dyads with a one-generation gap. We found that LegacySphere promotes empathetic and reflexive intergenerational dialogue. Specifically, avatar embodiment encourages what we term "relationship cushioning,'' fostering a trustful, open environment for genuine communications. The blending of real and embodied identities prompts insightful questions, merging both perspectives. The experience also nurtures a sense of unity and stimulates reflections on aging. Our work highlights the potential of immersive technologies for enhancing empathetic intergenerational relationships.</p>
<h3>Open Sesame? Open Salami! Personalizing Vocabulary Assessment-Intervention for Children via Pervasive Profiling and Bespoke Storybook Generation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Suwon Yoon, Wonjeong Park, Eunae Jeong, Inseok Hwang, Jungeun Lee, Dongsun Yim, Kyoosik Lee, Jae-Eun Cho</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147041">Link</a></p>
<p>Abstract: Children acquire language by interacting with their surroundings. Due to the different language environments each child is exposed to, the words they encounter and need in their life vary. Despite the standard tools for assessment and intervention as per predefined vocabulary sets, speech-language pathologists and parents struggle with the absence of systematic tools for child-specific custom vocabulary, i.e., out-of-standard but personally more important. </p>
<p>We propose "Open Sesame? Open Salami! (OSOS)", a personalized vocabulary assessment and intervention system with pervasive language profiling and targeted storybook generation, collaboratively developed with speech-language pathologists. </p>
<p>Melded into a child's daily life and powered by large language models (LLM), OSOS profiles the child's language environment, extracts priority words therein, and generates bespoke storybooks naturally incorporating those words. We evaluated OSOS through 4-week-long deployments to 9 families. We report their experiences with OSOS, and its implications in supporting personalization outside standards. </p>
<h3>Parent-Child Joint Media Engagement within HCI: A Scoping Analysis of the Research Landscape</h3>
<p>Authors: Junnan Yu, Siqi Yang, Xiang QI</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147467">Link</a></p>
<p>Abstract: Parents play essential roles in children's play and learning with various media, often leading to positive and productive engagement outcomes for both parties. As such, an increasing number of HCI research has focused on understanding parent-child joint media engagement (JME) and designing new technologies to foster productive joint media experiences for children and parents. However, we currently lack a systematic view of this emerging field, which hinders the research and design of new joint media experiences and technologies for families. In this work, we conduct a scoping review of parent-child JME research within HCI (N = 89) and analyze the included papers from three lenses: publication features, methodological features, and JME features. Based on these findings, we identify gaps and opportunities in parent-child JME research and further expand the theoretical framing of JME by developing a framework that captures different JME dimensions.</p>
<h3>"When He Feels Cold, He Goes to the Seahorse"—Blending Generative AI into Multimaterial Storymaking for Family Expressive Arts Therapy</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Di Liu, Pengcheng An, Hanqing Zhou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147056">Link</a></p>
<p>Abstract: Storymaking, as an integrative form of expressive arts therapy, is an effective means to foster family communication. Yet, the integration of generative AI as expressive materials in therapeutic storymaking remains underexplored. And there is a lack of HCI implications on how to support families and therapists in this context. Addressing this, our study involved five weeks of storymaking sessions with seven families guided by a professional therapist. In these sessions, the families used both traditional art-making materials and image-based generative AI to create and evolve their family stories. Via the rich empirical data and commentaries from four expert therapists, we contextualize how families creatively melded AI and traditional expressive materials to externalize their ideas and feelings. Through the lens of Expressive Therapies Continuum (ETC), we characterize the therapeutic implications of AI as expressive materials. Desirable interaction qualities to support children, parents, and therapists are distilled for future HCI research.</p>
<h3>"I want it to talk like Darth Vader": Helping Children Construct Creative Self-Efficacy with Generative AI</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Matthew Pedraja, Maia B. Song, Kaiwen Sun, Ritesh Kanchi, Ilena Dalla Gasperina, Grace Shin, Jason Yip, Jin Ha Lee, Michele Newman, Rannie Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147049">Link</a></p>
<p>Abstract: The emergence of generative artificial intelligence (GenAI) has ignited discussions surrounding its potential to enhance creative pursuits. However, distinctions between children's and adult's creative needs exist, which is important when considering the possibility of GenAI for children's creative usage. Building upon work in Human-Computer Interaction (HCI), fostering children's computational thinking skills, this study explores interactions between children (aged 7-13) and GenAI tools through methods of participatory design. We seek to answer two questions: (1) How do children in co-design workshops perceive GenAI tools and their usage for creative works? and (2) How do children navigate the creative process while using GenAI tools? How might these interactions support their confidence in their ability to create? Our findings contribute a model that describes the potential contexts underpinning child-GenAI creative interactions and explores implications of this model for theories of creativity, design, and use of GenAI as a constructionist tool for creative self-efficacy.</p>
<h2>Creative Practices, Arts and AI</h2>
<h3>CollageVis: Rapid Previsualization Tool for Indie Filmmaking using Video Collages</h3>
<p>Authors: Ryo Suzuki, Hye-Young Jo, Yoonji Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147599">Link</a></p>
<p>Abstract: Previsualization, previs, is essential for film production, allowing cinematographic experiments and effective collaboration. However, traditional previs methods like 2D storyboarding and 3D animation require substantial time, cost, and technical expertise, posing challenges for indie filmmakers. We introduce CollageVis, a rapid previsualization tool using video collages. CollageVis enables filmmakers to create previs through two main user interfaces. First, it automatically segments actors from videos and assigns roles using name tags, color filters, and face swaps. Second, it positions video layers on a virtual stage and allows users to record shots using mobile as a proxy for a virtual camera. These features were developed based on formative interviews by reflecting indie filmmakers’ needs and working methods. We demonstrate the system’s capability by replicating seven film scenes and evaluate the system’s usability with six indie filmmakers. The findings indicate that CollageVis allows more flexible yet expressive previs creation for idea development and collaboration.</p>
<h3>Machine Learning Processes As Sources of Ambiguity: Insights from AI Art</h3>
<p>Authors: Guido Salimbeni, Jichen Zhu, Steven Benford, Christian Sivertsen, Anders Løvlie</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148345">Link</a></p>
<p>Abstract: Ongoing efforts to turn Machine Learning (ML) into a design material have encountered limited success. </p>
<p>This paper examines the burgeoning area of AI art to understand how artists incorporate ML in their creative work. Drawing upon related HCI theories, we investigate how artists create ambiguity by analyzing nine AI artworks that use computer vision and image synthesis.</p>
<p>Our analysis shows that, in addition to the established types of ambiguity, artists worked closely with the ML process (dataset curation, model training, and application) and developed various techniques to evoke the ambiguity of processes. Our finding indicates that the current conceptualization of ML as a design material needs to reframe the ML process as design elements, instead of technical details. Finally, this paper offers reflections on commonly held assumptions in HCI about ML uncertainty, dependability, and explainability, and advocates to supplement the artifact-centered design perspective of ML with a process-centered one.</p>
<h3>Metamorpheus: Interactive, Affective, and Creative Dream Narration Through Metaphorical Visual Storytelling</h3>
<p>Authors: Zhicong Lu, Xin Feng, Zhiqi Gao, Qian Wan, Yining Bei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148065">Link</a></p>
<p>Abstract: Human emotions are essentially molded by lived experiences, from which we construct personalised meaning. The engagement in such meaning-making process has been practiced as an intervention in various psychotherapies to promote wellness. Nevertheless, to support recollecting and recounting lived experiences in everyday life remains under explored in HCI. It also remains unknown how technologies such as generative AI models can facilitate the meaning making process, and ultimately support affective mindfulness. In this paper we present Metamorpheus, an affective interface that engages users in a creative visual storytelling of emotional experiences during dreams. Metamorpheus arranges the storyline based on a dream's emotional arc, and provokes self-reflection through the creation of metaphorical images and text depictions. The system provides metaphor suggestions, and generates visual metaphors and text depictions using generative AI models, while users can apply generations to recolour and re-arrange the interface to be visually affective. Our experience-centred evaluation manifests that, by interacting with Metamorpheus, users can recall their dreams in vivid detail, through which they relive and reflect upon their experiences in a meaningful way.</p>
<h3>An Artists' Perspectives on Natural Interactions for Virtual Reality 3D Sketching</h3>
<p>Authors: Francisco Ortega, Richard Rodriguez, Cyane Tornatzky, Mayra Barrera Machuca, Anil Ufuk Batmaz, Brian Sullivan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147688">Link</a></p>
<p>Abstract: Virtual Reality (VR) applications like OpenBrush offer artists access to 3D sketching tools within the digital 3D virtual space. These 3D sketching tools allow users to ``paint'' using virtual digital strokes that emulate real-world mark-making. Yet, users paint these strokes through (unimodal) VR controllers. Given that sketching in VR is a relatively nascent field, this paper investigates ways to expand our understanding of sketching in virtual space, taking full advantage of what an immersive digital canvas offers. Through a study conducted with the participation of artists, we identify potential methods for natural multimodal and unimodal interaction techniques in 3D sketching. These methods demonstrate ways to incrementally improve existing interaction techniques and incorporate artistic feedback into the design.</p>
<h3>#PoetsOfInstagram: Navigating The Practices And Challenges Of Novice Poets On Instagram</h3>
<p>Authors: Ankolika De, Zhicong Lu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148301">Link</a></p>
<p>Abstract: Commencing as a photo-sharing platform, Instagram has since become multifaceted, accommodating diverse art forms, with poetry emerging as a prominent one. However, the academic understanding of Instagram's poetry community is limited, yet its significance emerges from its distinctive utilization of a primarily visual social media platform guided by recommendation algorithms for disseminating poetry, further characterized by a predominantly novice creative population. We employ qualitative analysis to explore motivations, experiences, and algorithmic influence within Instagram's poetry community. We demonstrate that participants prioritize conforming to algorithmic constraints for visibility, yet maintain their community's values of integrity and originality, illustrating the tension between algorithmic growth and participant authenticity. We introduce the concept of Algorithmically Mediated Creative Labor, a phenomenon specific to non-monetizing creative users who are impacted by the prioritization of professional creators and continually adapt their creative endeavours to align with platform logic, thereby affecting their motivation and creative outputs.</p>
<h2>Creativity: Visualizations and AI</h2>
<h3>IntentTuner: An Interactive Framework for Integrating Human Intentions in Fine-tuning Text-to-Image Generative Models</h3>
<p>Authors: Wei Zeng, Xingchen Zeng, Ziyao Gao, Yilin Ye</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147372">Link</a></p>
<p>Abstract: Fine-tuning facilitates the adaptation of text-to-image generative models to novel concepts (e.g., styles and portraits), empowering users to forge creatively customized content. Recent efforts on fine-tuning focus on reducing training data and lightening computation overload but neglect alignment with user intentions, particularly in manual curation of multi-modal training data and intent-oriented evaluation. Informed by a formative study with fine-tuning practitioners for comprehending user intentions, we propose IntentTuner, an interactive framework that intelligently incorporates human intentions throughout each phase of the fine-tuning workflow. IntentTuner enables users to articulate training intentions with imagery exemplars and textual descriptions, automatically converting them into effective data augmentation strategies. Furthermore, IntentTuner introduces novel metrics to measure user intent alignment, allowing intent-aware monitoring and evaluation of model training. Application exemplars and user studies demonstrate that IntentTuner streamlines fine-tuning, reducing cognitive effort and yielding superior models compared to the common baseline tool.</p>
<h3>Table Illustrator: Puzzle-based interactive authoring of plain tables</h3>
<p>Authors: Di Weng, Yurun Yang, Yanwei Huang, Ran Chen, Yingcai Wu, Xinhuan Shu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147780">Link</a></p>
<p>Abstract: Plain tables excel at displaying data details and are widely used in data presentation, often polished to an elaborate appearance for readability in many scenarios. However, existing authoring tools fail to provide both flexible and efficient support for altering the table layout and styles, motivating us to develop an intuitive and swift tool for table prototyping. To this end, we contribute Table Illustrator, a table authoring system taking a novel visual metaphor, puzzle, as the primary interaction unit. Through combinations and configurations on puzzles, the system enables rapid table construction and supports a diverse range of table layouts and styles. The tool design is informed by practical challenges and requirements from interviews with 10 table practitioners and a structured design space based on an analysis of over 2,500 real-world tables. User studies showed that Table Illustrator achieved comparable performance to Microsoft Excel while reducing users' completion time and perceived workload.</p>
<h3>Is It AI or Is It Me? Understanding Users’ Prompt Journey with Text-to-Image Generative AI Tools</h3>
<p>Authors: Atefeh Mahdavi Goloujeh, Brian Magerko, Anne Sullivan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146973">Link</a></p>
<p>Abstract: Generative Artificial Intelligence (AI) has witnessed unprecedented growth in text-to-image AI tools. Yet, much remains unknown about users' prompt journey with such tools in the wild. In this paper, we posit that designing human-centered text-to-image AI tools requires a clear understanding of how individuals intuitively approach crafting prompts, and what challenges they may encounter. To address this, we conducted semi-structured interviews with 19 existing users of a text-to-image AI tool. Our findings (1) offer insights into users’ prompt journey including structures and processes for writing, evaluating, and refining prompts in text-to-image AI tools and (2) indicate that users must overcome barriers to aligning AI to their intents, and mastering prompt crafting knowledge. From the findings, we discuss the prompt journey as an individual yet a social experience and highlight opportunities for aligning text-to-image AI tools and users’ intents.</p>
<h3>PromptCharm: Text-to-Image Generation through Multi-modal Prompting and Refinement</h3>
<p>Authors: Lei Ma, Yuheng Huang, Zhijie Wang, Da Song, Tianyi Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148288">Link</a></p>
<p>Abstract: The recent advancements in Generative AI have significantly advanced the field of text-to-image generation. The state-of-the-art text-to-image model, Stable Diffusion, is now capable of synthesizing high-quality images with a strong sense of aesthetics. Crafting text prompts that align with the model's interpretation and the user's intent thus becomes crucial. However, prompting remains challenging for novice users due to the complexity of the stable diffusion model and the non-trivial efforts required for iteratively editing and refining the text prompts. To address these challenges, we propose PromptCharm, a mixed-initiative system that facilitates text-to-image creation through multi-modal prompt engineering and refinement. To assist novice users in prompting, PromptCharm first automatically refines and optimizes the user's initial prompt. Furthermore, PromptCharm supports the user in exploring and selecting different image styles within a large database. To assist users in effectively refining their prompts and images, PromptCharm renders model explanations by visualizing the model's attention values. If the user notices any unsatisfactory areas in the generated images, they can further refine the images through model attention adjustment or image inpainting within the rich feedback loop of PromptCharm. To evaluate the effectiveness and usability of PromptCharm, we conducted a controlled user study with 12 participants and an exploratory user study with another 12 participants. These two studies show that participants using PromptCharm were able to create images with higher quality and better aligned with the user's expectations compared with using two variants of PromptCharm that lacked interaction or visualization support.</p>
<h3>An Accessible, Three-Axis Plotter for Enhancing Calligraphy Learning through Generated Motion</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Cathy Mengying Fang, Zach Lieberman, Quincy Kuang, Pattie Maes, Hiroshi Ishii, Lingdong Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147202">Link</a></p>
<p>Abstract: An Accessible, Three-Axis Plotter for Enhancing Calligraphy Learning through Generated Motion</p>
<h2>Data Visualization and Literacy</h2>
<h3>Data Storytelling in Data Visualisation: Does it Enhance the Efficiency and Effectiveness of Information Retrieval and Insights Comprehension?</h3>
<p>Authors: Roberto Martinez-Maldonado, Lixiang Yan, Vanessa Echeverria, Hongbo Shao, Dragan Gasevic</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146892">Link</a></p>
<p>Abstract: Data storytelling (DS) is rapidly gaining attention as an approach that integrates data, visuals, and narratives to create data stories that can help a particular audience to comprehend the key messages underscored by the data with enhanced efficiency and effectiveness. It has been posited that DS can be especially advantageous for audiences with limited visualisation literacy, by presenting the data clearly and concisely. However, empirical studies confirming whether data stories indeed provide these benefits over conventional data visualisations are scarce. To bridge this gap, we conducted a study with 103 participants to determine whether DS indeed improve both efficiency and effectiveness in tasks related to information retrieval and insights comprehension. Our findings suggest that data stories do improve the efficiency of comprehension tasks, as well as the effectiveness of comprehension tasks that involve a single insight, compared with conventional visualisations. Interestingly, these benefits were not associated with participants' visualisation literacy.</p>
<h3>Make Interaction Situated: Designing User Acceptable Interaction for Situated Visualization in Public Environments</h3>
<p>Authors: Zhuo Wang, Wei Zeng, Xiaojuan Ma, Weiyue Lin, Qian Zhu, Wai Tong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147605">Link</a></p>
<p>Abstract: Situated visualization blends data into the real world to fulfill individuals’ contextual information needs. However, interacting with situated visualization in public environments faces challenges posed by users’ acceptance and contextual constraints. To explore appropriate interaction design, we first conduct a formative study to identify users’ needs for data and interaction. Informed by the findings, we summarize appropriate interaction modalities with eye-based, hand-based and spatially-aware object interaction for</p>
<p>situated visualization in public environments. Then, through an iterative design process with six users, we explore and implement interactive techniques for activating and analyzing with situated visualization. To assess the effectiveness and acceptance of these</p>
<p>interactions, we integrate them into an AR prototype and conduct a within-subjects study in public scenarios using conventional hand-only interactions as the baseline. The results show that participants preferred our prototype over the baseline, attributing their preference to the interactions being more acceptable, flexible, and practical in public.</p>
<h3>A Human Information Processing Theory of the Interpretation of Visualizations: Demonstrating Its Utility</h3>
<p>Authors: Mateja Jamnik, Peter Cheng, Daniel Raggi, Grecia Garcia Garcia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147576">Link</a></p>
<p>Abstract: Providing an approach to model the memory structures that humans build as they use visualizations could be useful for researchers, designers and educators in the field of information visualization.  Cheng and colleagues formulated Representation Interpretive Structure Theory (RIST) for that purpose.  RIST adopts a human information processing perspective in order to address the immediate, short timescale, cognitive load likely to be experienced by visualization users.  RIST is operationalized in a graphical modeling notation and browser-based editor.  This paper demonstrates the utility of RIST by showing that (a): RIST models are compatible with established empirical and computational cognitive findings about differences in human performance on alternative representations; (b) they can encompass existing explanations from the literature; and, (c) they provide new explanations about causes of those performance differences.</p>
<h3>VAID: Indexing View Designs in Visual Analytics System</h3>
<p>Authors: Zikun Deng, Ji Lan, Haotian Li, Yong Wang, Dazhen Deng, Aoyu Wu, Huamin Qu, Lu Ying, Jiang Wu, Yingcai Wu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148123">Link</a></p>
<p>Abstract: Visual analytics (VA) systems have been widely used in various application domains. However, VA systems are complex in design, which imposes a serious problem: although the academic community constantly designs and implements new designs, the designs are difficult to query, understand, and refer to by subsequent designers. To mark a major step forward in tackling this problem, we index VA designs in an expressive and accessible way, transforming the designs into a structured format. We first conducted a workshop study with VA designers to learn user requirements for understanding and retrieving professional designs in VA systems. Thereafter, we came up with an index structure VAID to describe advanced and composited visualization designs with comprehensive labels about their analytical tasks and visual designs. The usefulness of VAID was validated through user studies. Our work opens new perspectives for enhancing the accessibility and reusability of professional visualization designs.</p>
<h3>Reading Between the Pixels: Investigating the Barriers to Visualization Literacy</h3>
<p>Authors: Kehang Zhu, Hanspeter Pfister, Carolina Nobre, Johanna Beyer, Eric Mörth</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147374">Link</a></p>
<p>Abstract: In our current visual-centric digital age, the capability to interpret, understand, and produce visual representations of data —termed visualization literacy— is paramount. However, not everyone is adept at navigating this visual terrain. This paper explores the barriers that individuals who misread a visualization encounter, aiming to understand their specific mental gaps.</p>
<p>Utilizing a mixed-method approach, we administered the Visualization Literacy Assessment Test (VLAT) to a group of 120 participants drawn from diverse demographic backgrounds, which provided us with 1774 task completions. We augmented the standard VLAT test to capture quantitative and qualitative data on participants' errors. We collected participant sketches and open-ended text about their analysis approach, providing insight into users' mental models and rationale.</p>
<p>Our findings reveal that individuals who incorrectly answer visualization literacy questions often misread visual channels, confound chart labels with data values, or struggle to translate data-driven questions into visual queries. Recognizing and bridging visualization literacy gaps not only ensures inclusivity but also enhances the overall effectiveness of visual communication in our society. </p>
<h2>Data Visualization and Physicalization</h2>
<h3>StableLev: Data-Driven Stability Enhancement for Multi-Particle Acoustic Levitation</h3>
<p>Authors: Sriram Subramanian, Prateek Mittal, Giorgos Christopoulos, Lei Gao, Ryuji Hirayama</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148311">Link</a></p>
<p>Abstract: Acoustic levitation is an emerging technique that has found application in contactless assembly and dynamic displays. It uses precise phase control in an ultrasound transducer array to manage the positions and movements of multiple particles. Yet, maintaining stable mid-air particles is challenging, with unexpected drops disrupting the intended motion and position. Here, we present StableLev, a data-driven pipeline for the detection and amendment of instabilities in multi-particle levitation. We first curate a hybrid levitation dataset, blending optimized simulations with labels based on actual trajectory outcomes. We then design an AutoEncoder to detect anomalies in the simulated data, correlating closely with observed particle drops. Finally, we reconstruct the acoustic field at anomaly regions to improve particle stability and experimentally demonstrate successful dynamic levitation for trajectories within our dataset. Our work provides new insights into multi-particle levitation and enhances its robustness, which will be valuable in a wide range of applications.</p>
<h3>"Yeah, this graph doesn't show that": Analysis of Online Engagement with Misleading Data Visualizations</h3>
<p>Authors: Alexander Lex, Marina Kogan, Maxim Lisnic</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147712">Link</a></p>
<p>Abstract: Attempting to make sense of a phenomenon or crisis, social media users often share data visualizations and interpretations that can be erroneous or misleading. Prior work has studied how data visualizations can mislead, but do misleading visualizations reach a broad social media audience? And if so, do users amplify or challenge misleading interpretations? To answer these questions, we conducted a mixed-methods analysis of the public's engagement with data visualization posts about COVID-19 on Twitter. Compared to posts with accurate visual insights, our results show that posts with misleading visualizations garner more replies in which the audiences point out nuanced fallacies and caveats in data interpretations. Based on the results of our thematic analysis of engagement, we identify and discuss important opportunities and limitations to effectively leveraging crowdsourced assessments to address data-driven misinformation.</p>
<h3>Epigraphics: Message-Driven Infographics Authoring</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Tongyu Zhou, Gromit Yeuk-Yin Chan, Jeff Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148344">Link</a></p>
<p>Abstract: The message a designer wants to convey plays a pivotal role in directing the design of an infographic, yet most authoring workflows start with creating the visualizations or graphics first without gauging whether they fit the message. To address this gap, we propose Epigraphics, a web-based authoring system that treats an "epigraph" as the first-class object, and uses it to guide infographic asset creation, editing, and syncing. The system uses the text-based message to recommend visualizations, graphics, data filters, color palettes, and animations. It further supports between-asset interactions and fine-tuning such as recoloring, highlighting, and animation syncing that enhance the aesthetic cohesiveness of the assets. A gallery and case studies show that our system can produce infographics inspired by existing popular ones, and a task-based usability study with 10 designers show that a text-sourced workflow can standardize content, empower users to think more about the big picture, and facilitate rapid prototyping.</p>
<h3>From Exploration to End of Life: Unpacking Sustainability in Physicalization Practices</h3>
<p>BEST_PAPER</p>
<p>Authors: Tatiana Losev, Sarah Hayes, Rebecca Noonan, Georgia Panagiotidou, Uta Hinrichs, Luiz Morais</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147627">Link</a></p>
<p>Abstract: Data physicalizations have gained prominence across domains, but their environmental impact has been largely overlooked. This work addresses this gap by investigating the interplay between sustainability and physicalization practices. We conducted interviews with experts from diverse backgrounds, followed by a survey to gather insights into how they approach physicalization projects and reflect on sustainability. Our thematic analysis revealed sustainability considerations throughout the entire physicalization life cycle — a framework that encompasses various stages in a physicalization's existence. Notably, we found no single agreed-upon definition for sustainable physicalizations, highlighting the complexity of integrating sustainability into physicalization practices. We outline sustainability challenges and strategies based on participants' experiences and propose the Sustainable Physicalization Practices (SuPPra) Matrix, providing a structured approach for designers to reflect on and enhance the environmental impact of their future physicalizations.</p>
<h3>That's Rough! Encoding Data into Roughness for Physicalization</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Xiaojiao Du, Kadek Ananta Satriadi, Andrew Cunningham, Ross Smith, Adam Drogemuller, Brandon Matthews, James A. Walsh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147680">Link</a></p>
<p>Abstract: While visual channels (e.g., color, shape, size) have been explored for visualizing data in data physicalizations, there is a lack of understanding regarding how to encode data into physical material properties (e.g., roughness, hardness). This understanding is critical for ensuring data is correctly communicated and for potentially extending the channels and bandwidth available for encoding that data. We present a method to encode ordinal data into roughness, validated through user studies. In the first study, we identified just noticeable differences in perceived roughness from this method. In the second study, we 3D-printed proof of concepts for five different multivariate physicalizations using the model. These physicalizations were qualitatively explored (N=10) to understand people's comprehension and impressions of the roughness channel. Our findings suggest roughness may be used for certain types of data encoding, and the context of the data can impact how people interpret roughness mapping direction.</p>
<h2>Design Methods</h2>
<h3>Demystifying Tacit Knowledge in Graphic Design: Characteristics, Instances, Approaches, and Guidelines</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: DaEun Choi, Tae Soo Kim, Juho Kim, Kihoon Son</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147058">Link</a></p>
<p>Abstract: Despite the growing demand for professional graphic design knowledge, the tacit nature of design inhibits knowledge sharing. However, there is a limited understanding on the characteristics and instances of tacit knowledge in graphic design. In this work, we build a comprehensive set of tacit knowledge characteristics through a literature review. Through interviews with 10 professional graphic designers, we collected 123 tacit knowledge instances and labeled their characteristics. By qualitatively coding the instances, we identified the prominent elements, actions, and purposes of tacit knowledge. To identify which instances have been addressed the least, we conducted a systematic literature review of prior system support to graphic design. By understanding the reasons for the lack of support on these instances based on their characteristics, we propose design guidelines for capturing and applying tacit knowledge in design tools. This work takes a step towards understanding tacit knowledge, and how this knowledge can be communicated.</p>
<h3>A Living Framework for Understanding Cooperative Games</h3>
<p>Authors: Pedro Pais, André Rodrigues, Pedro Trindade, Kathrin Gerling, Dmitry Alexandrovsky, Manuel Piçarra, Daniel Reis, João Guerreiro, David Gonçalves, João Godinho, João Morais</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148293">Link</a></p>
<p>Abstract: Playing cooperative games is recognised as a positive social activity. Yet, we have limited means to rigorously define or communicate the structures that govern these experiences, hindering attempts at consolidating knowledge and limiting the potential of design efforts. In this work, we introduce the Living Framework for Cooperative Games (LFCG), a framework derived from a multi-step systematic analysis of 129 cooperative games with contributions of eleven researchers. We describe how LFCG can be used as a tool for analyses and ideation, and as a shared language for describing a game’s design. LFCG is published as a web application to facilitate use and appropriation. It supports the creation, dissemination and aggregation of game reports and specifications; and enables stakeholders to extend and publish custom versions. Lastly, we discuss using a research-driven approach for formalising game structures and the advantages of community contributions for consolidation and reach.</p>
<h3>"I Am So Overwhelmed I Don't Know Where to Begin!" Towards Developing Relationship-Based and Values-Based End-of-Life Data Planning Approaches</h3>
<p>Authors: Jed Brubaker, Dylan Doyle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148141">Link</a></p>
<p>Abstract: To support people at the end of life as they create management plans for their assets, planning approaches like estate planning are increasingly considering data. HCI scholarship has argued that developing more effective planning approaches to support end-of-life data planning is important. However, empirical research is needed to evaluate specific approaches and identify design considerations. To support end-of-life data planning, this paper presents a qualitative study evaluating two approaches to co-designing end-of-life data plans with participants. We find that asset-first inventory-centric approaches, common in material estate planning, may be ineffective when making plans for data. In contrast, heavily facilitated, mission-driven, relationship-centric approaches were more effective. This study expands previous research by validating the importance of starting end-of-life data planning with relationships and values, and highlights collaborative facilitation as a critical part of successful data planning approaches. </p>
<h3>Embodied Tentacle: Mapping Design to Control of Non-Analogous Body Parts with the Human Body</h3>
<p>Authors: Shuto Takashita, Michiteru Kitazaki, Hiroto Saito, Ken Arai, Masahiko Inami</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147057">Link</a></p>
<p>Abstract: Manipulating a non-humanoid body using a mapping approach that translates human body activity into different structural movements enables users to perform tasks that are difficult with their innate bodies. However, a key challenge is how to design an effective mapping to control non-analogous body parts with the human body. To address this challenge, we designed an articulated virtual arm and investigated the effect of mapping methods on a user's manipulation experience. Specifically, we developed an unbranched 12-joint virtual arm with an octopus-like appearance. Using this arm, we conducted a user study to compare the effects of several mapping methods with different arrangements on task performance and subjective evaluations of embodiment and user preference. As a result, we identified three important factors in mapping: "Visual and Configurational Similarity", "Kinematics Suitability for the User", and "Correspondence with Everyday Actions." Based on these findings, we discuss a mapping design for non-humanoid body manipulation.</p>
<h3>Imagining Sustainable Energy Communities: Design Narratives of Future Digital Technologies, Sites, and Participation</h3>
<p>Authors: Rachel Smith, Rikke Hagensby Jensen, Victor Jensen, Kristina Laursen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147766">Link</a></p>
<p>Abstract: Increasingly, research projects narrate visions of energy communities that portray hopes of more sustainable, democratic energy futures. However, it remains unarticulated how such research narratives are embedded in the design of digital technology for communal energy futures that are situated in everyday life. While sustainable HCI has identified relevant design narratives, little attention has been paid to those of communal energy projects. In this paper, we scope energy community literature at ACM to identify design narratives that tell stories about how energy communities are imagined and why they are relevant. Through a critical discourse analysis, we describe how design narratives currently shape energy community research on sites, participation, and digital technologies. We use these stories to discuss and suggest three trajectories of how future HCI researchers and practitioners may explore alternative and sustainable visions of energy community futures.</p>
<h2>Design Tools A</h2>
<h3>KOALA Hero Toolkit: A New Approach to Inform Families of Mobile Datafication Risks</h3>
<p>Authors: Blanche Duron, Nigel Shadbolt, Ge Wang, Adrien Zier, Max Van Kleek, Zhilin Zhang, Jun Zhao, Konrad Kollnig</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148198">Link</a></p>
<p>Abstract: Children today are deeply immersed in the online world, where their activities are routinely tracked, analysed, and monetised. This exposes them to various datafication risks, including harmful profiling, micro-targeting and behavioural engineering. Most existing measures focus on immediate online threats, rather than informing children about these implicit risks. In this paper, we present The KOALA Hero Toolkit, a hybrid toolkit designed to help children and parents jointly understand the datafication risks posed by their mobile apps. Through user studies involving 17 families we evaluate how the toolkit influenced families' thought processes, perceptions and decision-making regarding mobile datafication risks. Our findings show that KOALA Hero supports families' critical thinking and promotes family engagement. We identify future design recommendations for family support, featuring ideas such as integrating triggering moments and bonding moments in toolkit designs. This work provides timely inputs on global efforts aimed at addressing datafication risks and underscores the importance of strengthening legislative and policy enforcement of ethical data governance.</p>
<h3>Rapid Prototyping with VideoClipper: In-camera Storyboarding and Video Capture</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Wendy Mackay, Germán Leiva, Alexandre Battut, Michel Beaudouin-Lafon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147150">Link</a></p>
<p>Abstract: Although video is extremely useful for expressing interaction, post-hoc editing makes it impractical for rapid prototyping. We present an early-stage video-based design method — “editing-in-the-camera” — where title cards guide video capture and label video clips. This method lets designers easily create video prototypes that can be discussed within the same design session, without further editing. We present VideoClipper, a mobile app that incorporates this method by transforming sequences of title cards into an interactive storyboard that designers can shoot into directly. VideoClipper offers simple special effects to better illustrate user interaction with paper prototypes, including ghosting and stop-motion animation. We also present Collaborative VideoClipper, which was created during the COVID-19 pandemic to support multi-user, multi-device rapid prototyping with remote participants. We describe evaluation results of both applications and describe our experiences in diverse educational and professional settings, including brainstorming, interviewing, video prototyping, user studies and participatory design workshops.</p>
<h3>Grand challenges in WaterHCI</h3>
<p>Authors: Winslow Burleson, Paul Dietz, Scott Bateman, John Quarles, Florian Mueller, Sarah Jane Pell, Ian Smith, Alexander Bakogeorge, Ali Mazalek, Joe Marshall, Maria Montoya, Steve Mann, Don Samitha Elvitigala, Mathieu Simonnet, Swamy Ananthanarayan, Nathan Semertzidis, Christal Clashing, Leif Oppermann, Kirsten Ellis, Mark Blythe, Chris Hill, Alexander Verni</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147744">Link</a></p>
<p>Abstract: Recent combinations of interactive technology, humans, and water have resulted in “WaterHCI”. WaterHCI design seeks to complement the many benefits of engagement with the aquatic domain, by offering, for example, augmented reality systems for snorkelers, virtual reality in floatation tanks, underwater musical instruments for artists, robotic systems for divers, and wearables for swimmers. We conducted a workshop in which WaterHCI experts articulated the field’s grand challenges, aiming to contribute towards a systematic WaterHCI research agenda and ultimately advance the field.</p>
<h3>A temporal vocabulary of Design Events for Research through Design</h3>
<p>Authors: Audrey Desjardins, Doenja Oogjes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148024">Link</a></p>
<p>Abstract: Much reporting on research-through-design (RtD) is vague about markers of time and temporal qualities. This lack of temporal attunement risks obscuring important contextual knowledge, hidden labour, material agencies and potential knowledge contributions. We turn to the notion of the event to articulate the granularities and nuances of RtD processes with an expanded vocabulary. We draw on prior calls from RtD practitioners, the philosophical roots of events, and our previous work with the term in our own research. We describe seven terms to expand the temporal vocabulary of RtD, which can be used to build narratives that emphasize knowledge created along the way, and relieve pressure from the ‘final’ artifact. Our contributions are 1) design events as an ontological shift and analytical tool and 2) a vocabulary that scaffolds design events as a sensitizing tool. We end with a call for more experimentation of non-chronological narratives of RtD.</p>
<h3>Strategies of Product Managers: Negotiating Social Values in Digital Product Design</h3>
<p>Authors: Eran Toch, Maayan Roichman, Eilat Lev Ari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147477">Link</a></p>
<p>Abstract: Product managers are central figures in digital product development, coordinating teams and prioritizing features. Despite their influence, little research explores how their decisions affect user experience, especially in integrating social values into product architecture. Employing a mixed-methods framework, we conducted semi-structured interviews with 20 product managers and an online survey with an additional 81, all based in Israel. Our study identifies four unique strategies product managers utilize to balance business goals, user satisfaction, and ethical considerations. The survey data further substantiates the prevalence of these strategies across diverse sectors, confirming they reflect industry-wide approaches in the Israeli tech sector rather than isolated practices. To conclude, we emphasize how ``soft resistance'' tactics, such as adjusting data interpretations based on personal values, impact digital product designs. Moreover, our findings highlight that maintaining an ethical reputation in the job market can be pivotal in shaping product design.</p>
<h2>Design Tools B</h2>
<h3>Griffith: A Storyboarding Tool Designed with Japanese Animation Professionals</h3>
<p>Authors: Kenta Hara, Nao Hirasawa, Jun Kato</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147403">Link</a></p>
<p>Abstract: The <code>E-conte,'' storyboard in English, is commonly referred to as the</code>blueprint'' in Japanese animation (anime) production, consisting of scene illustrations, timing information, and textual descriptions. This paper introduces ``Griffith,'' a digital system for creating these storyboards.</p>
<p>Due to its highly cultural and domain-specific nature, the tool design entailed an in-depth study of the E-conte process and a longitudinal collaboration with an experienced anime director and producers.</p>
<p>The resulting system contributes not only domain knowledge, but also generalizable insights into a creativity support environment for visual storytelling, including the importance of vertical timelines and discrete yet integrated tools.</p>
<p>To reflect on the interaction design, we presented Griffith to professionals with diverse roles in anime production. Our findings highlight the benefits of the Griffith user interface and the need for a socio-technical focus in designing creativity support tools.</p>
<h3>From Concept to Community: Unpacking the Work of Designing Educational and Activist Toolkits</h3>
<p>Authors: Jennifer Turns, Hana Frluckaj, Sreehana Mandava, Ayesha Bhimdiwala, Ahmer Arif, Tamar Wilner, Krishna Akhil Kumar Adavi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147784">Link</a></p>
<p>Abstract: Toolkits are an important means of sharing expertise and influencing practice. However, the work of making and sustaining toolkits is not well understood. We address this gap by conducting 20 semi-structured interviews with toolkit designers, focusing on toolkits intended to help practitioners such as librarians, teachers, and community workers. We analyze these interviews to surface key aspects of participants’ design journeys: (1) how their projects began; (2) how they conceptualized use; (3) how they collaborated with users; (4) and what happened once their toolkit was released. We illustrate these aspects through three narratives, and discuss our findings to provide considerations for designers and scholars. We highlight how designers co-construct communities alongside their toolkits, helping us form a more nuanced understanding of the social aspects underpinning toolkit projects. Collectively, these contributions can help us identify challenges and opportunities in this design space, laying the groundwork to increase toolkits' social impact.</p>
<h3>AdapTics: A Toolkit for Creative Design and Integration of Real-Time Adaptive Mid-Air Ultrasound Tactons</h3>
<p>Authors: Yinan Li, Kevin John, Hasti Seifi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148147">Link</a></p>
<p>Abstract: Mid-air ultrasound haptic technology can enhance user interaction and immersion in extended reality (XR) applications through contactless touch feedback. Yet, existing design tools for mid-air haptics primarily support creating tactile sensations (i.e., tactons) which cannot change at runtime. These tactons lack expressiveness in interactive scenarios where a continuous closed-loop response to user movement or environmental states is desirable. This paper introduces AdapTics, a toolkit featuring a graphical interface for rapid prototyping of adaptive tactons—dynamic sensations that can adjust at runtime based on user interactions, environmental changes, or other inputs. A software library and a Unity package accompany the graphical interface to enable integration of adaptive tactons in existing applications. We present the design space offered by AdapTics for creating adaptive mid-air ultrasound tactons and show the design tool can improve Creativity Support Index ratings for Exploration and Expressiveness in a user study with 12 XR and haptic designers.</p>
<h3>Bitacora: A Toolkit for Supporting  NonProfits to Critically Reflect on Social Media Data Use</h3>
<p>Authors: Christopher Le Dantec, Marisol Wong-Villacres, Benjamín Hernández, Adriana Alvarado Garcia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146866">Link</a></p>
<p>Abstract: In this paper, we describe the design and evaluation of the toolkit Bitacora, addressed to practitioners working in non-profit organizations interested in integrating Twitter data into their work. The toolkit responds to the call to maintain the locality of data by promoting a qualitative and contextualized approach to analyzing Twitter data. We assessed the toolkit's effectiveness in guiding practitioners to search, collect, and be critical when analyzing data from Twitter. We evaluated the toolkit with ten practitioners from three non-profit organizations of different aims and sizes in Mexico. The assessment surfaced tensions between the assumptions embedded in the toolkit's design and practitioners' expectations, needs, and backgrounds. We show that practitioners navigated these tensions in some cases by developing strategies and, in others, questioning the appropriateness of using Twitter data to inform their work. We conclude with recommendations for researchers who developed tools for non-profit organizations to inform humanitarian action.</p>
<h3>Design Patterns for Data-Driven News Articles</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zezhong Wang, Benjamin Bach, Shan Hao, Larissa Pschetz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146944">Link</a></p>
<p>Abstract: Technological advancements have resulted in great shifts in the production and consumption of news articles. This, in turn, lead to the requirement of new educational and practical frameworks. In this paper, we present a classification of data-driven news articles and related design patterns defined to describe their visual and textual components. Through the analysis of 162 data-driven news articles collected from news media, we identified five types of articles based on the level of data involvement and narrative complexity: Quick Update, Briefing, Chart Description, Investigation, and In-depth Investigation. We then identified 72 design patterns to understand and construct data-driven news articles. To evaluate this approach, we conducted workshops with 23 students from journalism, design, and sociology who were newly introduced to the subject. Our findings suggest that our approach can be used as an out-of-box framework for the formulation of plans and consideration of details in the workflow of data-driven news creation.</p>
<h2>Drivers and Pedestrians A</h2>
<h3>Inter-regional Lens on the Privacy Preferences of Drivers for ITS and Future VANETs</h3>
<p>Authors: Lejla Islami, Simone Fischer-Hübner, Agnieszka Kitkowska</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146934">Link</a></p>
<p>Abstract: Intelligent Transportation Systems (ITS) are on the rise, yet the knowledge about </p>
<p>privacy preferences by different types of drivers in this context needs to be improved. This paper presents survey-based research (N=528) focusing on preferences of drivers from South Africa and the Nordic countries for data processing and sharing by ITS, including future vehicular ad hoc networks. Our results indicate regionally framed drivers' privacy attitudes and behaviours. South African participants have higher privacy concerns and risk perception. However, their preferences to share location data with police, family and friends, emergency services, and insurance companies are higher. </p>
<p>Moreover, the region significantly affects preferences for transparency and control and sharing frequency, as well as willingness to pay for privacy, which are higher among the South Africans. </p>
<p>We discuss how our results on factors, including region, impacting drivers’ privacy preferences can contribute to the design of usable privacy and identity management for ITS.</p>
<h3>AdaptiveVoice: Cognitively Adaptive Voice Interface for Driving Assistance</h3>
<p>Authors: Yukang Yan, Songming Ping, Hai-Ning Liang, Xuhai "Orson" Xu, Shaoyue Wen, Jialin Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147590">Link</a></p>
<p>Abstract: Current voice assistants present messages in a predefined format without considering users’ mental states. </p>
<p>This paper presents an optimization-based approach to alleviate this issue which adjusts the level of details and speech speed of the voice messages according to the estimated cognitive load of the user.</p>
<p>In the first user study (N=12), we investigated the impact of cognitive load on user performance.</p>
<p>The findings reveal significant differences in preferred message formats across five cognitive load levels, substantiating the need for voice message adaptation. </p>
<p>We then implemented AdaptiveVoice, an algorithm based on combinatorial optimization to generate adaptive voice messages in real-time. </p>
<p>In the second user study (N=30) conducted in a VR-simulated driving environment, we compared AdaptiveVoice with a fixed format baseline, with and without visual guidance on the Heads-up display(HUD). Results indicate that users benefit from AdaptiveVoice with reduced response time and improved driving performance, particularly when it is augmented with HUD.</p>
<h3>Portobello: Extending Driving Simulation from the Lab to the Road</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mark Colley, Wendy Ju, Stacey Li, David Goedicke, Gyanendra Sharma, Fanjun Bu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146873">Link</a></p>
<p>Abstract: In automotive user interface design, testing often starts with lab-based driving simulators and migrates toward on-road studies to mitigate risks. Mixed reality (XR) helps translate virtual study designs to the real road to increase ecological validity. However, researchers rarely run the same study in both in-lab and on-road simulators due to the challenges of replicating studies in both physical and virtual worlds. To provide a common infrastructure to port in-lab study designs on-road, we built a platform-portable infrastructure, Portobello, to enable us to run twinned physical-virtual studies. As a proof-of-concept, we extended the on-road simulator XR-OOM with Portobello. We ran a within-subjects, autonomous-vehicle crosswalk cooperation study (N=32) both in-lab and on-road to investigate study design portability and platform-driven influences on study outcomes. To our knowledge, this is the first system that enables the twinning of studies originally designed for in-lab simulators to be carried out in an on-road platform.</p>
<h3>SYNC-VR: Synchronizing Your Senses to Conquer Motion Sickness for Enriching In-Vehicle Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Aya Ataya, SeungJun Kim, Eunsol An, Ahmed Elsharkawy, Dohyeon Yeo, Seokhyun Hwang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147287">Link</a></p>
<p>Abstract: Passengers can engage more in nondriving-related tasks owing to recent advancements in autonomous vehicles (AVs), making immersive tools such as virtual reality (VR) appealing; however, motion sickness (MS) remains a significant challenge. We present SYNC-VR, a system that aligns with visual, haptic, and auditory cues and provides proprioceptive feedback to illustrate its effect on MS and presence within the in-vehicle VR. We conducted an experiment with 24 participants using a real vehicle along a route with known MS-triggering events. Using subjective and physiological measures, we assessed participants’ presence and MS under four conditions by gradually varying the level of synchronized input sensations. Results reveal that SYNC-VR reduces MS and increases the sense of presence. Additionally, it emphasizes the impact of our interactive VR content and its role in achieving proprioceptive feedback with haptic feedback through electrical muscle stimulation, introducing an innovative approach to MS mitigation in in-vehicle VR.</p>
<h3>Can You Hazard a Guess?: Evaluating the Effect of Augmented Reality Cues on Driver Hazard Prediction</h3>
<p>Authors: Frank Pollick, Thomas Goodge, Stephen Brewster</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146912">Link</a></p>
<p>Abstract: Semi-autonomous vehicles allow drivers to engage with non-driving related tasks (NDRTs). However, these tasks interfere with the driver's situational awareness, key when they need  to safely retake control of the vehicle. This paper investigates if  Augmented Reality (AR) could be used to present NDRTs to reduce their impact on situational awareness. Two experiments compared driver performance on a hazard prediction task whilst  interacting with an NDRT, presented either as an AR Heads-Up Display or a traditional Heads-Down Display. The results demonstrate that an AR display including a novel dynamic attentional cue improves  situational awareness, depending on the workload of the NDRT and design of the cue. The results provide novel insights for designers of in-car systems about how to design NDRTs to aid driver situational awareness in future vehicles.</p>
<h2>Drivers and Pedestrians B</h2>
<h3>Investigating the Effects of External Communication and Platoon Behavior on Manual Drivers at Highway Access</h3>
<p>Authors: Mark Colley, Omid Rajabi, Enrico Rukzio</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147216">Link</a></p>
<p>Abstract: Automated vehicles are expected to improve traffic safety and efficiency. One approach to achieve this is via platooning, that is, (automated) vehicles can drive behind each other at very close proximity to reduce air resistance. However, this behavior could lead to difficulties in mixed traffic, for example, when manual drivers try to enter a highway. </p>
<p>Therefore, we report the results of a within-subject Virtual Reality study (N=29) evaluating different platoon behaviors (single vs. multiple, i.e., four, gaps) and communication strategies (HUD, AR, attached displays). </p>
<p>Results show that AR communication reduced mental workload, improved perceived safety, and a single big gap led to the safest merging behavior.</p>
<p>Our work helps to incorporate novel behavior enabled by automation into general traffic better.</p>
<h3>Understanding Human-machine Cooperation in Game-theoretical Driving Scenarios amid Mixed Traffic</h3>
<p>Authors: Morgan Frank, Edmond Awad, Yutong Zhang, Na Du, Peng Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147435">Link</a></p>
<p>Abstract: Introducing automated vehicles (AVs) on roads may challenge established norms as drivers of human-driven vehicles (HVs) interact with AVs. Our study explored drivers' decisions in game-theoretical scenarios amid mixed traffic using an online survey study. We manipulated factors including interaction types (HV-HV vs. HV-AV), scenario types (chicken game vs. public goods game), vehicle driving styles (aggressive vs. conservative), and time constraints (high vs. low). The quantitative results showed that human drivers tended to “defect” more, that is, not cooperate, against vehicles with conservative driving styles. The effect of vehicle driving styles was pronounced when interacting with AVs and in chicken game scenarios. Drivers exhibited more “defection” in public goods game scenarios and the effect of scenario types was weakened under high time constraints. Only drivers with moderate driving styles “defected” more in HV-AV interaction. Our qualitative findings provide essential insights into how drivers perceived conditions and formulated strategies for decision-making.</p>
<h3>An Eye Gaze Heatmap Analysis of Uncertainty Head-Up Display Designs for Conditional Automated Driving</h3>
<p>Authors: Michael Gerber, Daniel Johnson, Andry Rakotonirainy, Jonny Kuo, Mike Lenné, Christian Janssen, Ronald Schroeter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147765">Link</a></p>
<p>Abstract: This paper reports results from a high-fidelity driving simulator study (N=215) about a head-up display (HUD) that conveys a conditional automated vehicle’s dynamic “uncertainty” about the current situation while fallback drivers watch entertaining videos. We compared (between-group) three design interventions: display (a bar visualisation of uncertainty close to the video), interruption (interrupting the video during uncertain situations), and combination (a combination of both), against a baseline (video-only). We visualised eye-tracking data to conduct a heatmap analysis of the four groups’ gaze behaviour over time. We found interruptions initiated a phase during which participants interleaved their attention between monitoring and entertainment. This improved monitoring behaviour was more pronounced in combination compared to interruption, suggesting pre-warning interruptions have positive effects. The same addition had negative effects without interruptions (comparing baseline &amp; display). Intermittent interruptions may have safety benefits over placing additional peripheral displays without compromising usability.</p>
<h3>From Slow-Mo to Ludicrous Speed: Comfortably Manipulating the Perception of Linear In-Car VR Motion Through Vehicular Translational Gain and Attenuation</h3>
<p>Authors: Katharina Pöhlmann, Graham Wilson, Mark McGill, Stephen Brewster, Gang Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148305">Link</a></p>
<p>Abstract: To prevent motion sickness, Virtual Reality (VR) experiences for vehicle passengers typically present ``matched motion'': real vehicle movements are replicated 1:1 by movements in VR. To expand this design space, we provide foundations for in-car VR experiences that break free from this constraint by manipulating the passenger's visual perception of linear velocity through amplifying and reducing the virtual speed.</p>
<p>In two on-the-road studies, we examined the application of Vehicular Translational Gain (1.5-9.5x) and Attenuation (0.66-0.14x) to real car speeds (~50km/h) across two VR tasks (reading and gaming), exploring journey perception, impact on motion sickness, travel experience and tasks. </p>
<p>We found that vehicular gain/attenuation can be applied without significantly increasing motion sickness. Gain was more noticeable and affected perceived speed, distance, safety, relaxation and excitement, being well-suited to gaming, while attenuation was more suitable for productivity. Our work unlocks new ways that VR applications can safely enhance and alter the passenger experience through novel perceptual manipulations of vehicle velocity. </p>
<h3>Understanding Pedestrians’ Perception of Safety and Safe Mobility Practices</h3>
<p>Authors: Min Zhang, Arosha Bandara</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146652">Link</a></p>
<p>Abstract: Walking is one of the greenest and most common travel modes. However, evidence shows a trend of decreased walking, and safety is a key barrier preventing many people from walking. Additionally, there is a limited understanding of pedestrians’ safe mobility practices and safety perception. Drawing on 449 survey responses from a representative sample in the United Kingdom, our work highlights how identities and walking situations intersect with individuals’ safety perceptions and diverse practices of pedestrians’ safe mobility. The role of technology used for negotiating safety and current challenges in both safe route planning and walking are also highlighted. Our work extends existing insights into pedestrians’ perception of safety and practices by adding empirical evidence and more nuanced contexts. This paper proposes two implications for design in response to design opportunities that surfaced from our mixed-method data analysis. Both the contributions and limitations of our work are also discussed.</p>
<h2>Drone Interaction</h2>
<h3>Swarm Body: Embodied Swarm Robots</h3>
<p>Authors: Mai Nishimura, So Kuroki, Sosuke Ichihashi, Takefumi Hiraki, Shigeo Yoshida, Kazumi Kasaura, Kazutoshi Tanaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146948">Link</a></p>
<p>Abstract: The human brain's plasticity allows for the integration of artificial body parts into the human body. Leveraging this, embodied systems realize intuitive interactions with the environment. We introduce a novel concept: embodied swarm robots. Swarm robots constitute a collective of robots working in harmony to achieve a common objective, in our case, serving as functional body parts. Embodied swarm robots can dynamically alter their shape, density, and the correspondences between body parts and individual robots. We contribute an investigation of the influence on embodiment of swarm robot-specific factors derived from these characteristics, focusing on a hand. Our paper is the first to examine these factors through virtual reality (VR) and real-world robot studies to provide essential design considerations and applications of embodied swarm robots. Through quantitative and qualitative analysis, we identified a system configuration to achieve the embodiment of swarm robots.</p>
<h3>Exploring Intended Functions of Indoor Flying Robots Interacting With Humans in Proximity</h3>
<p>Authors: Xiaowei Chen, Ziming Wang, Shiwei Yang, Morten Fjeld, Yiqian Wu, Björn Rohles</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147793">Link</a></p>
<p>Abstract: What will people experience when drones become common in home environments? How will their functions and distances impact human experiences? To explore the potential usage of indoor drones, we conducted a mixed-methods study (N=60) on the reported perceptions of a small flying robot. We employed a factorial experimental design, involving four intended drone functions (\textit{camera}, \textit{education}, \textit{pet}, \textit{unknown}) at two distances (\textit{near}, \textit{far}). Our findings suggest that intended functions significantly influence participants’ perceptions. Among the functions examined, participants found the \textit{camera} useful but annoying, and the \textit{pet} useless but pleasant. The \textit{education} emerged as the most favored function, while the \textit{unknown} function was the least preferred one. Based on these findings, we discuss implications for designing positive interactions between humans and indoor drones, considering aspects such as context, transparency, privacy, technical factors, and personalization.  </p>
<h3>Firefighters' Perceptions on Collaboration and Interaction with Autonomous Drones: Results of a Field Trial</h3>
<p>Authors: Dzmitry Katsiuba, Moyi Li, Mateusz Dolata, Gerhard Schwabe</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147198">Link</a></p>
<p>Abstract: Applications of drones in emergency response, like firefighting, have been promoted in the past decade. As the autonomy of drones continues to improve, the ways in which they are integrated into firefighting teams and their impact on crews are changing. This demands more understanding of how firefighters perceive and interact with autonomous drones. This paper presents a drone-based system for emergency operations with which firefighters can interact through sound, lights, and a graphical user interface. We use interviews with stakeholders collected in two field trials to explore their perceptions of the interaction and collaboration with drones. Our result shows that firefighters perceived visual interaction as adequate. However, for audio instructions and interfaces, information overload emerges as an essential problem. The potential impact of drones on current work configurations may involve shifting the position of humans closer to supervisory decision-makers and changing the training structure and content.</p>
<h3>HIFuzz: Human Interaction Fuzzing for Small Unmanned Aerial Vehicles</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Salil Purandare, Theodore Chambers, Ankit Agrawal, Michael Vierhauser, Myra Cohen, Michael Murphy, Jason Matthew Brauer, Jane Cleland-Huang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147755">Link</a></p>
<p>Abstract: Small Unmanned Aerial Systems (sUAS) must meet rigorous safety standards when deployed in high-stress emergency response scenarios; however many reported accidents have involved humans in the loop. In this paper, we, therefore, present the HiFuzz testing framework, which uses fuzz testing to identify system vulnerabilities associated with human interactions. HiFuzz includes three distinct levels that progress from a low-cost, limited-fidelity, large-scale, no-hazard environment, using fully simulated Proxy Human Agents, via an intermediate level, where proxy humans are replaced with real humans, to a high-stakes, high-cost, real-world environment. Through applying HiFuzz to an autonomous multi-sUAS system-under-test, we show that each test level serves a unique purpose in revealing vulnerabilities and making the system more robust with respect to human mistakes. While HiFuzz is designed for testing sUAS systems, we further discuss its potential for use in other Cyber-Physical Systems.</p>
<h3>Dances with Drones: Spatial Matching and Perceived Agency in Improvised Movements with Drone and Human Partners</h3>
<p>Authors: Pakpong Chirarattananon, Kaixu Dong, Zhiyuan Zhang, Xiaoyu CHANG, RAY LC</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147482">Link</a></p>
<p>Abstract: As drones become interwoven in human activities, increasingly taking on tasks interpreted as creative and performative, such as choreographed light shows, there is emerging interest in understanding how drones and humans can perform together.  Humans have different habits when performing with partners as opposed to solo. How do people adapt their behaviors and perspectives when improvising with robotic partners? To explore these questions, we conducted a study investigating dancer-drone interactions using a system of micro aerial vehicles designed to facilitate improvised solo and partnered dances. Through solo and tandem dances with one or two robots, we analyzed the performers' perceived workflow from semi-structured interviews and quantified their movement patterns during the improvisation. We found that the dancers perceived drone movements through spatial metaphors like the ceiling and gravity, anthropomorphizing drones as props on a stage through position and generated sound. The dancers felt a greater connection in single-drone scenarios and showed heightened avoidance behavior in two-drone situations. Our work shows how a robotic system can energize human dancers to improvise individually and in pairs.</p>
<h2>Fabrication and Tangible Interaction A</h2>
<h3>MoiréWidgets: High-Precision, Passive Tangible Interfaces via Moiré Effect</h3>
<p>Authors: Mustafa Doga Dogan, Alexa Siu, Chang Xiao, Eunyee Koh, Daniel Campos Zamora</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147630">Link</a></p>
<p>Abstract: We introduce MoiréWidgets, a novel approach for tangible interaction that harnesses the Moiré effect—a prevalent optical phenomenon—to enable high-precision event detection on physical widgets. Unlike other electronics-free tangible user interfaces which require close coupling with external hardware, MoiréWidgets can be used  at greater distances while maintaining high-resolution sensing of interactions. We define a set of interaction primitives, e.g., buttons, sliders, and dials, which can be used  as standalone objects or combined to build complex physical controls. These consist of 3D printed structural mechanisms with patterns printed on two layers—one on paper and the other on a plastic transparency sheet—which create a visual signal that amplifies subtle movements, enabling the detection of user inputs. Our technical evaluation shows that our method outperforms standard fiducial markers and maintains sub-millimeter accuracy at 100 cm distance and wide viewing angles. We demonstrate our approach by creating an audio console and indicate how our approach could extend to other domains. </p>
<h3>DungeonMaker: Embedding Tangible Creation and Destruction in Hybrid Board Games through Personal Fabrication Technology</h3>
<p>Authors: Anja Schikorr, Omid Rajabi, Ali Askari, Julian Frommel, Tobias Wagner, Evgeny Stemasov, Enrico Rukzio, Jessica Janek, Jan Gugenheimer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146888">Link</a></p>
<p>Abstract: Hybrid board games (HBGs) augment their analog origins digitally (e.g., through apps) and are an increasingly popular pastime activity. Continuous world and character development and customization, known to facilitate engagement in video games, remain rare in HBGs. If present, they happen digitally or imaginarily, often leaving physical aspects generic. We developed DungeonMaker, a fabrication-augmented HBG bridging physical and digital game elements: 1) the setup narrates a story and projects a digital game board onto a laser cutter; 2) DungeonMaker assesses player-crafted artifacts; 3) DungeonMaker's modified laser head senses and moves player- and non-player figures, and 4) can physically damage figures. An evaluation (n=4x3) indicated that DungeonMaker provides an engaging experience, may support players' connection to their figures, and potentially spark novices' interest in fabrication. DungeonMaker provides a rich constellation to play HBGs by blending aspects of craft and automation to couple the physical and digital elements of an HBG tightly.</p>
<h3>Squishy, Yet Satisfying: Exploring Deformable Shapes' Cross-Modal Correspondences with Colours and Emotions</h3>
<p>Authors: Michael Proulx, Kim Sauvé, Crescent Jicol, Cameron Steer, Omosunmisola Lawal, Jason Alexander, Anika Jain</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148261">Link</a></p>
<p>Abstract: Surfaces with deformable and shape-changing properties seek to enhance and diversify tangible interactions with computing systems. However, we currently lack fundamental knowledge and user interface design principles that connect the inherent properties of deformable shapes with our human senses and cognitive associations. To address this knowledge gap, we systematically explored deformable shapes' cross-modal correspondences (CC) with colours and emotions. In our CC study, 52 participants were presented with deformable shape stimuli that varied in stiffness and angularity. They were asked to associate these stimuli with colours and emotions under (i) visuo-tactile and; (ii) tactile-only conditions. For the first time, our findings reveal (1) how stiffness level primarily influences the CC associations and; (2) that stiffness and angularity play a significant role in CC associations over the visibility of the shapes. The results were distilled into design guidelines for future deformable, shape-changing interfaces that engage specific human senses and responses.</p>
<h3>PaperTouch: Tangible Interfaces through Paper Craft and Touchscreen Devices</h3>
<p>Authors: Zhen Zhou Yong, Clement Zheng, Bo Han, Ching Chiuan Yen, Qian Ye</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146860">Link</a></p>
<p>Abstract: Paper and touchscreen devices are two common objects found around us, and we investigated the potential of their intersection for tangible interface design. In this research, we developed PaperTouch, an approach to design paper based mechanisms that translate a variety of physical interactions to touch events on a capacitive touchscreen. These mechanisms act as switches that close during interaction, connecting the touchscreen to the device’s ground bus. To develop PaperTouch, we explored different types of paper along with the making process around them. We also built a range of applications to showcase different tangible interfaces facilitated with PaperTouch, including music instruments, educational dioramas, and playful products. By reflecting on this exploration, we uncovered the emerging design dimensions that considers the interactions, materiality, and embodiment of PaperTouch interfaces. We also surfaced the tacit know-how that we gained through our design process through annotations for others to refer to.</p>
<h3>WooDowel: Electrode Isolation for Electromagnetic Shielding in Triboelectric Plywood Sensors</h3>
<p>Authors: Xing-Dong Yang, Yonghao Shi, Te-Yen Wu, Yuning Su, Chenzheng Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147211">Link</a></p>
<p>Abstract: We present a new approach to address the challenges associated with maintaining the functionality of triboelectric vibration sensors in smart plywood during woodworking operations involving nails and screws. The current state-of-the-art sensor design employs non-overlapping electrodes, which unfortunately leads to significant compromises in terms of signal strength and clarity, particularly in real-world scenarios that involve electromagnetic (EM) interference. To overcome these limitations, we propose a method that enables the woodworker to manually isolate short-circuited electrodes. This method facilitates the creation of sensors using overlapping electrodes, while also incorporating EM shielding, thereby resulting in a substantial improvement in the sensor's robustness when detecting user activities. To validate the effectiveness of our proposed approach, we conducted a series of experiments, which not only shed light on the drawbacks of non-overlapping electrode designs but also demonstrated the significant improvements achieved through our method. </p>
<h2>Fabrication and Tangible Interaction B</h2>
<h3>Tandem: Reproducible Digital Fabrication Workflows as Multimodal Programs</h3>
<p>Authors: Jasper Tran O'Leary, Nadya Peek, Octi Zhang, Thrisha Ramesh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146800">Link</a></p>
<p>Abstract: Experimental digital fabrication workflows are increasingly common in human-computer interaction research, but are difficult to reproduce. We present Tandem, a software library that lets a fabricator implement an end-to-end fabrication workflow as a computational notebook program that others can run to physically reproduce the workflow. Tandem notebook programs read and write to CAD and CAM software, project augmented reality interfaces onto machines for manual interventions, and directly control fabrication machines. Fabricators can also denote potential mismatches between the physical and the digital as explicit assertions in code. Using two-sided CNC milling as an example, we demonstrate how to implement a complex workflow as a single program that can be re-run by others while supporting quality control and improving reproducibility.</p>
<h3>ecSkin: Low-Cost Fabrication of Epidermal Electrochemical Sensors for Detecting Biomarkers in Sweat</h3>
<p>Authors: Mohammad Janghorban, Aditya Shekhar Nittala, Richa Pandey, Vrahant Nagoria, Chang Lee, Sai Nandan Panigrahy</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147205">Link</a></p>
<p>Abstract: The development of low-cost and non-invasive biosensors for monitoring electrochemical biomarkers in sweat holds great promise for personalized healthcare and early disease detection. In this work, we present ecSkin, a novel fabrication approach for realizing epidermal electrochemical sensors that can detect two vital biomarkers in sweat: glucose and cortisol. We contribute the synthesis of functional reusable inks, that can be formulated using simple household materials. Electrical characterization of inks indicates that they outperform commercially available carbon inks. Cyclic voltammetry experiments show that our inks are electrochemically active and detect glucose and cortisol at activation voltages of -0.36 V and -0.22 V, respectively. Chronoamperometry experiments show that the sensors can detect the full range of glucose and cortisol levels typically found in sweat. Results from a user evaluation show that ecSkin sensors successfully function on the skin. Finally, we demonstrate three applications to illustrate how ecSkin devices can be deployed for various interactive applications.</p>
<h3>VabricBeads : Variable Stiffness Structured Fabric using Artificial Muscle in Woven Beads</h3>
<p>Authors: Hideki Koike, Shio Miyafuji, Nobuhiro Takahashi, Jefferson Pardomuan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147426">Link</a></p>
<p>Abstract: Woven beads, a structured fabric category, comprises interconnected rows of beads joined by fiber strands. While the stiffness of woven beads can be adjusted by relying on fiber tension during fabrication, the resulting shape and stiffness properties remain fixed. This study explores the potential of tunable shape and stiffness in woven beads, offering adaptability in comfort, functionality, and form factor. By leveraging Pneumatic Artificial Muscles (PAMs), we employ a state-of-the-art technique for dynamically modulating fabric stiffness through mechanical constraints in bead form. This approach enables a modular and scalable fabrication process, fostering programmability in mechanical properties. Our investigation encompasses diverse bead iterations and stitching patterns to broaden their applicability in fabric behavior including degree of freedom, stretchability, permeability, and textures. We evaluate the mechanical properties to differentiate design capabilities, and present techniques for locally adjusting stiffness. We showcase the versatility through applications, including variable stiffness wearables and shape-changing everyday objects.</p>
<h3>DisplayFab: The State of the Art and a Roadmap in the Personal Fabrication of Free-Form Displays Using Active Materials and Additive Manufacturing.</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mike Fraser, Ollie Hanton, Anne Roudaut</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147502">Link</a></p>
<p>Abstract: Over recent years, there has been significant research within HCI towards free-form physical interactive devices. However, such devices are not straightforward to design, produce and deploy on demand. Traditional development revolves around iterative prototyping through component-based assembly, limiting device structure and implementation. Material-centric personal display fabrication (DisplayFab) opens the possibility of decentralised, configurable production by low-skill makers. Currently, DisplayFab is severely limited by its embryonic stage of development, the complexity of involved processes and materials, and the challenges around designing interactive structures. We present a development framework to provide a path for future research. DisplayFab has been developed by identifying 4 key breakpoints in the existing “Personal Fabrication” framework: Material and Deposition, Conception and Software, Feedback and Interactivity and Responsible Innovation. We use these breakpoints to form a targeted literature review of relevant work. Doing this we identify 30 challenges that act as roadmap for future research in DisplayFab.</p>
<h3>pARam: Leveraging Parametric Design in Extended Reality to Support the Personalization of Artifacts for Personal Fabrication</h3>
<p>Authors: Simon Demharter, Max Rädler, Evgeny Stemasov, Enrico Rukzio, Jan Gugenheimer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147551">Link</a></p>
<p>Abstract: Extended Reality (XR) allows in-situ previewing of designs to be manufactured through Personal Fabrication (PF). These in-situ interactions exhibit advantages for PF, like incorporating the environment into the design process. However, design-for-fabrication in XR often happens through either highly complex 3D-modeling or is reduced to rudimentary adaptations of crowd-sourced models. We present pARam, a tool combining parametric designs (PDs) and XR, enabling in-situ configuration of artifacts for PF. In contrast to modeling- or search-focused approaches, pARam supports customization through embodied and practical inputs (e.g., gestures, recommendations) and evaluation (e.g., lighting estimation) without demanding complex 3D-modeling skills. We implemented pARam for HoloLens 2 and evaluated it (n=20), comparing XR and desktop conditions. Users succeeded in choosing context-related parameters and took their environment into account for their configuration using pARam. We reflect on the prospects and challenges of PDs in XR to streamline complex design methods for PF while retaining suitable expressivity.  </p>
<h2>Game Design A</h2>
<h3>Not All the Same: Understanding and Informing Similarity Estimation in Tile-Based Video Games</h3>
<p>Authors: Christian Guckelsberger, Vanessa Volz, Laurissa Tokarchuk, Sebastian Berns, Sam Snodgrass</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147878">Link</a></p>
<p>Abstract: Similarity estimation is essential for many game AI applications, from the procedural generation of distinct assets to automated exploration with game-playing agents. While similarity metrics often substitute human evaluation, their alignment with our judgement is unclear. Consequently, the result of their application can fail human expectations, leading to e.g. unappreciated content or unbelievable agent behaviour. We alleviate this gap through a multi-factorial study of two tile-based games in two representations, where participants (N=456) judged the similarity of level triplets. Based on this data, we construct domain-specific perceptual spaces, encoding similarity-relevant attributes. We compare 12 metrics to these spaces and evaluate their approximation quality through several quantitative lenses. Moreover, we conduct a qualitative labelling study to identify the features underlying the human similarity judgement in this popular genre. Our findings inform the selection of existing metrics and highlight requirements for the design of new similarity metrics benefiting game development and research. </p>
<h3>Find the Bot!: Gamifying Facial Emotion Recognition for Both Human Training and Machine Learning Data Collection</h3>
<p>Authors: John Chung, Jean Song, Ahyeon Shin, Yeonsun Yang, Huidam Woo, Nayoung Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148164">Link</a></p>
<p>Abstract: Facial emotion recognition (FER) constitutes an essential social skill for both humans and machines to interact with others. To this end, computer interfaces serve as valuable tools for training individuals to improve FER abilities, while also serving as tools for gathering labels to train FER machine learning datasets. However, existing tools have limitations on the scope and methods of training non-clinical populations and also on collecting labels for machines. In this study, we introduce Find the Bot!, an integrated game that effectively engages the general population to support not only human FER learning on spontaneous expressions but also the collection of reliable judgment-based labels. We incorporated design guidelines from gamification, education, and crowdsourcing literature to engage and motivate players. Our evaluation (N=59) shows that the game encourages players to learn emotional social norms on perceived facial expressions with a high agreement rate, facilitating effective FER learning and reliable label collection all while enjoying gameplay.</p>
<h3>Cheat Codes as External Support for Players Navigating Fear of Failure and Self-Regulation Challenges In Digital Games</h3>
<p>Authors: Susanne Poeller, Nicola Baumann, Martin Dechant, Karla Waldenmeier, Regan Mandryk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147333">Link</a></p>
<p>Abstract: Failure is an integral element of most games, and while some players may benefit from external support, such as cheat codes, to prompt self-soothing, most games lack supportive elements. We asked participants (N=88) to play Anno 1404 in single-player mode, and presented a money-generating cheat code in a challenging situation, also measuring the personality trait of action-state orientation, which explains differences in self-regulation ability (i.e., self-soothing) in response to threats of failure. Individuals higher in state orientation were more likely to take the offer, and used the cheat code more frequently. The cheat code also acted as an external support, as differences in experienced pressure between action- and state-oriented participants vanished when it was used. We found no negative consequences of using external support in intrinsic motivation, needs satisfaction, flow, or performance. We argue that external support mechanisms can help state-oriented players to self-regulate in gaming, when faced with failure.</p>
<h3>How does Juicy Game Feedback Motivate? Testing Curiosity, Competence, and Effectance</h3>
<p>Authors: Kathrin Gerling, Sebastian Deterding, Dominic Kao, Nick Ballou, Heiko Breitsohl</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148171">Link</a></p>
<p>Abstract: 'Juicy' or immediate abundant action feedback is widely held to make video games enjoyable and intrinsically motivating. Yet we do not know why it works: Which motives are mediating it? Which features afford it? In a pre-registered (n=1,699) online experiment, we tested three motives mapping prior practitioner discourse---effectance, competence, and curiosity---and connected design features. Using a dedicated action RPG and a 2x2+control design, we varied feedback amplification, success-dependence, and variability and recorded self-reported effectance, competence, curiosity, and enjoyment as well as free-choice playtime. Structural equation models show curiosity as the strongest enjoyment and only playtime predictor and support theorised competence pathways. Success dependence enhanced all motives, while amplification unexpectedly reduced them, possibly because the tested condition unintentionally impeded players' sense of agency. Our study evidences uncertain success affording curiosity as an underappreciated moment-to-moment engagement driver, directly supports competence-related theory, and suggests that prior juicy game feel guidance ties to legible action-outcome bindings and graded success as preconditions of positive 'low-level' user experience.</p>
<h3>"Ah! I see'' - Facilitating Process Reflection in Gameplay through a Novel Spatio-Temporal Visualization System</h3>
<p>Authors: Sai Siddartha Maram, Jennifer Villareale, Erica Kleinman, Jichen Zhu, Magy Seif El-Nasr</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147359">Link</a></p>
<p>Abstract: Educational games have emerged as potent tools for helping students understand complex concepts and are now ubiquitous in global classrooms, amassing vast data. However, there is a notable gap in research concerning the effective visualization of this data to serve two key functions: (a) guiding students in reflecting upon their game-based learning and (b) aiding them in analyzing peer strategies. In this paper, we engage educators, students, and researchers as essential stakeholders. Taking a Design-Based Research (DBR) approach, we incorporate UX design methods to develop an innovative visualization system that helps players learn through gaining insights from their own and peers' gameplay and strategies. </p>
<h2>Game Design B</h2>
<h3>A Game of Love for Women: Social Support in Otome Game Mr. Love: Queen’s Choice in China</h3>
<p>Authors: Jingyi Guo, Hiu Man Ho, Ran Tang, Qinyuan Lei, Zilu Tang, Han Zhou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147914">Link</a></p>
<p>Abstract: Otome games (also known as romantic video games, or RVGs) are story-based video games that are designed for young women, simulating the experience of a romantic relationship. Players are invited to adopt the female avatar’s perspective in the story and date one or more of the male characters. Our empirical study focuses on the different types of social support among the players of the Chinese otome game Mr. Love: Queen’s Choice. We discovered that although the game was initially designed to be a consumer product aiming to profit from a largely marginalized and stigmatized group of gamers, i.e., young female gamers, the game has created a gaming community in which the players seek and provide each other with social support. We primarily use ethnographic methods, including participant observation and in-depth interviews. Our study contributes to HCI research on mediated social support in game. </p>
<h3>Independent Validation of the Player Experience Inventory: Findings from a Large Set of Video Game Players</h3>
<p>Authors: Klaus Opwis, Sebastian Perrig, Lena Aeschbach, Nicolas Scharowski, Florian Brühlmann, Nick von Felten</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147606">Link</a></p>
<p>Abstract: Measuring the subjective experience of digital game players is essential to player experience research. Recently, the Player Experience Inventory (PXI) was developed, which assesses both functional and psychosocial consequences of digital gameplay. We present a pre-registered independent online study with a large sample to provide additional evidence of psychometric quality for the PXI. Responses from 1518 participants were collected, rating a recent or memorable experience playing a digital game using the PXI and related measures. While our results from standard psychometric reliability and validity analyses generally favored the PXI, we also identified challenges with the immersion construct. Further, we find a ten-factor model, or alternatively, an 11-factor should enjoyment be measured, to fit our collected data best. In sum, the PXI is a valuable tool to measure a variety of constructs central to player experience.</p>
<h3>Effects of a Gaze-Based 2D Platform Game on User Enjoyment, Perceived Competence, and Digital Eye Strain</h3>
<p>Authors: Mark Colley, Pascal Jansen, Julian Frommel, Max Rädler, Beate Wanner, Teresa Hirzle, Enrico Rukzio, Marcel Rötzer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148322">Link</a></p>
<p>Abstract: Gaze interaction is a promising interaction method to increase va-</p>
<p>riety, challenge, and fun in games.We present “Shed Some Fear”, a 2D platform game including numerous eye-gaze-based interactions. \shedSomeFear includes control with eye-gaze and traditional keyboard input. The eye-gaze interactions are partially based on eye exercises reducing digital eye strain but also on employing peripheral vision. By employing eye-gaze as a necessary input mechanism, we explore the effects on and tradeoffs between user enjoyment and digital eye strain in a five-day longitudinal between-subject study (N=17) compared to interaction with a traditional mouse. We found that perceived competence was significantly higher with eye gaze interaction and significantly higher internal eye strain. </p>
<p>With this work, we contribute to the not straightforward inclusion of eye tracking as a useful and fun input method for games. </p>
<h3>Damage Optimization in Video Games: A Player-Driven Co-Creative Approach</h3>
<p>Authors: Erica Kleinman, Manik Charan, Johannes Pfau, Magy Seif El-Nasr</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147749">Link</a></p>
<p>Abstract: The concept of dealing damage is established and widespread in video games. With growing complexity and countless interactions in modern games, capturing how damage unfolds becomes an intricate problem - for developers just as for players. Misunderstanding how to optimize damage potentials includes risks of game imbalances, game-breaking exploits, mismatches between player skill and challenge (harming flow), and impaired perceived competence. All of these considerably impact player experience, game reception, success, and retention, yet polishing optimal strategies remains often a player community effort. To accelerate, inform and ease this process, we implemented an interactive tool capable of simulating, visualizing, planning and comparing damage strategies in video games. Following a case study within the Guild Wars 2 community, we contribute a player-driven perspective on the problem of damage optimization, as well as an artifact that resulted in empirical improvements – advancing the fields of game analytics, game evaluation methods and self-regulated learning.</p>
<h3>The Trick is to Stay Behind?: Defining and Exploring the Design Space of Player Balancing Mechanics</h3>
<p>Authors: Pedro Pais, André Rodrigues, Daniel Barros, Tiago Guerreiro, João Guerreiro, David Gonçalves</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147203">Link</a></p>
<p>Abstract: In multiplayer gaming, skill disparity can lead to frustrating and excluding experiences. Balancing approaches exist to level the playing field (e.g., providing aim assistance to low-performing players), but it is unclear how different design choices affect individual player experience. We first introduce a design space for balancing mechanics encompassing six categories: Determination, Timing, Targeting, Effect, Feedback, and Information. We then present a mixed-methods study, focused on the effect of two subcategories: Targeting Direction and Effect Dependency on skill. In this study, eight pairs of participants played a game prototype and experienced seven balancing mechanics. We collected data from questionnaires and group interviews, revealing implications for future designs, including the importance of 1) merited victory that does not ignore individual achievements, 2) sense of agency when determining the balancing before and during gameplay, and 3) balancing as an intrinsic part of the game that does not disrupt the core gameplay.</p>
<h2>Generative AI for Design</h2>
<h3>The Effects of Generative AI on Design Fixation and Divergent Thinking</h3>
<p>Authors: Ryan Kelly, Saumya Pareek, Samangi Wadinambiarachchi, Eduardo Velloso, Qiushi Zhou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147562">Link</a></p>
<p>Abstract: Generative AI systems have been heralded as tools for augmenting human creativity and inspiring divergent thinking, though with little empirical evidence for these claims. This paper explores the effects of exposure to AI-generated images on measures of design fixation and divergent thinking in a visual ideation task. Through a between-participants experiment (N=60), we found that support from an AI image generator during ideation leads to higher fixation on an initial example. Participants who used AI produced fewer ideas, with less variety and lower originality compared to a baseline. Our qualitative analysis suggests that the effectiveness of co-ideation with AI rests on participants' chosen approach to prompt creation and on the strategies used by participants to generate ideas in response to the AI's suggestions. We discuss opportunities for designing generative AI systems for ideation support and incorporating these AI tools into ideation workflows.</p>
<h3>Beyond Numbers: Creating Analogies to Enhance Data Comprehension and Communication with Generative AI</h3>
<p>Authors: Zhida Sun, Jiyao Zhang, Wei Shuai, Nan Cao, Qing Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146906">Link</a></p>
<p>Abstract: Unfamiliar measurements usually hinder readers from grasping the scale of the numerical data, understanding the content, and feeling engaged with the context. To enhance data comprehension and communication, we leverage analogies to bridge the gap between abstract data and familiar measurements. In this work, we first conduct semi-structured interviews with design experts to identify design problems and summarize design considerations. Then, we collect an analogy dataset of 138 cases from various online sources. Based on the collected dataset, we characterize a design space for creating data analogies. Next, we build a prototype system, AnalogyMate, that automatically suggests data analogies, their corresponding design solutions, and generated visual representations powered by generative AI. The study results show the usefulness of AnalogyMate in aiding the creation process of data analogies and the effectiveness of data analogy in enhancing data comprehension and communication. </p>
<h3>RoomDreaming: Generative-AI Approach to Facilitating Iterative, Preliminary Interior Design Exploration</h3>
<p>Authors: Alwena Lin, Ching-Yi Tsai, Serena Chen, Mike Chen, Wei-Chung Su, Marta Misztal, Yu Chen, Katherine Cheng, Shun-Yu Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147375">Link</a></p>
<p>Abstract: Interior design aims to create aesthetically pleasing and functional environments within an architectural space. For a simple room, the preliminary design exploration currently takes multiple meetings and days of work for interior designers to incorporate homeowners' personal preferences through layout, furnishings, form, colors, and materials.</p>
<p>We present RoomDreaming, a generative AI-based approach designed to facilitate preliminary interior design exploration. It empowers owners and designers to rapidly and efficiently iterate through a broad range of AI-generated, photo-realistic design alternatives, each uniquely tailored to fit actual space layouts and individual design preferences.</p>
<p>We conducted a series of formative and summative studies with a total of 18 homeowners and 20 interior designers to help design, improve, and evaluate RoomDreaming.</p>
<p>Owners reported that RoomDreaming effectively increased the breadth and depth of design exploration with higher efficiency and satisfaction. Designers reported that one hour of collaborative designing with RoomDreaming yielded results comparable to several days of traditional owner-designer meetings, plus days to weeks worth of designer work to develop and refine designs.</p>
<h3>Design Principles for Generative AI Applications</h3>
<p>Authors: Justin Weisz, Gabriela Hoefer, Michael Muller, Rachel Miles, Werner Geyer, Jessica He</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147832">Link</a></p>
<p>Abstract: Generative AI applications present unique design challenges. As generative AI technologies are increasingly being incorporated into mainstream applications, there is an urgent need for guidance on how to design user experiences that foster effective and safe use. We present six principles for the design of generative AI applications that address unique characteristics of generative AI UX and offer new interpretations and extensions of known issues in the design of AI applications. Each principle is coupled with a set of design strategies for implementing that principle via UX capabilities or through the design process. The principles and strategies were developed through an iterative process involving literature review, feedback from design practitioners, validation against real-world generative AI applications, and incorporation into the design process of two generative AI applications. We anticipate the principles to usefully inform the design of generative AI applications by driving actionable design recommendations.</p>
<h3>User Experience Design Professionals’ Perceptions of Generative Artificial Intelligence</h3>
<p>Authors: Jie Li, Hancheng Cao, Ruihao Zhu, Abdallah El Ali, Youyang Hou, Laura Lin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148101">Link</a></p>
<p>Abstract: Among creative professionals, Generative Artificial Intelligence (GenAI) has sparked excitement over its capabilities and fear over unanticipated consequences. How does GenAI impact User Experience Design (UXD) practice, and are fears warranted? We interviewed 20 UX Designers, with diverse experience and across companies (startups to large enterprises). We probed them to characterize their practices, and sample their attitudes, concerns, and expectations. We found that experienced designers are confident in their originality, creativity, and empathic skills, and find GenAI’s role as assistive. They emphasized the unique human factors of “enjoyment” and “agency”, where humans remain the arbiters of “AI alignment”. However, skill degradation, job replacement, and creativity exhaustion can adversely impact junior designers. We discuss implications for human-GenAI collaboration, specifically copyright and ownership, human creativity and agency, and AI literacy and access. Through the lens of responsible and participatory AI, we contribute a deeper understanding of GenAI fears and opportunities for UXD.</p>
<h2>Haptics and Embodied Interaction A</h2>
<h3>Touching the Moon: Leveraging Passive Haptics, Embodiment and Presence for Operational Assessments in Virtual Reality</h3>
<p>BEST_PAPER</p>
<p>Authors: Nikolai Callus, Aidan Cowley, Olivier Christmann, André Zenner, Tommy Nilsson, Geoffrey Gorisse, Enrico Guerra, Florian Dufresne, Leonie Bensch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147838">Link</a></p>
<p>Abstract: Space agencies are in the process of drawing up carefully thought-out Concepts of Operations (ConOps) for future human missions on the Moon. These are typically assessed and validated through costly and logistically demanding analogue field studies. While interactive simulations in Virtual Reality (VR) offer a comparatively cost-effective alternative, they have faced criticism for lacking the fidelity of real-world deployments. This paper explores the applicability of passive haptic interfaces in bridging the gap between simulated and real-world ConOps assessments. Leveraging passive haptic props (equipment mockup and astronaut gloves), we virtually recreated the Apollo 12 mission procedure and assessed it with experienced astronauts and other space experts. Quantitative and qualitative findings indicate that haptics increased presence and embodiment, thus improving perceived simulation fidelity and validity of user reflections. We conclude by discussing the potential role of passive haptic modalities in facilitating early-stage ConOps assessments for human endeavours on the Moon and beyond.</p>
<h3>A Meta-Bayesian Approach for Rapid Online Parametric Optimization for Wrist-based Interactions</h3>
<p>Authors: Yi-Chi Liao, Alec Pierce, Ruta Desai, Krista Taylor, Tanya Jonker, Aakar Gupta, Hrvoje Benko</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146812">Link</a></p>
<p>Abstract: Wrist-based input often requires tuning parameter settings in correspondence to between-user and between-session differences, such as variations in hand anatomy, wearing position, posture, etc. Traditionally, users either work with predefined parameter values not optimized for individuals or undergo time-consuming calibration processes. We propose an online Bayesian Optimization (BO)-based method for rapidly determining the user-specific optimal settings of wrist-based pointing. Specifically, we develop a meta-Bayesian optimization (meta-BO) method, differing from traditional human-in-the-loop BO: By incorporating meta-learning of prior optimization data from a user population with BO, meta-BO enables rapid calibration of parameters for new users with a handful of trials. We evaluate our method with two representative and distinct wrist-based interactions: absolute and relative pointing. On a weighted-sum metric that consists of completion time, aiming error, and trajectory quality, meta-BO improves absolute pointing performance by 22.92% and 21.35% compared to BO and manual calibration, and improves relative pointing performance by 25.43% and 13.60%.</p>
<h3>vARitouch: Back of the Finger Device for Adding Variable Compliance to Rigid Objects</h3>
<p>Authors: Audrey Girouard, Valentin Martinez-Missir, Gabriela Vega, Karen Cochrane, Dennis Wittchen, Nihar Sabnis, Paul Strohmeier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147275">Link</a></p>
<p>Abstract: We present vARitouch, a back-of-the-finger wearable that can modify the perceived tactile material properties of the uninstrumented world around us: vARitouch can modulate the perceived softness of a rigid object through a vibrotactile compliance illusion. As vARitouch does not cover the fingertip, all-natural tactile properties are preserved. We provide three contributions: (1) We demonstrate the feasibility of the concept through a psychophysics study, showing that virtual compliance can be continuously modulated, and perceived softness can be increased by approximately 30 Shore A levels. (2) A qualitative study indicates the desirability of such a device, showing that a back-of-the-finger haptic device has many attractive qualities. (3) To implement vARitouch, we identify a novel way to measure pressure from the back of the finger by repurposing a pulse oximetry sensor. Based on these contributions, we present the finalized vARitouch system, accompanied by a series of application scenarios.</p>
<h3>Haptic Source-effector: Full-body Haptics via Non-invasive Brain Stimulation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Jacob Serfaty, Pedro Lopes, Yudai Tanaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147704">Link</a></p>
<p>Abstract: We propose a novel concept for haptics in which one centralized on-body actuator renders haptic effects on multiple body parts by stimulating the brain, i.e., the source of the nervous system—we call this a haptic source-effector, as opposed to the traditional wearables’ approach of attaching one actuator per body part (end-effectors). We implement our concept via transcranial-magnetic-stimulation (TMS)—a non-invasive technique from neuroscience/medicine in which electromagnetic pulses safely stimulate brain areas. Our approach renders ~15 touch/force-feedback sensations throughout the body (e.g., hands, arms, legs, feet, and jaw—which we found in our first user study), all by stimulating the user’s sensorimotor cortex with a single magnetic coil moved mechanically across the scalp. In our second user study, we probed into participants’ experiences while using our haptic display in VR. Finally, as the first implementation of full-body haptics based on non-invasive brain stimulation, we discuss the roadmap to extend its interactive opportunities.</p>
<h3>MouseRing: Always-available Touchpad Interaction with IMU Rings</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Xutong Wang, Yuanchun Shi, Xiyuan Shen, Chen Liang, Chun Yu, Haozhan Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148332">Link</a></p>
<p>Abstract: Tracking fine-grained finger movements with IMUs for continuous 2D-cursor control poses significant challenges due to limited sensing capabilities. Our findings suggest that finger-motion patterns and the inherent structure of joints provide beneficial physical knowledge, which lead us to enhance motion perception accuracy by integrating physical priors into ML models. We propose MouseRing, a novel ring-shaped IMU device that enables continuous finger-sliding on unmodified physical surfaces like a touchpad. A motion dataset was created using infrared cameras, touchpads, and IMUs. We then identified several useful physical constraints, such as joint co-planarity, rigid constraints, and velocity consistency. These principles help refine the finger-tracking predictions from an RNN model. By incorporating touch state detection as a cursor movement switch, we achieved precise cursor control. In a Fitts’ Law study, MouseRing demonstrated input efficiency comparable to touchpads. In real-world applications, MouseRing ensured robust, efficient input and good usability across various surfaces and body postures.</p>
<h2>Haptics and Embodied Interaction B</h2>
<h3>Thermal Masking: When the Illusion Takes Over the Real</h3>
<p>Authors: Hyunjae Gil, Yatharth Singhal, Jin Ryong Kim, Haokun Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147304">Link</a></p>
<p>Abstract: This paper reports on a thermal illusion called thermal masking. Thermal masking is a phenomenon induced by thermal referral to completely mask the original thermal sensation, providing thermal sensation only at the tactile site. Three experiments are conducted using thermal and vibrotactile actuators to investigate the nature of thermal masking on human arms. The first experiment investigates the effects of different temperatures on masking. The results show a higher percentage of thermal masking occurs in warm than hot or cold conditions. The second experiment examines how far the thermal masking can be perceived. The results show that masking can reach up to 24 cm from the thermal site. The third experiment explores the interaction space by placing the tactile actuators on the opposite side of the thermal actuator. The results confirm that thermal masking can reach the other side of the arm, and the performance was higher in warm conditions.</p>
<h3>Haptic Permeability: Adding Holes to Tactile Devices Improves Dexterity</h3>
<p>Authors: Shan-Yuan Teng, Pedro Lopes, Aryan Gupta</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146851">Link</a></p>
<p>Abstract: Feeling haptics with our fingerpads is how we achieve manual tasks (e.g., operate a needle or press buttons). Following this, research started adding actuators atop the users’ fingerpads to render haptic feedback for interactive virtual environments. Recently, many have moved away from thick actuators (e.g., vibration motors) and turned to electrode-films with electrotactile stimulation—allowing users to still feel some sensations through the devices when touching physical objects (e.g., compliance or some macro features). However, we argue &amp; demonstrate that thin devices are not enough to maximize the user’s dexterity. We evaluate how adding small holes to electrotactile films can allow direct contact and thus increase haptic permeability, resulting in: (1) improved perception of tactile features; and (2) improved force control in grasping tasks. Finally, we observed participants in interactive experiences and found that holes can preserve dexterity with physical tasks while still benefiting from haptic feedback.</p>
<h3>Don’t Look Now: Audio/Haptic Guidance for 3D Scanning of Landmarks</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Gabriel Brostow, Liv Urwin, Jessica Van Brummelen, Mohamed Sayed, Oliver Johnston</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147615">Link</a></p>
<p>Abstract: People are increasingly using their smartphones to 3D scan objects and landmarks. On one hand, users have intrinsic motivations to scan well, i.e. keeping the object in-frame while walking around it to achieve coverage. On the other, users can lose interest when filming inanimate objects, and feel rushed and uncertain of their progress when watching their step in public, seeking to avoid attention.</p>
<p>We set out to guide users while reducing their stress and increasing engagement, by moving away from the on-screen feedback ubiquitous in existing products and apps meant for 3D scanning. Specifically, our novel interface gives users audio/haptic guidance while they scan statue-type landmarks in public. The interface results from a conceptual design process and a pilot study. Ultimately, we tested 50 users in an ultra-high-traffic area of central London. Compared to regular on-screen feedback, users were more engaged, had unchanged stress levels, and produced better scans.</p>
<h3>ErgoPulse: Electrifying Your Lower Body With Biomechanical Simulation-based Electrical Muscle Stimulation Haptic System in Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Minwoo Seong, SeungJun Kim, Seongjun Kang, Jeongseok Oh, Ahmed Elsharkawy, Seokhyun Hwang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147568">Link</a></p>
<p>Abstract: This study presents ErgoPulse, a system that integrates biomechanical simulation with electrical muscle stimulation (EMS) to provide kinesthetic force feedback to the lower-body in virtual reality (VR). ErgoPulse features two main parts: a biomechanical simulation part that calculates the lower-body joint torques to replicate forces from VR environments, and an EMS part that translates torques into muscle stimulations. In the first experiment, we assessed users' ability to discern haptic force intensity and direction, and observed variations in perceived resolution based on force direction. The second experiment evaluated ErgoPulse's ability to increase haptic force accuracy and user presence in both continuous and impulse force VR game environments. The experimental results showed that ErgoPulse's biomechanical simulation increased the accuracy of force delivery compared to traditional EMS, enhancing the overall user presence. Furthermore, the interviews proposed improvements to the haptic experience by integrating additional stimuli such as temperature, skin stretch, and impact.</p>
<h3>Motionless Movement: Towards Vibrotactile Kinesthetic Displays</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yuran Ding, Nihar Sabnis, Paul Strohmeier</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147366">Link</a></p>
<p>Abstract: Beyond visual and auditory displays, tactile displays and grounded force feedback devices have become more common. Other sensory modalities are also catered to by a broad range of display devices, including temperature, taste, and olfaction. However, one sensory modality remains challenging to represent: kinesthesia – the sense of movement. Inspired by grain-based compliance illusions, we investigate how vibrotactile cues can evoke kinesthetic experiences, even when no movement is performed. We examine the effects of vibrotactile mappings and granularity on the magnitude of perceived motion; distance-based mappings provided the greatest sense of movement. Using an implementation that combines visual feedback and our prototype kinesthetic display, we demonstrate that action-coupled vibrotactile cues are significantly better at conveying an embodied sense of movement than the corresponding visual stimulus, and that combining vibrotactile and visual feedback is best. These results point towards a future where kinesthetic displays will be used in rehabilitation, sports, virtual-reality and beyond.</p>
<h2>HCI for Development A</h2>
<h3>Enhancing Communication Equity: Evaluation of an Automated Speech Recognition Application in Ghana</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Gifty Ayoka, Giulia Barbareschi, Richard Cave, Catherine Holloway</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147191">Link</a></p>
<p>Abstract: In Ghana people who struggle to articulate speech as a result of different conditions experience barriers in interacting with others due to difficulties in being understood. Automatic speech recognition software can be used to help listeners understand people with communication difficulties. However, studies have not looked at the practical feasibility of these technologies beyond the Global North. We present a novel user study examining the introduction of one such technology, Google Project Relate, to Ghana. This freely available mobile application can create personalised speech recognition models in English for non-standard speech to support communication. Our user study spans the training of local speech and language therapists and 20 people with communication difficulties. We utilise the Technology Amplification Theory to contribute insights on the need for technological adaptations, awareness and support to reduce differential gaps of access, capacity and motivation to expand the reach of these technologies rather than exacerbating inequalities.</p>
<h3>Hearing Community Voices in HCI4D: Establishing Safe Places to Co-Create Counter-Collective Narratives with Women Farmers in Bangladesh</h3>
<p>Authors: Delvin Varghese, Patrick Olivier, Gillian Oliver, Jessica Watterson, Stephen Lindsay, Syed Ishtiaque Ahmed, Ms Mallika Saha, Tom Bartindale, Manika Saha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147578">Link</a></p>
<p>Abstract: Although listening to community voice is a core value in HCI4D, we have limited methods to capture the community voice of marginalized groups within disadvantaged communities. Working with NGOs and 24 marginalized women farmers in Bangladesh, we promoted psychological safety and empowerment through our configuration of the process. Our stakeholders decided to record and produce a radio-style audio</p>
<p>recording that presented their counter-collective narratives for development projects. We reflect on this process using the Benefits of Community Voice framework to document rich insights into community contexts, lived experiences, local knowledge, and building trust and buy-in and through interviews with three NGO workers. We discuss the fundamental need of stakeholders for a safe place to share, the value of letting stakeholders guide method selection, the significance of counter-collective narratives, the benefits of participatory audio to hear community voices for democratizing and sustaining development and design implications of our work for HCI4D.</p>
<h3>Digital Repression in Palestine</h3>
<p>Authors: Ghadeer Awwad, Kentaro Toyama</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146966">Link</a></p>
<p>Abstract: While Israeli suppression of Palestinian voices is well-understood,</p>
<p>much less is known about the Palestinian authorities’ repression</p>
<p>of Palestinians – the very people they are supposed to represent.</p>
<p>This paper investigates digital repression by Hamas and the Pales-</p>
<p>tinian Authority through semi-structured interviews – in-person</p>
<p>and online – with 19 Palestinian activists who post on social media.</p>
<p>Many of our findings echo those from other repressive contexts,</p>
<p>but the unusual Palestinian context also gives rise to several unique</p>
<p>elements. For example, Palestinian authorities, while incorporating</p>
<p>some high-tech methods, appear to rely primarily on a low-tech,</p>
<p>labor-intensive apparatus to monitor, intimidate, and censor their</p>
<p>targets, some of which involves highly personalized forms of repres-</p>
<p>sion. We also heard credible accusations of Palestinian authorities’</p>
<p>collaboration with Iranian and Israeli governments, the latter typ-</p>
<p>ically viewed as an adversary by Palestinians. We consider the</p>
<p>implications of these findings and offer recommendations both for</p>
<p>activists and social media platforms.</p>
<h3>"Unrest and trauma stays with you!": Navigating mental health and professional service-seeking in Kashmir</h3>
<p>Authors: Asra Wani, Ishika Joshi, Pushpendra Singh, Nadia Nahvi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147671">Link</a></p>
<p>Abstract: Mental health well-being is a global concern, with disparities in treatment services being a challenge. Though, digital mental health interventions are proposed to bridge the gaps and supplement support and assistance. Yet, many individuals still struggle with mental health issues, particularly in regions encountering socio-political unrest, and face obstacles in seeking professional assistance. Situating our work in Kashmir, India, a region with a long history of socio-political unrest, we conducted 18 semi-structured interviews with participants seeking professional support to explore how individuals navigate mental health and professional help-seeking. Our findings identify the struggles in seeking support rooted in the context through socio-political and socio-cultural influences, strategies and methods adopted to navigate these struggles, and the role of technology in seeking support. Using a social-ecological approach to mental health care, we emphasize accounting for the socio-political realities that shape support-seeking in politically disturbed contexts and offer socio-technical design recommendations. </p>
<h3>“I know I have this till my Last Breath”: Unmasking the Gaps in Chronic Obstructive Pulmonary Disease (COPD) Care in India</h3>
<p>BEST_PAPER</p>
<p>Authors: Gautami Tripathi, Medhavi Sabherwal, Pushpendra Singh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147082">Link</a></p>
<p>Abstract: COPD is an incurable Chronic Respiratory Disease that results in restricted airflow and respiratory issues. India faces rising pollution and health infrastructure challenges, significantly contributing to the prevalence of respiratory diseases like COPD. Studies have reported that COPD is India's second leading cause of death and Disability Adjusted Life Years. Our study delves into the current state of COPD care and awareness in India. Our mixed-methods research, encompassing online surveys with medical personnel (n=9) and individuals (n=141) and semi-structured interviews (n=13) with various stakeholders (patients, doctors and caregivers), revealed a noteworthy lack of COPD awareness amongst the public, consequently affecting the COPD diagnosis, treatment and management strategies. We further explored how COPD affects patients' self-perception and quality of life while identifying the barriers to COPD care. Finally, we conclude with design recommendations for technology-based interventions which can support the management of COPD patients in the Indian context.</p>
<h2>HCI for Development B</h2>
<h3>Challenges to Online Disability Rights Advocacy in India</h3>
<p>Authors: Sukhnidh Kaur, Manohar Swaminathan, Kalika Bali, Aditya Vashistha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147020">Link</a></p>
<p>Abstract: People with disabilities experience high levels of  social discrimination worldwide. But, these harms are more pronounced in the Global South due to the intense stigma around disability and its intersections with structural embeddings of patriarchy. The massive growth of social media in the Global South provides people with disabilities a unique opportunity to advocate for disability rights and challenge regressive ableist norms. Yet, little is known about the challenges they face in doing their advocacy work on social media. Through interviews with 20 disability advocates in India with diverse gender identities and abilities, we found that disability advocates routinely face ableist hate and harassment, patronizing and invalidating comments, and lack of visibility and support, which forces them to self-censor as a form of self-protection, leading to low advocacy outcomes. We draw on these findings to illuminate the role of social media in the invisibilization of people with disabilities in the online sphere.</p>
<h3>Expanding Concepts of Non-Consensual Image-Disclosure Abuse: A Study of NCIDA in Pakistan</h3>
<p>Authors: Mustafa Naseem, Amna Batool, Kentaro Toyama</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146885">Link</a></p>
<p>Abstract: Non-Consensual Image-Disclosure Abuse (NCIDA) represents a subset of technology-facilitated sexual abuse where imagery and video with romantic or sexual connotations are used to control, extort, and otherwise harm victims. Despite considerable research on NCIDA, little is known about them in non-Western contexts. We investigate NCIDA in Pakistan, through interviews with victims, their relatives, and investigative officers; and observations of NCIDA cases being processed at a law enforcement agency. We find, first, that what constitutes NCIDA is much broader in Pakistan's patriarchal society, and that its effects can be more severe than in Western contexts. On every dimension -- types of content, perpetrators, impact on victims, and desired response by victims -- our findings suggest an expansion of the concepts associated with NCIDA. We conclude by making technical and policy-level recommendations, both to address the specific context of Pakistan, and to enable a more global conception of NCIDA.</p>
<h3>Viewer2Explorer: Designing a Map Interface for Spatial Navigation in Linear 360 Museum Exhibition Video</h3>
<p>Authors: HyeonBeom Yi, Chaeeun Lee, Woohun Lee, Jinwook Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147613">Link</a></p>
<p>Abstract: The pandemic has contributed to the increased digital content development for remote experiences. Notably, museums have begun creating virtual exhibitions using 360-videos, providing a sense of presence and high level of immersion. However, 360-video content often uses a linear timeline interface that requires viewers to follow the path decided by the video creators. This format limits viewers’ ability to actively engage with and explore the virtual space independently. Therefore, we designed a map-based video interface, Viewer2Explorer, that enables the user to perceive and explore virtual spaces autonomously. We then conducted a study to compare the overall experience between the existing linear timeline and map interfaces. Viewer2Explorer enhanced users' spatial controllability and enabled active exploration in virtual museum exhibition spaces. Additionally, based on our map interface, we discuss a new type of immersion and assisted autonomy that can be experienced through a 360-video interface and provide design insights for future content.</p>
<h3>Explorable Explainable AI: Improving AI Understanding for Community Health Workers in India</h3>
<p>Authors: Ian Solano-Kamaiko, Dibyendu Mishra, Nicola Dell, Aditya Vashistha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147612">Link</a></p>
<p>Abstract: AI technologies are increasingly deployed to support community health workers (CHWs) in high-stakes healthcare settings, from malnutrition diagnosis to diabetic retinopathy. Yet, little is known about how such technologies are understood by CHWs with low digital literacy and what can be done to make AI more understandable for them. This paper examines the potential of explorable explanations in improving AI understanding for CHWs in rural India. Explorable explanations integrate visual heuristics and written explanations to promote active learning. We conducted semi-structured interviews with CHWs who interacted with a design probe in which AI predictions of child malnutrition were accompanied by explorable explanations. Our findings show that explorable explanations shift CHWs' AI-related folk theories, help develop a more nuanced understanding of AI, augment CHWs' learning and occupational capabilities, and enhance their ability to contest AI decisions. We also uncover the effects of CHWs' sociopolitical environments on AI understanding and argue for a more holistic conception of AI explainability that goes beyond cognition and literacy.</p>
<h2>Healthy Aging</h2>
<h3>Redefining Activity Tracking Through Older Adults' Reflections on Meaningful Activities</h3>
<p>Authors: Bongshin Lee, Margaret Danilovich, Eun Kyoung Choe, Mengying Li, David E Conroy, Amanda Lazar, Yiwen Wang, Young-Ho Kim, Hernisa Kacorri</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148041">Link</a></p>
<p>Abstract: Activity tracking has the potential to promote active lifestyles among older adults. However, current activity tracking technologies may inadvertently perpetuate ageism by focusing on age-related health risks. Advocating for a personalized approach in activity tracking technology, we sought to understand what activities older adults find meaningful to track and the underlying values of those activities. We conducted a reflective interview study following a 7-day activity journaling with 13 participants. We identified various underlying values motivating participants to track activities they deemed meaningful. These values, whether competing or aligned, shape the desirability of activities. Older adults appreciate low-exertion activities, but they are difficult to track. We discuss how these activities can become central in designing activity tracking systems. Our research offers insights for creating value-driven, personalized activity trackers that resonate more fully with the meaningful activities of older adults.</p>
<h3>“X-Ray Vision” as a Compensatory Augmentation for Slowing Cognitive Map Decay in Older Adults</h3>
<p>Authors: Christopher Bennett, Paul Fink, Nicholas Giudice</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147822">Link</a></p>
<p>Abstract: Safe and efficient navigation often relies on the development and retention of accurate cognitive maps that include inter-landmark relations. For many older adults, cognitive maps are difficult to form and remember over time, which introduces serious challenges for independence and mobility. To address this problem, we explore an innovative compensatory augmentation solution enabling enhanced inter-landmark learning via an “X-Ray Vision” simulation. Results with (n=45) user study participants suggest superior older adult cognitive map retention over time from a single learning session with the augmentation versus a control condition without the augmentation. Furthermore, results characterize differences in decay of cognitive maps between older adults and a control of younger adults. These findings suggest important implications for future augmented reality devices and the ways in which they can be used to promote memory and independence among older adults.</p>
<h3>Mentorable Interfaces for Automated Vehicles: A New Paradigm for Designing Learnable Technology for Older Adults</h3>
<p>Authors: Togtokhtur Batbold, Alessandro Soro, Ronald Schroeter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147087">Link</a></p>
<p>Abstract: We introduce a conceptual framework exploring the learning methods for older adults in navigating automated vehicle interfaces. Through semi-structured interviews, we observed distinct approaches to learning, and based on these, offer a novel conceptualization of a ‘mentorable’ interface to enhance technology education. The introduction of automated vehicles (AVs) to transportation has required novel lenses to technology adoption. Although AVs require less demand in cognitive, motor, and sensory acuity, there is an increasing dependence on digital literacy. While technology education has been broadly explored through the lens of learnability, this paradigm does not work well for older adults due to its inherent trial-and-error approach to independent learning. Because older adults rely heavily on additional external support in learning technologies, we present a conceptual framework for ‘mentorability’, where a network of support is emphasized, and mentorship is integrated into the design process for in-vehicle interfaces.</p>
<h3>Navigating the Maze of Routine Disruption: Exploring How Older Adults Living Alone Navigate Barriers to Establishing and Maintaining Physical Activity Habits</h3>
<p>Authors: Karyn Moffatt, Muhe Yang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147390">Link</a></p>
<p>Abstract: Older adults, especially those living alone, are less likely to meet recommended physical activity levels than other age groups. How- ever, current physical activity promoting technologies have seen low uptake among older adults, likely due to poor attention to their unique needs. To understand the perspectives of older adults living alone towards physical activity, including their motivations for and the challenges encountered in maintaining routines, we conducted a qualitative study with 17 participants. Through thematic analysis of semi-structured interviews and diaries, we reveal their diverse motivations for engaging in physical activity while also detailing how their intentions and routines are habitually disrupted by multi- dimensional and interrelated barriers, including changing personal and environmental circumstances, lack of stimulus to maintaining motivation, and limited access to resources. We suggest future PA promoting technologies to leverage social interaction to develop commitments and employ a holistic design approach to addressing the interplay between the barriers.</p>
<h3>LightSword: A Customized Virtual Reality Exergame for Long-Term Cognitive Inhibition Training in Older Adults</h3>
<p>Authors: Mingming Fan, Xiaoying Wei, Zhen Song, Haiyan Jiang, Qiuxin Du, Dongdong Weng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147594">Link</a></p>
<p>Abstract: The decline of cognitive inhibition significantly impacts older adults' quality of life and well-being, making it a vital public health problem in today's aging society. Previous research has demonstrated that Virtual reality (VR) exergames have great potential to enhance cognitive inhibition among older adults. However, existing commercial VR exergames were unsuitable for older adults' long-term cognitive training due to the inappropriate cognitive activation paradigm, unnecessary complexity, and unbefitting difficulty levels. To bridge these gaps, we developed a customized VR cognitive training exergame (LightSword) based on Dual-task and Stroop paradigms for long-term cognitive inhibition training among healthy older adults. Subsequently, we conducted an eight-month longitudinal user study with 12 older adults aged 60 years and above to demonstrate the effectiveness of LightSword in improving cognitive inhibition. After the training, the cognitive inhibition abilities of older adults were significantly enhanced, with benefits persisting for 6 months. This result indicated that LightSword has both short-term and long-term effects in enhancing cognitive inhibition. Furthermore, qualitative feedback revealed that older adults exhibited a positive attitude toward long-term training with LightSword, which enhanced their motivation and compliance.</p>
<h2>Interaction and Input in Immersive Environments</h2>
<h3>Spatial Gaze Markers: Supporting Effective Task Switching in Augmented Reality</h3>
<p>Authors: Hans Gellersen, Jens Emil Grønbæk, Tobias Langlotz, Mathias Lystbæk, Ken Pfeuffer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147964">Link</a></p>
<p>Abstract: Task switching can occur frequently in daily routines with physical activity. In this paper, we introduce Spatial Gaze Markers, an augmented reality tool to support users in immediately returning to the last point of interest after an attention shift. The tool is task-agnostic, using only eye-tracking information to infer distinct points of visual attention and to mark the corresponding area in the physical environment. We present a user study that evaluates the effectiveness of Spatial Gaze Markers in simulated physical repair and inspection tasks against a no-marker baseline. The results give insights into how Spatial Gaze Markers affect user performance, task load, and experience of users with varying levels of task type and distractions. Our work is relevant to assist physical workers with simple AR techniques and render task switching faster with less effort.</p>
<h3>The RayHand Navigation: A Virtual Navigation Method with Relative Position between Hand and Gaze-Ray</h3>
<p>Authors: Gun Lee, Sei Kang, Soo-Hyung Kim, Hyung-Jeong Yang, Seungwon Kim, Jaejoon Jeong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148284">Link</a></p>
<p>Abstract: In this paper, we introduce a novel Virtual Reality (VR) navigation method using gaze ray and hand, named RayHand navigation. It supports controlling navigation speed and direction by quickly indicating the initial direction using gaze and then using dexterous hand movement for controlling the speed and direction based on the relative position between the gaze ray and user’s hand. We conducted a user study comparing our approach to the head-hand and torso-leaning-based navigation methods, and also evaluated their learning effect. The results showed that the RayHand and head-hand navigations were less physically demanding than the torso-leaning navigation, and the RayHand supported rich navigation experience with high hedonic quality and solved the issue of the user unintentionally stepping out from the designated interaction area. In addition, our approach showed a significant improvement over time with a learning effect.</p>
<h3>Effects of Device Environment and Information Layout on Spatial Memory and Performance in VR Selection Tasks</h3>
<p>Authors: Kim Kargut, Carl Gutwin, Andy Cockburn</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147581">Link</a></p>
<p>Abstract: Virtual Reality systems are increasingly proposed as a platform for everyday interactive software. Many applications are dependent on actions such as navigation and selection, but it is not clear how well immersive environments support these basic activities. Previous studies have suggested advantages for spatial learning in VR, so we carried out a study that investigated two aspects of immersion on spatial memory and selection: the degree to which the user is immersed in the data, and whether the system uses immersive input and output. The study showed that more-immersive conditions had substantially worse selection performance, and did not improve spatial learning. However, most participants believed that the immersive conditions were better for learning object locations, and most people preferred the immersive layout and the HMD. Our study suggests that designers should be cautious about assuming that everyday software applications will benefit from being deployed in an immersive VR environment.</p>
<h3>Rowing Beyond: Investigating Steering Methods for Rowing-based Locomotion in Virtual Environments</h3>
<p>Authors: Gerrit Meixner, Andrii Matviienko, Martin Hedlund, Cristian Bogdan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147740">Link</a></p>
<p>Abstract: Rowing has great potential in Virtual Reality (VR) exergames as it requires physical effort and uses physical motion to map the locomotion in a virtual space. However, rowing in VR is currently restricted to locomotion along one axis, leaving 2D and 3D locomotion out of the scope. To facilitate rowing-based locomotion, we implemented three steering techniques based on head, hands, and feet movements for 2D and 3D VR environments. To investigate these methods, we conducted a controlled experiment (N = 24) to assess the user performance, experience and VR sickness. We found that head steering leads to fast and precise steering in 2D and 3D, and hand steering is the most realistic. Feet steering had the largest performance difference between 2D and 3D but comparable precision to hands in 2D. Lastly, head steering is the least mentally demanding, and all methods had comparable VR sickness. </p>
<h3>Sicknificant Steps: A Systematic Review and Meta-analysis of VR Sickness in Walking-based Locomotion for Virtual Reality</h3>
<p>Authors: Niels Christian Nilsson, Joanna Bergström, Teresa Hirzle, Thomas van Gemert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147138">Link</a></p>
<p>Abstract: Walking-based locomotion techniques in virtual reality (VR) can use redirection to enable walking in a virtual environment larger than the physical one. This results in a mismatch between the perceived virtual and physical movement, which is known to cause VR sickness. However, it is unclear if different types of walking techniques (e.g., resetting, reorientation, or self-overlapping spaces) affect VR sickness differently. To address this, we conducted a systematic review and meta-analysis of 96 papers published in 2016–2022 that measure VR sickness in walking-based locomotion. We find different VR sickness effects between types of redirection and between normal walking and redirection. However, we also identified several problems with the use and reporting of VR sickness measures. We discuss the challenges in understanding VR sickness differences between walking techniques and present guidelines for measuring VR sickness in locomotion studies.</p>
<h2>Reality and Un-Reality in Immersive Interactions</h2>
<h3>The Effects of False but Stable Heart Rate Feedback on Cybersickness and User Experience in Virtual Reality</h3>
<p>Authors: Hanseob Kim, DongYun Joo, Gerard Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148245">Link</a></p>
<p>Abstract: Virtual reality (VR) offers a compelling and immersive experience; however, cybersickness (or VR sickness) stands as a significant obstacle to its widespread adoption. </p>
<p>When a user experiences cybersickness, one's physical condition deteriorates with various symptoms, often accompanied by an increased and destabilized heart rate and even altered perception of one's state. In this paper, we propose to provide ``False but Stable Heart rate (FSH)'' feedback through auditory and vibrotactile stimulation to reversely induce a stably perceived heart rate and, thereby, alleviate cybersickness while navigating a sickness-inducing VR content. </p>
<p>The validation of the human experiment confirmed the intended effect in a statistically significant way. Furthermore, it was found that the lesser compatible FSH feedback had a more substantial sickness reduction effect but distracted the user with the reduced immersive experience. </p>
<p>The compatible FSH feedback still showed moderate sickness reduction with the maintained sense of presence and immersion. </p>
<h3>Was it Real or Virtual? Confirming the Occurrence and Explaining Causes of Memory Source Confusion between Reality and Virtual Reality</h3>
<p>Authors: Julian Frommel, Elise Bonnail, Eric Lecolinet, Samuel Huron, Jan Gugenheimer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147768">Link</a></p>
<p>Abstract: Source confusion occurs when individuals attribute a memory to the wrong source (e.g., confusing a picture with an experienced event). Virtual Reality (VR) represents a new source of memories particularly prone to being confused with reality. While previous research identified causes of source confusion between reality and other sources (e.g., imagination, pictures), there is currently no understanding of what characteristics specific to VR (e.g., immersion, presence) could influence source confusion. Through a laboratory study (n=29), we 1) confirm the existence of VR source confusion with current technology, and 2) present a quantitative and qualitative exploration of factors influencing VR source confusion. Building on the Source Monitoring Framework, we identify VR characteristics and assumptions about VR capabilities (e.g., poor rendering) that are used to distinguish virtual from real memories. From these insights, we reflect on how the increasing realism of VR could leave users vulnerable to memory errors and perceptual manipulations.</p>
<h3>Socially Late, Virtually Present: The Effects of Transforming Asynchronous Social Interactions in Virtual Reality</h3>
<p>Authors: Jeremy Bailenson, Anna Queiroz, Mark Miller, Portia Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148136">Link</a></p>
<p>Abstract: Social Virtual Reality (VR) typically entails users interacting in real time. However, asynchronous Social VR presents the possibility of combining the convenience of asynchronous communication with the high presence of VR. Because the tools to easily record and replay VR social interactions are fairly new, scholars have not yet examined how users perceive asynchronous VR social interactions, and how nonverbal transformations of recorded interactions influence user behavior. In this work, we study nonverbal transformations of group interactions around proxemics and gaze and present results from an exploratory user study (N=128) investigating their effects. We found that the combination of spatial accommodation and added gaze increases social presence, perceived attention, and mutual gaze. Results also showed an inverse relationship between interpersonal distance and perceived levels of dominance and threat of the recorded group. Finally, we outline implications for educators and virtual meeting organizers to incorporate these transformations into real-world scenarios.</p>
<h3>“I’d rather drink in VRChat”: Understanding Drinking in Social Virtual Reality</h3>
<p>Authors: Qijia Chen, Giulio Jacucci, Andrea Bellucci</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147852">Link</a></p>
<p>Abstract: Drinking in social VR has become popular, yet little is known about how users perceive and experience alcohol consumption while immersed in virtual spaces with others, as well as its potential harm and negative effects on their offline and online lives. To better understand this emerging phenomenon from the perspective of both drinkers and non-drinkers, we analyzed public discussions from the r/VRchat online community on users' perceptions, and experiences with alcohol consumption in social VR. Heavy drinking is prevalent. We find that VR drinkers feel less intoxicated, which makes them drink more without being aware of it. Anti-cybersickness designs may affect users' perception of vertigo, even if the vertigo is not caused by VR. We discuss how affordances that support meaningful activities (i.e., sense of presence, embodiment, and social interactions) exacerbate alcohol abuse. We propose implications for the design of safer social VR experiences for both drinkers and non-drinkers.</p>
<h3>Using Feedforward to Reveal Interaction Possibilities in Virtual Reality</h3>
<p>Authors: Kasper Hornbæk, Andreea Muresan, Jess McIntosh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150634">Link</a></p>
<p>Abstract: In virtual reality (VR), interactions may fail when users encounter new, unknown, or unexpected objects. We propose using feedforward in VR to help users interact with objects by revealing how such objects work. Feedforward lets users know what to do and how to do it by showing the available actions and outcomes before an interaction. In this article, we first chart the design space of feedforward in VR and illustrate how to design feedforward for specific VR interactions. We discuss starting the feedforward, previewing actions and outcomes, and returning the virtual world to its state before the feedforward. Second, we implement three real-world VR applications to show how feedforward can be applied to multistep interactions, perceived interactivity, and discoverability. Third, we conduct an evaluation of the design space with 14 VR experts to understand its usefulness. Finally, we summarize the findings of our work on VR feedforward in 15 guidelines.</p>
<h2>Large Language Models</h2>
<h3>Model Compression in Practice: Lessons Learned from Practitioners Creating On-device Machine Learning Experiences</h3>
<p>Authors: Donghao Ren, Fred Hohman, Dominik Moritz, Mary Beth Kery</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147982">Link</a></p>
<p>Abstract: On-device machine learning (ML) promises to improve the privacy, responsiveness, and proliferation of new, intelligent user experiences by moving ML computation onto everyday personal devices. However, today's large ML models must be drastically compressed to run efficiently on-device, a hurtle that requires deep, yet currently niche expertise. To engage the broader human-centered ML community in on-device ML experiences, we present the results from an interview study with 30 experts at Apple that specialize in producing efficient models. We compile tacit knowledge that experts have developed through practical experience with model compression across different hardware platforms. Our findings offer pragmatic considerations missing from prior work, covering the design process, trade-offs, and technical strategies that go into creating efficient models. Finally, we distill design recommendations for tooling to help ease the difficulty of this work and bring on-device ML into to more widespread practice.</p>
<h3>Talaria: Interactively Optimizing Machine Learning Models for Efficient Inference</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Zhile Ren, Cecile Foret, Fred Hohman, Chaoqun Wang, Jeffrey Bigham, Jochen Görtler, Dominik Moritz, Xiaoyi Zhang, Qi Shan, Jinmook Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146741">Link</a></p>
<p>Abstract: On-device machine learning (ML) moves computation from the cloud to personal devices, protecting user privacy and enabling intelligent user experiences. However, fitting models on devices with limited resources presents a major technical challenge: practitioners need to optimize models and balance hardware metrics such as model size, latency, and power. To help practitioners create efficient ML models, we designed and developed Talaria: a model visualization and optimization system. Talaria enables practitioners to compile models to hardware, interactively visualize model statistics, and simulate optimizations to test the impact on inference metrics. Since its internal deployment two years ago, we have evaluated Talaria using three methodologies: (1) a log analysis highlighting its growth of 800+ practitioners submitting 3,600+ models; (2) a usability survey with 26 users assessing the utility of 20 Talaria features; and (3) a qualitative interview with the 7 most active users about their experience using Talaria.</p>
<h3>Luminate: Structured Generation and Exploration of Design Space with Large Language Models for Human-AI Co-Creation</h3>
<p>Authors: Bryan Min, Toby Li, Haijun Xia, Sangho Suh, Meng Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147623">Link</a></p>
<p>Abstract: Thanks to their generative capabilities, large language models (LLMs) have become an invaluable tool for creative processes. These models have the capacity to produce hundreds and thousands of visual and textual outputs, offering abundant inspiration for creative endeavors. But are we harnessing their full potential? We argue that current interaction paradigms fall short, guiding users towards rapid convergence on a limited set of ideas, rather than empowering them to explore the vast latent design space in generative models. To address this limitation, we propose a framework that facilitates the structured generation of design space in which users can seamlessly explore, evaluate, and synthesize a multitude of responses. We demonstrate the feasibility and usefulness of this framework through the design and development of an interactive system, Luminate, and a user study with 14 professional writers. Our work advances how we interact with LLMs for creative tasks, introducing a way to harness the creative potential of LLMs.</p>
<h3>Narrating Fitness: Leveraging Large Language Models for Reflective Fitness Tracker Data Interpretation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Stanislas Henry, Jasmin Niess, Paweł W. Woźniak, Tim Johansson, Konstantin Strömel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147608">Link</a></p>
<p>Abstract: While fitness trackers generate and present quantitative data, past research suggests that users often conceptualise their wellbeing in qualitative terms. This discrepancy between numeric data and personal wellbeing perception may limit the effectiveness of personal informatics tools in encouraging meaningful engagement with one’s wellbeing. In this work, we aim to bridge the gap between raw numeric metrics and users’ qualitative perceptions of wellbeing. In an online survey with $n=273$ participants, we used step data from fitness trackers and compared three presentation formats: standard charts, qualitative descriptions generated by an LLM (Large Language Model), and a combination of both. Our findings reveal that users experienced more reflection, focused attention and reward when presented with the generated qualitative data compared to the standard charts alone. Our work demonstrates how automatically generated data descriptions can effectively complement numeric fitness data, fostering a richer, more reflective engagement with personal wellbeing information.</p>
<h3>RELIC: Investigating Large Language Model Responses using Self-Consistency</h3>
<p>Authors: Mennatallah El-Assady, Hendrik Strobelt, Simran Arora, Vilém Zouhar, Mrinmaya Sachan, Furui Cheng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147472">Link</a></p>
<p>Abstract: Large Language Models (LLMs) are notorious for blending fact with fiction and generating non-factual content, known as hallucinations. To address this challenge, we propose an interactive system that helps users gain insight into the reliability of the generated text. Our approach is based on the idea that the self-consistency of multiple samples generated by the same LLM relates to its confidence in individual claims in the generated texts. Using this idea, we design RELIC, an interactive system that enables users to investigate and verify semantic-level variations in multiple long-form responses. This allows users to recognize potentially inaccurate information in the generated text and make necessary corrections. From a user study with ten participants, we demonstrate that our approach helps users better verify the reliability of the generated text. We further summarize the design implications and lessons learned from this research for future studies of reliable human-LLM interactions.</p>
<h2>Learning and Teaching CS and STEAM</h2>
<h3>EXPLORA: A teacher-apprentice methodology for eliciting natural child-computer interactions</h3>
<p>Authors: Vanessa Figueiredo, Catherine Ann Cameron</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148216">Link</a></p>
<p>Abstract: Investigating child-computer interactions within their contexts is vital for designing technology that caters to children’s needs. However, determining what aspects of context are relevant for designing child-centric technology remains a challenge. We introduce EXPLORA, a multimodal, multistage online methodology comprising three pivotal stages: 1) building a teacher-apprentice relationship, 2) learning from child-teachers, and 3) assessing and reinforcing researcher-apprentice learning. Central to EXPLORA is the collection of attitudinal data through pre-observation interviews, offering researchers a deeper understanding of children’s characteristics and contexts. This informs subsequent online observations, allowing researchers to focus on frequent interactions. Furthermore, researchers can validate preliminary assumptions with children. A means-ends analysis framework aids in the systematic analysis of data, shedding light on context, agency and homework-information searching processes children employ in their activities. To illustrate EXPLORA’s capabilities, we present nine single case studies investigating Brazilian child-caregiver dyads (children ages 9-11) use of technology in homework information-searching. </p>
<h3>Interactive Murals: New Opportunities for Collaborative STEAM Learning</h3>
<p>Authors: Alyshia Bustos, Fiona Bell, Leah Buechley, Nanibah Chacon, Mia Shaw</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147930">Link</a></p>
<p>Abstract: This paper introduces interactive murals—artworks that combine longstanding traditions in community mural painting with ubiquitous computing—as new sites for collaborative STEAM learning. Using research-through-design and participatory design methods, we conducted an intensive spring and summer workshop in which high school students were introduced to electronics and programming through the process of creating an interactive mural. We describe the workshop activities, the mural design process, and the data collection and analysis methods. Through documenting student learning in programming and electronics and the collaboration that occurred, we build an argument for the novel learning affordances of interactive murals, emphasizing the unique opportunities that they provide for collaborative STEAM learning.</p>
<h3>From Prisons to Programming: Fostering Self-Efficacy via Virtual Web Design Curricula in Prisons and Jails</h3>
<p>Authors: Faraz Faruqi, Raechel Soicher, Martin Nisser, Joshua Long, Marisa Gaetz, Andrew Fishberg</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147558">Link</a></p>
<p>Abstract: Self-efficacy and digital literacy are key predictors to incarcerated people's success in the modern workplace. While digitization in correctional facilities is expanding, few templates exist for how to design computing curricula that foster self-efficacy and digital literacy in carceral environments. As a result, formerly incarcerated people face increasing social and professional exclusion post-release. We report on a 12-week college-accredited web design class, taught virtually and synchronously, across 5 correctional facilities across the United States. The program brought together men and women from gender-segregated facilities into one classroom to learn fundamentals in HTML, CSS and Javascript, and create websites addressing social issues of their choosing. We conducted surveys with participating students, using dichotomous and open-ended questions, and performed thematic and quantitative analyses of their responses that suggest students' increased self-efficacy. Our study discusses key design choices, needs, and recommendations for furthering computing curricula that foster self-efficacy and digital literacy in carceral settings.</p>
<h3>Mapping Accessibility Assignments into Core Computer Science Topics: An Empirical Study with Interviews and Surveys of Instructors and Students</h3>
<p>Authors: Emily Kuang, Kristen Shinohara, Catherine Baker, Di Pham, Yasmine Elglaly, Selah Bellscheidt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147853">Link</a></p>
<p>Abstract: Incorporating accessibility education into undergraduate computer science (CS) programs is essential for preparing future technology professionals to create inclusive technology. However, many CS programs lack accessibility coverage, often confining it to human-computer interaction (HCI) courses. To address this gap, we developed accessibility assignments seamlessly integrated into core CS courses. We collaborated closely with ten instructors to select and customize these assignments to suit their needs. To evaluate the impact of these assignments, we conducted interviews with instructors and administered surveys and interviews with their students. Our findings indicate significant improvement in students' familiarity with accessibility concepts and confidence in implementation following completion of the assignments. However, their mindset and future interest in accessibility remained the same. Instructors found it straightforward to incorporate these assignments without compromising core computing concepts. In sum, we validated a foundation for effectively resourcing instructors with accessibility teaching materials and increasing their capacity in accessibility knowledge.</p>
<h3>The Matchmaker Inclusive Design Curriculum: A Faculty-Enabling Curriculum to Teach Inclusive Design Throughout Undergraduate CS</h3>
<p>Authors: Maria Jesus Alzugaray-Orellana, Gail Verdi, Heather Garcia, Spencer Madsen, Patricia Morreale, Elizabeth Li, Geraldine Jimena Noa, Rosalinda Garcia, Margaret Burnett</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147021">Link</a></p>
<p>Abstract: Despite efforts to raise awareness of societal and ethical issues in CS education, research shows students often do not act upon their new awareness (Problem 1). One such issue, well-established by HCI research, is that much of technology contains barriers impacting numerous populations—such as minoritized genders, races, ethnicities, and more. HCI has inclusive design methods that help—but these skills are rarely taught, even in HCI classes (Problem 2). To address Problems 1 and 2, we created the Matchmaker Curriculum to pair CS faculty—including non-HCI faculty—with inclusive design elements to allow for inclusive design skill-building throughout their CS program. We present the curriculum and a field study, in which we followed 18 faculty along their journey. The results show how the Matchmaker Curriculum equipped 88% of these faculty with enough inclusive design teaching knowledge to successfully embed actionable inclusive design skill-building into 13 CS courses.</p>
<h2>Learning and Teaching Technologies A</h2>
<h3>Investigating the Effects of Real-time Student Monitoring Interface on Instructors’ Monitoring Practices in Online Teaching</h3>
<p>Authors: Seora Park, Ha Yeon Lee, Esther Hehsun Kim, Hajin Lim, Joonhwan Lee, Jiyeon Seo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146670">Link</a></p>
<p>Abstract: The shift to online education, accelerated by the COVID-19 pandemic, has introduced challenges in monitoring student engagement, an essential aspect of effective teaching. In response, real-time student monitoring interfaces have emerged as potential tools to aid instructors, yet their efficacy has not been thoroughly examined. Addressing this gap, we conducted a controlled experiment with 20 instructors examining the impact of engagement cues (presence versus absence) and student engagement levels (high versus low) on instructors' monitoring effectiveness, teaching behavior adjustments, and cognitive load in online classes. Our findings underscored the fundamental benefits of student engagement monitoring interfaces for improving monitoring quality and effectiveness. Furthermore, our study highlighted the critical need for customizable interfaces that could balance the informational utility of engagement cues with the associated cognitive load and psychological stress on instructors. These insights may offer design implications for the design of future student engagement monitoring interfaces.</p>
<h3>Bridging the Literacy Gap for Adults: Streaming and Engaging in Adult Literacy Education through Livestreaming</h3>
<p>Authors: Emily Kuang, Mingming Fan, Shihan Fu, Jianhao Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148074">Link</a></p>
<p>Abstract: Literacy---the ability to read, write, and comprehend text---is an important topic addressed by UNESCO. Despite global efforts to promote adult literacy education, rural areas with limited resources still lag behind. As livestreaming has gained popularity in China, many streamers leveraged its accessibility and affordability to reach low-literate adults. To gain a better understanding of the practices and challenges faced by adult literacy education through livestreaming, we conducted a mixed-methods study involving a 7-day observation of livestreaming sessions and an interview study with twelve streamers and ten viewers. We discovered streamers' altruistic motives and unique interactive approaches. Viewers perceived livestreaming as a more engaging, community-supportive method than traditional approaches. We also identified both shared and unique challenges for streamers and viewers that limit its efficacy as a learning tool. Finally, we recognized opportunities to enhance educational equity, emphasizing design implications for advancing adult literacy education and promoting diversity in livestreaming.</p>
<h3>ClassMeta: Designing Interactive Virtual Classmate to Promote VR Classroom Participation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Xiyun Hu, Kylie Peppler, Karthik Ramani, Ziyi Liu, Lijun Zhu, Enze Jiang, Zhengzhe Zhu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147941">Link</a></p>
<p>Abstract: Peer influence plays a crucial role in promoting classroom participation, where behaviors from active students can contribute to a collective classroom learning experience. </p>
<p>However, the presence of these active students depends on several conditions and is not consistently available across all circumstances. Recently, Large Language Models (LLMs) such as GPT have demonstrated the ability to simulate diverse human behaviors convincingly due to their capacity to generate contextually coherent responses based on their role settings. Inspired by this advancement in technology, we designed ClassMeta, a GPT-4 powered agent to help promote classroom participation by playing the role of an active student. These agents, which are embodied as 3D avatars in virtual reality, interact with actual instructors and students with both spoken language and body gestures.</p>
<p>We conducted a comparative study to investigate the potential of ClassMeta for improving the overall learning experience of the class. </p>
<h3>Simulator-based Mixed Reality eVTOL Pilot Training: The Instructor Operator Station</h3>
<p>Authors: Sharina Kimura, Florian Holzapfel, Michael Zintl, Claudius Hammann</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146971">Link</a></p>
<p>Abstract: Advanced Air Mobility aircraft designs following the Simplified Vehicle Operations (SVO) concept require novel environments for practical and intuitive pilot training. Mixed Reality (MR) technologies can support immersive and interactive learning methods for operating several SVO aircraft, including electric Vertical Take-Off and Landing (eVTOL) systems. Despite this potential, regulatory guidelines for simulator-based eVTOL pilot training, especially concerning the Instructor Operator Station (IOS) design, are nascent and require substantive development. This paper investigates the feasibility of an MR eVTOL research simulator as a training tool for instructors. A user study forms the basis for a bottom-up categorization of the instructor's performance shaping factors, which are pivotal for the design of an MR IOS. This paper contributes to the discourse on MR integration in pilot training by identifying key enhancements necessary for an IOS design.</p>
<h3>Privacy Concerns of Student Data Shared with Instructors in an Online Learning Management System</h3>
<p>Authors: Avanya Kohli, Prashanth Rajivan, Monika Kwapisz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146719">Link</a></p>
<p>Abstract: Learning management systems are used for facilitating communication between instructors and students, dissemination of lecture materials, and grading of assignments. They collect large amounts of student data, necessary or otherwise, with or without explicit consent from students. Furthermore, they make the data visible to instructors, which could have significant implications for students’ grades and experience in the classroom. In this study, we interviewed 31 students enrolled in a large public university about their privacy concerns towards different data sharing practices related to the learning management system used at their university – Canvas. Data from the study was analyzed by two researchers using inductive thematic analysis methods. The results show concerns about misrepresentation, the justification for information being visible, and discrimination. We present the implications of this study on instruction, design of learning management systems, and policy.</p>
<h2>Learning and Teaching Technologies B</h2>
<h3>“Oh My God! It’s Recreating Our Room!” Understanding Children’s Experiences with A Room-Scale Augmented Reality Authoring Toolkit</h3>
<p>Authors: Yinmiao Li, Uri Wilensky, Mike Horn, Zhennian Xie, Lexie Zhao, John Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147001">Link</a></p>
<p>Abstract: Human-Computer Interaction (HCI) and education researchers have applied Augmented Reality (AR) to support spatial thinking in K-12 education. However, fewer studies support spatial thinking through spatial exploration. Room-scale AR, a recent technology development, brings new opportunities not yet researched. We developed NetLogo AR, an AR authoring toolkit, that allows children to play with, design, and create room-scale AR experiences that combine AR with computational models. To acquire a deeper and more nuanced understanding of children's interactions with this new technology, we conducted eight-week participatory design sessions with seven children aged 11-13. We analyzed 48 hours of video data, interview transcripts, and design artifacts. Children were enthusiastic and engaged in spatial thinking activities. We affirmed room-scale AR's role in spatial exploration by comparing it with other supported modalities. Building on existing studies, we propose a new AR design framework around spatial movement and exploration that could help inform design decisions.</p>
<h3>ClassInSight: Designing Conversation Support Tools to Visualize Classroom Discussion for Personalized Teacher Professional Development</h3>
<p>Authors: S Sushil, Angela Stewart, Prasenjit Mitra, Saranya Venkatraman, Neil Thawani, John Zimmerman, Ung-Sang Lee, Amy Ogan, Sherice Clarke, Tricia Ngoon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146615">Link</a></p>
<p>Abstract: Teaching is one of many professions for which personalized feedback and reflection can help improve dialogue and discussion between the professional and those they serve. However, professional development (PD) is often impersonal as human observation is labor-intensive. Data-driven PD tools in teaching are of growing interest, but open questions about how professionals engage with their data in practice remain. In this paper, we present ClassInSight, a tool that visualizes three levels of teachers’ discussion data and structures reflection. Through 22 reflection sessions and interviews with 5 high school science teachers, we found themes related to dissonance, contextualization, and sustainability in how teachers engaged with their data in the tool and in how their professional vision, the use of professional expertise to interpret events, shifted over time. We discuss guidelines for these conversational support tools to support personalized PD in professions beyond teaching where conversation and interaction are important.</p>
<h3>Virtual Reality, Real Pedagogy: A Contextual Inquiry of Instructor Practices with VR Video</h3>
<p>Authors: Yu Liu, Bo Han, Feng Qian, Qiao Jin, Svetlana Yarosh, Ye Yuan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146868">Link</a></p>
<p>Abstract: Virtual reality (VR) offers promise in education given its immersive and socially engaging nature, but it can pose challenges for educators when creating VR-specific content. VR videos can function as a new educational tool for VR content creation due to their creation affordability and user-friendliness. However, little empirical research exists on how educators utilize VR videos and associated pedagogy in real classes. Our research employed a contextual inquiry, through in-person interviews and online surveys with 11 instructors to gain actionable insights from envisioned teaching scenarios for VR videos that are informed by actual instructional practices. Our study aims to understand the factors that motivate instructors' adoption of VR videos, identify challenges educators face when incorporating VR videos into instructional units, and examine pedagogical adjustments when integrating VR videos into teaching. Through empirical evidence, we provide design implications for the development of VR-based learning experiences across diverse educational contexts. Our study also serves as a practical case of how VR can be adopted and integrated into education.</p>
<h3>Investigating Demographics and Motivation in Engineering Education Using Radio and Phone-Based Educational Technologies</h3>
<p>Authors: Darren Butler, Judith Uchidiuno, John Stamper, Christine Kwon, Amy Ogan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147291">Link</a></p>
<p>Abstract: Despite the best intentions to support equity with educational technologies, they often lead to a “rich get richer” effect, in which communities of more advantaged learners gain greater benefit from these solutions. Effective design of these technologies necessitates a deeper understanding of learners in understudied contexts and their motivations to pursue an education. Consequently, we studied a 15-week remote course launched in 2021 with 17,896 learners that provided engineering education through a radio and phone-based system aimed for use in rural settings within Northern Uganda. We address shifts in learners’ motivations for course participation and investigate the impact of demographic features and motivations of students on persistence and performance. We found significant increases in student motivation to learn more about and pursue STEM. Importantly, the course was most successful for learners in demographics who typically experience fewer educational opportunities, showing promise for such technologies to close opportunity gaps. </p>
<h3>Xylocode: A Novel Approach to Fostering Interest in Computer Science via an Embodied Music Simulation</h3>
<p>Authors: Brian Magerko, Jiaxi Yang, Duri Long, Cassandra Naomi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146705">Link</a></p>
<p>Abstract: Fostering learners’ interest remains an important challenge in computer science (CS) education. In this paper, we explore how creative music-making, tangible interfaces, and embodiment can be used toward this end. The primary contribution of this paper is Xylocode, a novel exhibit that introduces middle school age learners to computing concepts and fosters interest in CS via a tangible playspace for making music using an embodied simulation. We additionally present an in-museum evaluation of Xylocode with 29 middle school age children. Our results indicate that the exhibit fosters situational interest in computer science and leads to recognition of certain computing concepts, including arrays and global variables. Future research is needed to assess whether the exhibit leads to longer-term learning and/or interest gains and to explore why other computing concepts were not recognized by as many learners. We identify several implications and directions for future work based on our findings.</p>
<h2>Music</h2>
<h3>A Way for Deaf and Hard of Hearing People to Enjoy Music by Exploring and Customizing Cross-modal Music Concepts</h3>
<p>Authors: Jin-Hyuk Hong, Yeo-Gyeong Noh, ChungHa Lee, Youjin Choi, Junryeol Jeon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147004">Link</a></p>
<p>Abstract: Deaf and hard of hearing (DHH) people enjoy music and access it using a music-sensory substitution system that delivers sound together with the corresponding visual and tactile feedback. However, it is often challenging for them to comprehend the colorful visuals and strong vibrations that are designed to represent music. We confirmed that it is necessary to conceptualize cross-modal mapping before experiencing music sensory substitution through focus group interviews with 24 DHH people. To improve the music appreciation experience, a cross-modal music conceptualization system was implemented herein, which is a prototype that allows DHH people to explore the visuals and vibrations associated with music to perceive and appreciate. An evaluation with 28 DHH individuals demonstrated the capability of the system to improve subjective music appreciation experience via music-sensory substitution. Eventually, DHH people with negative attitudes toward music became positive in the exploration and customization process with our system.</p>
<h3>Capturing Cancer as Music: Cancer Mechanisms Expressed through Musification</h3>
<p>Authors: Rostyslav Hnatyshyn, Jiayi Hong, Christopher Norby, Carlo C. Maley, Ross Maciejewski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146927">Link</a></p>
<p>Abstract: The development of cancer is difficult to express on a simple and intuitive level due to its complexity. Since cancer is so widespread, raising public awareness about its mechanisms can help those affected cope with its realities, as well as inspire others to make lifestyle adjustments and screen for the disease. Unfortunately, studies have shown that cancer literature is too technical for the general public to understand. We found that musification, the process of turning data into music, remains an unexplored avenue for conveying this information. We explore the pedagogical effectiveness of musification through the use of an algorithm that manipulates a piece of music in a manner analogous to the development of cancer. We conducted two lab studies and found that our approach is marginally more effective at promoting cancer literacy when accompanied by a text-based article than text-based articles alone.</p>
<h3>MARingBA: Music-Adaptive Ringtones for Blended Audio Notification Delivery</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Alexander Wang, Yi Fei Cheng, David Lindlbauer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147470">Link</a></p>
<p>Abstract: Audio notifications provide users with an efficient way to access information beyond their current focus of attention. </p>
<p>Current notification delivery methods,</p>
<p>like phone ringtones, are primarily optimized for high noticeability, enhancing situational awareness in some scenarios but causing disruption and annoyance in others. In this work, we build on the observation that music listening is now a commonplace practice and present MARingBA, a novel approach that blends ringtones into background music to modulate their noticeability. We contribute a design space exploration of music-adaptive manipulation parameters, including beat matching, key matching, and timbre modifications, to tailor ringtones to different songs. Through two studies, we demonstrate that MARingBA supports content creators in authoring audio notifications that fit low, medium, and high levels of urgency and noticeability. Additionally, end users prefer music-adaptive audio notifications over conventional delivery methods, such as volume fading.</p>
<h3>Challenges of Music Score Writing and the Potentials of Interactive Surfaces</h3>
<p>Authors: Caroline Appert, Catherine Letondal, Emmanuel Pietriga, Vincent Cavez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148089">Link</a></p>
<p>Abstract: Composers use music notation programs throughout their creative process. Those programs are essentially elaborate structured document editors that enable composers to create high-quality scores by enforcing musical notation rules. They effectively support music engraving, but impede the more creative stages in the composition process because of their lack of flexibility. Composers thus often combine these desktop tools with other mediums such as paper. Interactive surfaces that support pen and touch input have the potential to address the tension between the contradicting needs for structure and flexibility. We interview nine professional composers. We report insights about their thought process and creative intentions, and rely on the ``Cognitive Dimensions of Notations'' framework to capture the frictions they experience when materializing those intentions on a score. We then discuss how interactive surfaces could increase flexibility by temporarily breaking the structure when manipulating the notation.</p>
<h3>Sound Designer-Generative AI Interactions: Towards Designing Creative Support Tools for Professional Sound Designers</h3>
<p>Authors: Purnima Kamath, Priambudi Lintang Bagaskara, Fabio Morreale, Yize Wei, Suranga Nanayakkara</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148093">Link</a></p>
<p>Abstract: The practice of sound design involves creating and manipulating environmental sounds for music, films, or games. Recently, an increasing number of studies have adopted generative AI to assist in sound design co-creation. Most of these studies focus on the needs of novices, and less on the pragmatic needs of sound design practitioners. In this paper, we aim to understand how generative AI models might support sound designers in their practice. We designed two interactive generative AI models as Creative Support Tools (CSTs) and invited nine professional sound design practitioners to apply the CSTs in their practice. We conducted semi-structured interviews and reflected on the challenges and opportunities of using generative AI in mixed-initiative interfaces for sound design. We provide insights into sound designers' expectations of generative AI and highlight opportunities to situate generative AI-based tools within the design process. Finally, we discuss design considerations for human-AI interaction researchers working with audio.</p>
<h2>Players and Game Experiences</h2>
<h3>Sweating the Details: Emotion Recognition and the Influence of Physical Exertion in Virtual Reality Exergaming</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Tarini Sehgal, Dominic Potts, Zoe Broad, Christopher Clarke, Christof Lutteroth, Eamonn O'Neill, Joseph Hartley, Crescent Jicol</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148111">Link</a></p>
<p>Abstract: There is great potential for adapting Virtual Reality (VR) exergames based on a user's affective state. However, physical activity and VR interfere with physiological sensors, making affect recognition challenging. We conducted a study (n=72) in which users experienced four emotion inducing VR exergaming environments (happiness, sadness, stress and calmness) at three different levels of exertion (low, medium, high). We collected physiological measures through pupillometry, electrodermal activity, heart rate, and facial tracking, as well as subjective affect ratings. Our validated virtual environments, data, and analyses are openly available. We found that the level of exertion influences the way affect can be recognised, as well as affect itself. Furthermore, our results highlight the importance of data cleaning to account for environmental and interpersonal factors interfering with physiological measures. The results shed light on the relationships between physiological measures and affective states and inform design choices about sensors and data cleaning approaches for affective VR.</p>
<h3>Exploring the association between engagement with location-based game features and getting inspired about environmental issues and nature</h3>
<p>Authors: Samuli Laato, Bastian Kordyaka, Sebastian Weber, Bjoern Niehaves, Juho Hamari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147451">Link</a></p>
<p>Abstract: Today, millions worldwide play popular location-based games (LBGs) such as Pokémon GO. LBGs are designed to be played outdoors, and past research has shown that they can incentivize players to travel to nature. To further explore this nature-connection, we investigated via a mixed-methods approach the connections between engagement with LBGs, inspiration and environmental awareness as follows. First, we identified relevant gamification features in Study 1. Based on the insights, we built a survey that we sent to Pokémon GO players (N=311) in Study 2. The results showed that (a) social networking features, reminders, and virtual objects were the most relevant gamification features to explain inspired by playing Pokémon GO and that (b) inspired to outdoor engagement partially mediated the relationship between inspired by playing Pokémon GO and environmental awareness. These results warrant further investigations into whether LBGs could motivate pro-environment attitudes and inspire people to care for nature.</p>
<h3>``Backseat Gaming" A Study of Co-Regulated Learning within a Collegiate Male Esports Community</h3>
<p>Authors: Garrett Powell, Brent Reeves, Erica Kleinman, James Prather, Reza Habibi, Magy Seif El-Nasr</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147778">Link</a></p>
<p>Abstract: Previous work demonstrated that esports players often leverage insights from other players and communities to learn and improve. However, little research examined social learning in esports, over time, in granular detail. Understanding the role of others in the esports learning process has implications for the design of computational support systems that can help esports players learn and make the games more accessible. Therefore, we perform an exploration of this topic using Co-Regulated Learning as a theoretical lens. In doing so, we hope to enrich existing knowledge on social learning in esports, provide insights for the future development of computational support, and a road-map for future work. Through an interview study of an esports community consisting of 14, college-aged, male players, we uncovered 10 themes regarding how Co-Regulated learning occurs within their teams. Based on these, we discuss three main takeaways and their implications for future research and development.</p>
<h3>Quantifying Wrist-Aiming Habits with A Dual-Sensor Mouse: Implications for Player Performance and Workload</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Donghyeon Kang, Namsub Kim, June-Seop Yoon, Sunjun Kim, Byungjoo Lee, Daekaun Kang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146862">Link</a></p>
<p>Abstract: Computer mice are widely used today as the primary input device in competitive video games. If a player exhibits more wrist rotation than other players when moving the mouse laterally, the player is said to have stronger wrist-aiming habits. Despite strong public interest, there has been no affordable technique to quantify the extent of a player's wrist-aiming habits and no scientific investigation into how the habits affect player performance and workload. We present a reliable and affordable technique to quantify the extent of a player's wrist-aiming habits using a mouse equipped with two optical sensors (i.e., a dual-sensor mouse). In two user studies, we demonstrate the reliability of the technique and examine the relationship between wrist-aiming habits and player performance or workload. In summary, player expertise and mouse sensitivity significantly impacted wrist-aiming habits; the extent of wrist-aiming showed a positive correlation with upper limb workload.</p>
<h3>Traumatizing or Just Annoying? Unveiling the Spectrum of Gamer Toxicity in the StarCraft II Community</h3>
<p>Authors: Samuli Laato, Bastian Kordyaka, Juho Hamari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148033">Link</a></p>
<p>Abstract: The aim of this work is to explore the forms of toxic behaviour that players encounter in competitive multiplayer real-time strategy (RTS) games. To this end, we carried out ethnographic observations and player interviews within the popular RTS game StarCraft II, and approached the data inductively, leading us to discover ten categories of toxic behaviour. While the harmfulness of toxic actions can be obtained as a product of severity and frequency, players' assessment of the severity of toxic behaviors was contextualized by, (1) directly observed; (2) background; and (3) extraneous factors. Following our empirical findings, we derive a conceptual model for differentiating toxicity from mildly annoying and more severe behaviors. The discovered view of toxicity challenges the prevailing paradigm of treating players' toxic behavior as a monolithic construct with a linear intensity spectrum. Instead, we advocate for a granular approach that acknowledges the underlying dynamics behind negative online behaviors. </p>
<h2>Understanding Player Experiences</h2>
<h3>Tunnel Runner: a Proof-of-principle for the Feasibility and Benefits of Facilitating Players' Sense of Control in Cognitive Assessment Games</h3>
<p>Authors: Max Birk, Panos Markopoulos, Benny Markovitch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147125">Link</a></p>
<p>Abstract: Cognitive assessment games attempt to improve cognitive assessment's experience and data quality by implementing game-like features, e.g., points and narratives. However, cognitive games maintain the repetitiveness and restricted control common in traditional cognitive assessment tasks, which thwart players' sense of control and impair their motivation and experience. Leading to only modest improvements over traditional tasks.</p>
<p>To demonstrate the value of designing cognitive games that facilitate a sense of control, we created and evaluated the infinite runner game Tunnel Runner. In two studies ($n_1$=117, $n_2$=121), we assessed the validity of the game’s cognitive measurements (inhibitory control, decision-making) against traditional cognitive tasks. Our results demonstrate Tunnel Runner’s valid and reliable cognitive measurements alongside substantial improvements to players’ experience and sense of control compared to the cognitive tasks, showcasing the feasibility and benefits of cognitive games designed to facilitate players’ sense of control.</p>
<h3>"I Know What You Mean": Context-Aware Recognition to Enhance Speech-Based Games</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Thomas Muender, Mohamed Lamine Fetni, Nima Zargham, Rainer Malaka, Laura Spillner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147848">Link</a></p>
<p>Abstract: Recent advances in language processing and speech recognition open up a large opportunity for video game companies to embrace voice interaction as an intuitive feature and appealing game mechanics. However, speech-based systems still remain liable to recognition errors. These add a layer of challenge on top of the game's existing obstacles, preventing players from reaching their goals and thus often resulting in player frustration. This work investigates a novel method called context-aware speech recognition, where the game environment and actions are used as supplementary information to enhance recognition in a speech-based game. In a between-subject user study (N=40), we compared our proposed method with a standard method in which recognition is based only on the voice input without taking context into account. Our results indicate that our proposed method could improve the player experience and the usability of the speech system.</p>
<h3>Screenless Interactive Tabletop Gaming with Capacitive Surface Sensing</h3>
<p>Authors: Anna Walczak, Julia Dominiak, Krzysztof Adamkiewicz, Paweł W. Woźniak, Andrzej Romanowski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147873">Link</a></p>
<p>Abstract: Many interactive systems that support tabletop games either augment the experience with additional elements or transform game components into digital counterparts, e.g., using mixed reality. However, as many users prefer tangible game elements, digital augmentations can disrupt the immersion they seek to enhance, often due to the complexity of the hardware used. Responding to this challenge, we designed a screenless interactive tabletop system with capacitive sensing. The system is suitable for novice players and provides automatic score-keeping. Our method eliminates the need for external sensors and retains all original game pieces intact. We evaluated our system in a study with a forest planting game (n = 20). Gameplay with our system exhibited shorter turn duration, and participants adopted more effective strategies than in traditional gameplay. These results underscore the potential of screenless interactive tabletops to amplify the gaming experience without causing distractions.</p>
<h3>Characterizing and Quantifying Expert Input Behavior in League of Legends</h3>
<p>Authors: Youngjung Uh, Seyeon Lee, Hanbyeol Lee, Byungjoo Lee, Rohan Nallapati</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148156">Link</a></p>
<p>Abstract: To achieve high performance in esports, players must be able to effectively and efficiently control input devices such as a computer mouse and keyboard (i.e., input skills). Characterizing and quantifying a player’s input skills can provide useful insights, but collecting and analyzing sufficient amounts of data in ecologically valid settings remains a challenge. Targeting the popular esports game, League of Legends, we go beyond the limitations of previous studies and demonstrate a holistic pipeline of input behavior analysis: from quantifying the quality of players’ input behavior (i.e., input skill) to training players based on the analysis. Based on interviews with five top-tier professionals and analysis of input behavior logs from 4,835 matches played freely at home collected from 193 players (including 18 professionals), we confirmed that players with higher ranks in the game implement eight different input skills with higher quality. In a three-week follow-up study using a training aid that visualizes a player’s input skill levels, we found that the analysis provided players with actionable lessons, potentially leading to meaningful changes in their input behavior.</p>
<h3>Toxicity in Online Games: The Prevalence and Efficacy of Coping Strategies</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Julian Frommel, Regan Mandryk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147177">Link</a></p>
<p>Abstract: Toxicity is pervasive in online multiplayer games, exposing players to disruptive and harmful behaviours. Players employ various approaches to cope with exposure to toxicity; however, game designers and researchers lack guidance on how to implement coping support within games. In this paper, we first conduct a formative study to collect a comprehensive list of coping approaches from toxicity literature and use affinity mapping to identify overarching game-based coping strategies. Then, we report findings from a survey (n = 85) on players’ experiences with toxicity, how they employ the identified coping strategies, how games support coping, and their general coping styles. Our paper contributes a framework for coping strategies to deal with game-based toxicity and provides insights into the prevalence of these strategies among players and factors that affect their usage and effectiveness. These findings can be used to guide better in-game tools that help players mitigate the harm caused by toxicity.  </p>
<h2>Reflecting on Online Content</h2>
<h3>Help Me Reflect: Leveraging Self-Reflection Interface Nudges to Enhance Deliberativeness on Online Deliberation Platforms</h3>
<p>Authors: Simon Perrault, Weiyu Zhang, Gionnieve Lim, ShunYi Yeo, Jie Gao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147640">Link</a></p>
<p>Abstract: The deliberative potential of online platforms has been widely examined. However, little is known about how various interface-based \textbf{reflection nudges impact the quality of deliberation}. This paper presents two user studies with 12 and 120 participants, respectively, to investigate the impacts of different reflective nudges on the quality of deliberation. In the first study, we examined five distinct reflective nudges: \textbf{persona, temporal prompts, analogies and metaphors, cultural prompts and storytelling}. Persona, temporal prompts, and storytelling emerged as the preferred nudges for implementation on online deliberation platforms. In the second study, we assess the impacts of these preferred reflectors more thoroughly. Results revealed a significant positive impact of these reflectors on deliberative quality. Specifically, persona promotes a deliberative environment for balanced and opinionated viewpoints while temporal prompts promote more individualised viewpoints. Our findings suggest that the choice of reflectors can significantly influence the dynamics and shape the nature of online discussions.</p>
<h3>Capra: Making Use of Multiple Perspectives for Capturing, Noticing and Revisiting Hiking Experiences Over Time</h3>
<p>Authors: Tal Amram, Henry Lin, MinYoung Yoo, Samuel Barnett, Nico Brand, William Odom, Jordan White</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148073">Link</a></p>
<p>Abstract: As the practice of hiking becomes increasingly captured through personal data, it is timely to consider what kinds of alternative data encounters might support forms of noticing and connecting to nature as well as one’s self and life history over time. To investigate this emerging design space, we designed Capra — a system that brings together the capture, storage, and exploration of personal hiking data with an emphasis on longer-term, occasional yet indefinite use. Over four years, our team adopted a designer-researcher approach where we progressively designed, built, refined, and tested Capra. This process produced frictions in terms of balancing unobtrusiveness, transforming hiking data into evolving interconnected elements in the archive, and managing the sheer quantity and diversity of information with our goal of supporting open-ended and ongoing engagements. It is these insights that emerged through the practice-based design research approach involved in creating Capra that we reflect on in this paper.</p>
<h3>AI-Driven Mediation Strategies for Audience Depolarisation in Online Debates</h3>
<p>Authors: Jorge Goncalves, Jarod Govers, Vassilis Kostakos, Eduardo Velloso</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147072">Link</a></p>
<p>Abstract: Online polarisation can tear the fabric of civility through reinforcing social media's perceptions of division and discord. Social media platforms often rely on content-moderation to combat polarisation, contingent on the reactive removal or flagging of content. However, this approach often remains agnostic of the underlying debate's ideas and stifles open discourse. In this study, we use prompt-tuned language models to mediate social media debates, applying the strategies of the Thomas-Kilmann Conflict Mode Instrument (TKI). We evaluate multiple mediation strategies in providing targeted responses to the debates, as shown to a debate audience. Our findings show that high-cooperativeness TKI strategies offered more persuasive arguments, while an accommodating argument strategy was the most successful at depolarising the audience's opinion. Furthermore, high-cooperativeness strategies also increased the perception that the debaters will reach a consensus. Our work paves the way for scalable and personalised tools that mediate social media debates to encourage depolarisation.</p>
<h3>Debate Chatbots to Facilitate Critical Thinking on YouTube: Social Identity and Conversational Style Make A Difference</h3>
<p>BEST_PAPER</p>
<p>Authors: Sidney Fels, Dongwook Yoon, Luanne Sinnamon, Thitaree Tanprasert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147628">Link</a></p>
<p>Abstract: Exposure to diverse perspectives is helpful for bursting the filter bubble in online public video platforms. The recent advancement of Large Language Models (LLMs) illuminates the potential of creating a debate chatbot that prompts users to critically examine their stances on a topic formed by watching videos. However, whether the viewer is influenced by the chatbot may depend on its persona. In this paper, we investigated the effect of two relevant persona attributes - social identity and rhetorical styles - on critical thinking. In a mixed-methods study (n=36), we found that chatbots with outgroup (vs. ingroup) identity (t(33)=-2.33, p=0.03) and persuasive (vs. eristic) rhetoric (t(44)=1.98, p=0.05) induced critical thinking most effectively, making participants re-examine their arguments. However, participants' stances remain largely unaffected, likely due to the chatbot's lack of contextual knowledge and human touch. Our paper provides empirical groundwork for designing chatbot persona for remedying filter bubbles in online communities.</p>
<h3>Viblio: Introducing Credibility Signals and Citations to Video-Sharing Platforms</h3>
<p>Authors: Renee Wang, Tanushree Mitra, Tony Li, Prerna Juneja, Amy Zhang, Emelia Hughes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148085">Link</a></p>
<p>Abstract: As more users turn to video-sharing platforms like YouTube as an information source, they may consume misinformation despite their best efforts. In this work, we investigate ways that users can better assess the credibility of videos by first exploring how users currently determine credibility using existing signals on platforms and then by introducing and evaluating new credibility-based signals. We conducted 12 contextual inquiry interviews with YouTube users, determining that participants used a combination of existing signals, such as the channel name, the production quality, and prior knowledge, to evaluate credibility, yet sometimes stumbled in their efforts to do so. We then developed Viblio, a prototype system that enables YouTube users to view and add citations and related information while watching a video based on our participants' needs. From an evaluation with 12 people, all participants found Viblio to be intuitive and useful in the process of evaluating a video’s credibility and could see themselves using Viblio in the future.</p>
<h2>Security</h2>
<h3>Comparing the Use and Usefulness of Four IoT Security Labels</h3>
<p>Authors: Jacob Abbott, Peter Caven, Zitao Zhang, Xinyao Ma, LJean Camp</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147913">Link</a></p>
<p>Abstract: There are currently multiple proposed security label designs for consumer products, with each prioritizing different security and privacy factors. These differences risk making product comparisons more confusing than informative. Standardized labels could potentially resolve this by informing consumers of a product's security features at the point of purchase. But which standard? This survey, of 500 participants, studied four label designs and measured comprehension, response time, acceptability, and cognitive load. We gauged understanding of participant perception and preferences using three smart devices: light bulbs, cameras, and thermostats. We identified preferences and behaviors before, during, and after label use for product selection. At first, participants believed more information-dense labels would better support their purchasing behavior; however, after they evaluated and compared products, participants gravitated towards less cognitively demanding designs. We identified how participants utilized and prioritized label elements to provide recommendations for US label design efforts. </p>
<h3>Better Together: The Interplay Between a Phishing Awareness Video and a Link-centric Phishing Support Tool</h3>
<p>Authors: Mattia Mossano, Benjamin Berens, Melanie Volkamer, Florian Schaub</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147585">Link</a></p>
<p>Abstract: Two popular approaches for helping consumers avoid phishing threats are phishing awareness videos and tools supporting users in identifying phishing emails. Awareness videos and tools have each been shown on their own to increase people's phishing detection rate. Videos have been shown to be a particularly effective awareness measure; link-centric warnings have been shown to provide effective tool support. However, it is unclear how these two approaches compare to each other. </p>
<p>We conducted a between-subjects online experiment (n=409) in which we compared the effectiveness of the NoPhish video and the TORPEDO tool and their combination. Our main findings suggest that the TORPEDO tool outperformed the NoPhish video and that the combination of both performs significantly better than just the tool. </p>
<p>We discuss the implications of our findings for the design and deployment of phishing awareness measures and support tools. </p>
<h3>The Effects of Group Discussion and Role-playing Training on Self-efficacy, Support-seeking, and Reporting Phishing Emails: Evidence from a Mixed-design Experiment</h3>
<p>Authors: Xiaowei Chen, Gabriele Lenzini, Anastasia Sergeeva, Verena Distler, Margault Sacré, Samuel Greiff</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146688">Link</a></p>
<p>Abstract: Organizations rely on phishing interventions to enhance employees' vigilance and safe responses to phishing emails that bypass technical solutions. While various resources are available to counteract phishing, studies emphasize the need for interactive and practical training approaches. To investigate the effectiveness of such an approach, we developed and delivered two anti-phishing trainings, group discussion and role-playing, at a European university. We conducted a pre-registered experiment (N = 105), incorporating repeated measures at three time points, a control group, and three in-situ phishing tests. Both trainings enhanced employees' anti-phishing self-efficacy and support-seeking intention in within-group analyses. Only the role-playing training significantly improved support-seeking intention when compared to the control group. Participants in both trainings reported more phishing tests and demonstrated heightened vigilance to phishing attacks compared to the control group. We discuss practical implications for evaluating and improving phishing interventions and promoting safe responses to phishing threats within organizations.</p>
<h3>Usable News Authentication: How the Presentation and Location of Cryptographic Information Impacts the Usability of Provenance Information and Perceptions of News Articles</h3>
<p>Authors: Kimberly Brown, Ayana Monroe, Samya Potlapalli, Catherine Barwulor, Julia Jose, Errol Francis II, Kelly Caine, Susan McGregor, Emily Sidnam-Mauch, Kediel Morales</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147602">Link</a></p>
<p>Abstract: Cryptographic tools for authenticating the provenance of web-based information are a promising approach to increasing trust in online news and information. However, making these tools' technical assurances sufficiently usable for news consumers is essential to realizing their potential. We conduct an online study with 160 participants to investigate how the presentation (visual vs. textual) and location (on a news article page or a third-party site) of the provenance information affects news consumers' perception of the content's credibility and trustworthiness, as well as the usability of the tool itself. We find that although the visual presentation of provenance information is more challenging to adopt than its text-based counterpart, this approach leads its users to put more faith in the credibility and trustworthiness of digital news, especially when situated internally to the news article.</p>
<h3>Interdisciplinary Approaches to Cybervulnerability Impact Assessment for Energy Critical Infrastructure</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Katya Le Blanc, Lorrie Cranor, Lujo Bauer, Robert Erbes, Andrea Gallardo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147155">Link</a></p>
<p>Abstract: As energy infrastructure becomes more interconnected, understanding cybersecurity risks to production systems requires integrating operational and computer security knowledge. We interviewed 18 experts working in the field of energy critical infrastructure to compare what information they find necessary to assess the impact of computer vulnerabilities on energy operational technology. These experts came from two groups: 1) computer security experts and 2) energy sector operations experts. We find that both groups responded similarly for general categories of information and displayed knowledge about both domains, perhaps due to their interdisciplinary work at the same organization. Yet, we found notable differences in the details of their responses and in their stated perceptions of each group’s approaches to impact assessment. Their suggestions for collaboration across domains highlighted how these two groups can work together to help each other secure the energy grid. Our findings inform the development of interdisciplinary security approaches in critical-infrastructure contexts.</p>
<h2>Sensemaking with AI A</h2>
<h3>Selenite: Scaffolding Online Sensemaking with Comprehensive Overviews Elicited from Large Language Models</h3>
<p>Authors: Aniket Kittur, Brad Myers, Michael Xieyang Liu, Franklin Mingzhe Li, Tongshuang Wu, Tianying Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148071">Link</a></p>
<p>Abstract: Sensemaking in unfamiliar domains can be challenging, demanding considerable user effort to compare different options with respect to various criteria. Prior research and our formative study found that people would benefit from reading an overview of an information space upfront, including the criteria others previously found useful. However, existing sensemaking tools struggle with the "cold-start" problem -- not only requiring significant input from previous users to generate and share these overviews, but also that such overviews may turn out to be biased and incomplete. In this work, we introduce a novel system, Selenite, which leverages Large Language Models (LLMs) as reasoning machines and knowledge retrievers to automatically produce a comprehensive overview of options and criteria to jumpstart users' sensemaking processes. Subsequently, Selenite also adapts as people use it, helping users find, read, and navigate unfamiliar information in a systematic yet personalized manner. Through three studies, we found that Selenite produced accurate and high-quality overviews reliably, significantly accelerated users' information processing, and effectively improved their overall comprehension and sensemaking experience.</p>
<h3>Supporting Sensemaking of Large Language Model Outputs at Scale</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Ziwei Gu, Chelse Swoopes, Jonathan Kummerfeld, Katy Gero, Elena Glassman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146937">Link</a></p>
<p>Abstract: Large language models (LLMs) are capable of generating multiple responses to a single prompt, yet little effort has been expended to help end-users or system designers make use of this capability. In this paper, we explore how to present many LLM responses at once. We design five features, which include both pre-existing and novel methods for computing similarities and differences across textual documents, as well as how to render their outputs. We report on a controlled user study (n=24) and eight case studies evaluating these features and how they support users in different tasks. We find that the features support a wide variety of sensemaking tasks and even make tasks tractable that our participants previously considered to be too difficult to attempt. Finally, we present design guidelines to inform future explorations of new LLM interfaces.</p>
<h3>Explanations, Fairness, and Appropriate Reliance in Human-AI Decision-Making</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Maria De-Arteaga, Niklas Kühl, Jakob Schoeffer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147316">Link</a></p>
<p>Abstract: In this work, we study the effects of feature-based explanations on distributive fairness of AI-assisted decisions, specifically focusing on the task of predicting occupations from short textual bios. We also investigate how any effects are mediated by humans' fairness perceptions and their reliance on AI recommendations. Our findings show that explanations influence fairness perceptions, which, in turn, relate to humans' tendency to adhere to AI recommendations. However, we see that such explanations do not enable humans to discern correct and incorrect AI recommendations. Instead, we show that they may affect reliance irrespective of the correctness of AI recommendations. Depending on which features an explanation highlights, this can foster or hinder distributive fairness: when explanations highlight features that are task-irrelevant and evidently associated with the sensitive attribute, this prompts overrides that counter AI recommendations that align with gender stereotypes. Meanwhile, if explanations appear task-relevant, this induces reliance behavior that reinforces stereotype-aligned errors. These results imply that feature-based explanations are not a reliable mechanism to improve distributive fairness.</p>
<h3>Unraveling the Dilemma of AI Errors: Exploring the Effectiveness of Human and Machine Explanations for Large Language Models</h3>
<p>Authors: Mark Hancock, Marvin Pafla, Kate Larson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147603">Link</a></p>
<p>Abstract: The field of eXplainable artificial intelligence (XAI) has produced a plethora of methods (e.g., saliency-maps) to gain insight into artificial intelligence (AI) models, and has exploded with the rise of deep learning (DL). However, human-participant studies question the efficacy of these methods, particularly when the AI output is wrong. In this study, we collected and analyzed 156 human-generated text and saliency-based explanations collected in a question-answering task (N=40) and compared them empirically to state-of-the-art XAI explanations (integrated gradients, conservative LRP, and ChatGPT) in a human-participant study (N=136). Our findings show that participants found human saliency maps to be more helpful in explaining AI answers than machine saliency maps, but performance negatively correlated with trust in the AI model and explanations. This finding hints at the dilemma of AI errors in explanation, where helpful explanations can lead to lower task performance when they support wrong AI predictions. </p>
<h3>"Are You Really Sure?'' Understanding the Effects of Human Self-Confidence Calibration in AI-Assisted Decision Making</h3>
<p>Authors: Shuai Ma, Chuhan Shi, Xinru Wang, Xiaojuan Ma, Ying Lei, Ming Yin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147034">Link</a></p>
<p>Abstract: In AI-assisted decision-making, it is crucial but challenging for humans to achieve appropriate reliance on AI. This paper approaches this problem from a human-centered perspective, "human self-confidence calibration". We begin by proposing an analytical framework to highlight the importance of calibrated human self-confidence. In our first study, we explore the relationship between human self-confidence appropriateness and reliance appropriateness. Then in our second study, We propose three calibration mechanisms and compare their effects on humans' self-confidence and user experience. Subsequently, our third study investigates the effects of self-confidence calibration on AI-assisted decision-making. Results show that calibrating human self-confidence enhances human-AI team performance and encourages more rational reliance on AI (in some aspects) compared to uncalibrated baselines. Finally, we discuss our main findings and provide implications for designing future AI-assisted decision-making interfaces.</p>
<h2>Sensemaking with AI B</h2>
<h3>Towards a Diffractive Analysis of Prompt-Based Generative AI</h3>
<p>Authors: Jon McCormack, Maria Teresa Llano Rodriguez, Nina Rajcic</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148226">Link</a></p>
<p>Abstract: Recent developments in prompt-based generative AI has given rise to discourse surrounding the perceived ethical concerns, economic implications, and consequences for the future of cultural production. As generative imagery becomes pervasive in mainstream society, dominated primarily by emerging industry leaders, we encourage that the role of the CHI community be one of inquiry; to investigate the numerous ways in which generative AI has the potential to, and already is, augmenting human creativity. In this paper, we conducted a diffractive analysis exploring the potential role of prompt-based interfaces in artists' creative practice. Over a two week period, seven visual artists were given access to a personalised instance of Stable Diffusion, fine-tuned on a dataset of their work. In the following diffractive analysis, we identified two dominant modes adopted by participants, AI for ideation, and AI for production. We furthermore present a number of ethical design considerations for the future development of generative AI interfaces.</p>
<h3>Where Are We So Far? Understanding Data Storytelling Tools from the Perspective of Human-AI Collaboration</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Haotian Li, Huamin Qu, Yun Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146630">Link</a></p>
<p>Abstract: Data storytelling is powerful for communicating data insights, but it requires diverse skills and considerable effort from human creators. Recent research has widely explored the potential for artificial intelligence (AI) to support and augment humans in data storytelling. However, there lacks a systematic review to understand data storytelling tools from the perspective of human-AI collaboration, which hinders researchers from reflecting on the existing collaborative tool designs that promote humans' and AI's advantages and mitigate their shortcomings. This paper investigated existing tools with a framework from two perspectives: the stages in the storytelling workflow where a tool serves, including analysis, planning, implementation, and communication, and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers. Through our analysis, we recognize the common collaboration patterns in existing tools, summarize lessons learned from these patterns, and further illustrate research opportunities for human-AI collaboration in data storytelling.</p>
<h3>Dissecting users' needs for search result explanations</h3>
<p>Authors: Alex Jaimes, Wenjuan Zhang, Joel Tetreault, Prerna Juneja, Alison Smith-Renner, Hemank Lamba</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148160">Link</a></p>
<p>Abstract: There is a growing demand for transparency in search engines to understand how search results are curated and to enhance users' trust. Prior research has introduced search result explanations with a focus on "how" to explain, assuming explanations are beneficial. Our study takes a step back to examine "if" search explanations are needed and "when" they are likely to provide benefits. Additionally, we summarize key characteristics of helpful explanations and share users' perspectives on explanation features provided by Google and Bing. Interviews with non-technical individuals reveal that users do not always seek or understand search explanations and mostly desire them for complex and critical tasks. They find Google's search explanations too obvious but appreciate the ability to contest search results. Based on our findings, we offer design recommendations for search engines and explanations to help users better evaluate search results and enhance their search experience.</p>
<h3>Natural Language Dataset Generation Framework for Visualizations Powered by Large Language Models</h3>
<p>Authors: Kwon Ko, Hyeon Jeon, Dae Hyun Kim, Jinwook Seo, Juho Kim, Gwanmo Park, Nam Wook Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147000">Link</a></p>
<p>Abstract: We introduce VL2NL, a Large Language Model (LLM) framework that generates rich and diverse NL datasets using Vega-Lite specifications as input, thereby streamlining the development of Natural Language Interfaces (NLIs) for data visualization. To synthesize relevant chart semantics accurately and enhance syntactic diversity in each NL dataset, we leverage 1) a guided discovery incorporated into prompting so that LLMs can steer themselves to create faithful NL datasets in a self-directed manner; 2) a score-based paraphrasing to augment NL syntax along with four language axes. We also present a new collection of 1,981 real-world Vega-Lite specifications that have increased diversity and complexity than existing chart collections. When tested on our chart collection, VL2NL extracted chart semantics and generated L1/L2 captions with 89.4% and 76.0% accuracy, respectively. It also demonstrated generating and paraphrasing utterances and questions with greater diversity compared to the benchmarks. Last, we discuss how our NL datasets and framework can be utilized in real-world scenarios. The codes and chart collection are available at https://github.com/hyungkwonko/chart-llm.</p>
<h3>Marco: Supporting Business Document Workflows via Collection-Centric Information Foraging with Large Language Models</h3>
<p>Authors: Tong Sun, Alexa Siu, Nedim Lipka, Raymond Fok</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147634">Link</a></p>
<p>Abstract: Knowledge workers often need to extract and analyze information from a collection of documents to solve complex information tasks in the workplace, e.g., hiring managers reviewing resumes or analysts assessing risk in contracts. However, foraging for relevant information can become tedious and repetitive over many documents and criteria of interest. We introduce Marco, a mixed-initiative workspace supporting sensemaking over diverse business document collections. Through collection-centric assistance, Marco reduces the cognitive costs of extracting and structuring information, allowing users to prioritize comparative synthesis and decision making processes. Users interactively communicate their information needs to an AI assistant using natural language and compose schemas that provide an overview of a document collection. Findings from a usability study (n=16) demonstrate that when using Marco, users complete sensemaking tasks 16% more quickly, with less effort, and without diminishing accuracy. A design probe with seven domain experts identifies how Marco can benefit various real-world workflows.</p>
<h2>Smart Homes and Environments</h2>
<h3>Decide Yourself or Delegate - User Preferences Regarding the Autonomy of Personal Privacy Assistants in Private IoT-Equipped Environments</h3>
<p>Authors: Paul Gerber, Alina Stöver, Karola Marky, Max Mühlhäuser, Verena Zimmermann, Sarah Prange, Kira Bleck, Florian Müller, Florian Alt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146932">Link</a></p>
<p>Abstract: Personalized privacy assistants (PPAs) communicate privacy-related decisions of their users to Internet of Things (IoT) devices. There are different ways to implement PPAs by varying the degree of autonomy or decision model. This paper investigates user perceptions of PPA autonomy models and privacy profiles - archetypes of individual privacy needs - as a basis for PPA decisions in private environments (e.g., a friend's home). We first explore how privacy profiles can be assigned to users and propose an assignment method. Next, we investigate user perceptions in 18 usage scenarios with varying contexts, data types and number of decisions in a study with 1126 participants. We found considerable differences between the profiles in settings with few decisions. If the number of decisions gets high (&gt; 1/h), participants exclusively preferred fully autonomous PPAs. Finally, we discuss implications and recommendations for designing scalable PPAs that serve as privacy interfaces for future IoT devices.</p>
<h3>“You can’t write down the logic”: Bringing smart technology into the water infrastructure control room</h3>
<p>Authors: Jacquelyn Schmidt, Branko Kerkez, Ariel Roy</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147334">Link</a></p>
<p>Abstract: Smart water systems, in which optimization algorithms autonomously control water infrastructure, are widely touted as a promising solution to urban water management and sanitation problems. Presently, however, adoption remains low. Even as automation and ubiquitous computing expand into consumer and civic applications, the operation of water infrastructure around the world remains stubbornly manual. We examine the barriers to adoption of smart water systems through a user study of control room operators managing a large urban sewer in Detroit, Michigan, USA. We find that limited operator trust, system complexity, high uncertainty in critical data sources, and structural barriers to regional cooperation are impeding smart technology adoption. In response, we introduce SewerTycoon, an interactive, model-based simulation tool, which we use as a scenario-based prototype. Discussion with operators on how the use of smart technologies can be expanded in the sewer system reveals opportunities for low risk testing of new technologies.</p>
<h3>Tagnoo: Enabling Smart Room-Scale Environments with RFID-Augmented Plywood</h3>
<p>Authors: Tingyu Zhang, Xing-Dong Yang, Yonghao Shi, Te-Yen Wu, Yuning Su, Jiuen Feng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148075">Link</a></p>
<p>Abstract: Tagnoo is a computational plywood augmented with RFID tags, aimed at empowering woodworkers to effortlessly create room-scale smart environments. Unlike existing solutions, Tagnoo does not necessitate technical expertise or disrupt established woodworking routines. This battery-free and cost-effective solution seamlessly integrates computation capabilities into plywood, while preserving its original appearance and functionality. In this paper, we explore various parameters that can influence Tagnoo's sensing performance and woodworking compatibility through a series of experiments. Additionally, we demonstrate the construction of a small office environment, comprising a desk, chair, shelf, and floor, all crafted by an experienced woodworker using conventional tools such as a table saw and screws while adhering to established construction workflows. Our evaluation confirms that the smart environment can accurately recognize 18 daily objects and user activities, such as a user sitting on the floor or a glass lunchbox placed on the desk, with over 90% accuracy.</p>
<h3>Who Should Hold Control? Rethinking Empowerment in Home Automation among Cohabitants through the Lens of Co-Design</h3>
<p>Authors: Xinyi Fu, Xiao XUE, Xinyang Li, Jiachen Du, Boyang Jia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147601">Link</a></p>
<p>Abstract: Recent HCI research has highlighted home automation's potential in providing residents with technology-enhanced domestic autonomy. However, in the cohabitation context, the prevalent solutionist paradigm of automated systems introduces challenges to non-experts, paradoxically marginalizing specific members. This paper reports a co-creation initiative involving cohabitants, exploring a new understanding of empowerment in home automation. Participants collaborated to construct Trigger-Action Program (TAP) schemes using card-based tools during workshops. Our findings showcase how cohabitants engaged in collective ideations and embodied different negotiation patterns, which reveals the significance of more perceptible and participatory design. We frame home automation as "problematic co-design", arguing the universal overlook of collaborative resources. Furthermore, we examine how automation systems act as obstacles and sources of empowerment through the co-design lens. The paper concludes with pragmatic recommendations for designers and researchers, emphasizing the need to foster contestability for cohabitants in the evolving home automation landscape.</p>
<h3>Understanding Users' Interaction with Login Notifications</h3>
<p>Authors: Markus Dürmuth, Leona Lassak, Philipp Markert, Maximilian Golla</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147051">Link</a></p>
<p>Abstract: Login notifications intend to inform users about sign-ins and help them protect their accounts from unauthorized access. Notifications are usually sent if a login deviates from previous ones, potentially indicating malicious activity. They contain information like the location, date, time, and device used to sign in. Users are challenged to verify whether they recognize the login (because it was them or someone they know) or to protect their account from unwanted access. In a user study, we explore users' comprehension, reactions, and expectations of login notifications. We utilize two treatments to measure users' behavior in response to notifications sent for a login they initiated or based on a malicious actor relying on statistical sign-in information. We find that users identify legitimate logins but need more support to halt malicious sign-ins. We discuss the identified problems and give recommendations for service providers to ensure usable and secure logins for everyone.</p>
<h2>Smart Textiles and Changing Displays</h2>
<h3>MagneSwift: Low-Cost, Interactive Shape Display Leveraging Magnetic Materials</h3>
<p>Authors: Kentaro Yasu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146985">Link</a></p>
<p>Abstract: Pin-based shape displays present shapes and motion by moving arrays of pins. However, using many linear actuators to achieve this inevitably increases the size and cost of the device. MagneShape instead uses magnetic force to control the levitation height of passive magnetic pins to display shape and motion. While it is simple and inexpensive, MagneShape offers only limited interactivity. Since a certain distance has to be maintained between the magnetic pins to avoid magnetic interference arising between them, MagneShape requires appropriate magnetic patterns and time-consuming magnetization processes to display characters properly. To address this limitation, we improved the configuration of the magnetic pins and developed MagneSwift, a magnetic belt conveyor system with a high-density pin array. When a hand-drawn magnetic pattern is conveyed under the high-density pin array, the drawn pattern is presented on the pin array. We also demonstrate several interactive applications and discuss future possibilities. </p>
<h3>Shape-Changing Clay-Dough: Taking a Material-Oriented Approach to 3D Printing Ceramic Forms</h3>
<p>Authors: Fiona Bell, Ruby Ta, Erin McClure, Leah Buechley, Camila Friedman-Gerlicz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146926">Link</a></p>
<p>Abstract: This paper presents clay-dough, a 3D printable ceramic material that is made from a mixture of stoneware clay and a biomaterial dough. While all clays shrink when they are fired at high temperatures, clay-dough enables more dramatic shrinkage due to the dough burning away. We developed three clay-dough recipes made from different ratios of clay-to-dough and characterized the properties of each recipe; ultimately correlating shrinkage, density, strength, and porosity to the amount of dough in the recipe. We then leveraged clay-dough's shrinkage in our material-oriented approach to create ceramic forms, where form is dictated by the pattern we load the clay-dough materials in for 3D printing. To exemplify this approach, we built a design space around basic cylindrical forms that change shape during the firing process into more complex forms and explored a range of non-cylindrical applications. Lastly, we reflect on the limitations and opportunities for clay-dough and material-centered research.  </p>
<h3>Waxpaper Actuator: Sequentially and Conditionally Programmable Wax Paper for Morphing Interfaces</h3>
<p>Authors: Di Wu, Yunjia Zhang, Qiuyu Lu, Lining Yao, Hsuanju Lai, Emily Guan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148150">Link</a></p>
<p>Abstract: We print wax on the paper and turn the composite into a sequentially-controllable, moisture-triggered, rapidly-fabricated, and low-cost shape-changing interface. This technique relies on a sequential control method that harnesses two critical variables: gray levels and water amount. By integrating these variables within a bilayer structure, composed of a paper substrate and wax layer, we produce a diverse wax pattern using a solid inkjet printer. These patterns empower wax paper actuators with rapid control over sequential deformations, harnessing various bending degrees and response times, which helps to facilitate the potential of swift personal actuator customization. Our exploration encompasses the material mechanism, the sequential control method, fabrication procedures, primitive structures, and evaluations. Additionally, we introduce a user-friendly software tool for design and simulation. Lastly, we demonstrate our approach through applications across four domains: agricultural seeding, interactive toys and art, home decoration, and electrical control.</p>
<h3>Loopsense: low-scale, unobtrusive, and minimally invasive knitted force sensors for multi-modal input, enabled by selective loop-meshing</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Roland Aigner, Mira Haberfellner, Michael Haller</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147384">Link</a></p>
<p>Abstract: Integrating sensors into knitted input devices traditionally comes with considerable constraints for textile and UI design freedom. In this work, we demonstrate a novel, minimally invasive method for fabricating knitted sensors that overcomes this limitation. We integrate copper wire with piezoresistive enamel directly into the fabric using weft knitting to establish strain and pressure sensing cells that consist only of single pairs of intermeshed loops. The result is unobtrusive and potentially invisible, which provides tremendous latitude for visual and haptic design. Furthermore, we present several variations of stitch compositions, resulting in loop meshes that feature distinct response with respect to direction of exerting force. Utilizing this property, we are able to infer actuation modalities and considerably expand the device's input space. In particular, we discern strain directions and surface pressure. Moreover, we provide an in-depth description of our fabrication method, and demonstrate our solution's versatility on three exemplary use cases.</p>
<h3>Cymatics Cup: Shape-Changing Drinks by Leveraging Cymatics</h3>
<p>Authors: Yun Suen Pai, Yang Yang, Kao-Hua Liu, Junichi Yamaoka, Weijen Chen, Kouta Minamizawa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147592">Link</a></p>
<p>Abstract: To enhance the dining experience, prior studies in Human-Computer Interaction (HCI) and gastrophysics have demonstrated that modifying the static shape of solid foods can amplify taste perception. However, the exploration of dynamic shape-changing mechanisms in liquid foods remains largely untapped. In the present study, we employ cymatics, a scientific discipline focused on utilizing sound frequencies to generate patterns in liquids and particles—to augment the drinking experience. Utilizing speakers, we dynamically reshaped liquids exhibiting five distinct taste profiles and evaluated resultant changes in taste perception and drinking experience. Our research objectives extend beyond merely augmenting taste from visual to tactile sensations; we also prioritize the experiential aspects of drinking. Through a series of experiments and workshops, we revealed a significant impact on taste perception and overall drinking experience when mediated by cymatics effects. Building upon these findings, we designed and developed tableware to integrate cymatics principles into gastronomic experiences.</p>
<h2>Social and Political Activism</h2>
<h3>Keyboard Fighters: The Use of ICTs by Activists in Times of Military Coup in Myanmar</h3>
<p>Authors: Laura Guntrum</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147122">Link</a></p>
<p>Abstract: Amidst the ongoing anti-military protests in Myanmar since 2021, there is a noticeable research gap on ICT-supported activism. Generally, ICTs play an important role during political crises in conjunction with activists' practices on the ground. Inspired by Resource Mobilization Theory, I conducted qualitative interviews (N=16) and a qualitative online survey (N=34), which demonstrate the intersection between analog and digital domains, showcasing the ingenuity of the activists, and the rapid adoption of ICTs in a country that has experienced a digital revolution within the last few years. As not all people were able to protest on-the-ground, they acted as keyboard fighters to organize protests, to share information, and to support the civil disobedience movement in Myanmar. The study identifies, inter alia, the need for better offline applications with wider coverage in times of internet shutdowns, applications that cannot be easily identified during physical controls, and providing free and secure VPN access.</p>
<h3>Designing for Harm Reduction: Communication Repair for Multicultural Users' Voice Interactions</h3>
<p>BEST_PAPER</p>
<p>Authors: Geoff Kaufman, Kimi Wenzel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147425">Link</a></p>
<p>Abstract: Voice assistants’ inability to serve people-of-color and non-native English speakers has largely been documented as a quality-of-service harm. However, little work has investigated what downstream harms propagate from this poor service. How does poor usability materially manifest and affect users’ lives? And what interaction designs might help users recover from these effects? We identify 6 downstream harms that propagate from quality-of-service harms in voice assistants. Through interviews and design activities with 16 multicultural participants, we unveil these 6 harms, outline how multicultural users uniquely personify their voice assistant, and suggest how these harms and personifications may affect their interactions. Lastly, we employ techniques from psychology on communication repair to contribute suggestions for harm-reducing repair that may be implemented in voice technologies. Our communication repair strategies include: identity affirmations (intermittent frequency), cultural sensitivity, and blame redirection. This work shows potential for a harm-repair framework to positively influence voice interactions.</p>
<h3>Persuasion or Insulting? Unpacking Discursive Strategies of Gender Debate in Everyday Feminism in China</h3>
<p>Authors: Zheng Chen, Bo Li, Changyang He, Zhicong Lu, Yue DENG</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147170">Link</a></p>
<p>Abstract: Speaking out for women's daily needs on social media has become a crucial form of everyday feminism in China. Gender debate naturally intertwines with such feminist advocacy, where users in opposite stances discuss gender-related issues through intense discourse. The complexities of gender debate necessitate a systematic understanding of discursive strategies for achieving effective gender communication that balances civility and constructiveness. To address this problem, we adopted a mixed-methods study to navigate discursive strategies in gender debate, focusing on 38,636 posts and 187,539 comments from two representative cases in China. Through open coding, we identified a comprehensive taxonomy of linguistic strategies in gender debate, capturing five overarching themes including derogation, gender distinction, intensification, mitigation, and cognizance guidance. Further, we applied regression analysis to unveil these strategies' correlations with user participation and response, illustrating the tension between debating tactics and public engagement. We discuss design implications to facilitate feminist advocacy on social media.</p>
<p>Content Warning: This paper contains discussions on gender debate that may include swear words and sensitive topics, such as sex, potentially causing discomfort.</p>
<h3>Starting a New Life after Crossing the Tumen River: How North Korean Defectors Use Digital Technology in Transition</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Hayoun Noh, Soohyun Yoon, Hyunah Jo, Max Van Kleek, Younah Kang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147753">Link</a></p>
<p>Abstract: In a world where digital technology is omnipresent, North Korea stands as an outlier, with most citizens uninformed about its existence. This study explores the experiences of North Korean defectors as they transition to a highly digitally connected society—South Korea. Through 21 semi-structured interviews, we initially investigate the critical needs and challenges they encounter during their transitions. Then, we examine the role of digital technology as they adapt to the highly connected digital environment of South Korea. Our findings highlight that social media serves as a double-edged sword, providing the freedom to construct a desired identity while accentuating the gap between their real and ideal selves. This empirical research offers insights into how an underrepresented population navigates the digital landscape during life transitions, shedding light on the drawbacks and ways to better address their needs.</p>
<h2>Sound, Rhythm, Movement</h2>
<h3>FabSound: Audio-Tactile and Affective Fabric Experiences Through Mid-air Haptics</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Patricia Cornelio, Christopher Dawes, Roberto Montano Murillo, William Frier, Marianna Obrist, Jing Xue</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147299">Link</a></p>
<p>Abstract: The sound produced when touching fabrics, like a blanket, often provides information regarding the fabric’s texture properties (e.g., its roughness). Fabric roughness is one of the most important aspects of assessing fabric tactile properties. Prior research has demonstrated that touch-related sounds can alter the perception of textures. However, understanding touch-related sound of digital fabric textures, and how they could convey affective responses remain a challenge. In this study, we mapped digital fabric textures using mid-air haptics stimuli and examined how auditory manipulation influences people’s roughness perception. Through qualitative interviews, participants detailed that while rubbing sounds smoothen fabric texture perception, pure tone sounds of 450Hz and 900Hz accent roughness perception. The rubbing sound of fabric evoked associations with soft-materials and led to more calming experiences. In addition, we discussed how haptic interaction can be extended to multisensory modes, revealing a new perspective of mapping multisensory experiences for digital fabrics.</p>
<h3>Exploring Collaborative Movement Improvisation Towards the Design of LuminAI—a Co-Creative AI Dance Partner</h3>
<p>Authors: Andrea Knowlton, Brian Magerko, Milka Trajkova, Manoj Deshpande, Duri Long</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147151">Link</a></p>
<p>Abstract: Co-creation in embodied contexts is central to the human experience but is often lacking in our interactions with computers. We seek to develop a better understanding of embodied human co-creativity to inform the human-centered design of machines that can co-create with us. In this paper, we ask: What characterizes dancers’ experiences of embodied dyadic interaction in movement improvisation? To answer this, we ran focus groups with 24 university dance students and conducted a thematic analysis of their responses. We synthesize our findings in an interconnected model of improvisational dance inputs where movement choices are shaped by interplays such as in-the-moment influences between the self, partner, and the environment as well as a set of generative strategies and heuristics for a successful collaboration. We present a set of design recommendations for LuminAI, a co-creative AI dance partner. Our contributions can inform the design of AI in embodied co-creative domains. </p>
<h3>Understanding Feedback in Rhythmic Gymnastics Training: An Ethnographic-Informed Study of a Competition Class</h3>
<p>BEST_PAPER</p>
<p>Authors: Leonor Portugal da Fonseca, Paula Alexandra Silva, Francisco Nunes</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148223">Link</a></p>
<p>Abstract: Rhythmic Gymnastics is an Olympic sport that demands an exceptional level of expertise. From early age, athletes relentlessly practise exercises until they can flawlessly perform them before an audience and a panel of judges. Technology can potentially support rhythmic gymnasts' training by monitoring gymnasts' exercises and providing feedback on their execution. However, the limited understanding of the training nuances in Rhythmic Gymnastics restricts the development of technologies to support training. Drawing on the observation of training sessions and on interviews with athletes and coaches, this paper uncovers how coaches personalise feedback timing, type, form, format, and quantity, to adapt it to the gymnasts' skill level and type of exercise. Taking stock of our findings, we draw out five implications that can inform the design of systems to support feedback in Rhythmic Gymnastics training.</p>
<h3>Designing and Evaluating an Advanced Dance Video Comprehension Tool with In-situ Move Identification Capabilities</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Garreth Tigwell, Caluã de Lacerda Pataca, Saad Hassan, Laleh Nourian, Will Silver Wagman, Briana Davis</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147258">Link</a></p>
<p>Abstract: Analyzing dance moves and routines is a foundational step in learning dance. Videos are often utilized at this step, and advancements in machine learning, particularly in human-movement recognition, could further assist dance learners. We developed and evaluated a Wizard-of-Oz prototype of a video comprehension tool that offers automatic in-situ dance move identification functionality. Our system design was informed by an interview study involving 12 dancers to understand the challenges they face when trying to comprehend complex dance videos and taking notes. Subsequently, we conducted a within-subject study with 8 Cuban salsa dancers to identify the benefits of our system compared to an existing traditional feature-based search system. We found that the quality of notes taken by participants improved when using our tool, and they reported a lower workload. Based on participants’ interactions with our system, we offer recommendations on how an AI-powered span-search feature can enhance dance video comprehension tools.</p>
<h3>DoodleTunes: Interactive Visual Analysis of Music-Inspired Children Doodles with Automated Feature Annotation</h3>
<p>Authors: Mingtian Tao, Huayuan Ye, Changbo Wang, Jia Bu, Shuqi Liu, Shiqi Jiang, Chenhui Li, Juntong Chen, Liping Guo</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147267">Link</a></p>
<p>Abstract: Music and visual arts are essential in children's arts education, and their integration has garnered significant attention. Existing data analysis methods for exploring audio-visual correlations are limited. Yet, relevant research is necessary for innovating and promoting arts integration courses. In our work, we collected substantial volumes of music-inspired doodles created by children and interviewed education experts to comprehend the challenges they encountered in the relevant analysis. Based on the insights we obtained, we designed and constructed an interactive visualization system DoodleTunes. DoodleTunes integrates deep learning-driven methods for automatically annotating several types of data features. The visual designs of the system are based on a four-level analysis structure to construct a progressive workflow, facilitating data exploration and insight discovery between doodle images and corresponding music pieces. We evaluated the accuracy of our feature prediction results and collected usage feedback on DoodleTunes from five domain experts.</p>
<h2>Supporting Accessibility of Text, Image and Video A</h2>
<h3>“It’s Kind of Context Dependent”: Understanding Blind and Low Vision People’s Video Accessibility Preferences Across Viewing Scenarios</h3>
<p>Authors: Crescentia Jung, Mahika Phutane, Lucy Jiang, Abigale Stangl, Shiri Azenkot</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146788">Link</a></p>
<p>Abstract: While audio description (AD) is the standard approach for making videos accessible to blind and low vision (BLV) people, existing AD guidelines do not consider BLV users’ varied preferences across viewing scenarios. These scenarios range from how-to videos on YouTube, where users seek to learn new skills, to historical dramas on Netflix, where a user’s goal is entertainment. Additionally, the increase in video watching on mobile devices provides an opportunity to integrate nonverbal output modalities (e.g., audio cues, tactile elements, and visual enhancements). Through a formative survey and 15 semi-structured interviews, we identified BLV people’s video accessibility preferences across diverse scenarios. For example, participants valued action and equipment details for how-to videos, tactile graphics for learning scenarios, and 3D models for fantastical content. We define a six-dimensional video accessibility design space to guide future innovation and discuss how to move from “one-size-fits-all” paradigms to scenario-specific approaches.</p>
<h3>GazePrompt: Enhancing Low Vision People's Reading Experience with Gaze-Aware Augmentations</h3>
<p>Authors: Yun Ho, Sanbrita Mondal, Linxiu Zeng, Yuhang Zhao, Ru Wang, Daniel Killough, Zach Potter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147371">Link</a></p>
<p>Abstract: Reading is a challenging task for low vision people. While conventional low vision aids (e.g., magnification) offer certain support, they cannot fully address the difficulties faced by low vision users, such as locating the next line and distinguishing similar words. To fill this gap, we present GazePrompt, a gaze-aware reading aid that provides timely and targeted visual and audio augmentations based on users' gaze behaviors. GazePrompt includes two key features: (1) a Line-Switching support that highlights the line a reader intends to read; and (2) a Difficult-Word support that magnifies or reads aloud a word that the reader hesitates with. Through a study with 13 low vision participants who performed well-controlled reading-aloud tasks with and without GazePrompt, we found that GazePrompt significantly reduced participants' line switching time, reduced word recognition errors, and improved their subjective reading experiences. A follow-up silent-reading study showed that GazePrompt can enhance users' concentration and perceived comprehension of the reading contents. We further derive design considerations for future gaze-based low vision aids.</p>
<h3>Constrained Highlighting in a Document Reader can Improve Reading Comprehension</h3>
<p>BEST_PAPER</p>
<p>Authors: Nikhita Joshi, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147932">Link</a></p>
<p>Abstract: Highlighting text in a document is a common active reading strategy to remember information from documents. Learning theory suggests that for highlights to be effective, readers must be selective with what they choose to highlight. We investigate if an imposed user interface constraint limiting the number of highlighted words in a document reader can improve reading comprehension. A large-scale between-subjects experiment shows that constraining the number of words that can be highlighted leads to higher reading comprehension scores than highlighting nothing or highlighting an unlimited number of words. Our work empirically validates theories in psychology, which in turn enables several new research directions within HCI.</p>
<h3>Making Short-Form Videos Accessible with Hierarchical Video Summaries</h3>
<p>Authors: Tess Van Daele, Akhil Iyer, Amy Pavel, Yuning Zhang, Mina Huh, Jalyn Derry</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148297">Link</a></p>
<p>Abstract: Short videos on platforms such as TikTok, Instagram Reels, and YouTube Shorts (i.e. short-form videos) have become a primary source of information and entertainment. Many short-form videos are inaccessible to blind and low vision (BLV) viewers due to their rapid visual changes, on-screen text, and music or meme-audio overlays. In our formative study, 7 BLV viewers who regularly watched short-form videos reported frequently skipping such inaccessible content. We present ShortScribe, a system that provides hierarchical visual summaries of short-form videos at three levels of detail to support BLV viewers in selecting and understanding short-form videos. ShortScribe allows BLV users to navigate between video descriptions based on their level of interest. To evaluate ShortScribe, we assessed description accuracy and conducted a user study with 10 BLV participants comparing ShortScribe to a baseline interface. When using ShortScribe, participants reported higher comprehension and provided more accurate summaries of video content.</p>
<h2>Supporting Accessibility of Text, Image and Video B</h2>
<h3>Caption Royale: Exploring the Design Space of Affective Captions from the Perspective of Deaf and Hard-of-Hearing Individuals</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Caluã de Lacerda Pataca, Roshan Peiris, Saad Hassan, Matt Huenerfauth, Nathan Tinker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148008">Link</a></p>
<p>Abstract: Affective captions employ visual typographic modulations to convey a speaker's emotions, improving speech accessibility for Deaf and Hard-of-Hearing (DHH) individuals. However, the most effective visual modulations for expressing emotions remain uncertain. Bridging this gap, we ran three studies with 39 DHH participants, exploring the design space of affective captions, which include parameters like text color, boldness, size, and so on. Study 1 assessed preferences for nine of these styles, each conveying either valence or arousal separately. Study 2 combined Study 1's top-performing styles and measured preferences for captions depicting both valence and arousal simultaneously. Participants outlined readability, minimal distraction, intuitiveness, and emotional clarity as key factors behind their choices. In Study 3, these factors and an emotion-recognition task were used to compare how Study 2's winning styles performed versus a non-styled baseline. Based on our findings, we present the two best-performing styles as design recommendations for applications employing affective captions.</p>
<h3>SPICA: Interactive Video Content Exploration through Augmented Audio Descriptions for Blind or Low-Vision Viewers</h3>
<p>Authors: Zheng Ning, Kaiwen Jiang, Brianna Wimer, Toby Li, Jerrick Ban, Yuhang Zhao, Keyi Chen, Yapeng Tian</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147481">Link</a></p>
<p>Abstract: Blind or Low-Vision (BLV) users often rely on audio descriptions (AD) to access video content. However, conventional static ADs can leave out detailed information in videos, impose a high mental load, neglect the diverse needs and preferences of BLV users, and lack immersion. To tackle these challenges, we introduce SPICA, an AI-powered system that enables BLV users to interactively explore video content. Informed by prior empirical studies on BLV video consumption, SPICA offers novel interactive mechanisms for supporting temporal navigation of frame captions and spatial exploration of objects within key frames. Leveraging an audio-visual machine learning pipeline, SPICA augments existing ADs by adding interactivity, spatial sound effects, and individual object descriptions without requiring additional human annotation. Through a user study with 14 BLV participants, we evaluated the usability and usefulness of SPICA and explored user behaviors, preferences, and mental models when interacting with augmented ADs.</p>
<h3>An AI-Resilient Text Rendering Technique for Reading and Skimming Documents</h3>
<p>Authors: Ziwei Gu, Jonathan Kummerfeld, Ian Arawjo, Elena Glassman, Kenneth Li</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147987">Link</a></p>
<p>Abstract: Readers find text difficult to consume for many reasons. Summarization can address some of these difficulties, but introduce others, such as omitting, misrepresenting, or hallucinating information, which can be hard for a reader to notice. One approach to addressing this problem is to instead modify how the original text is rendered to make important information more salient. We introduce Grammar-Preserving Text Saliency Modulation (GP-TSM), a text rendering method with a novel means of identifying what to de-emphasize. Specifically, GP-TSM uses a recursive sentence compression method to identify successive levels of detail beyond the core meaning of a passage, which are de-emphasized by rendering words in successively lighter but still legible gray text. In a lab study (n=18), participants preferred GP-TSM over pre-existing word-level text rendering methods and were able to answer GRE reading comprehension questions more efficiently.</p>
<h3>Investigating Use Cases of AI-Powered Scene Description Applications for Blind and Low Vision People</h3>
<p>Authors: Jazmin Collins, Ricardo Gonzalez Penuela, Shiri Azenkot, Cynthia Bennett</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147196">Link</a></p>
<p>Abstract: “Scene description” applications that describe visual content in a photo are useful daily tools for blind and low vision (BLV) people. Researchers have studied their use, but they have only explored those that leverage remote sighted assistants; little is known about applications that use AI to generate their descriptions. Thus, to investigate their use cases, we conducted a two-week diary study where 16 BLV participants used an AI-powered scene description application we designed. Through their diary entries and follow-up interviews, users shared their information goals and assessments of the visual descriptions they received. We analyzed the entries and found frequent use cases, such as identifying visual features of known objects, and surprising ones, such as avoiding contact with dangerous objects. We also found users scored the descriptions relatively low on average, 2.7 out of 5 (SD=1.5) for satisfaction and 2.4 out of 4 (SD=1.2) for trust, showing that descriptions still need significant improvements to deliver satisfying and trustworthy experiences. We discuss future opportunities for AI as it becomes a more powerful accessibility tool for BLV users.</p>
<h3>From Provenance to Aberrations: Image Creator and Screen Reader User Perspectives on Alt Text for AI-Generated Images</h3>
<p>Authors: Shaun Kane, Meredith Morris, Alexander Fiannaca, Maitraye Das, Cynthia Bennett</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148306">Link</a></p>
<p>Abstract: AI-generated images are proliferating as a new visual medium. However, state-of-the-art image generation models do not output alternative (alt) text with their images, rendering them largely inaccessible to screen reader users (SRUs). Moreover, less is known about what information would be most desirable to SRUs in this new medium. To address this, we invited AI image creators and SRUs to evaluate alt text prepared from various sources and write their own alt text for AI images. Our mixed-methods analysis makes three contributions. First, we highlight creators’ perspectives on alt text, as creators are well-positioned to write descriptions of their images. Second, we illustrate SRUs’ alt text needs particular to the emerging medium of AI images. Finally, we discuss the promises and pitfalls of utilizing text prompts written as input for AI models in alt text generation, and areas where broader digital accessibility guidelines could expand to account for AI images.</p>
<h2>Supporting Communication Needs A</h2>
<h3>Lights, Camera, Access: A Closeup on Audiovisual Media Accessibility and Aphasia</h3>
<p>Authors: Elena Simperl, Alexandre Nevsky, Madeline Cruice, Timothy Neate</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147404">Link</a></p>
<p>Abstract: The presence of audiovisual media is a mainstay in the lives of many, increasingly so with technological progress. Accessing video and audio content, however, can be challenging for people with diverse needs. Existing research has explored a wide range of accessibility challenges and worked with disabled communities to design technologies that help bridge the access gap. Despite this work, our understanding of the challenges faced by communities with complex communication needs (CCNs) remains poor. To address this shortcoming, we present the first study that investigates the viewing experience of people with the communication impairment aphasia through an online survey (N=41) and two focus group sessions (N=10), with the aim of understanding their specific access challenges. We find that aphasia significantly impact viewing experience and present a taxonomy of access barriers and facilitators, with suggestions for future research.</p>
<h3>Co-Designing QuickPic: Automated Topic-Specific Communication Boards from Photographs for AAC-Based Language Instruction</h3>
<p>Authors: Karyn Moffatt, Howard C. Shane, Christina Yu, Mauricio Fontana de Vargas</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147269">Link</a></p>
<p>Abstract:  Traditional topic-specific communication boards for Augmentative and Alternative Communication (AAC)  require  manual programming of relevant symbolic vocabulary, which is time-consuming and often impractical even for experienced Speech-Language Pathologists (SLPs). While recent research has demonstrated the potential to automatically generate these boards from photographs using artificial intelligence, there has been no exploration on how to design such tools to support the specific needs of AAC-based language instruction. This paper introduces QuickPic, a mobile AAC application co-designed with SLPs and special educators, aimed at enhancing language learning for non-speaking individuals, such as autistic children. Through a 17-month design process, we uncover the unique design features required to provide timely language support in therapy and special education contexts. We present emerging evidence on the overall satisfaction of SLPs using QuickPic, and on the advantages of large language model-based generation compared to the existing technique for automated vocabulary from photographs for AAC.</p>
<h3>Empowering Independence Through Design: Investigating Standard Digital Design Patterns For Easy-to-Read Users.</h3>
<p>Authors: Ann Bessemans, Sabina Sieghart, Björn Rohles</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148221">Link</a></p>
<p>Abstract: As designers and researchers, it is our duty to ensure information accessibility for all, irrespective of cognitive abilities. Currently, Easy-to-Read (ETR) is commonly used to simplify text for individuals with cognitive impairments. Although design aspects of text</p>
<p>comprehensibility have recently gained attention, digital design patterns remain relatively unexplored. Our understanding of how ETR users interact with digital media, and how to design specifically for their needs, is still limited. Our study involved observing 20 German</p>
<p>ETR users engaging with a digital PDF and a website designed in a participatory process. We collected data on their access to digital media, personal use and workarounds, and their interaction with digital design patterns. Tasks on the smartphone were completed mostly successfully, while only 50% could navigate a digital PDF. In both cases, visual cues played a significant role. Our findings contribute recommendations for beneficial digital design patterns and future research.</p>
<h3>ChatDirector: Enhancing Video Conferencing with Space-Aware Scene Rendering and Speech-Driven Layout Transition</h3>
<p>Authors: Brian Collins, Ruofei Du, Karthik Ramani, Yinda Zhang, David Kim, Feitong Tan, Alex Olwal, Xun Qian</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148295">Link</a></p>
<p>Abstract: Remote video conferencing systems (RVCS) are widely adopted in personal and professional communication. However, they often lack the co-presence experience of in-person meetings. This is largely due to the absence of intuitive visual cues and clear spatial relationships among remote participants, which can lead to speech interruptions and loss of attention. This paper presents ChatDirector, a novel RVCS that overcomes these limitations by incorporating space-aware visual presence and speech-aware attention transition assistance. ChatDirector employs a real-time pipeline that converts participants' RGB video streams into 3D portrait avatars and renders them in a virtual 3D scene. We also contribute a decision tree algorithm that directs the avatar layouts and behaviors based on participants' speech states. We report on results from a user study (N=16) where we evaluated ChatDirector. The satisfactory algorithm performance and complimentary subject user feedback imply that ChatDirector significantly enhances communication efficacy and user engagement.</p>
<h3>COR Themes for Readability from Iterative Feedback</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Bernard Kerr, Zoya Bylinskii, Michael Kraley, Aleena Niklaus, Tianyuan Cai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148158">Link</a></p>
<p>Abstract: Digital reading applications give readers the ability to customize fonts, sizes, and spacings, all of which have been shown to improve the reading experience for readers from different demographics. However, tweaking these text features can be challenging, especially given their interactions on the final look and feel of the text. Our solution is to offer readers preset combinations of font, character, word and line spacing, which we bundle together into reading themes. We identify a recommended set of reading themes through data-driven design iterations with the crowd and experts. We show that after four design iterations, we converge on a set of three COR themes (Compact, Open, and Relaxed) that meet diverse readers' preferences, when evaluating the reading speeds, comprehension scores, and preferences of hundreds of readers with and without dyslexia, using crowdsourced experiments.</p>
<h2>Supporting Communication Needs B</h2>
<h3>COMPA: Using Conversation Context to Achieve Common Ground in AAC</h3>
<p>Authors: Henny Admoni, Yufei Wu, Stephanie Valencia, Zixuan Zheng, Amy Pavel, Jessica Huynh, Jeffrey Bigham, Teresa Wan, Emma Jiang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146686">Link</a></p>
<p>Abstract: Group conversations often shift quickly from topic to topic, leaving a small window of time for participants to contribute. AAC users often miss this window due to the speed asymmetry between using speech and using AAC devices. AAC users may take over a minute longer to contribute, and this speed difference can cause mismatches between the ongoing conversation and the AAC user's response. This results in misunderstandings and missed opportunities to participate. We present COMPA, an add-on tool for online group conversations that seeks to support conversation partners in achieving common ground. COMPA uses a conversation's live transcription to enable AAC users to mark conversation segments they intend to address (Context Marking) and generate contextual starter phrases related to the marked conversation segment (Phrase Assistance) and a selected user intent. We study COMPA in 5 different triadic group conversations, each composed by a researcher, an AAC user and a conversation partner (n=10) and share findings on how conversational context supports conversation partners in achieving common ground.</p>
<h3>Finding My Voice over Zoom: An Autoethnography of Videoconferencing Experience for a Person Who Stutters</h3>
<p>Authors: Shaomei Wu, Jingjin Li, Gilly Leshed</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146953">Link</a></p>
<p>Abstract: Existing videoconferencing (VC) technologies are often optimized for productivity and efficiency, with little support for the "soft side" of VC meetings such as empathy, authenticity, belonging, and emotional connections. This paper presents findings from a 15-month long autoethnographic study of VC experiences by the first author, a person who stutters (PWS). Our research shed light on the hidden costs of VC for PWS, uncovering the substantial emotional and cognitive efforts that other meeting attendants are often unaware of. Recognizing the disproportionate burden on PWS to be heard in VC, we propose a set of design implications for a more inclusive communication environment, advocating for shared responsibility among all, including communication technologies, to ensure the inclusion and respect of every voice.</p>
<h3>Breaking Badge: Augmenting Communication with Wearable AAC Smartbadges and Displays</h3>
<p>Authors: Humphrey Curtis, Duncan Lau, Timothy Neate</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147567">Link</a></p>
<p>Abstract: People living with complex communication needs employ multimodal pathways to communicate including: limited speech, paralinguistics, non-verbal communication and leveraging low-tech devices. However, most augmentative and alternative communication (AAC) interventions undermine end-users' agency by obstructing these intuitive communication pathways. In this paper, we collaborate with 19 people living with the language impairment aphasia exploring contextual communication challenges, before low-fidelity prototyping and wireframing wearable AAC displays. These activities culminated in two low-input wearable AAC prototypes that instead, scaffold users' pre-existing communication abilities. Firstly, the InkTalker is a low-power and affordable eInk AAC smartbadge designed to discreetly reveal invisible disabilities and usable as a communication prop. Secondly, WalkieTalkie is a scalable AAC app that converts smartphones into a feature-rich public display operable via multimodal input/outputs. We offer results from communication interactions with both devices, discussions and feedback responses. Participants used both AAC devices to interdependently socialise with others and augment pre-existing communication abilities.</p>
<h3>"It Is Easy Using My Apps:" Understanding Technology Use and Needs of Adults with Down Syndrome</h3>
<p>Authors: Audra Sterling, Hailey Johnson, Bilge Mutlu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147214">Link</a></p>
<p>Abstract: Assistive technologies for adults with Down syndrome (DS) need designs tailored to their specific technology requirements. While prior research has explored technology design for individuals with intellectual disabilities, little is understood about the needs and expectations of adults with DS. Assistive technologies should leverage the abilities and interests of the population, while incorporating age- and context-considerate content. In this work, we interviewed six adults with DS, seven parents of adults with DS, and three experts in speech-language pathology, special education, and occupational therapy to determine how technology could support adults with DS. In our thematic analysis, four main themes emerged, including (1) community vs. home social involvement; (2) misalignment of skill expectations between adults with DS and parents; (3) family limitations in technology support; and (4) considerations for technology development. Our findings extend prior literature by including the voices of adults with DS in how and when they use technology.</p>
<h3>Voice Assistive Technology for Activities of Daily Living: Developing an Alexa Telehealth Training for Adults with Cognitive-Communication Disorders</h3>
<p>Authors: Yao Du, Ginna Byun, Lauren Kim, Priyal Vora, Siona Amrgousian, Claire O'Connor</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147679">Link</a></p>
<p>Abstract: Individuals with cognitive-communication disorders (CCDs) due to neurological conditions, such as traumatic brain injury and aphasia, experience difficulties in communication and cognition that impact their ability to perform activities of daily living, or ADLs (e.g., self-care, meal preparation, scheduling). Voice assistive technology (VAT) can support the independent performance of ADLs; however, there are limited VAT training programs that teach individuals with CCDs how to properly implement and use VAT for ADLs. The present study examined the implementation of an online training program using Alexa voice commands for five ADL domains (scheduling, entertainment, self-care, news &amp; facts, and meal preparation). Using video analysis with seven adults with CCDs between ages 25 and 82 and interviews with five participants and three caregivers, we synthesized five weeks of training performance, analyzed participants' perceived benefits and challenges, and discussed challenges and opportunities for implementing VAT training for ADLs skills for adults with CCDs. </p>
<h2>Supporting Programmers and Learners A</h2>
<h3>Understanding the Needs of Novice Developers in Creating Self-Powered IoT</h3>
<p>Authors: Tian Min, Chengshuo Xia, Daxing Zhang, Congsi Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147080">Link</a></p>
<p>Abstract: The rise of the Internet of Things (IoT) has given birth to transformative and massively deployed computing applications that raise the significant issue of energy sources. It is impractical and irresponsible to rely on wires and batteries to power trillion-level devices. One promising prediction is that energy harvesting technologies will serve as alternative power sources for IoT devices. However, we might be losing this prophecy for lack of understanding of how novice developers comprehend energy in developing IoT. In response, we conducted a mentored physical prototyping study with a two-day workshop involving eight novice developers. The study consisted of qualitative and quantitative analyses, the artifacts, interviews with both novice developers and an expert, and implications of designs for future tools. The findings reveal informational gaps that demand educational efforts and assistive features to facilitate novice developers. We present major findings from the study and implications for the design of future tools.</p>
<h3>AQuA: Automated Question-Answering in Software Tutorial Videos with Visual Anchors</h3>
<p>Authors: Saelyne Yang, George Fitzmaurice, Justin Matejka, Jo Vermeulen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148273">Link</a></p>
<p>Abstract: Tutorial videos are a popular help source for learning feature-rich software. However, getting quick answers to questions about tutorial videos is difficult. We present an automated approach for responding to tutorial questions. By analyzing 633 questions found in 5,944 video comments, we identified different question types and observed that users frequently described parts of the video in questions. We then asked participants (N=24) to watch tutorial videos and ask questions while annotating the video with relevant visual anchors. Most visual anchors referred to UI elements and the application workspace. Based on these insights, we built AQuA, a pipeline that generates useful answers to questions with visual anchors. We demonstrate this for Fusion 360, showing that we can recognize UI elements in visual anchors and generate answers using GPT-4 augmented with that visual information and software documentation. An evaluation study (N=16) demonstrates that our approach provides better answers than baseline methods.</p>
<h3>Meta-Manager: A Tool for Collecting and Exploring Meta Information about Code</h3>
<p>Authors: Brad Myers, Amber Horvath, Andrew Macvean</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147791">Link</a></p>
<p>Abstract: Modern software engineering is in a state of flux. With more development utilizing AI code generation tools and the continued reliance on online programming resources, understanding code and the original intent behind it is becoming more important than it ever has been. To this end, we have developed the "Meta-Manager'", a Visual Studio Code extension, with a supplementary browser extension, that automatically collects and organizes changes made to code while keeping track of the provenance of each part of the code, including code that has been AI-generated or copy-pasted from popular programming resources online. These sources and subsequent changes are represented in the editor and may be explored using searching and filtering mechanisms to help developers answer historically hard-to-answer questions about code, its provenance, and its design rationale. In our evaluation of Meta-Manager, we found developers were successfully able to use it to answer otherwise unanswerable questions about an unfamiliar code base.</p>
<h3>SQL Puzzles: Evaluating Micro Parsons Problems With Different Feedbacks as Practice for Novices</h3>
<p>Authors: Zihan Wu, Barbara Ericson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148131">Link</a></p>
<p>Abstract: This paper investigates using micro Parsons problems as a novel practice approach for learning  Structured Query Language (SQL).  In micro Parsons problems learners arrange predefined code fragments to form a SQL statement instead of typing the code. SQL is a standard language for working with relational databases.</p>
<p>Targeting beginner-level SQL statements, we evaluated the efficacy of micro Parsons problems with block-based feedback and execution-based feedback compared to traditional text-entry problems. To delve into learners' experiences and preferences for the three problem types, we conducted a within-subjects think-aloud study with 12 participants. We found that learners reported very different preferences. Factors they considered included perceived learning, task authenticity, and prior knowledge. Next, we conducted two between-subjects classroom studies to evaluate the effectiveness of micro Parsons problems with different feedback types versus text-entry problems for SQL practice. We found that learners who practiced by solving Parsons problems with block-based feedback had a significantly higher learning gain than those who practiced with traditional text-entry problems.</p>
<h3>Taking ASCII Drawings Seriously: How Programmers Diagram Code</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Brian Hempel, Philip Guo, William Duan, Devamardeep Hayatpur, Haijun Xia, Kathy Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147729">Link</a></p>
<p>Abstract: Documentation in codebases facilitates knowledge transfer. But tools for programming are largely text-based, and so developers resort to creating ASCII diagrams---graphical artifacts approximated with text---to show visual ideas within their code. Despite real-world use, little is known about these diagrams. We interviewed nine authors of ASCII diagrams, learning why they use ASCII and what roles the diagrams play. We also compile and analyze a corpus of 507 ASCII diagrams from four open source projects, deriving a design space with seven dimensions that classify what these diagrams show, how they show it, and ways they connect to code. These investigations reveal that ASCII diagrams are professional artifacts used across many steps in the development lifecycle, diverse in role and content, and used because they visualize ideas within the variety of programming tools in use. Our findings highlight the importance of visualization within code and lay a foundation for future programming tools that tightly couple text and graphics.</p>
<h2>Supporting Programmers and Learners B</h2>
<h3>"Do You Want Me to Participate or Not?": Investigating the Accessibility of Software Development Meetings for Blind and Low Vision Professionals</h3>
<p>Authors: André van der Hoek, Emory Edwards, Stacy Branham, Jessy Ayala, Yoonha Cha, Isabela Figueira, Joshua Garcia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147835">Link</a></p>
<p>Abstract: Scholars have investigated numerous barriers to accessible software development tools and processes for Blind and Low Vision (BLV) developers. However, the research community has yet to study the accessibility of software development meetings, which are known to play a crucial role in software development practice. We conducted semi-structured interviews with 26 BLV software professionals about software development meeting accessibility. We found four key themes related to in-person and remote software development meetings: (1) participants observed that certain meeting activities and software tools used in meetings were inaccessible, (2) participants performed additional labor in order to make meetings accessible, (3) participants avoided disclosing their disability during meetings due to fear of career repercussions, (4) participants suggested technical, social and organizational solutions for accessible meetings, including developing their own solutions. We suggest recommendations and design implications for future accessible software development meetings including technical and policy-driven solutions.</p>
<h3>MµSE: Supporting Exploration of Software-Hardware Interactions Through Examples</h3>
<p>Authors: Stefan Ramson, Robert Hirschfeld, Tom Beckmann, Paul Methfessel, Patrick Rein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148162">Link</a></p>
<p>Abstract: Programmers regularly explore the execution of code examples to verify assumptions by adding print statements or commenting in and out setup code in their implementation to isolate code paths of interest.</p>
<p>In our formative study on developing embedded programs, where proximity to hardware dictates low abstraction levels, we observed that wrong assumptions occur frequently.</p>
<p>However, traditional editors for embedded programs lack support for such explorations.</p>
<p>Consequently, programmers have to re-create and clean up setup and print statements in their code for each example. </p>
<p>MµSE supports isolated explorations of code examples by promoting examples to first-class entities that allow for the mocking of side effects from code and hardware, which could interfere with examples, and automatically showing values of expressions, replacing print statements for debugging.</p>
<p>Our exploratory study found that MµSE supports participants in developing an understanding of software and hardware components and identifying false assumptions from observation of incorrect behavior.</p>
<h3>Is Stack Overflow Obsolete? An Empirical Study of the Characteristics of ChatGPT Answers to Stack Overflow Questions</h3>
<p>Authors: Samia Kabir, Bonan Kou, David N. Udo-Imeh, Tianyi Zhang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146667">Link</a></p>
<p>Abstract: Q&amp;A platforms have been crucial for the online help-seeking behavior of programmers. However, the recent popularity of ChatGPT is altering this trend. Despite this popularity, no comprehensive study has been conducted to evaluate the characteristics of ChatGPT’s answers to programming questions. To bridge the gap, we conducted the first in-depth analysis of ChatGPT answers to 517 programming questions on Stack Overflow and examined the correctness, consistency, comprehensiveness, and conciseness of ChatGPT answers. Furthermore, we conducted a large-scale linguistic analysis, as well as a user study, to understand the characteristics of ChatGPT answers from linguistic and human aspects. Our analysis shows that 52% of ChatGPT answers contain incorrect information and 77% are verbose. Nonetheless, our user study participants still preferred ChatGPT answers 35% of the time due to their comprehensiveness and well-articulated language style. However, they also overlooked the misinformation in the ChatGPT answers 39% of the time. This implies the need to counter misinformation in ChatGPT answers to programming questions and raise awareness of the risks associated with seemingly correct answers.</p>
<h3>CoPrompt: Supporting Prompt Sharing and Referring in Collaborative Natural Language Programming</h3>
<p>Authors: Mingming Fan, Zhicong Lu, Jian Zhao, Ryan Yen, Yuzhe You, Li Feng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147317">Link</a></p>
<p>Abstract: Natural language (NL) programming has become more approachable due to the powerful code-generation capability of large language models (LLMs). This shift to using NL to program enhances collaborative programming by reducing communication barriers and context-switching among programmers from varying backgrounds. However, programmers may face challenges during prompt engineering in a collaborative setting as they need to actively keep aware of their collaborators' progress and intents. In this paper, we aim to investigate ways to assist programmers’ prompt engineering in a collaborative context. We first conducted a formative study to understand the workflows and challenges of programmers when using NL for collaborative programming. Based on our findings, we implemented a prototype, CoPrompt, to support collaborative prompt engineering by providing referring, requesting, sharing, and linking mechanisms. Our user study indicates that CoPrompt assists programmers in comprehending collaborators' prompts and building on their collaborators’ work, reducing repetitive updates and communication costs. </p>
<h3>Understanding Documentation Use Through Log Analysis: A Case Study of Four Cloud Services</h3>
<p>Authors: Brad Myers, Daye Nam, Andrew Macvean, Bogdan Vasilescu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147074">Link</a></p>
<p>Abstract: Almost no modern software system is written from scratch, and developers are required to effectively learn to use third-party libraries and software services. Thus, many practitioners and researchers have looked for ways to create effective documentation that supports developers' learning. However, few efforts have focused on how people actually use the documentation. In this paper, we report on an exploratory, multi-phase, mixed methods empirical study of documentation page-view logs from four cloud-based industrial services. By analyzing page-view logs for over 100,000 users, we find diverse patterns of documentation page visits. Moreover, we show statistically that which documentation pages people visit often correlates with user characteristics such as past experience with the specific product, on the one hand, and with future adoption of the API on the other hand. We discuss the implications of these results on documentation design and propose documentation page-view log analysis as a feasible technique for design audits of documentation, from ones written for software developers to ones designed to support end users (e.g., Adobe Photoshop).</p>
<h2>Trust in Social Media</h2>
<h3>Uncovering Human Traits in Determining Real and Spoofed Audio: Insights from Blind and Sighted Individuals</h3>
<p>Authors: Chaeeun Han, Prasenjit Mitra, Syed Masum Billah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146813">Link</a></p>
<p>Abstract: This paper explores how blind and sighted individuals perceive real and spoofed audio, highlighting differences and similarities between the groups. Through two studies, we find that both groups focus on specific human traits in audio--such as accents, vocal inflections, breathing patterns, and emotions--to assess audio authenticity. We further reveal that humans, irrespective of visual ability, can still outperform current state-of-the-art machine learning models in discerning audio authenticity; however, the task proves psychologically demanding. Moreover, detection accuracy scores between blind and sighted individuals are comparable, but each group exhibits unique strengths: the sighted group excels at detecting deepfake-generated audio, while the blind group excels at detecting text-to-speech (TTS) generated audio. These findings not only deepen our understanding of machine-manipulated and neural-renderer audio but also have implications for developing countermeasures, such as perceptible watermarks and human-AI collaboration strategies for spoofing detection.</p>
<h3>Understanding Underground Incentivized Review Services</h3>
<p>Authors: Rajvardhan Oak, Zubair Shafiq</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147503">Link</a></p>
<p>Abstract: While human factors in fraud have been studied by the HCI and security communities, most research has been directed to understanding either the victims' perspectives or prevention strategies, and not on fraudsters, their motivations and operation techniques. </p>
<p>Additionally, the focus has been on a narrow set of problems: phishing, spam and bullying. In this work, we seek to understand review fraud on e-commerce platforms through an HCI lens. Through surveys with real fraudsters (N=36 agents and N=38 reviewers), we uncover sophisticated recruitment, execution, and reporting mechanisms fraudsters use to scale their operation while resisting takedown attempts, including the use of AI tools like ChatGPT. We find that countermeasures that crack down on communication channels through which these services operate are effective in combating incentivized reviews. This research sheds light on the complex landscape of incentivized reviews, providing insights into the mechanics of underground services and their resilience to removal efforts.</p>
<h3>Trust, Privacy, and Safety Factors Associated with Decision Making in P2P Markets Based on Social Networks: A Case Study of Facebook Marketplace in USA and Canada</h3>
<p>Authors: Masoud Mehrabi Koushki, Yue Huang, Konstantin (Kosta) Beznosov, Guillaume Humbert, Borke Obada-Obieh, Azadeh Mokhberi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148310">Link</a></p>
<p>Abstract: As peer-to-peer (P2P) marketplaces have grown rapidly, concerns related to trust, privacy, and safety (TPS) have also increased. While previous studies have explored these aspects in various P2P marketplaces, there has been limited research on Facebook Marketplace (FM), which is distinguished by dramatic growth and intricate entanglement with the Facebook social networking site (SNS). To address this knowledge gap, we conducted interviews with 42 FM users in the US and Canada, investigating TPS factors associated with trading decisions. We identified four categories of factors: pre-existing concerns, signals, interactions, and perceived benefits. We uncover the challenges arising from the interplay of these factors, offer design recommendations for SNS–based marketplaces like FM, and suggest directions for future research. Our study advances the understanding of decision-making processes in SNS–based marketplaces, informs future design improvements for such platforms, and ultimately contributes to a better user experience related to trust, privacy, and safety.</p>
<h3>Profiling the Dynamics of Trust &amp; Distrust in Social Media: A Survey Study</h3>
<p>Authors: Jacqueline Griffin, Yimeng Wang, Joseph Gaggiano, Andrea Parker, Yixuan Zhang, Miso Kim, Nurul Suhaimi, Nutchanon Yongsatianchot, Anne Okrah</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148331">Link</a></p>
<p>Abstract: In the era of digital communication, misinformation on social media threatens the foundational trust in these platforms. While myriad measures have been implemented to counteract misinformation, the complex relationship between these interventions and the multifaceted dynamics of trust and distrust on social media remains underexplored. To bridge this gap, we surveyed 1,769 participants in the U.S. to gauge their trust and distrust in social media and examine their experiences with anti-misinformation features. Our research demonstrates how trust and distrust in social media are not simply two ends of a spectrum; but can also co-exist, enriching the theoretical understanding of these constructs. Furthermore, participants exhibited varying patterns of trust and distrust across demographic characteristics and platforms. Our results also show that current misinformation interventions helped heighten awareness of misinformation and bolstered trust in social media, but did not alleviate underlying distrust. We discuss theoretical and practical implications for future research. </p>
<h3>A Browser Extension for in-place Signaling and Assessment of Misinformation</h3>
<p>Authors: Farnaz Jahanbakhsh, David Karger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148142">Link</a></p>
<p>Abstract: The status-quo of misinformation moderation is a central authority, usually social platforms, deciding what content constitutes misinformation and how it should be handled. However, to preserve users’ autonomy, researchers have explored democratized misinformation moderation. One proposition is to enable users to assess content accuracy and specify whose assessments they trust. We explore how these affordances can be provided on the web, without cooperation from the platforms where users consume content.</p>
<p>We present a browser extension that empowers users to assess the accuracy of any content on the web and shows the user assessments from their trusted sources in-situ. Through a two-week user study, we report on how users perceive such a tool, the kind of content users want to assess, and the rationales they use in their assessments. We identify implications for designing tools that enable users to moderate content for themselves with the help of those they trust.</p>
<h2>Wellbeing in Aging</h2>
<h3>An Iterative Participatory Design Approach to Develop Collaborative Augmented Reality Activities for Older Adults in Long-Term Care Facilities</h3>
<p>Authors: Mahrukh Tauseef, Cathy Maxwell, JUDITH TATE, Nilanjan Sarkar, Lorraine Mion, Akshith Ullal, Alexandra Watkins, Lisa Juckett</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147541">Link</a></p>
<p>Abstract: Over four million older adults living in long-term care (LTC) communities experience loneliness, adversely impacting their health. Increased contact with friends and family is an evidence-based intervention to reduce loneliness, but in-person visits are not always possible. Augmented Reality (AR)-based telepresence activities can offer viable alternatives with increased immersion and presence compared to video calls. However, its feasibility as an interaction technology for older adults is not known. In this paper, we detail the design of two dyadic collaborative AR activities that accommodate diminished physical and cognitive abilities of older adults. The findings include a general design framework based on an iterative participatory design focusing on preferred activities, modes of interaction, and overall AR experience of eight older adults, two family members, and five LTC staff. Results demonstrate the potential of collaborative AR as an effective means of interaction for older adults with their family, if designed to cater to their needs.</p>
<h3>Understanding Socio-technical Opportunities for Enhancing Communication Between Older Adults and their Remote Family</h3>
<p>Authors: Xueliang Li, Baihui Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146735">Link</a></p>
<p>Abstract: With the digitalization and mobilization of the society, older people face the challenge of maintaining high-quality communication with their younger family members who move out and lead separate lives at a distance. In HCI, little work is done to understand the social dynamics between distributed families and their remote communication mediated by the technologies. To identify design opportunities to support their remote communication, we conducted interviews with nine family pairs composed of distributed intergenerational family members. In addition, we interviewed eight community volunteers to formulate a perspective of social service providers. Our paper contributes to the HCI community by providing an account of the social dynamics mediated by communication technologies between older adults and their remote families, and opportunities to promote their social connections from a multi-stakeholder perspective. This paper presents valuable insights for designers aiming to enhance wellbeing of older adults within the context of distributed families.</p>
<h3>Designing for Inclusive Experiences: Investigating Opportunities for Supporting Older Adults in Community-based Social Programs</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yushan Xing, Ryan Kelly, Kashifa Aslam, Melissa Rogerson, Jenny Waycott</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147962">Link</a></p>
<p>Abstract: Community-based social programs, such as interest groups and outings, provide valuable ways for older adults to maintain social connectedness. To understand how technology can be designed to support older adults in such programs, we conducted a four-month field study with a local community centre, involving: (1) observations of social program sessions, (2) interviews with staff, and (3) co-design workshops with staff and program participants. We found that staff used technologies in a situated way to make social programs more inclusive for older adults. Technology promoted incidental social interactions and group learning, but also excluded participants from some activities. Participants believed that future technologies to support community-based social programs should be designed to enable efficient communication, promote flexible interactions, and maintain the flow of social activities. We argue that technology interventions in this setting should not become the focus of an activity but instead support social interactions triggered by existing activities.</p>
<h3>Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults</h3>
<p>Authors: Wanling Cai, Yizhe Zhang, Tonglin Jiang, Li Chen, Gavin Doherty, Yucheng Jin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147408">Link</a></p>
<p>Abstract: Music-based reminiscence has the potential to positively impact the psychological well-being of older adults. However, the aging process and physiological changes, such as memory decline and limited verbal communication, may impede the ability of older adults to recall their memories and life experiences. Given the advanced capabilities of generative artificial intelligence (AI) systems, such as generated conversations and images, and their potential to facilitate the reminiscing process, this study aims to explore the design of generative AI to support music-based reminiscence in older adults. This study follows a user-centered design approach incorporating various stages, including detailed interviews with two social workers and two design workshops (involving ten older adults). Our work contributes to an in-depth understanding of older adults’ attitudes toward utilizing generative AI for supporting music-based reminiscence and identifies concrete design considerations for the future design of generative AI to enhance the reminiscence experience of older adults.</p>
<h3>Dancing with the Roles: Towards Designing Technology that Supports the Multifaceted Roles of Caregivers for Older Adults</h3>
<p>Authors: Chia-Fang Chung, Long-Jing Hsu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147745">Link</a></p>
<p>Abstract: Caregivers of older adults often undertake their caregiving journey driven by filial obligation, facing inherent expectations and multifaceted roles. While Human-Computer Interaction (HCI) research has explored these roles, some invisible work in managing them remains under-examined. To address this gap, we interviewed 19 informal caregivers of older adults to uncover their invisible work and the potential role of technology in supporting these complex responsibilities. Our findings detail the caregivers' lived experiences, highlighting the challenges and strategies they employ in managing multiple roles. We discuss design opportunities that include facilitating the identification and reflection on existing roles, leveraging this understanding for coordination, aiding in role-based scheduling with acknowledgment, and providing support for the dynamic roles transitioning between various responsibilities. These insights could inform future caregiving technology design, enhancing support for caregivers in their multifaceted roles.</p>
<h2>Working Practices and Tools B</h2>
<h3>The Impact of Social Norms on Hybrid Workers’ Well-Being: A Cross-Cultural Comparison of Japan and the United States</h3>
<p>Authors: Momoko Nakatani, Ryo Hashimoto, Jack Jamieson, Wataru Akahori, Masahiro Watanabe, Naomi Yamashita</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146875">Link</a></p>
<p>Abstract: Previous research has shown that workplace social norms influence employee well-being. However, such norms vary based on the cultures in which workplaces are embedded, suggesting that cultural differences may influence perceived norms about when and where work should occur. These differences, in turn, could impact employee well-being. Accordingly, through the lenses of cultural tightness-looseness and individualism-collectivism, this paper investigates cultural differences in perceived social norms, and the relationship between those norms and hybrid workers' well-being. We conducted a survey of 1,000 Japanese and 1,000 American hybrid workers. Results indicated that American respondents perceived stronger norms and demonstrated a higher willingness to conform to norms compared to Japanese respondents. Additionally, strong injunctive norms were positively associated with well-being among Americans but not among Japanese. Interviews (N = 24) showed that Japanese perceived injunctive norms negatively, while Americans saw them positively. We discuss implications for future remote-collaboration technologies in hybrid-work settings.</p>
<h3>Mental Models of Meeting Goals: Supporting Intentionality in Meeting Technologies</h3>
<p>Authors: Lev Tankelevitch, Ava Scott, Sean Rintel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146999">Link</a></p>
<p>Abstract: Ineffective meetings due to unclear goals are major obstacles to productivity, yet support for intentionality is surprisingly scant in our meeting and allied workflow technologies. To design for intentionality, we need to understand workers’ attitudes and practices around goals. We interviewed 21 employees of a global technology company and identified contrasting mental models of meeting goals: meetings as a means to an end, and meetings as an end in themselves. We explore how these mental models impact how meeting goals arise, goal prioritization, obstacles to considering goals, and how lack of alignment around goals may create tension between organizers and attendees. We highlight the challenges in balancing preparation, constraining scope, and clear outcomes, with the need for intentional adaptability and discovery in meetings. Our findings have implications for designing systems which increase effectiveness in meetings by catalyzing intentionality and reducing tension in the organisation of meetings. </p>
<h3>Circle Back Next Week: The Effect of Meeting-Free Weeks on Distributed Workers’ Unstructured Time and Attention Negotiation</h3>
<p>Authors: Sharon Ferguson, Michael Massimi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147336">Link</a></p>
<p>Abstract: While distributed workers rely on scheduled meetings for coordination and collaboration, these meetings can also challenge their ability to focus. Protecting worker focus has been addressed from a technical perspective, but companies are now attempting organizational interventions, such as meeting-free weeks. Recognizing distributed collaboration as a sociotechnical challenge, we first present an interview study with distributed workers participating in meeting-free weeks at an enterprise software company. We identify three orientations workers exhibit during these weeks: Focus, Collaborative, and Time-Bound, each with varying levels and use of unstructured time. These different orientations result in challenges in attention negotiation, which may be suited for technical interventions. This motivated a follow-up study investigating attention negotiation and the compensating mechanisms workers developed during meeting-free weeks. Our framework identified tensions between the attention-getting and attention-delegation strategies. We extend past work to show how workers adapt their virtual collaboration mechanisms in response to organizational interventions.</p>
<h3>Exploring the Diminishing Allure of Paper and Low-Fidelity Prototyping Among Designers in the Software Industry: Impacts of Hybrid Work, Digital Tools, and Corporate Culture</h3>
<p>Authors: Dongwook Yoon, Jonathan Chen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146922">Link</a></p>
<p>Abstract: In a rapidly evolving UX/UI design landscape marked by technological advancements and shifts toward hybrid work, understanding the implications of these changes on software prototyping practices is crucial. This study investigates the influence of evolving work practices, tool advancements, and designers' attitudes on prototyping practices and design processes in the contemporary software industry. Based on in-depth interviews with 10 practitioners and educators, we explore the factors contributing to the preference for digital-first prototypes and the diminishing appeal of low-fidelity prototyping methods. Our findings reveal how digital prototypes outshine physical counterparts in hybrid work, the role of all-in-one digital tools in centralizing designers' workflows and encouraging high-fidelity prototyping, corporate preferences for visually appealing prototypes, and the impact of designers' educational backgrounds, generational differences, and professional maturity. This research offers valuable insights to inform decision-making and strategies for design practitioners, educators, and organizations in adapting to current and future prototyping practices.</p>
<h3>Reinforcing and Reclaiming The Home: Co-speculating Future Technologies to Support Remote and Hybrid Work</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Dasom Choi, Junnan Yu, Stephen Voida, Janghee Cho</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146980">Link</a></p>
<p>Abstract: With the rise of remote and hybrid work after COVID-19, there is growing interest in understanding remote workers' experiences and designing digital technology for the future of work within the field of HCI. To gain a holistic understanding of how remote workers navigate the blurred boundary between work and home and how designers can better support their boundary work, we employ humanistic geography as a lens. We engaged in co-speculative design practices with 11 remote workers in the US, exploring how future technologies might sustainably enhance participants’ work and home lives in remote/hybrid arrangements. We present the imagined technologies that resulted from this process, which both reinforce remote workers’ existing boundary work practices through everyday routines/rituals and reclaim the notion of home by fostering independence, joy, and healthy relationships. Our discussions with participants inform implications for designing digital technologies that promote sustainability in the future remote/hybrid work landscape. </p>
<h2>Working Practices and Tools C</h2>
<h3>Practice-informed Patterns for Organising Large Groups in Distributed Mixed Reality Collaboration</h3>
<p>Authors: Jens Emil Grønbæk, Germán Leiva, Eduardo Velloso, Emily Wong, Juan Sánchez Esquivel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147880">Link</a></p>
<p>Abstract: Collaborating across dissimilar, distributed spaces presents numerous challenges for computer-aided spatial communication. Mixed reality (MR) can blend selected surfaces, allowing collaborators to work in blended f-formations (facing formations), even when their workstations are physically misaligned. Since collaboration often involves more than just participant pairs, this research examines how we might scale MR experiences for large-group collaboration. To do so, this study recruited collaboration designers (CDs) to evaluate and reimagine MR for large-scale collaboration. These CDs were engaged in a four-part user study that involved a technology probe, a semi-structured interview, a speculative low-fidelity prototyping activity and a validation session. The outcomes of this paper contribute (1) a set of collaboration design principles to inspire future computer-supported collaborative work, (2) eight collaboration patterns for blended f-formations and collaboration at scale and (3) theoretical implications for f-formations and space-place relationships. As a result, this work creates a blueprint for scaling collaboration across distributed spaces.</p>
<h3>Whispering Through Walls: Towards Inclusive Backchannel Communication in Hybrid Meetings</h3>
<p>Authors: Jens Emil Grønbæk, Qianqian Mu, Eve Hoggan, Marcel Borowski, Susanne Bødker</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148087">Link</a></p>
<p>Abstract: Backchannel communication, like whispering or instant messaging, is common in meetings and holds significant value. However, it remains largely unexplored in the context of hybrid meetings with co-located and remote participants. To address this gap, we derived unique challenges of backchannel communication in hybrid meetings through an interview study. These challenges inspired a new voice-based backchannel communication system, WhisperChannel, aimed to be inclusive and low effort. WhisperChannel enables users to whisper remotely to anyone in the meeting — similar to whispering to co-located seat neighbors. In a user study with three groups, each having two sessions of hybrid meetings, we investigated the inclusiveness and effort of WhisperChannel for both co-located and remote participants. We provide insights into the benefits and limitations of using remote whispering. We show that WhisperChannel helped remote and co-located participants feel more included while requiring low effort to use, however, also introduced new challenges in backchannel communication.</p>
<h3>DISCERN: Designing Decision Support Interfaces to Investigate the Complexities of Workplace Social Decision-Making With Line Managers</h3>
<p>Authors: Kate Nowak, Lindy Le, Shamsi Iqbal, Pranav Khadpe, Jina Suh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147698">Link</a></p>
<p>Abstract: Line managers form the first level of management in organizations, and must make complex decisions, while maintaining relationships with those impacted by their decisions. Amidst growing interest in technology-supported decision-making at work, their needs remain understudied. Further, most existing design knowledge for supporting social decision-making comes from domains where decision-makers are more socially detached from those they decide for. We conducted iterative design research with line managers within a technology organization, investigating decision-making practices, and opportunities for technological support. Through formative research, development of a decision-representation tool—DISCERN—and user enactments, we identify their communication and analysis needs that lack adequate support. We found they preferred tools for externalizing reasoning rather than tools that replace interpersonal interactions, and they wanted tools to support a range of intuitive and calculative decision-making. We discuss how design of social decision-making supports, especially in the workplace, can more explicitly support highly interactional social decision-making.</p>
<h3>The Effects of Update Interval and Reveal Method on Writer Comfort in Synchronized Shared-Editors</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Yen-Ting Yeh, Nikhita Joshi, Daniel Vogel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148285">Link</a></p>
<p>Abstract: Synchronized shared-editors like Google Docs allow people to write together, but there is no “privacy of writing” which can make writers feel uncomfortable. We propose methods to give writers more control over when and how their edits are shown to collaborators to increase comfort. These are in the form of different update strategies composed of an update interval and a reveal method. Results from an experiment with simulated observers show that alternative update strategies can be beneficial, each having their own pros and cons. A follow-up experiment with writer and observer pairs validates these findings and shows that observers are amenable to experiencing short delays caused by alternative update strategies. Our work shows that synchronous writing tools should support alternative update strategies that preserve both collaborator awareness and writer comfort.</p>
<h3>Exploring the Effectiveness of Time-lapse Screen Recording for Self-Reflection in Work Context</h3>
<p>Authors: Donghan Hu, Sang Won Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148168">Link</a></p>
<p>Abstract: Effective self-tracking in working contexts empowers individuals to explore and reflect on past activities. Recordings of computer activities contain rich metadata that can offer valuable insight into users' previous tasks and endeavors. However, presenting a simple summary of time usage may not effectively engage users with data because it is not contextualized, and users may not understand what to do with the data. This work explores time-lapse videos as a visual-temporal medium to facilitate self-reflection among workers in productivity contexts. To explore this space, we conducted a four-week study (n=15) to investigate how a computer screen's history of states can help workers recall previous undertakings and gain comprehensive insights via self-reflection. Our results support that watching time-lapse videos can enhance self-reflection more effectively than traditional self-tracking tools by providing contextual clues about users' past activities. The experience with both traditional tools and time-lapse videos resulted in increased productivity. Additionally, time-lapse videos assist users in cultivating a positive understanding of their work. We discuss how multimodal cues, such as time-lapse videos, can complement personal informatics tools.</p>
<h2>Working with Data A</h2>
<h3>Generative Echo Chamber? Effect of LLM-Powered Search Systems on Diverse Information Seeking</h3>
<p>BEST_PAPER</p>
<p>Authors: Ziang Xiao, Nikhil Sharma, Q. Vera Liao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147446">Link</a></p>
<p>Abstract: Large language models (LLMs) powered conversational search systems have already been used by hundreds of millions of people, and are believed to bring many benefits over conventional search. However, while decades of research and public discourse interrogated the risk of search systems in increasing selective exposure and creating echo chambers---limiting exposure to diverse opinions and leading to opinion polarization, little is known about such a risk of LLM-powered conversational search. We conduct two experiments to investigate: 1) whether and how LLM-powered conversational search increases selective exposure compared to conventional search; 2) whether and how LLMs with opinion biases that either reinforce or challenge the user's view change the effect. Overall, we found that participants engaged in more biased information querying with LLM-powered conversational search, and an opinionated LLM reinforcing their views exacerbated this bias. These results present critical implications for the development of LLMs and conversational search systems, and the policy governing these technologies.</p>
<h3>SwapVid: Integrating Video Viewing and Document Exploration with Direct Manipulation</h3>
<p>Authors: Kazuki Takashima, Kotaro Hara, Kazuyuki Fujita, Taichi Murakami, Yoshifumi Kitamura</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147489">Link</a></p>
<p>Abstract: Videos accompanied by documents---\textit{document-based videos}---enable presenters to share contents beyond videos and audience to use them for detailed content comprehension. </p>
<p>However, concurrently exploring multiple channels of information could be taxing.</p>
<p>We propose SwapVid, a novel interface for viewing and exploring document-based videos. </p>
<p>SwapVid seamlessly integrates a video and a document into a single view and lets the content behaves as both video and a document; it adaptively switches a document-based video to act as a video or a document upon direct manipulation (\textit{e.g.,} scrolling the document, manipulating the video timeline). </p>
<p>We conducted a user study with twenty participants, comparing SwapVid to a side-by-side video/document views. </p>
<p>Results showed that our interface reduces time and physical workload when exploring slide-based documents based on video referencing. </p>
<p>Based on the study findings, we extended SwapVid with additional functionalities and demonstrated that it further extends the practical capabilities.</p>
<h3>rTisane: Externalizing conceptual models for data analysis increases engagement with domain knowledge and improves statistical model quality</h3>
<p>BEST_PAPER</p>
<p>Authors: Jeffrey Heer, Eunice Jun, Edward Misback, Rene Just</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147809">Link</a></p>
<p>Abstract: Statistical models should accurately reflect analysts’ domain knowledge about variables and their relationships. While recent tools let analysts express these assumptions and use them to produce a resulting statistical model, it remains unclear what analysts want to express and how externalization impacts statistical model quality. This paper addresses these gaps. We first conduct an exploratory study of analysts using a domain-specific language (DSL) to express conceptual models. We observe a preference for detailing how variables relate and a desire to allow, and then later resolve, ambiguity in their conceptual models. We leverage these findings to develop rTisane, a DSL for expressing conceptual models augmented with an interactive disambiguation process. In a controlled evaluation, we find that analysts reconsidered their assumptions, self-reported externalizing their assumptions accurately, and maintained analysis intent with rTisane. Additionally, rTisane enabled some analysts to author statistical models they were unable to specify manually. For others, rTisane resulted in models that better fit the data or enabled iterative improvement.</p>
<h3>Odds and Insights: Decision Quality in Exploratory Data Analysis Under Uncertainty</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Matthew Kay, Michael Correll, Abhraneel Sarma, Yuan Cui, Xiaoying Pu, Eli Brown</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146941">Link</a></p>
<p>Abstract: Recent studies have shown that users of visual analytics tools can have difficulty distinguishing robust findings in the data from statistical noise, but the true extent of this problem is likely dependent on both the incentive structure motivating their decisions, and the ways that uncertainty and variability are (or are not) represented in visualisations. In this work, we perform a crowd-sourced study measuring decision-making quality in visual analytics, testing both an explicit structure of incentives designed to reward cautious decision-making as well as a variety of designs for communicating uncertainty. We find that, while participants are unable to perfectly control for false discoveries as well as idealised statistical models such as the Benjamini-Hochberg, certain forms of uncertainty visualisations can improve the quality of participants’ decisions and lead to fewer false discoveries than not correcting for multiple comparisons. We conclude with a call for researchers to further explore visual analytics decision quality under different decision-making contexts, and for designers to directly present uncertainty and reliability information to users of visual analytics tools. The supplementary materials are available at: https://osf.io/xtsfz/.</p>
<h3>Using Open Data to Automatically Generate Localized Analogies</h3>
<p>Authors: Daniel Goldstein, Sofia Eleni Spatharioti, Jake Hofman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147137">Link</a></p>
<p>Abstract: Numerical analogies (or "perspectives") that translate unfamiliar measurements into comparisons with familiar reference objects (e.g., "275,000 square miles is roughly as large as Texas") have been shown to aid readers' recall, estimation, and error detection for numbers. However, because familiar reference objects are culture-specific, analogies do not always generalize across audiences. Crowdsourcing perspectives has proven effective but is limited by scalability issues and a lack of crowdworking markets in many regions. In this research, we develop an automated technique for generating localized perspectives. We utilize several open data sources for relevance signals and develop a surprisingly simple model capable of localizing analogies to new audiences without any retraining from human judges. We validate the model by testing it in both a new domain and with a different linguistic audience residing in another country. We release the compiled dataset of 400,000 reference objects to the research community.</p>
<h2>Immersive Experiences: Design and Evaluation</h2>
<h3>Milliways: Taming Multiverses through Principled Evaluation of Data Analysis Paths</h3>
<p>Authors: Matthew Kay, Abhraneel Sarma, Kyle Hwang, Jessica Hullman</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146939">Link</a></p>
<p>Abstract: Multiverse analyses involve conducting all combinations of reasonable choices in a data analysis process. A reader of a study containing a multiverse analysis might question—are all the choices included in the multiverse reasonable and equally justifiable? How much do results vary if we make different choices in the analysis process? In this work, we identify principles for validating the composition of, and interpreting the uncertainty in, the results of a multiverse analysis. We present Milliways, a novel interactive visualisation system to support principled evaluation of multiverse analyses. Milliways provides interlinked panels presenting result distributions, individual analysis composition, multiverse code specification, and data summaries. Milliways supports interactions to sort, filter and aggregate results based on the analysis specification to identify decisions in the analysis process to which the results are sensitive. To represent the two qualitatively different types of uncertainty that arise in multiverse analyses—probabilistic uncertainty from estimating unknown quantities of interest such as regression coefficients, and possibilistic uncertainty from choices in the data analysis—Milliways uses consonance curves and probability boxes. Through an evaluative study with five users familiar with multiverse analysis, we demonstrate how Milliways can support multiverse analysis tasks, including a principled assessment of the results of a multiverse analysis.</p>
<h3>Development and Validation of the Collision Anxiety Questionnaire for VR Applications</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Julius Tietenberg, Patrizia Ring, Katharina Emmerich, Maic Masuch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147339">Link</a></p>
<p>Abstract: The high degree of sensory immersion is a distinctive feature of head-mounted virtual reality (VR) systems. While the visual detachment from the real world enables unique immersive experiences, users risk collisions due to their inability to perceive physical obstacles in their environment. Even the mere anticipation of a collision can adversely affect the overall experience and erode user confidence in the VR system. However, there are currently no valid tools for assessing collision anxiety. We present the iterative development and validation of the Collision Anxiety Questionnaire (CAQ), involving an exploratory and a confirmatory factor analysis with a total of 159 participants. The results provide evidence for both discriminant and convergent validity and a good model fit for the final CAQ with three subscales: general collision anxiety, orientation, and interpersonal collision anxiety. By utilizing the CAQ, researchers can examine potential confounding effects of collision anxiety and evaluate methods for its mitigation.</p>
<h3>Assessing User Apprehensions About Mixed Reality Artifacts and Applications: The Mixed Reality Concerns (MRC) Questionnaire</h3>
<p>Authors: Aodi Chen, Luu Viet Trinh Le, John Uschold, Christopher Katins, Paweł W. Woźniak, Ihsan Tumay, Thomas Kosch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146992">Link</a></p>
<p>Abstract: Current research in Mixed Reality (MR) presents a wide range of novel use cases for blending virtual elements with the real world. This yet-to-be-ubiquitous technology challenges how users currently work and interact with digital content. While offering many potential advantages, MR technologies introduce new security, safety, and privacy challenges. Thus, it is relevant to understand users' apprehensions towards MR technologies, ranging from security concerns to social acceptance. To address this challenge, we present the Mixed Reality Concerns (MRC) Questionnaire, designed to assess users' concerns towards MR artifacts and applications systematically. The development followed a structured process considering previous work, expert interviews, iterative refinements, and confirmatory tests to analytically validate the questionnaire. The MRC Questionnaire offers a new method of assessing users' critical opinions to compare and assess novel MR artifacts and applications regarding security, privacy, social implications, and trust.</p>
<h3>Virtual Unreality: Augmentation-Oriented Ideation Through Design Cards</h3>
<p>Authors: Marc Hassenzahl, Daniel Courtney, Robin Neuhaus, Madlen Kneile, Ronda Ringfort-Felner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148278">Link</a></p>
<p>Abstract: While realism is a common design goal for virtual reality (VR), VR also offers opportunities that are impossible in the real world (e.g., telekinesis). So far, there is no design support to exploit the potential of such “impossible” augmentations, especially for serious applications. We developed a card set and a workshop format, which features 15 opportunities to facilitate the ideation of augmentation-oriented VR. We piloted the method in five workshops with people in the early stages of developing a VR application (N=35). Participants found the cards easy to use and to inspire viable new concepts that differed from earlier ideas. Analysis of the concepts with interaction criticism identified two strategies: (1) augmentations that are only loosely related to the purpose of the application, simply to increase “fun”, and (2) augmentations that are closely related to the core purpose and thereby subtly facilitate its fulfillment. The latter has the greater potential.</p>
<h3>Evaluating Navigation and Comparison Performance of Computational Notebooks on Desktop and in Virtual Reality</h3>
<p>Authors: Yalong Yang, Chris North, Sungwon In, Eric Krokos, Kirsten Whitley</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146704">Link</a></p>
<p>Abstract: The computational notebook serves as a versatile tool for data analysis. However, its conventional user interface falls short of keeping pace with the ever-growing data-related tasks, signaling the need for novel approaches. With the rapid development of interaction techniques and computing environments, there is a growing interest in integrating emerging technologies in data-driven workflows. Virtual reality, in particular, has demonstrated its potential in interactive data visualizations. In this work, we aimed to experiment with adapting computational notebooks into VR and verify the potential benefits VR can bring. We focus on the navigation and comparison aspects as they are primitive components in analysts' workflow. To further improve comparison, we have designed and implemented a Branching&amp;Merging functionality. We tested computational notebooks on the desktop and in VR, both with and without the added Branching&amp;Merging capability. We found VR significantly facilitated navigation compared to desktop, and the ability to create branches enhanced comparison.</p>
<h2>Understanding Immersive Experiences</h2>
<h3>Fast-Forward Reality: Authoring Error-Free Context-Aware Policies with Real-Time Unit Tests in Extended Reality</h3>
<p>Authors: Kashyap Todi, Tanya Jonker, Tianyi Wang, Xun Qian, Xuhai "Orson" Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147548">Link</a></p>
<p>Abstract: Advances in ubiquitous computing have enabled end-user authoring of context-aware policies (CAPs) that control smart devices based on specific contexts of the user and environment. However, authoring CAPs accurately and avoiding run-time errors is challenging for end-users as it is difficult to foresee CAP behaviors under complex real-world conditions. We propose Fast-Forward Reality, an Extended Reality (XR) based authoring workflow that enables end-users to iteratively author and refine CAPs by validating their behaviors via simulated unit test cases. We develop a computational approach to automatically generate test cases based on the authored CAP and the user's context history. Our system delivers each test case with immersive visualizations in XR, facilitating users to verify the CAP behavior and identify necessary refinements. We evaluated Fast-Forward Reality in a user study (N=12). Our authoring and validation process improved the accuracy of CAPs and the users provided positive feedback on the system usability.</p>
<h3>Towards Building Condition-Based Cross-Modality Intention-Aware Human-AI Cooperation under VR Environment</h3>
<p>Authors: Ziyao He, Yunpeng Song, Shiyuan Li, Zhongmin Cai</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147782">Link</a></p>
<p>Abstract: To address critical challenges in effectively identifying user intent and forming relevant information presentations and recommendations in VR environments, we propose an innovative condition-based multi-modal human-AI cooperation framework. It highlights the intent tuples (intent, condition, intent prompt, action prompt) and 2-Large-Language-Models (2-LLMs) architecture. This design, utilizes ``condition'' as the core to describe tasks, dynamically match user interactions with intentions, and empower generations of various tailored multi-modal AI responses. The architecture of 2-LLMs separates the roles of intent detection and action generation, decreasing the prompt length and helping with generating appropriate responses. We implemented a VR-based intelligent furniture purchasing system based on the proposed framework and conducted a three-phase comparative user study. The results conclusively demonstrate the system's superiority in time efficiency and accuracy, intention conveyance improvements, effective product acquisitions, and user satisfaction and cooperation preference. Our framework provides a promising approach towards personalized and efficient user experiences in VR.</p>
<h3>Predicting the Noticeability of Dynamic Virtual Elements in Virtual Reality</h3>
<p>Authors: Yukang Yan, Yi Fei Cheng, Zhipeng Li, David Lindlbauer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148043">Link</a></p>
<p>Abstract: While Virtual Reality (VR) systems can present virtual elements such as notifications anywhere, designing them so they are not missed by or distracting to users is highly challenging for content creators. To address this challenge, we introduce a novel approach to predict the noticeability of virtual elements. It computes the visual saliency distribution of what users see, and analyzes the temporal changes of the distribution with respect to the dynamic virtual elements that are animated. The computed features serve as input for a long short-term memory (LSTM) model that predicts whether a virtual element will be noticed. Our approach is based on data collected from 24 users in different VR environments performing tasks such as watching a video or typing. We evaluate our approach (n = 12), and show that it can predict the timing of when users notice a change to a virtual element within 2.56 sec compared to a ground truth, and demonstrate the versatility of our approach with a set of applications. We believe that our predictive approach opens the path for computational design tools that assist VR content creators in creating interfaces that automatically adapt virtual elements based on noticeability.</p>
<h3>Just Undo It: Exploring Undo Mechanics in Multi-User Virtual Reality</h3>
<p>Authors: Julian Rasch, Yannick Weiss, Florian Perzl, Florian Müller</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147280">Link</a></p>
<p>Abstract: With the proliferation of VR and a metaverse on the horizon, many multi-user activities are migrating to the VR world, calling for effective collaboration support. As one key feature, traditional collaborative systems provide users with undo mechanics to reverse errors and other unwanted changes. While undo has been extensively researched in this domain and is now considered industry standard, it is strikingly absent for VR systems in research and industry.</p>
<p>This work addresses this research gap by exploring different undo techniques for basic object manipulation in different collaboration modes in VR. We conducted a study involving 32 participants organized in teams of two. Here, we studied users' performance and preferences in a tower stacking task, varying the available undo techniques and their mode of collaboration. The results suggest that users desire and use undo in VR and that the choice of the undo technique impacts users' performance and social connection.</p>
<h2>Immersive Experiences: UIs and Personalisation</h2>
<h3>UI Mobility Control in XR: Switching UI Positionings between Static, Dynamic, and Self Entities</h3>
<p>Authors: Yang Zhang, Ruofei Du, Alex Olwal, Siyou Pei, David Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147970">Link</a></p>
<p>Abstract: Extended reality (XR) has the potential for seamless user interface (UI) transitions across people, objects, and environments. However, the design space, applications, and common practices of 3D UI transitions remain underexplored. To address this gap, we conducted a need-finding study with 11 participants, identifying and distilling a taxonomy based on three types of UI placements --- affixed to static, dynamic, or self entities. We further surveyed 113 commercial applications to understand the common practices of 3D UI mobility control, where only 6.2% of these applications allowed users to transition UI between entities. In response, we built interaction prototypes to facilitate UI transitions between entities. We report on results from a qualitative user study (N=14) on 3D UI mobility control using our FingerSwitches technique, which suggests that perceived usefulness is affected by types of entities and environments. We aspire to tackle a vital need in UI mobility within XR.</p>
<h3>ProInterAR: A Visual Programming Platform for Creating Immersive AR Interactions</h3>
<p>Authors: Karan Singh, Hongbo Fu, Hui Ye, Jiaye Leng, Pengfei Xu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148242">Link</a></p>
<p>Abstract: AR applications commonly contain diverse interactions among different AR contents. Creating such applications requires creators to have advanced programming skills for scripting interactive behaviors of AR contents, repeated transferring and adjustment of virtual contents from virtual to physical scenes, testing by traversing between desktop interfaces and target AR scenes, and digitalizing AR contents. Existing immersive tools for prototyping/authoring such interactions are tailored for domain-specific applications. To support programming general interactive behaviors of real object(s)/environment(s) and virtual object(s)/environment(s) for novice AR creators, we propose ProInterAR, an integrated visual programming platform to create immersive AR applications with a tablet and an AR-HMD. Users can construct interaction scenes by creating virtual contents and augmenting real contents from the view of an AR-HMD, script interactive behaviors by stacking blocks from a tablet UI, and then execute and control the interactions in the AR scene. We showcase a wide range of AR application scenarios enabled by ProInterAR, including AR game, AR teaching, sequential animation, AR information visualization, etc. Two usability studies validate that novice AR creators can easily program various desired AR applications using ProInterAR.</p>
<h3>MineXR: Mining Personalized Extended Reality Interfaces</h3>
<p>Authors: Kashyap Todi, Yukang Yan, Missie Smith, Hyunsung Cho, Mark Parent, Tanya Jonker, David Lindlbauer, Hrvoje Benko</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147924">Link</a></p>
<p>Abstract: Extended Reality (XR) interfaces offer engaging user experiences, but their effective design requires a nuanced understanding of user behavior and preferences. This knowledge is challenging to obtain without the widespread adoption of XR devices. We introduce MineXR, a design mining workflow and data analysis platform for collecting and analyzing personalized XR user interaction and experience data. MineXR enables elicitation of personalized interfaces from participants of a data collection: for any particular context, participants create interface elements using application screenshots from their own smartphone, place them in the environment, and simultaneously preview the resulting XR layout on a headset. Using MineXR, we contribute a dataset of personalized XR interfaces collected from 31 participants, consisting of 695 XR widgets created from 178 unique applications. We provide insights for XR widget functionalities, categories, clusters, UI element types, and placement. Our open-source tools and data support researchers and designers in developing future XR interfaces.</p>
<h3>VirtuWander: Enhancing Multi-modal Interaction for Virtual Tour Guidance through Large Language Models</h3>
<p>Authors: Linping Yuan, Wei Zeng, Liangwei Wang, Bingchuan Jiang, Zhan Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148243">Link</a></p>
<p>Abstract: Tour guidance in virtual museums encourages multi-modal interactions to boost user experiences, concerning engagement, immersion, and spatial awareness. Nevertheless, achieving the goal is challenging due to the complexity of comprehending diverse user needs and accommodating personalized user preferences. Informed by a formative study that characterizes guidance-seeking contexts, we establish a multi-modal interaction design framework for virtual tour guidance. We then design VirtuWander, a two-stage innovative system using domain-oriented large language models to transform user inquiries into diverse guidance-seeking contexts and facilitate multi-modal interactions. The feasibility and versatility of VirtuWander are demonstrated with virtual guiding examples that encompass various touring scenarios and cater to personalized preferences. We further evaluate VirtuWander through a user study within an immersive simulated museum. The results suggest that our system enhances engaging virtual tour experiences through personalized communication and knowledgeable assistance, indicating its potential for expanding into real-world scenarios.</p>
<h2>Immersive Experiences: Creating and Communicating</h2>
<h3>Elastica: Adaptive Live Augmented Presentations with Elastic Mappings Across Modalities</h3>
<p>Authors: Li-Yi Wei, Deepali Aneja, Haijun Xia, Rubaiat Habib Kazi, Yining Cao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147635">Link</a></p>
<p>Abstract: Augmented presentations offer compelling storytelling by combining speech content, gestural performance, and animated graphics in a congruent manner. The expressiveness of these presentations stems from the harmonious coordination of spoken words and graphic elements, complemented by smooth animations aligned with the presenter's gestures. However, achieving such desired congruence in a live presentation poses significant challenges due to the unpredictability and imprecision inherent in presenters' real-time actions. Existing methods either leveraged rigid mapping without predefined states or required the presenters to conform to predefined animations. We introduce adaptive presentations that dynamically adjust predefined graphic animations to real-time speech and gestures. Our approach leverages script following and motion warping to establish elastic mappings that generate runtime graphic parameters coordinating speech, gesture, and predefined animation state. Our evaluation demonstrated that the proposed adaptive presentation can effectively mitigate undesired visual artifacts caused by performance deviations and enhance the expressiveness of resulting presentations.</p>
<h3>Unlocking Understanding: An Investigation of Multimodal Communication in Virtual Reality Collaboration</h3>
<p>Authors: Ryan P. McMahan, Eugene Taranta, Yahya Hmaiti, Mykola Maslych, Ravi Kiran Kattoju, Joseph LaViola, Ryan Ghamandi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146938">Link</a></p>
<p>Abstract: Communication in collaboration, especially synchronous, remote communication, is crucial to the success of task-specific goals. Insufficient or excessive forms of communication may lead to detrimental effects on task performance while increasing mental fatigue. However, identifying which combinations of communication modalities provide the most efficient transfer of information in collaborative settings will greatly improve collaboration. To investigate this, we developed a remote, synchronous, asymmetric VR collaborative assembly task application, where users play the role of either mentor or mentee, and were exposed to different combinations of three communication modalities: voice, gestures, and gaze. Through task-based experiments with 25 pairs of participants (50 individuals), we evaluated quantitative and qualitative data and found that gaze did not differ significantly from multiple combinations of communication modalities. Our qualitative results indicate that mentees experienced more difficulty and frustration in completing tasks than mentors, with both types of users preferring all three modalities to be present.</p>
<h3>Meaning Follows Purpose: Unravelling the Architectural Design Conventions in the Contemporary Metaverse</h3>
<p>Authors: Andrew Vande Moere, Adalberto Simeone, Jihae Han</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147826">Link</a></p>
<p>Abstract: Thousands of people regularly meet, work and play in the architectural spaces that the metaverse offers today. Yet despite the creative potential to disrupt how the built environment is represented, there exists a prevalent belief that the architectural design of the metaverse is rather conventional and reliant on simulating physical reality. We investigated this claim by conducting a design critique study of the most apparent architectural design conventions within the current most popular metaverse platforms, as determined by a scoping review and Google Trends analysis. Based on the opinions of 21 architectural experts on the design of interiors, buildings, and plazas within these platforms, we elicited three overarching design conventions that capture the representation, engagement, and purpose of metaverse architecture. By discussing the impact of these conventions on architectural quality, we inform the future design of metaverse spaces to more purposefully, and perhaps less frequently, use realism to convey meaning. </p>
<h3>LLMR: Real-time Prompting of Interactive Worlds using Large Language Models</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Fernanda De La Torre, Cathy Mengying Fang, Han Huang, Jaron Lanier, Judith Amores, Andrzej Banburski-Fahey</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146847">Link</a></p>
<p>Abstract: We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR's cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.</p>
<h3>Using the Visual Language of Comics to Alter Sensations in Augmented Reality</h3>
<p>Authors: Kasper Hornbæk, Henning Pohl, Arpit Bhatia, Hasti Seifi, Teresa Hirzle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147047">Link</a></p>
<p>Abstract: Augmented Reality (AR) excels at altering what we see but non-visual sensations are difficult to augment. To augment non-visual sensations in AR, we draw on the visual language of comic books. Synthesizing comic studies, we create a design space describing how to use comic elements (e.g., onomatopoeia) to depict non-visual sensations (e.g., hearing). To demonstrate this design space, we built eight demos, such as speed lines to make a user think they are faster and smell lines to make a scent seem stronger. We evaluate these elements in a qualitative user study (N=20) where participants performed everyday tasks with comic elements added as augmentations. All participants stated feeling a change in perception for at least one sensation, with perceived changes detected by between four participants (touch) and 15 participants (hearing). The elements also had positive effects on emotion and user experience, even when participants did not feel changes in perception.</p>
<h2>Highlight on Health</h2>
<h3>Shared Responsibility in Collaborative Tracking for Children with Type 1 Diabetes and their Parents</h3>
<p>Authors: Yoon Jeong Cha, Sun Young Park, Mark Newman, Alice Wou, Yasemin Gunal, Joyce Lee</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147031">Link</a></p>
<p>Abstract: Efficient Type 1 Diabetes (T1D) management necessitates comprehensive tracking of various factors that influence blood sugar levels. However, tracking health data for children with T1D poses unique challenges, as it requires the active involvement of both children and their parents. This study aims to uncover the benefits, challenges, and strategies associated with collaborative tracking for children (ages 6-12) with T1D and their parents. Over a three-week data collection probe study with 22 child-parent pairs, we found that collaborative tracking, characterized by the shared responsibility of tracking management and data provision, yielded positive outcomes for both children and their parents. Drawing from these findings, we delineate four distinct tracking approaches:  child-independent, child-led, parent-led, and parent-independent. Our study offers insights for designing health technologies that empower both children and parents in learning and encourage the sharing of different perspectives through collaborative tracking.</p>
<h3>Learning About Social Context From Smartphone Data: Generalization Across Countries and Daily Life Moments</h3>
<p>Authors: Aurel Ruben Mäder, Lakmal Meegahapola, Daniel Gatica-Perez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148104">Link</a></p>
<p>Abstract: Understanding how social situations unfold in people's daily lives is relevant to designing mobile systems that can support users in their personal goals, well-being, and activities. As an alternative to questionnaires, some studies have used passively collected smartphone sensor data to infer social context (i.e., being alone or not) with machine learning models. However, the few existing studies have focused on specific daily life occasions and limited geographic cohorts in one or two countries. This limits the understanding of how inference models work in terms of generalization to everyday life occasions and multiple countries. In this paper, we used a novel, large-scale, and multimodal smartphone sensing dataset with over 216K self-reports collected from 581 young adults in five countries (Mongolia, Italy, Denmark, UK, Paraguay), first to understand whether social context inference is feasible with sensor data, and then, to know how behavioral and country-level diversity affects inferences. We found that several sensors are informative of social context, that partially personalized multi-country models (trained and tested with data from all countries) and country-specific models (trained and tested within countries) can achieve similar performance above 90% AUC, and that models do not generalize well to unseen countries regardless of geographic proximity. These findings confirm the importance of the diversity of mobile data, to better understand social context inference models in different countries.</p>
<h3>Somaesthetic Meditation Wearable: Exploring the Effect of Targeted Warmth Technology on Meditators' Experiences</h3>
<p>Authors: Oren Zuckerman, Talia Ezer, Jonathan Giron, Hadas Erel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148124">Link</a></p>
<p>Abstract: Mindfulness meditation has vast benefits, yet is challenging for many. We designed a novel targeted warmth somaesthetic wearable and evaluated how the thermal sensation is perceived during meditation. In a qualitative study, twenty participants explored the wearable during meditation. Findings reveal participants' rich experiences, sensations, and feelings. They perceived the technology as an appropriate tool for self-exploration. Even when participants initially felt the wearable was distracting their meditation process, they easily learned how to leverage it in their introspection process. We report on four potential roles for warmth technology: functional (pulling focal of attention), behavioral (motivating to "get back to the practice"), emotional (comforting during the lonely process), and therapeutic feelings. We conclude with design guidelines, highlighting that warmth is a promising technology for meditation if designed to encourage self-exploration of body sensations and emotions while not compromising the natural meditation practice.</p>
<h3>Using and Appropriating Technology to Support The Menopause Journey in the UK</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Aisling Ann O'Kane, Marianela Ciolfi Felice, Emily Lopez Burst</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147124">Link</a></p>
<p>Abstract: The menopause transition has a direct impact on half of the global population, yet it has continued to be a stigmatised topic with limited focus on supporting it with technology. Whilst attention being given to menopause in HCI may be new, people experiencing it is not and people have adopted, adapted and appropriated technologies to support their menopause journey. In this questionnaire and interview study, we examine how people in the UK are using (and not using) existing general and menopause-specific technology to support themselves through the transition. Despite limited menopause-specific technologies available, participants have found novel uses of technologies such as social media and smartwatches for 1) connecting and sharing, 2) information seeking, 3) tracking and reflecting, and 4) self-care. This work contributes design considerations for menopause specific technologies, and design opportunities and challenges for technologies that can be appropriated to support menopause.</p>
<h3>"It's Sink or Swim": Exploring Patients' Challenges and Tool Needs for Self-Management of Postoperative Acute Pain</h3>
<p>Authors: Sylvain Bédard, M. Gabrielle Pagé, Jinghui Cheng, Mélanie Lussier, Souleima Zghab</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146987">Link</a></p>
<p>Abstract: Poorly managed postoperative acute pain can have long-lasting negative impacts and pose a major healthcare issue. There is limited investigation to understand and address the unique needs of patients experiencing acute pain. In this paper, we tackle this gap through an interview study with 14 patients who recently underwent postoperative acute pain to understand their challenges in pain self-management and their need for supportive tools. Our analysis identified various factors associated with the major aspects of acute pain self-management. Together, our findings indicated that tools for supporting these patients need to carefully consider information and support delivery to adapt to rapid changes in pain experiences, offer personalized and dynamic assistance that adapts to individual situations in context, and monitor emotion when promoting motivation. Overall, our work provided valuable knowledge to address the less-investigated but highly-needed problem of designing technology for the self-management of acute pain and similar health conditions.</p>
<h3>Individual Differences and Technology Affordances Combine to Predict Mobile Social Media Distraction Behaviors and Consequences</h3>
<p>Authors: Peter Monge, Emily Sidnam-Mauch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147042">Link</a></p>
<p>Abstract: Drawing upon theories from communication studies and cognitive psychology, this research develops a multitheoretical model that identifies human and technological factors that predict social media distraction engagement and explains how social media distractions can lead to negative consequences across various tasks. This model is empirically tested using data from a survey of U.S. mobile phone users (N = 1,026). The results from a structural equation modeling analysis support the model’s predictions that a person’s age, fear of missing out, smartphone checking habit strength, and the number of social media applications with notifications enabled all impact a variety of distraction behaviors and consequences. The findings show that communication technology distraction behavior is influenced by a complex intertwining of goal-driven communication and information-seeking behaviors, automatic processes in the brain, and technology affordances.</p>
<h3>"Speech is Silver, Silence is Golden " Analyzing Micro-communication Strategies between Visually Impaired Runners and their Guides</h3>
<p>Authors: Giulia Barbareschi, Kai Kunze, Christopher Kim, George Chernyshov, Tarika Kumar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147500">Link</a></p>
<p>Abstract: Running and jogging are popular activities for many visually impaired individuals thanks to the relatively low entry barriers. Research in HCI and beyond has focused primarily on leveraging technology to enable visually impaired people to run independently. However, depending on their residual vision and personal preferences, many chose to run with a sighted guide. This study presents a comprehensive analysis of the partnership between visually impaired runners and sighted guides. Using a combination of interaction and thematic analysis on video and interview data from 6 pairs of runners and guides, we unpack the complexity and directionality of three layers of vocal communication (directive, contextual, and recreational) and distinguish between intentional and unintentional corporeal communication. Building on the understanding of the importance of synchrony we also present some exploratory data looking at physiological synchrony between 2 pairs of runners with different level of experience and articulate recommendations for the HCI community.</p>
<h3>"If This Person is Suicidal, What Do I Do?": Designing Computational Approaches to Help Online Volunteers Respond to Suicidality</h3>
<p>Authors: Haiyi Zhu, Cindy Liu, Sunniva Liu, Logan Stapleton, Stevie Chancellor, Robert Kraut, Irene Hong</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147747">Link</a></p>
<p>Abstract: Online platforms provide support for many kinds of distress, including suicidal thoughts and behaviors. However, because many platforms restrict suicidal talk, volunteers on these platforms struggle with how to help suicidal people who come for support. We interviewed 11 volunteer counselors in a large online support platform, including after they role-played conversations with varying severities of suicidality, to explore practices and challenges when identifying and responding to suicidality. We then presented Speed Dating design concepts around emotional preparation and support, real-time guidance, training, and suicide detection. Participants wanted more support and preparation for conversations with suicidal people, but were conflicted about AI-based technologies, including trade-offs between potential benefits of conversational agents for training and limitations of prediction or real-time response suggestions, due to the sensitive, context-dependent decisions that volunteers must make. Our work has important implications for nuanced considerations and design choices around developing digital mental health technologies.</p>
<h3>Mindfulness-based Embodied Tangible Interactions for Stroke Rehabilitation at Home</h3>
<p>BEST_PAPER</p>
<p>Authors: Catherine Holloway, Wen Mo, Preetham Nagaraj</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146728">Link</a></p>
<p>Abstract: Current approaches to designing technologies for stroke rehabilitation at home show great promise using either mindfulness-based interventions or embodied tangible interactions. However, there is an untapped potential in integrating these approaches and a lack of understanding of how to embody aspects of mindfulness in tangible interactions for stroke rehabilitation. We report the first explicit effort to explore this dimension by conducting semi-structured interviews and co-design sessions involving four physiotherapists and four mindfulness experts. The major themes ‘Awareness – The essence of mindfulness’ and ‘Tactile sensations – A pathway to mindfulness’ point us towards new ways to embody mindfulness in tangible interactions to address stroke rehabilitation challenges. This work introduces a novel approach to designing technology called ‘Mindfulness-based Embodied Tangible Interactions’ (MBETI). We present five key design principles such as 'Design to support mindful awareness’ and ‘Design for Comfort’ while discussing the future research opportunities of assistive technologies for stroke rehabilitation.</p>
<h3>Quantifying the Pollan Effect: Investigating the Impact of Emerging Psychiatric Interventions on Online Mental Health Discourse</h3>
<p>Authors: Munmun De Choudhury, Sachin Pendse, Neha Kumar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146755">Link</a></p>
<p>Abstract: Psychedelic-assisted therapy has shown significant promise in alleviating treatment-resistant mental illness, prompting excitement among people with lived experience of mental illness. The emerging collective perception of psychedelics as tools for mental health has been dubbed the Pollan Effect. We investigate whether the Pollan Effect carries to online community discussions concerning psilocybin-containing mushrooms (PCMs). Through a matched computational analysis of 676,875 longform Reddit posts describing PCM use spanning a decade, we provide evidence of the Pollan Effect in terms of increased health discourse around PCMs following two inception points---release of a book and subsequent documentary on PCMs. We then introduce the notion of a Pollan shift, which we witness through increased collective sharing of emotional and social experiences following the two inception points. Our findings offer insights into how online discourse could be representative of emerging social movements around new psychiatric treatments, and the role of platforms in sensemaking and research. </p>
<h3>Holding AI to Account: Challenges for the Delivery of Trustworthy AI in Healthcare</h3>
<p>Authors: Mark Rouncefield, Peter Tolmie, Rob Procter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150872">Link</a></p>
<p>Abstract: The need for AI systems to provide explanations for their behaviour is now widely recognised as key to their adoption. In this article, we examine the problem of trustworthy AI and explore what delivering this means in practice, with a focus on healthcare applications. Work in this area typically treats trustworthy AI as a problem of Human–Computer Interaction involving the individual user and an AI system. However, we argue here that this overlooks the important part played by organisational accountability in how people reason about and trust AI in socio-technical settings. To illustrate the importance of organisational accountability, we present findings from ethnographic studies of breast cancer screening and cancer treatment planning in multidisciplinary team meetings to show how participants made themselves accountable both to each other and to the organisations of which they are members. We use these findings to enrich existing understandings of the requirements for trustworthy AI and to outline some candidate solutions to the problems of making AI accountable both to individual users and organisationally. We conclude by outlining the implications of this for future work on the development of trustworthy AI, including ways in which our proposed solutions may be re-used in different application settings.</p>
<h3>“If Someone Walks In On Us Talking, Pretend to be My Friend, Not My Therapist": Challenges and Opportunities for Digital Mental Health Support in Saudi Arabia</h3>
<p>Authors: Nigel Shadbolt, Max Van Kleek, Deemah Alateeq, Sarah Aldaweesh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147711">Link</a></p>
<p>Abstract: Mental health disorders are prevalent worldwide, yet they remain stigmatized, especially in the Middle East. While mHealth has the potential to circumvent traditional barriers, research on its application remains scarce in Arab countries. To address this gap, we conducted a mixed-methods study of mental health apps availability, adoption, and perceptions in the Kingdom of Saudi Arabia (KSA) where digital health transformation is rapidly progressing. We interviewed twelve psychiatrists and psychologists to elicit their views on local barriers and opportunities for digital mental health support. We further systematically reviewed the Saudi app market, analysing 110 Arabic mental health apps. Our findings indicate that whilst fear of stigma and cultural factors hindered help-seeking, the privacy and anonymity enabled by technology created new opportunities for accessing mental support in the KSA. We revealed tensions between experts' professional and practical perspectives, explored technology-exacerbated challenges and provided considerations for improving Saudi digital mental healthcare experience.</p>
<h2>Highlight on Interaction and Cultures</h2>
<h3>Commoning as a Strategy for HCI Research and Design in South Asia</h3>
<p>Authors: Robert Soden, Aarjav Chauhan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147596">Link</a></p>
<p>Abstract: Commons emerge and are reclaimed through collective, shared, and self-organized practices known as commoning. Despite their historical embeddedness in South Asian communities, commoning practices have succumbed to enclosure and destruction due to region-wide privatization and development schemes implemented over the past century. Certain HCI and ICTD research has critiqued such schemes for undermining community autonomy and well-being. To advance the development of alternative models, we conducted a literature review of HCI research involving the commons, considering both natural and digital resources, in South Asia. Additionally, we examine the social practices, rules, and institutional arrangements described in the corpus through the lens of Elinor Ostrom’s design principles for commons governance. Based on our findings, we formulate a commoning framework by synthesizing three areas of HCI research — infrastructuring, participatory design, and assets-based design — proposing it as an alternative to neoliberal development paradigms for future HCI research.</p>
<h3>Better Little People Pictures: Generative Creation of Demographically Diverse Anthropographics</h3>
<p>Authors: Lauren Perera, Wesley Willett, Priya Dhawka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147622">Link</a></p>
<p>Abstract: We explore the potential of generative AI text-to-image models to help designers efficiently craft unique, representative, and demographically diverse anthropographics that visualize data about people. Currently, creating data-driven iconic images to represent individuals in a dataset often requires considerable design effort. Generative text-to-image models can streamline the process of creating these images, but risk perpetuating designer biases in addition to stereotypes latent in the models. In response, we outline a conceptual workflow for crafting anthropographic assets for visualizations, highlighting possible sources of risk and bias as well as opportunities for reflection and refinement by a human designer. Using an implementation of this workflow with Stable Diffusion and Google Colab, we illustrate a variety of new anthropographic designs that showcase the visual expressiveness and scalability of these generative approaches. Based on our experiments, we also identify challenges and research opportunities for new AI-enabled anthropographic visualization tools.</p>
<h3>Design With Rural-To-Urban Migrant Women: Opportunities and Challenges in Designing within a Precarious Marriage Context in South China</h3>
<p>Authors: Yuchao Zhao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147663">Link</a></p>
<p>Abstract: This study elucidates the challenges faced by married migrant women (MMW) in South China in relation to design. Through 2-year ethnographic fieldwork and semi-structured interviews with 15 participants, I aim to understand the context and intricacies of their systemic marital problems that form the backdrop against which mobile technology design could occur. I discuss how they tactically appropriate cellphones to negotiate love, sex, and marriage while remaining stuck in gendered patterns of technological use. The marital issues raised by the participants concerning the place of technology could provide HCI researchers with valuable guidance. “Design with” implies avoiding an elite perspective, eschewing a top-down approach, and steering clear of a condescending attitude in technical design. Designers should act as collaborators, assisting MMW in uncovering and nurturing their values, collective traits, and life experiences, which could ultimately nourish the future development of MMW and the migrant community. Potential considerations include a better understanding of national history and local ecosystems, recognizing MMW’s agency and initiative in technology design and decision-making, valuing and learning from their “alternative” experiences of using technologies, and design beyond individual users for a more equal and safer environment.</p>
<h3>Justice-oriented Design Listening: Participatory Ecoacoustics with a Ghanaian Forest Community</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Alan Blackwell, Emmanuel Acheampong, Joycelyn Longdon, Jennifer Gabrys, Benjamin Ossom, Michelle Westerlaken, Adham Ashton-Butt</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147917">Link</a></p>
<p>Abstract: Despite a long tradition of ‘non-expert’ participation in ecoacoustics research, asymmetrical distribution of resources and engagement between the Global North and Global South continue, extending to ecoacoustic sensing and design. Whilst there exists a growing body of work in Participatory Design (PD) addressing the technical and social challenges of ecoacoustic research, we find that popular PD methods inadequately address design justice and decolonising agendas. Through participatory ecoacoustic sensing and design engagements with a forest community in Ghana, we highlight the tensions that emerge when employing visual and written modes of PD in a context where an oral approach to creativity and communication is more appropriate. We present Justice-oriented Design Listening, an acoustically-mediated approach to PD, described through three modes: polyphony, pace and transformation. This work contributes to calls for design justice by developing a methodological approach that facilitates pluralistic participation in design when developing conservation technologies in non-Western contexts.</p>
<h3>Politics of the Past: Understanding the Role of Memory, Postmemory, and Remembrance in Navigating the History of Migrant Families</h3>
<p>Authors: Cosmin Munteanu, Carolina Reyes Marquez, Marisol Wong-Villacres, Mohammad Rashidujjaman Rifat, Syed Ishtiaque Ahmed, Nabila Chowdhury, Azhagu Meena SP, Natasha Shokri, Negin Dahya, Cibeles Valera</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146983">Link</a></p>
<p>Abstract: The importance of history as an HCI method has been gaining increasing attention in HCI literature. However, the mainstream historical sources (books, documentaries, etc.) and methods often risk (re)producing western colonial biases potentially providing a narrow one-sided perspective on history and detaching “sanitized facts” from people’s emotional accounts. While oral history and similar alternative methods are often used as a countermeasure, their applicability has remained underexplored in HCI, especially in a sensitive context, such as migration.  We build on the rich body of social science work on collective memory to introduce a complementary way of navigating the past of the migrant families, and also reveal the corresponding challenges to advance this literature. Our interview study with 17 migrant families highlights how the politics of remembrance, family dynamics, and postmemory shape the past stories of migrant families. We discuss how these findings inform the HCI literature on migration, design, and postcolonial computing.</p>
<h3>Migrant Farmworkers' Experiences of Agricultural Technologies: Implications for Worker Sociality and Desired Change</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Olivia Doggett, Priyank Chandra, Matt Ratto</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147193">Link</a></p>
<p>Abstract: This mixed method study situated in Ontario, Canada, investigates how migrant farmworkers' experiences with agricultural technologies (agtech) affect their attitudes, conditions, and expectations of work, and how workers envision technologies serving as supportive interventions. Through a survey and interviews, we identify that surveillance and tracking agtech (chequeadoras) affect workers, imparting negative health and safety consequences. Workers' interactions with chequeadoras reveal three major impacts: performance expectations engender stress, surveillance causes fears of disciplinary action, and performance tracking heightens competition. These impacts demonstrate how chequeadoras erode workers' capacity to build sociality and solidarity. In response to these impacts and to support workers' desired workplace changes, which aim for safer environments with technical skill development opportunities, we examine tactics from HCI, critical design, and migrant justice movements. Our findings lead us to contemplate what qualifies as agtech and how we may support marginalised workers with divergent opinions regarding workplace technologies, and desired collective change.</p>
<h3>Play Across Boundaries: Exploring Cross-Cultural Maldaimonic Game Experiences</h3>
<p>Authors: Shruti Chandra, Sota Kobuki, Katie Seaborn, Satoru Iseya, Shun Hidaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147448">Link</a></p>
<p>Abstract: Maldaimonic game experiences occur when people engage in personally fulfilling play through egocentric, destructive, and/or exploitative acts. Initial qualitative work verified this orientation and experiential construct for English-speaking Westerners. In this comparative mixed methods study, we explored whether and how maldaimonic game experiences and orientations play out in Japan, an Eastern gaming capital that may have cultural values incongruous with the Western philosophical basis underlying maldaimonia. We present findings anchored to the initial frameworks on maldaimonia in game experiences that show little divergence between the Japanese and US cohorts. We also extend the qualitative findings with quantitative measures on affect, player experience, and the related constructs of hedonia and eudaimonia. We confirm this novel construct for Japan and set the stage for scale development.</p>
<h3>Air/time Travel: Rethinking Appropriation in Global HCI and Futures of Electronic Exchange</h3>
<p>Authors: Christopher Csikszentmihalyi, Daniel Mwesigwa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148174">Link</a></p>
<p>Abstract: This paper reexamines appropriation in human-computer interaction (HCI), which refers to the unexpected alterations made to artifacts by users. We analyze when earlier informal practices of exchanging airtime for cash became enclosed into proprietary mobile money platforms, and show that this enclosure has a longer history in global telecommunications. Building on interviews with 19 experts in computing, policy, and media, we challenge teleological narratives of the inevitability of mobile money often overlooked in computing and global development. We develop an ‘appropriation matrix’ introducing a dialectic of re- and reverse- appropriation animated by three elements—users, artifacts, and imaginaries—that unexpectedly switch between production and consumption, complicating invention and innovation in formal and informal economies. This matrix may help HCI and development better understand how different values, visions, and practices might have led (or could still lead) to different designs of products like mobile money.</p>
<h3>Low-Resourced Languages and Online Knowledge Repositories: A Need-Finding Study.</h3>
<p>Authors: Hellina Hailu Nigatu, Sarah Chasins, John Canny</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147539">Link</a></p>
<p>Abstract: Online Knowledge Repositories (OKRs) like Wikipedia offer communities a way to share and preserve information about themselves and their ways of living. However, for communities with low-resourced languages---including most African communities---the quality and volume of content available are often inadequate. One reason for this lack of adequate content could be that many OKRs embody Western ways of knowledge preservation and sharing, requiring many low-resourced language communities to adapt to new interactions. To understand the challenges faced by low-resourced language contributors on the popular OKR Wikipedia, we conducted (1) a thematic analysis of  Wikipedia forum discussions and (2) a contextual inquiry study with 14 novice contributors. We focused on three Ethiopian languages: Afan Oromo, Amharic, and Tigrinya. Our analysis revealed several recurring themes; for example, contributors struggle to find resources to corroborate their articles in low-resourced languages, and language technology support, like translation systems and spellcheck, result in several errors that waste contributors' time. We hope our study will support designers in making online knowledge repositories accessible to low-resourced language speakers. </p>
<h2>Highlight on Fabrication</h2>
<h3>Towards More Sustainable Interactive Textiles: A Literature Review on The Use of Biomaterials for eTextiles.</h3>
<p>Authors: Sofía Guridi, Emmi Pouta, Matteo Iannacchero</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147272">Link</a></p>
<p>Abstract: The development of functional fibres, active materials, and flexible electrical components has introduced new ways of embedding interactive capabilities within textiles. However, this seamless integration poses challenges in terms of materials, disassembly, and disposal, revealing an urgent need to address the issue of sustainability when creating new electronic textiles. Authors have proposed eco-design guidelines that emphasise the use of renewable and biodegradable materials. Despite these recommendations, the potential of biomaterials in eTextiles remains largely unexplored. This integrative literature review showcases how biomaterials emerged as catalysts for expanding possibilities within eTextiles and HCI, not only through their environmental sustainability but also through their dynamic and transformative nature, fostering a realm of novel interactive experiences. We suggest the potential of developing fully bio-based eTextile systems, the need for broader sustainability and aesthetic studies, the relevance of DIY methods, and the urgency of textile knowledge integration.</p>
<h3>ExCell: High Expansion Ratio Moisture-Responsive Wooden Actuators for DIY Shape-Changing and Deployable Structures</h3>
<p>Authors: Shuhong Wang, Lining Yao, Tucker Rae-Grant</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147588">Link</a></p>
<p>Abstract: While there has been sustained interest in shape-changing materials and deployable structures, many existing systems require engineering materials, precision fabrication, and computationally modeled kinematics in order to work. Additionally, many rely on external power sources in order to deploy. In light of these factors, we perceive a need for deployable materials that are easy to design, prototype, and deploy, and that can transform themselves in response to environmental stimuli, making them appropriate for ecological applications. In this paper, we present ExCell, a DIY-able system of water-responsive wooden linear actuators for self-actuating deployable structures. We show that ExCell can be used to develop a wide range of geometries, we present a prototyping method that can create accurate models of ExCell structures, and we suggest four possible applications for this system.</p>
<h3>Flextiles: Designing Customisable Shape-Change in Textiles with SMA-Actuated Smocking Patterns</h3>
<p>Authors: Alice Haynes, Jürgen Steimle</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147340">Link</a></p>
<p>Abstract: Shape Memory Alloys (SMAs) afford the seamless integration of shape-changing behaviour into textiles, enabling designers to augment apparel with dynamic shaping and styling. However, existing works fall short of providing versatile methods adaptable to varying scales, materials, and applications, curtailing designers’ capacity to prototype customised solutions. To address this, we introduce Flextiles, parameterised SMA design schema that leverage the traditional craft of smocking to integrate planar shape-change seamlessly into diverse textile projects. The conception of Flextiles stems from material experimentation and consultative dialogues with designers, whose insights inspired strategies for customising scale, elasticity, geometry, and actuation of Flextiles. To support the practical implementation of Flextiles, we provide a design tool and experimentally characterise their material properties. Lastly, through a design case study with practitioners, we explore the multifaceted applications and perspectives surrounding Flextiles, and subsequently realise four scenarios that illustrate the creative potential of these modular, customisable patterns.</p>
<h3>Evaluating ActuAir: Building Occupants' Experiences of a Shape-Changing Air Quality Display</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: David Kirk, Abigail Durrant, Eleni Margariti, Vasilis Vlachokyriakos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146904">Link</a></p>
<p>Abstract: With workplace buildings becoming increasingly sensor-rich environments and amidst climate change and global pandemic pressures, there is novel opportunity for utilizing climatic data within buildings for awareness and wellbeing purposes. Interaction design research, including on large, shared-displays, rarely addresses building occupants’ experiences of air quality (AQ); and to-date there are no studies evaluating such interventions in the context of communicating climatic data in the workplace. Responding to these research gaps, three prototype-led studies were conducted with 21 occupants of a smart office building over June-August 2022, evaluating occupants’ experiences of a large shape- and color-changing display responding to AQ data. A thematic analysis resulted in design implications for improving shape- and color-changing displays for communicating AQ data; linking biomimicry to data interpretation. Contributing to Human-Building Interaction (HBI) research in the Human-Computer Interaction (HCI) field, we provide design directions for future shape-changing and responsive architectures for climate awareness in smart buildings.</p>
<h2>Highlight on Immersive Interactions</h2>
<h3>ARCADIA: A Gamified Mixed Reality System for Emotional Regulation and Self-Compassion</h3>
<p>Authors: José Luis Soler-Domínguez, Samuel Navas-Medrano, Patricia Pons</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147990">Link</a></p>
<p>Abstract: Mental health and wellbeing have become one of the significant challenges in global society, for which emotional regulation strategies hold the potential to offer a transversal approach to addressing them. However, the persistently declining adherence of patients to therapeutic interventions, coupled with the limited applicability of current technological interventions across diverse individuals and diagnoses, underscores the need for innovative solutions. We present ARCADIA, a Mixed-Reality platform strategically co-designed with therapists to enhance emotional regulation and self-compassion. ARCADIA comprises several gamified therapeutic activities, with a strong emphasis on fostering patient motivation. Through a dual study involving therapists and mental health patients, we validate the fully functional prototype of ARCADIA. Encouraging results are observed in terms of system usability, user engagement, and therapeutic potential. These findings lead us to believe that the combination of Mixed Reality and gamified therapeutic activities could be a significant tool in the future of mental health.</p>
<h3>Implementation of Virtual Reality Motivated Physical Activity via Omnidirectional Treadmill in a Supported Living Facility for Older Adults: A Mixed-Methods Evaluation.</h3>
<p>Authors: Leonie Cooper, Hannah Bradwell, Rory Baxter, Ray Jones, Katie Jane Edwards, Anna Whittaker, Simone Tomaz</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148214">Link</a></p>
<p>Abstract: Virtual reality (VR) can support healthy ageing, but few devices have been trialed with frail older adults to increase physical activity. We conducted a preliminary mixed-methods implementation evaluation of an omnidirectional VR treadmill and a static VR experience with seven older adults over a six-week period in a supported living facility. Frequency of use and pre-post physical functioning measures were collected, mainly to establish technology suitability based on person characteristics. Diary entries following technology use, resident focus group and staff interview revealed technology acceptance and perceived potential for increasing physical activity, health and wellbeing through accessing virtual environments, which motivated continued activity. Results demonstrated technology suitability for a range of older adults with various mobility and physical impairments. However, residents noted interest in a seated treadmill for physical activity without perceived risks of falls with standing treadmills. Staff raised considerations around care home implementations including usability, cost and space.</p>
<h3>MobileGravity: Mobile Simulation of a High Range of Weight in Virtual Reality</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Niels Henze, Tien-Julian Ho, Alexander Kalus, Johannes Klein, Lee-Ann Seegets</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147373">Link</a></p>
<p>Abstract: Simulating accurate weight forces in Virtual Reality (VR) is an unsolved challenge. Therefore, providing real weight sensations by transferring liquid mass has emerged as a promising approach. However, key objectives conceptually interfere with each other. In particular, previous designs that support a high range of weight or high flow rate lack mobility. In this work, we present MobileGravity, a system, that decouples the weight-changing object from the liquid supply and the pump. It enables weight changes of up to 1 kg at a rate of 235 g/s and allows the user to walk around freely. Through a study with 30 participants, we show that the system enables users to perceive the weight of different virtual objects and enhances realism, as well as enjoyment.</p>
<h3>Behind the Scenes: Adapting Cinematography and Editing Concepts to Navigation in Virtual Reality</h3>
<p>Authors: Dorota Glowacka, Alan Medlar, Mari Lehtikari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147397">Link</a></p>
<p>Abstract: Teleportation is a popular method of navigation in virtual reality (VR) because it does not induce symptoms of VR sickness, such as nausea and disorientation. However, teleportation may reduce spatial awareness, causing users to miss important aspects of their surroundings. We present ACTIVE, a novel approach to teleportation that uses techniques from cinematography to enhance the user experience of navigation in VR. ACTIVE adapts heuristics from continuity editing to dynamically reposition and reorient the camera after teleportation. This approach aims to improve the aesthetic quality of entities and environmental features while respecting users' intended trajectory through the virtual environment. In a user study, we found that even though ACTIVE did not improve users' recall of which entities were present in the environment, it increased engagement by significantly improving aesthetic appeal. Lastly, despite removing some agency from users, ACTIVE had no impact on presence or VR sickness compared to teleportation.</p>
<h3>The Impact of Avatar Completeness on Embodiment and the Detectability of Hand Redirection in Virtual Reality</h3>
<p>Authors: Anthony Tang, André Zenner, Antonio Krüger, Martin Feick, Simon Seibert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147279">Link</a></p>
<p>Abstract: To enhance interactions in VR, many techniques introduce offsets between the virtual and real-world position of users’ hands. Nevertheless, such hand redirection (HR) techniques are only effective as long as they go unnoticed by users—not disrupting the VR experience. While several studies consider how much unnoticeable redirection can be applied, these focus on mid-air floating hands that are disconnected from users’ bodies. Increasingly, VR avatars are embodied as being directly connected with the user’s body, which provide more visual cue anchoring, and may therefore reduce the unnoticeable redirection threshold. In this work, we studied more complete avatars and their effect on the sense of embodiment and the detectability of HR. We found that higher avatar completeness increases embodiment, and we provide evidence for the absence of practically relevant effects on the detectability of HR.</p>
<h3>A Survey On Measuring Presence in Mixed Reality</h3>
<p>Authors: Tanh Tran, Tobias Langlotz, Holger Regenbrecht</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148206">Link</a></p>
<p>Abstract: Presence is a defining element of virtual reality (VR), but it is also increasingly used when assessing mixed reality (MR) experiences. The increased interest in measuring presence in MR and recent works underpinning the specific nature of presence in MR raise the question of the current state and practice of assessing presence in MR. To address this question, we present an analysis of more than 320 studies that report on presence measurements in MR. Our analysis showed that questionnaires are the dominant measurement but also identify problematic trends that stem from the lack of a generally agreed-upon concept or measurement for presence in MR. More specifically, we show that using measurements that are not validated in MR or custom questionnaires limiting the comparability of results is commonplace and could contribute to a looming replication crisis in an increasingly relevant field.</p>
<h3>On the Benefits of Image-Schematic Metaphors when Designing Mixed Reality Systems</h3>
<p>Authors: Jingyi Li, Per Ola Kristensson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146697">Link</a></p>
<p>Abstract: A Mixed Reality (MR) system encompasses various aspects, such as visualization and spatial registration of user interface elements, user interactions and interaction feedback. Image-schematic metaphors (ISMs) are universal knowledge structures shared by a wide range of users. They hold a theoretical promise of facilitating greater ease of learning and use for interactive systems without costly adaptations. This paper investigates whether image-schematic metaphors (ISMs) can improve user learning, by comparing an existing MR instruction authoring system with or without ISM enhancements. In a user study with 32 participants, we found that the ISM-enhanced system significantly improved task performance, learnability and mental efficiency compared to the baseline. Participants also rated the ISM-enhanced system significantly higher in terms of perspicuity, efficiency, and novelty. These results empirically demonstrate multiple benefits of ISMs when integrated into the design of this MR system and encourage further studies to explore the wider applicability of ISMs in user interface design.</p>
<h2>Highlight on AI</h2>
<h3>Mind The Gap: Designers and Standards on Algorithmic System Transparency for Users</h3>
<p>Authors: bianca schor, Chris Norval, Jat Singh, Ellen Charlesworth</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147422">Link</a></p>
<p>Abstract: Many call for algorithmic systems to be more transparent, yet it is often unclear for designers how to do so in practice. Standards are emerging that aim to support designers in building transparent systems, e.g by setting testable transparency levels, but their efficacy in this regard is not yet understood. In this paper, we use the <code>Standard for Transparency of Autonomous Systems' (IEEE 7001) to explore designers' understanding of algorithmic system transparency, and the degree to which their perspectives align with the standard's recommendations. Our mixed-method study reveals participants consider transparency important, difficult to implement, and welcome support. However, despite IEEE 7001's potential, many did not find its recommendations particularly appropriate. Given the importance and increased attention on transparency, and because standards like this purport to guide system design, our findings reveal the need for</code>bridging the gap,' through (i) raising designers’ awareness about the importance of algorithmic system transparency, alongside (ii) better engagement between stakeholders (i.e. standards bodies, designers, users). We further identify opportunities towards developing transparency best practices, as means to help drive more responsible systems going forward.</p>
<h3>I lose vs. I earn: Consumer perceived price fairness toward algorithmic (vs. human) price discrimination</h3>
<p>Authors: Xiaoping Zhang, Xusen Cheng</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147741">Link</a></p>
<p>Abstract: Many companies are turning to algorithms to determine prices. However, little research has been done to investigate consumers’ perceived price fairness when price discrimination is implemented by either a human or an algorithm. The results of two experiments with 2 (price-setting agent: algorithm vs. human) × 2 (price discrimination: advantaged vs. disadvantaged) between-subjects design reveal that consumers perceive disadvantaged price discrimination as being more unfair when it is implemented by a human (vs. algorithm). Conversely, they perceive advantaged price discrimination as being more unfair when it is implemented by an algorithm (vs. human). This difference is caused by distinct attribution processes. Consumers are more likely to externalize disadvantaged price discrimination implemented by a human than an algorithm (i.e., attributing it to the unintentionality of price-setting agents), while they are more likely to internalize advantaged price discrimination implemented by a human than an algorithm (i.e., attributing it to perceived personal luck). Based on these findings, we discuss how designers and managers can design and utilize algorithms to implement price discrimination that reduces consumer perception of price unfairness. We believe that reasonable disclosure of algorithmic clues to consumers can maximize the benefits of price discrimination strategies.</p>
<h3>Towards a Non-Ideal Methodological Framework for Responsible ML</h3>
<p>Authors: Ramaravind Kommiya Mothilal, Syed Ishtiaque Ahmed, Shion Guha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148062">Link</a></p>
<p>Abstract: Though ML practitioners increasingly employ various Responsible ML (RML) strategies, their methodological approach in practice is still unclear. In particular, the constraints, assumptions, and choices of practitioners with technical duties--such as developers, engineers, and data scientists---are often implicit, subtle, and under-scrutinized in HCI and related fields. We interviewed 22 technically oriented ML practitioners across seven domains to understand the characteristics of their methodological approaches to RML through the lens of ideal and non-ideal theorizing of fairness. We find that practitioners’ methodological approaches fall along a spectrum of idealization. While they structured their approaches through ideal theorizing, such as by abstracting RML workflow from the inquiry of applicability of ML, they did not systematically document nor pay deliberate attention to their non-ideal approaches, such as diagnosing imperfect conditions. We end our paper with a discussion of a new methodological approach, inspired by elements of non-ideal theory, to structure technical practitioners’ RML process and facilitate collaboration with other stakeholders.</p>
<h3>(Beyond) Reasonable Doubt: Challenges that Public Defenders Face in Scrutinizing AI in Court</h3>
<p>Authors: Niloufar Salehi, Angela Jin</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146685">Link</a></p>
<p>Abstract: Accountable use of AI systems in high-stakes settings relies on making systems contestable. In this paper we study efforts to contest AI systems in practice by studying how public defenders scrutinize AI in court. We present findings from interviews with 17 people in the U.S. public defense community to understand their perceptions of and experiences scrutinizing computational forensic software (CFS) --- automated decision systems that the government uses to convict and incarcerate, such as facial recognition, gunshot detection, and probabilistic genotyping tools. We find that our participants faced challenges assessing and contesting CFS reliability due to difficulties (a) navigating how CFS is developed and used, (b) overcoming judges and jurors’ non-critical perceptions of CFS, and (c) gathering CFS expertise. To conclude, we provide recommendations that center the technical, social, and institutional context to better position interventions such as performance evaluations to support contestability in practice. </p>
<h3>“The bus is nothing without us”: Making Visible the Labor of Bus Operators amid the Ongoing Push Towards Transit Automation</h3>
<p>Authors: Sarah Fox, Alice Xiaodi Tang, Chinar Mehta, Bonnie Fan, Nikolas Martelaro, Hunter Akridge</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147433">Link</a></p>
<p>Abstract:  This paper describes how the complexity of circumstances bus operators manage presents unique challenges to the feasibility of high-level automation in public transit. Avoiding an overly rationalized view of bus operators' labor is critical to ensure the introduction of automation technologies does not compromise public wellbeing, the dignity of transit workers, or the integrity of critical public infrastructure. Our findings from a group interview study show that bus operators take on work — undervalued by those advancing automation technologies — to ensure the well-being of passengers and community members. Notably, bus operators are positioned to function as shock absorbers during social crises in their communities and in moments of technological breakdown as new systems come on board. These roles present a critical argument against the rapid push toward driverless automation in public transit. We conclude by identifying opportunities for participatory design and collaborative human-machine teaming for a more just future of transit.</p>
<h3>Care-Based Eco-Feedback Augmented with Generative AI: Fostering Pro-Environmental Behavior through Emotional Attachment</h3>
<p>Authors: Adrian Holzer, Bruno Kocher, Manon Berney, Vladimir Macko, Abdessalam Ouaazki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147985">Link</a></p>
<p>Abstract: Lights out! With the escalating climate crisis, eco-feedback has gained prominence over the last decade. However, traditional approaches could be underperforming as they often use data-driven strategies and assume that people only need additional information about their consumption to change behavior. A proposed path to overcome this issue is to design eco-feedback to foster emotional connections with users. However, not much is known about the effectiveness of such designs. In this paper, we propose a novel care-based eco-feedback system. Central to the system is a Tamagotchi-inspired digital character named INFI who gets its life force from the user's energy savings. Additionally, we harness the latest advancements in generative artificial intelligence to enhance emotional attachment through conversational interactions that users can have with INFI. The results of a randomized controlled experiment (N=420) convey the fact that this design increases emotional attachment, which in turn increases energy-saving behavior.</p>
<h3>DeepTreeSketch: Neural Graph Prediction for Faithful 3D Tree Modeling from Sketches</h3>
<p>Authors: Ruiyuan Zhang, Naoto Yokoya, Zhanglin Cheng, Zhihao Liu, Yu LI, Fangyuan Tu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147555">Link</a></p>
<p>Abstract: We present DeepTreeSketch, a novel AI-assisted sketching system that enables users to create realistic 3D tree models from 2D freehand sketches. Our system leverages a tree graph prediction network, TGP-Net, to learn the underlying structural patterns of trees from a large collection of 3D tree models. The TGP-Net simulates the iterative growth of botanical trees and progressively constructs the 3D tree structures in a bottom-up manner. Furthermore, our system supports a flexible sketching mode for both precise and coarse control of the tree shapes by drawing branch strokes and foliage strokes, respectively. Combined with a procedural generation strategy, users can freely control the foliage propagation with diverse and fine details. We demonstrate the expressiveness, efficiency, and usability of our system through various experiments and user studies. Our system offers a practical tool for 3D tree creation, especially for natural scenes in games, movies, and landscape applications.</p>
<h3>Amplifying Human Capabilities in Prostate Cancer Diagnosis: An Empirical Study of Current Practices and AI Potentials in Radiology</h3>
<p>Authors: Volkmar Pipek, Sheree May Saßmannshausen, Aparecido Fabiano Pinatti de Carvalho, Mark Rouncefield, Nazmun Ontika</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147429">Link</a></p>
<p>Abstract: This paper examines the potential of Human-Centered AI (HCAI) solutions to support radiologists in diagnosing prostate cancer. Prostate cancer is one of the most prevalent and increasing cancers among men. The scarcity of radiologists raises concerns about their ability to address the growing demand for prostate cancer diagnosis, leading to a significant surge in the workload of radiologists. Drawing on an HCAI approach, we sought to understand the current practices concerning radiologists' work on detecting and diagnosing prostate cancer, as well as the challenges they face. The findings from our empirical studies point toward the potential that AI has to expedite informed decision-making and enhance accuracy, efficiency, and consistency. This is particularly beneficial for collaborative prostate cancer diagnosis processes. We discuss these results and introduce design recommendations and HCAI concepts for the domain of prostate cancer diagnosis, with the aim of amplifying the professional capabilities of radiologists.</p>
<h3>Data Ethics Emergency Drill: A Toolbox for Discussing Responsible AI for Industry Teams</h3>
<p>Authors: Dylan Rees, Paul Marshall, David Hopkinson, Vanessa Aisyahsari Hanschke, Merve Alanyali</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147218">Link</a></p>
<p>Abstract: Researchers urge technology practitioners such as data scientists to consider the impacts and ethical implications of algorithmic decisions. However, unlike programming, statistics, and data management, discussion of ethical implications is rarely included in standard data science training. To begin to address this gap, we designed and tested a toolbox called the data ethics emergency drill (DEED) to help data science teams discuss and reflect on the ethical implications of their work. The DEED is a roleplay of a fictional ethical emergency scenario that is contextually situated in the team’s specific workplace and applications. This paper outlines the DEED toolbox and describes three studies carried out with two different data science teams that iteratively shaped its design. Our findings show that practitioners can apply lessons learnt from the roleplay to real-life situations, and how the DEED opened up conversations around ethics and values.</p>
<h3>JupyterLab in Retrograde: Contextual Notifications That Highlight Fairness and Bias Issues for Data Scientists</h3>
<p>BEST_PAPER</p>
<p>Authors: Aleksander Binion, Ahmad Bamba, Luca Dovichi, Kevin Bryson, Arthur Borem, Blase Ur, Galen Harrison</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147904">Link</a></p>
<p>Abstract: Current algorithmic fairness tools focus on auditing completed models, neglecting the potential downstream impacts of iterative decisions about cleaning data and training machine learning models. In response, we developed Retrograde, a JupyterLab environment extension for Python that generates real-time, contextual notifications for data scientists about decisions they are making regarding protected classes, proxy variables, missing data, and demographic differences in model performance. Our novel framework uses automated code analysis to trace data provenance in JupyterLab, enabling these notifications. In a between-subjects online experiment, 51 data scientists constructed loan-decision models with Retrograde providing notifications continuously throughout the process, only at the end, or never. Retrograde's notifications successfully nudged participants to account for missing data, avoid using protected classes as predictors, minimize demographic differences in model performance, and exhibit healthy skepticism about their models.</p>
<h3>Understanding Contestability on the Margins: Implications for the Design of Algorithmic Decision-making in Public Services</h3>
<p>Authors: Sohini Upadhyay, Naveena Karusala, Rajesh Veeraraghavan, Krzysztof Gajos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148034">Link</a></p>
<p>Abstract: Policymakers have established that the ability to contest decisions made by or with algorithms is core to responsible artificial intelligence (AI). However, there has been a disconnect between research on contestability of algorithms, and what the situated practice of contestation looks like in contexts across the world, especially amongst communities on the margins. We address this gap through a qualitative study of follow-up and contestation in accessing public services for land ownership in rural India and affordable housing in the urban United States. We find there are significant barriers to exercising rights and contesting decisions, which intermediaries like NGO workers or lawyers work with communities to address. We draw on the notion of accompaniment in global health to highlight the open-ended work required to support people in navigating violent social systems. We discuss the implications of our findings for key aspects of contestability, including building capacity for contestation, human review, and the role of explanations. We also discuss how sociotechnical systems of algorithmic decision-making can embody accompaniment by taking on a higher burden of preventing denials and enabling contestation.</p>
<h3>In-Between Visuals and Visible: The Impacts of Text-to-Image Generative AI Tools on Digital Image-making Practices in the Global South</h3>
<p>Authors: Syed Ishtiaque Ahmed, Arundhuti Dey, Sadaf Khan, Dipannita Nandi, Nusrat Jahan Mim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147687">Link</a></p>
<p>Abstract: This paper joins the growing body of HCI work on critical AI studies and focuses on the impact of Generative Artificial Intelligence (GAI) tools in Bangladesh. While the West has started to examine the limitations and risks associated with these tools, their impacts on the Global South have remained understudied. Based on our interviews, focus group discussions (FGD), and social media-based qualitative study, this paper reports how popular text-to-image GAI tools (ex., DALL-E, Midjourney,  Stable Diffusion, Firefly) are affecting various image-related local creative fields. We report how these tools limit the creative explorations of marginal artists, struggle to understand linguistic nuances, fail to generate local forms of art and architecture, and misrepresent the diversity among citizens in the image production process. Drawing from a rich body of work on critical image theory, postcolonial computing, and design politics, we explain how our findings are pertinent to HCI's broader interest in social justice, decolonization, and global development.</p>
<h2>Highlight on Learning and Education</h2>
<h3>Emergency Remote Education in Nigeria: Challenges and Design Opportunities</h3>
<p>Authors: Rebecca Nicholson, Opeyemi Dele-Ajayi, Kemi Fasae, Rebecca Strachan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147787">Link</a></p>
<p>Abstract: There are currently approximately 20.2 million children in Nigeria out of school, exacerbated by ongoing conflicts demonstrating an ongoing need for Emergency Remote Education (ERE). Despite this, Nigeria remains an under-explored context and the specific challenges of providing ERE there are not fully understood. This paper reports on a mixed methods study of teachers experiences of enacting ERE in Nigeria in April 2020 with a questionnaire (n=374), diary study and follow up interviews (n=20) carried out. The contributions of the paper are two-fold; firstly, an in-depth study of ERE in Nigeria, demonstrating that teachers used WhatsApp as a tool of practical necessity, configured it to create a continued sense of place, and continued to enact largely traditional pedagogies. Secondly, through reflection on these findings, we offer initial design considerations for technology use in ERE in low resource settings before outlining continuing design challenges for HCI researchers in this context. </p>
<h3>Establishing Heuristics for Improving the Usability of GUI Machine Learning Tools for Novice Users</h3>
<p>Authors: Haifa Al-Shammare, Malak Baslyman, Asma Yamani</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148181">Link</a></p>
<p>Abstract: Machine learning (ML) tools with graphical user interfaces (GUI) are facing demand from novice users who do not have the background of their underlying concepts. These tools are frequently complex and pose unique challenges in terms of interaction and comprehension by novice users. There is yet to be an established set of usability heuristics to guide and assess GUI ML tool design. To address this gap, in this paper, we extend Nielsen's heuristics for evaluating GUI ML Tools through a set of empirical evaluations. To validate the proposed heuristics, user testing was conducted by novice users on a prototype that reflects those heuristics. Based on the results of the evaluations, our new heuristics set improves upon existing heuristics in the context of ML tools. It can serve as a resource for practitioners designing and evaluating these tools.</p>
<h3>Envisioning Support-Centered Technologies for Language Practice and Use: Needs and Design Opportunities for Immigrant English Language Learners (ELLs)</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Geoff Kaufman, Adinawa Adjagbodjou</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146672">Link</a></p>
<p>Abstract: Immigrant English Language Learners (ELLs) who are learning the majority language in a new country are required to participate in the informal language space on a daily basis to gain access to essential economic and social resources. In contrast to formal language spaces, which extensive literature has researched, exploration of informal language spaces, which present a number of linguistic and psychological challenges without scaffolded support, remains limited. In this work, we conduct a qualitative interview study to explore the use of support tools to facilitate participation in daily life for ELLs, investigating the efficacy of these tools, obstacles encountered, and perceptions of what defines positive and negative experiences. We aim to contribute a deeper, more nuanced understanding of the experience of language use in practical scenarios for ELLs and present a set of actionable considerations for designers working with ELLs that prioritize their linguistic, affective, and social needs.</p>
<h3>Understanding Takeovers and Telestration in Laparoscopic Surgery to Inform Telementoring System Design</h3>
<p>Authors: Jocelyne Troccaz, Sandrine Voros, Geoffroy Canlorbe, Ignacio Avellino, Solène Lambert</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147383">Link</a></p>
<p>Abstract: Surgery is primarily taught through mentoring, where an expert mentor supervises a mentee performing surgery, taking over when necessary. Telementoring systems aim to provide mentees with access to remote mentors, but the physical distance between mentors and mentees poses unique challenges to surgical training. We investigate the underlying needs leading to takeovers in onsite mentoring and assess mentors' ability to fulfill address these needs remotely using existing telestration tools, namely pointers and drawings on shared views. Through interviews and workshops with expert surgeons, we find that (1) mentors take over to convey gestures related to instrument placement, tissue displacement, force, and movement, (2) mentors gather information about location of tissue, equipment, and instruments, as well as gesture constraints, and (3) surgeons judge telestration insufficient for these needs. Based on this gap between onsite mentoring practices and telementoring tools, we discuss novel tools to address these needs and their evaluation.</p>
<h3>WriteUpRight: Regulating Children’s Handwriting Body Posture by Unobstrusively Error Amplification via Slow Visual Stimuli on Tablets</h3>
<p>Authors: Chenyang Wang, Daniel Tozadore, Pierre Dillenbourg, Barbara Bruno</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146950">Link</a></p>
<p>Abstract: Maintaining a proper body posture during interactions with educational tablet applications is crucial for children's physical well-being and task performance, especially considering digital tablet's increasingly pervasive use in classrooms. In this work we propose WriteUpRight, an interaction system for children's self-regulation of posture while writing on a tablet. The system relies on slowly deforming visual stimuli appearing on the tablet screen and compares two posture correction strategies: the Error Amplification method seeks to induce self-correction by amplifying the postural error, while the Error Correction method seeks to unobtrusively nudge the child towards the correct posture. Through a formative design and a user study with 42 children, we demonstrate the effectiveness of our solution and the advantages of the Error Amplification method with respect to the Error Correction method. The system shows potential for helping children maintain a proper head-screen distance and head roll angle during reading and writing tasks on tablets.</p>
<h3>Interrupting for Microlearning: Understanding Perceptions and Interruptibility of Proactive Conversational Microlearning Services</h3>
<p>Authors: Uichin Lee, Chanhee Lee, Jiwook Lee, Minyeong Kim, Youngji Koh, Auk Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148333">Link</a></p>
<p>Abstract: Significant investment of time and effort for language learning has prompted a growing interest in microlearning. While microlearning requires frequent participation in 3-to-10-minute learning sessions, the recent widespread of smart speakers in homes presents an opportunity to expand learning opportunities by proactively providing microlearning in daily life. However, such proactive provision can distract users. Despite the extensive research on proactive smart speakers and their opportune moments for proactive interactions, our understanding of opportune moments for more-than-one-minute interactions remains limited. This study aims to understand user perceptions and opportune moments for more-than-one-minute microlearning using proactive smart speakers at home. We first developed a proactive microlearning service through six pilot studies (n=29), and then conducted a three-week field study (n=28). We identified the key contextual factors relevant to opportune moments for microlearning of various durations, and discussed the design implications for proactive conversational microlearning services at home.</p>
<h3>The Realities of Evaluating Educational Technology in School Settings</h3>
<p>Authors: Susan Lechelt, Rebecca Nicholson, Ahmed Kharrufa, Abrar Almjally, Anthony Trory, Kate Howland, Megan Venn-Wycherley, Vidya Sarangapani</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150648">Link</a></p>
<p>Abstract: HCI researchers are increasingly interested in the evaluation of educational technologies in context, yet acknowledge that challenges remain regarding the logistical, material and methodological constraints of this approach to research.</p>
<p>Through the analysis of the authors’ contributed thematic research vignettes, the following article exposes the practical realities of evaluating educational technologies in school settings. This includes insights into the planning stages of evaluation, the relationship between the researcher and the school environment, and the impact of the school context on the data collection process. </p>
<p>We conclude by providing an orientation for the design of HCI educational technology research undertaken in school contexts, providing guidance such as considering the role of modular research design, clarifying goals and expectations with school partners, and reporting researcher positionality.</p>
<h2>Highlight on Input and Control Techniques</h2>
<h3>Ultrasonic Mid-Air Haptics on the Face: Effects of Lateral Modulation Frequency and Amplitude on Users’ Responses</h3>
<p>Authors: Xu Sun, Bingjian Liu, Ruiheng Lan, Qingfeng Wang</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148049">Link</a></p>
<p>Abstract: Ultrasonic mid-air haptics (UMH) has emerged as a promising technology for facial haptic applications, offering the advantage of contactless and high-resolution feedback. Despite this, previous studies have fallen short in thoroughly investigating individuals’ responses to UMH on the face. To bridge this gap, this study compares UMH feedback on various facial sites using the lateral modulation (LM) method. This method allows us to explore the impact of two LM parameters -frequency and amplitude - on both perceptual (intensity) and emotional (valence and arousal) responses. With 24 participants, positive relationships between LM amplitude and perceived intensity and arousal were observed, and the effect of LM frequency varied across facial sites. These findings not only contribute to the development of design guidelines and potential applications for UMH on the face, but also provide insights aimed to enhance the effectiveness and overall user experience in haptic interactions across diverse facial sites.</p>
<h3>Model-based Evaluation of Recall-based Interaction Techniques</h3>
<p>Authors: Bruno Fruchard, Gilles Bailly, Julien Gori</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147569">Link</a></p>
<p>Abstract: This article tackles two challenges of the empirical evaluation of interaction techniques that rely on user memory, such as hotkeys, here coined Recall-based interaction techniques (RBITs): (1) the lack of guidance to design the associated study protocols, and (2) the difficulty of comparing evaluations performed with different protocols.</p>
<p>To address these challenges, we propose a model-based evaluation of RBITs. This approach relies on a computational model of human memory to (1) predict the informativeness of a particular protocol through the variance of the estimated parameters (Fisher Information) (2) compare RBITs recall performance based on the inferred parameters rather than behavioral statistics, which has the advantage of being independent of the study protocol. We also release a Python library implementing our approach to aid researchers in producing more robust and meaningful comparisons of RBITs.</p>
<h3>Behavioral Differences between Tap and Swipe: Observations on Time, Error, Touch-point Distribution, and Trajectory for Tap-and-swipe Enabled Targets</h3>
<p>Authors: Hiroki Usuba, Junichi Sato, Shota Yamanaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147678">Link</a></p>
<p>Abstract: Existing guidelines for designing targets on smartphones often focus on single-tap operations for accurate selection. However, smartphone interfaces can support both tap and swipe actions. We explored user-performance differences between tap and swipe in two crowdsourced experiments using bar and square targets. Results indicated longer operation times, higher error rates, and significantly shifted touch points for swipe compared to tap. Our findings imply that current target-size guidelines may not apply to swipe-operated targets, and they reveal new research opportunities for swipeable-target designs.</p>
<h3>Impact of Fingernails Length on Mobile Tactile Interaction</h3>
<p>Authors: Céline Coutrix, Camélia Prost</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147406">Link</a></p>
<p>Abstract: Mobile users have fingernails of different lengths. This paper measures the impact of fingernail length on the use of tactile mobile phones. We first conducted interviews with participants wearing long fingernails. They reported difficulties and non-satisfactory coping strategies to hold their phone securely and acquire targets accurately. We then conducted three experiments comparing different lengths of fingernails (0 mm, 5 mm, and 10 mm). Our results quantify the drop in comfort and efficiency. We measured the range of incidental pitch angle on the surface, the comfortable and useful area of the thumb, and the target acquisition efficiency. 10 mm fingernails consistently decrease by 57 % the range of the finger pitch angle, by 36 % the comfortable area of the thumb, and by 24 % the throughput when acquiring targets. This paper contributes guidelines for future inclusive devices and techniques to also support users with long fingernails.</p>
<h3>Controlling the Rooms: How People Prefer Using Gestures to Control Their Smart Homes</h3>
<p>Authors: Susanne Boll, Heiko Mueller, Masoumehsadat Hosseini</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147598">Link</a></p>
<p>Abstract: Gesture interactions have become ubiquitous, and with increasingly reliable sensing technology we can anticipate their use in everyday environments such as smart homes. Gestures must meet users' needs and constraints in diverse scenarios to gain widespread acceptance. Although mid-air gestures have been proposed in various user contexts, it is still unclear to what extent users want to integrate them into different scenarios in their smart homes, along with the motivations driving this desire. Furthermore, it is uncertain whether users will remain consistent in their suggestions when transitioning to alternative scenarios within a smart home.</p>
<p>This study contributes methodologically by adapting a bottom-up frame-based design process. We offer insights into preferred devices and commands in different smart home scenarios. Using our results, we can assist in designing gestures in the smart home that are consistent with individual needs across devices and scenarios, while maximizing the reuse and transferability of gestural knowledge.</p>
<h3>Grip-Reach-Touch-Repeat: A Refined Model of Grasp to Encompass One-Handed Interaction with Arbitrary Form Factor Devices</h3>
<p>Authors: Marcos Serrano, Tao Xu, Liang He, Chaoyi Wu, Anne Roudaut, Kaixing Zhao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146671">Link</a></p>
<p>Abstract: We extend grasp models to encompass one-handed interaction with arbitrary shaped touchscreen devices. Current models focus on how objects are stably held by external forces. However, with touchscreen devices, we postulate that users do a trade-off between holding securely and exploring interactively. To verify this, we first conducted a qualitative study which asked participants to grasp 3D printed objects while considering its different interactivity. Results of the study confirm our hypothesis and reveal obvious change in postures. To further verify this trade-off and design interactions, we developed a simulation software capable of computing the stability of a grasp and its reachability. We conducted the second study based on the observed predominant grasps to validate our software with a glove. Results also confirm a consistent trade-off between stability and reachability. We conclude by discussing how this research can help designing computational tools focusing on hand-held interactions with arbitrary shaped touchscreen devices.</p>
<h3>Take a Seat, Make a Gesture: Charting User Preferences for On-Chair and From-Chair Gesture Input</h3>
<p>Authors: Alexandru-Tudor Andrei, Radu-Daniel Vatavu, Laura-Bianca Bilius</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147142">Link</a></p>
<p>Abstract: We explore the chair as a referential frame for facilitating hand gesture input to control interactive systems. First, we conduct a Systematic Literature Review on the topic of interactions supported by chairs, and uncover little research on harnessing everyday chairs for input, limited to chair rotation and tilting movements. Subsequently, to understand end users' preferences for gestures performed on the chair's surface (i.e., on-chair gestures) and in the space around the chair (i.e., from-chair gestures), we conduct an elicitation study involving 54 participants, 3 widespread chair variations-armchair, office-chair, and stool,- and 15 referents encompassing common actions, digital content types, and navigation commands for interactive systems. Our findings reveal a preference for unimanual gestures implemented with strokes, hand poses, and touch input, with specific nuances and kinematic profiles according to the chair type. Based on our findings, we propose a range of implications for interactive systems leveraging on-chair and from-chair gestures.</p>
<h3>Simulating Interaction Movements via Model Predictive Control</h3>
<p>Authors: Florian Fischer, Arthur Fleig, Markus Klar, Jörg Müller, Miroslav Bachinski</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150926">Link</a></p>
<p>Abstract: We present a Model Predictive Control (MPC) framework to simulate movement in interaction with computers, focusing on mid-air pointing as an example. Starting from understanding interaction from an Optimal Feedback Control (OFC) perspective, we assume that users aim at minimizing an internalized cost function, subject to the constraints imposed by the human body and the interactive system. Unlike previous approaches used in HCI, MPC can compute optimal controls for nonlinear systems. This allows to use state-of-the-art biomechanical models and handle nonlinearities that occur in almost any interactive system. Instead of torque actuation, our model employs second-order muscles acting directly at the joints. We compare three different cost functions and evaluate the simulation against user movements in a pointing study. Our results show that the combination of distance, control, and joint acceleration cost matches individual users’ movements best, and predicts movements with an accuracy that is within the between-user variance. To aid HCI researchers and designers in applying our approach for different users, interaction techniques, or tasks, we make our SimMPC framework, including CFAT, a tool to identify maximum voluntary torques in joint-actuated models, publicly available, and give step-by-step instructions.</p>
<h2>Highlight on Security and Privacy</h2>
<h3>Exploring Privacy Practices of Female mHealth Apps in a Post-Roe World</h3>
<p>Authors: Ruba Abu-Salma, Mark Warner, Dilisha Patel, Ina Kaleva, Lisa Malki</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147278">Link</a></p>
<p>Abstract: Mobile apps which support women’s health have developed rapidly alongside the increasing de-stigmatisation of female reproductive wellbeing. However, the ubiquity of these apps has advanced the practice of intimate surveillance and the commodification of sensitive user data. While the overturning of Roe v. Wade has prompted reflection on the privacy and safety implications of female mobile health (mHealth) apps, the privacy practices of these apps have yet to be thoroughly examined in a post-Roe world. We investigated the privacy practices of~20 popular female mHealth apps, combining a thematic analysis of Data safety sections and privacy policies with a privacy-focused usability inspection. Our findings revealed problematic practices, including inconsistencies across privacy policy content and privacy-related app features, flawed consent and data deletion mechanisms, and covert gathering of sensitive data. We present recommendations for improving privacy practices, and call for a dedicated focus not only on user privacy, but also safety.</p>
<h3>Counting Carrds: Investigating Personal Disclosure and Boundary Management in Transformative Fandom</h3>
<p>Authors: Kelly Wang, Dan Bially Levy, Kien Nguyen, Abigail Marsh, Ada Lerner</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147455">Link</a></p>
<p>Abstract: The privacy practices of transformative fandom are of interest to HCI researchers both for the community's high proportion of queer members and for the community's sophisticated privacy norms and behaviors. We investigated fans' use of single-serving websites on Carrd.co ("Carrds") as personal profiles linked from Twitter accounts. We scraped Twitter to gather 5252 Carrds from fans in a variety of fandoms, which we analyzed using a combination of keyword searches and hand-coding. Fans' Carrds frequently disclose queer identity, and articulate a complex system of community values and boundary management. Inspired by how these findings aren't well-explained by individual theories of privacy, we articulate first steps towards a theory of collective privacy based in a communal process of values construction, trust building, and personal disclosure that we believe helps us to understand the sophisticated nature of fans' observed behaviors.</p>
<h3>Stochastic Machine Witnesses at Work: Today's Critiques of Taylorism are Inadequate for Workplace Surveillance Epistemologies of the Future</h3>
<p>Authors: Sandy Gould</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147223">Link</a></p>
<p>Abstract: I argue that epistemologies of workplace surveillance are shifting in fundamental ways, and so critiques must shift accordingly. I begin the paper by relating Scientific Management to Human-Centred Computing's ways of knowing through a study of 'metaverse' virtual reality workplaces. From this, I develop two observations. The first is that today's workplace measurement science does not resemble the science that Taylor developed for Scientific Management. Contemporary workplace science is more passive, more intermediated and less controlled. The second observation is that new forms of workplace measurement challenge the norms of empirical science. Instead of having credentialed human witnesses observe phenomena and agree facts about them, we instead make outsourced, uncredentialed stochastic machine witnesses responsible for producing facts about work. With these observations in mind, I assert that critiques of workplace surveillance still framed by Taylorism will not be fit for interrogating workplace surveillance practices of the future.</p>
<h3>‘We Do Not Have the Capacity to Monitor All Media’: A Design Case Study on Cyber Situational Awareness in Computer Emergency Response Teams</h3>
<p>BEST_PAPER</p>
<p>Authors: Christian Reuter, Markus Bayer, Thea Riebe, Marc-André Kaufhold</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146975">Link</a></p>
<p>Abstract: Computer Emergency Response Teams (CERTs) provide advisory, preventive and reactive cybersecurity services for authorities, citizens, and businesses. However, their responsibility of monitoring, analyzing, and communicating cyber threats have become challenging due to the growing volume and varying quality of information disseminated through public channels. Based on a design case study conducted from 2021 to 2023, this paper combines three iterations of expert interviews, design workshops and cognitive walkthroughs to design an automated, cross-platform and real-time cybersecurity dashboard. By adopting the notion of cyber situational awareness, the study extracts user requirements and design heuristics for enhanced threat awareness and mission awareness in CERTs, discussing the aspects of source integration, data management, customizable visualization, relationship awareness, information assessment, software integration, (inter-)organizational collaboration, and communication of stakeholder warnings.</p>
<h3>Analyzing Security and Privacy Advice During the 2022 Russian Invasion of Ukraine on Twitter</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Stefan Dietze, Sascha Fahl, Noah Wöhler, Harshini Sri Ramulu, Christian Stransky, Dominik Wermke, Juliane Schmüser, Felix Bensmann, Dimitar Dimitrov, Sebastian Schellhammer, Yasemin Acar</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147984">Link</a></p>
<p>Abstract: The Russian Invasion of Ukraine in 2022 resulted in a rapidly changing cyber threat environment globally and incentivized the sharing of security and privacy advice on social media. </p>
<p>Previous research found a strong impact of online security advice on end-user behavior. </p>
<p>Twitter is an important platform for sharing information in crises.</p>
<p>We examined 306 tweets with security and privacy advice related to the Ukrainian war, and created a taxonomy of 224 unique pieces of advice in seven categories, targeted at individuals or organizations in Ukraine and elsewhere.</p>
<p>While our findings include untargeted and generic advice known from previous research, we identify novel advice specific to the invasion, offers for individual consultation, and misinformation on security and privacy advice as a new threat. </p>
<p>Our findings highlight the strengths and shortcomings of the security and privacy advice given online during the invasion and establish areas for improvements and future research.</p>
<h3>In Focus, Out of Privacy: The Wearer's Perspective on the Privacy Dilemma of Camera Glasses</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Adrian Dabrowski, Shreya Tomar, Divyanshu Bhardwaj, Katharina Krombholz, Alexander Ponticello</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147215">Link</a></p>
<p>Abstract: The rising popularity of camera glasses challenges societal norms of recording bystanders and thus requires efforts to mediate privacy preferences. We present the first study on the wearers' perspectives and explore privacy challenges associated with wearing camera glasses when bystanders are present. We conducted a micro-longitudinal diary study (N=15) followed by exit interviews with existing users and people without prior experience. </p>
<p>Our results show that wearers consider the currently available privacy indicators ineffective. They believe the looks and interaction design of the glasses conceal the technology from unaware people. Due to the lack of effective privacy-mediating measures, wearers feel emotionally burdened with preserving bystanders' privacy. We furthermore elicit how this sentiment impacts their usage of camera glasses and highlight the need for technical and non-technical solutions. Finally, we compare the wearers' and bystanders' perspectives and discuss the design space of a future privacy-preserving ecosystem for wearable cameras.</p>
<h3>The Impact of Risk Appeal Approaches on Users’ Sharing Confidential Information</h3>
<p>Authors: Peter Story, Elham Al Qahtani, Mohamed Shehab</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148170">Link</a></p>
<p>Abstract: End-to-end encrypted email can help users prevent unauthorized access of their sensitive information. However, many users struggle to utilize encryption tools due to usability issues and low understanding. Thus, we designed video messaging interventions to persuade users to use email encryption software (Virtru). Our first intervention combined Protection Motivation Theory with Anticipated Regret (PMT+AR), and was designed to help participants understand the benefits of using encrypted email. Our second intervention also included Action Planning (PMT+AR+AP), and was designed to help participants recognize opportunities to use encrypted email. We conducted online interviews with 121 participants and used a follow-up survey to evaluate our interventions. Pre-intervention, participants believed that Gmail encrypted standard email content by default. Post-intervention, both messages made participants more likely to utilize encrypted email in a simulated information sharing scenario compared to Control. Our results suggest that our interventions can help people adopt protective technologies and address their misconceptions about them.</p>
<h2>Highlight on Games and Play</h2>
<h3>Comic-making to Study Game-making: Using Comics in Qualitative Longitudinal Research on Game Development</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Annakaisa Kultima, Solip Park, Perttu Hämäläinen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147421">Link</a></p>
<p>Abstract: This paper reports the research method of the “Game Expats Story (GES)” project that used qualitative longitudinal research (“QLR”) incorporated with art-based research (“ABR”) in the context of game research. To facilitate greater participant engagement and a higher retention rate of longitudinal participants, we created comic artworks simultaneously while researching the case of migrant/expatriate game developers (“game expats”) in Finland 2020-2023 in two phases: (i) art creation as part of the qualitative data analysis to supplement the researcher’s inductive abstraction of the patterns, and (ii) artwork as a communication and recall tool when periodically engaging with the informants over the multi-year project span. Our findings suggest that the method of QLR-ABR helps game research as it positively influences the researcher’s abstractions of longitudinal data and participants’ continuous engagement with a high retention rate of 89%. We conclude that incorporating artistic methods provides new opportunities for ethnographic research on game development.</p>
<h3>Understanding Neurodiverse Social Play Between Autistic and Non-Autistic Children</h3>
<p>Authors: Alison Oldfield, Oussama Metatla, Brooke Morris, Hayati Havlucu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147697">Link</a></p>
<p>Abstract: Social play supports children to develop essential life skills and foster friendships. However, autistic and non-autistic children often do not have equal opportunities to engage in social play. Previous research to improve these opportunities tends to invoke social skill interventions solely for autistic children or is focused on designing for only one group, rather than considering the interactions or needs of all children in neurodiverse groups. In order to understand the different experiences of children during social play, we conducted interviews with 6 professionals who support neurodiverse social play and undertook observation sessions of 36 autistic and non-autistic children during unstructured social play. Our findings move beyond the existing characterizations of autistic social play and build upon the double empathy problem to capture and consider the needs of all children in neurodiverse playgroups. We argue these findings could be used to inform future neurodiverse social play technology design in HCI.</p>
<h3>Ecological In/Congruence: Becoming Sensitised to Nature in Video Games through Humanistic First-Person Research</h3>
<p>Authors: Oğuz 'Oz' Buruk, Velvet Spors, Juho Hamari</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147799">Link</a></p>
<p>Abstract: The ongoing ecological crisis is the current biggest threat for our species. As we attempt to address the situation through policy, interventions, and education, we urgently need to understand how people encounter and relate to nature: As it is, in the world, and portrayed through different media. As an exemplary medium facilitating digital nature, this paper focuses on video games. Using first-person research methods, we report on the first author sensitising themselves to nature as a ubiquitous feature, theme, and actor in video games. They played eight nature-focused games for three months. Through auto-ethnography, close reading and "noticing'' (after Tsing), we make sense of their experiences using the humanistic concept of ecological (in)congruence: We draw out the relational gap and potential meanings between real nature and its virtual equivalent. Based on these insights, we outline two design impulses for how the HCI community might approach nature—within games and beyond.</p>
<h3>Community, Storytelling, and Play: Making and Breaking Rituals in Destiny 2</h3>
<p>Authors: Bjarke Larsen, Elin Carstensdottir</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147767">Link</a></p>
<p>Abstract: Modern video game development relies increasingly on live service models and storytelling, putting strain on developer-player interactions and community management, the success of which is key to the success of such games. In this paper we report on a 2.5-year ethnography study on the Destiny player community, specifically on how players and developers interact and communicate about the game, and how is this interaction is affected by and affects ongoing rituals and storytelling in that game.</p>
<p>Our findings indicate that rituals of play are fundamental. They reinforce the players’ collective experiences, created by the ongoing relationship between the players and developers. Players test and break boundaries of rituals, and developers continually adjust and experiment with those boundaries in turn. Our findings show that developers create positive feedback loops from the community when they lean into creativity efforts and boundary-breaking from players, and use storytelling directly as a community management tool.</p>
<h3>A Design Framework for Reflective Play</h3>
<p>Authors: Matthew Whitby, Seth Cooper, Elisa Mekler, Ioanna Iacovides, Kutub Gandhi, Josh Aaron Miller, Mehmet Kosa</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146677">Link</a></p>
<p>Abstract: Recent research has begun exploring games as a medium for reflection due to their affordances as interactive systems of challenge. However, little effort has been put into (1) synthesizing insights across studies and disciplines and (2) translating the academic work on reflective play into practical takeaways for game developers. This article takes the first steps toward summarizing existing work on reflective play and translating insights for practical implementation by identifying key game elements present in games that evoke reflection. We divide these elements into five approaches: Disruptions, Slowdowns, Questioning, Revisiting, and Enhancers. Finally, we provide an actionable supplement for practicing game developers to apply these concepts to their games.</p>
<h3>Playing on Hard Mode: Accessibility, Difficulty and Joy in Video Game Adoption for Gamers with Disabilities</h3>
<p>Authors: Jon Froehlich, James Fogarty, Jesse Martinez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146616">Link</a></p>
<p>Abstract: Video games often pose accessibility barriers to gamers with disabilities, yet there is no standard method for identifying which games have barriers, what those barriers are, and whether and how they can be overcome. We propose and explore three phases of the “game adoption process”: Discovery, Evaluation, and Adaptation. To advance understanding of how gamers with disabilities experience this process, the resources and strategies they use, and the challenges experienced, we conducted an interview study with thirteen gamers with disabilities with differing backgrounds. We then engage with existing theories of consequence-based accessibility, of difficulty, and of identity-based gaming to better understand how these processes manifest “access difficulty” and to characterize the experience of “disabled gaming.” Finally, we present design recommendations for game developers and distributors to better support gamers with disabilities in the game adoption process by engaging with community-made resources, supporting socially-created access, and creating customizable experiences with opportunities for unconventional play.</p>
<h3>Outplay Your Weaker Self: A Mixed-Methods Study on Gamification to Overcome Procrastination in Academia</h3>
<p>Authors: Sofia Schöbel, Harald von Korflesch, Manuel Schmidt-Kraepelin, Ali Sunyaev, Mathias Ullrich, Jeanine Kirchner-Krath</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147416">Link</a></p>
<p>Abstract: Procrastination is the deliberate postponing of tasks knowing that it will have negative consequences in the future. Despite the potentially serious impact on mental and physical health, research has just started to explore the potential of information systems to help students combat procrastination. Specifically, while existing learning systems increasingly employ elements of game design to transform learning into an enjoyable and purposeful adventure, little is known about the effects of gameful approaches to overcome procrastination in academic settings. This study advances knowledge on gamification to counter procrastination by conducting a mixed-methods study among higher education students. Our results shed light on usage patterns and outcomes of gamification on self-efficacy, self-control, and procrastination behaviors. The findings contribute to theory by providing a better understanding of the potential of gamification to tackle procrastination. Practitioners are supported by implications on how to design gamified learning systems to support learners in self-organized work.</p>
<h2>Highlight on Diversity In HCI</h2>
<h3>A Playbook to be Proud of: Making the Case for LGBTQ+ Inclusive User Account Design</h3>
<p>Authors: Morgan Ames, Beatrice Fadrigon, Jane Lupica, Princess Gordon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148092">Link</a></p>
<p>Abstract: Digital platforms often require users to select from a limited set of options that may force them to misrepresent their gender identities and sexual orientation, which disproportionately affects the LGBTQ+ population. To provide digital product teams with a feasible industry-focused tool to ensure the inclusion of this population, we surveyed 151 participants, including 81 who identify as LGBTQ+; conducted five interviews with LGBTQ+ participants and 11 interviews with product managers in the technology industry; and analyzed the user account creation processes of 45 digital platforms commonly used or mentioned in survey responses to understand LGBTQ+ users’ wants, needs, and pain points in navigating user account sign-up. Participants recounted instances of microaggressions or micro-affirmations, and often had strong feelings about companies based on their account creation experience. Based on these results, we present a ‘Playbook’ of design recommendations, which is online at bit.ly/LGBTInclusive_UAGuide. </p>
<h3>Unpacking Norms, Narratives, and Nourishment: A Feminist HCI Critique on Food Tracking Technologies</h3>
<p>Authors: Max Birk, Daisy O'Neill, Regan Mandryk</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148303">Link</a></p>
<p>Abstract: Food tracking applications (apps) can provide benefits (e.g., helping diagnose food intolerances) but can also create harm (e.g., facilitating disordered eating). However, food tracking apps—viewed as a women’s health issue, and critically examined through the lens of feminist HCI—are absent from the discourse of sociocultural, ethical, and political implications of apps designed to track bodily data. We use a walkthrough method to critically analyze three commercial food tracking apps with differing marketing narratives and designs, applying a reflexive feminist lens grounded in a perspective of fat liberation. We articulate how these apps reproduce normativities of food and nutrition, health, and bodies, and how they perpetuate narratives of embodiment, simplification and quantification of health, and neoliberalism and the individualization of health. Our work exposes the normativities of bodies being propagated by food tracking apps, spotlighting how designs and interaction features are situated within prevalent anti-fat narratives. </p>
<h3>Cruising Queer HCI on the DL: A Literature Review of LGBTQ+ People in HCI</h3>
<p>Authors: Ellen Simpson, Haiyi Zhu, Jed Brubaker, Sarah Fox, Jordan Taylor, Anh-Ton Tran</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147332">Link</a></p>
<p>Abstract: LGBTQ+ people have received increased attention in HCI research, paralleling a greater emphasis on social justice in recent years. However, there has not been a systematic review of how LGBTQ+ people are researched or discussed in HCI. In this work, we review all research mentioning LGBTQ+ people across the HCI venues of CHI, CSCW, DIS, and TOCHI. Since 2014, we find a linear growth in the number of papers substantially about LGBTQ+ people and an exponential increase in the number of mentions. Research about LGBTQ+ people tends to center experiences of being politicized, outside the norm, stigmatized, or highly vulnerable. LGBTQ+ people are typically mentioned as a marginalized group or an area of future research. We identify gaps and opportunities for (1) research about and (2) the discussion of LGBTQ+ in HCI and provide a dataset to facilitate future Queer HCI research.</p>
<h3>Silver-Tongued and Sundry: Exploring Intersectional Pronouns with ChatGPT</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Takao Fujii, Madeleine Steeds, Katie Seaborn</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148287">Link</a></p>
<p>Abstract: ChatGPT is a conversational agent built on a large language model. Trained on a significant portion of human output, ChatGPT can mimic people to a degree. As such, we need to consider what social identities ChatGPT simulates (or can be designed to simulate). In this study, we explored the case of identity simulation through Japanese first-person pronouns, which are tightly connected to social identities in intersectional ways, i.e., intersectional pronouns. We conducted a controlled online experiment where people from two regions in Japan (Kanto and Kinki) witnessed interactions with ChatGPT using ten sets of first-person pronouns. We discovered that pronouns alone can evoke perceptions of social identities in ChatGPT at the intersections of gender, age, region, and formality, with caveats. This work highlights the importance of pronoun use for social identity simulation, provides a language-based methodology for culturally-sensitive persona development, and advances the potential of intersectional identities in intelligent agents.</p>
<h3>Deus Ex Machina and Personas from Large Language Models: Investigating the Composition of AI-Generated Persona Descriptions</h3>
<p>Authors: Jianxing Chi, Chang Liu, Joni Salminen, Essi Häyhänen, Wenjing Pian, Bernard Jansen</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148256">Link</a></p>
<p>Abstract: Large language models (LLMs) can generate personas based on prompts that describe the target user group. To understand what kind of personas LLMs generate, we investigate the diversity and bias in 450 LLM-generated personas with the help of internal evaluators (n=4) and subject-matter experts (SMEs) (n=5). The research findings reveal biases in LLM-generated personas, particularly in age, occupation, and pain points, as well as a strong bias towards personas from the United States. Human evaluations demonstrate that LLM persona descriptions were informative, believable, positive, relatable, and not stereotyped. The SMEs rated the personas slightly more stereotypical, less positive, and less relatable than the internal evaluators. The findings suggest that LLMs can generate consistent personas perceived as believable, relatable, and informative while containing relatively low amounts of stereotyping.</p>
<h3>Designing an Archive of Feelings: Queering Tangible Interaction with Button Portraits</h3>
<p>Authors: Noura Howell, Sylvia Janicki, Alexandra Teixeira Riggs, Anne Sullivan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147424">Link</a></p>
<p>Abstract: How can tangible, wearable design encourage affective, embodied reflections on queer history? We expand Queer HCI scholarship, using queer theory to inform the design of wearable experiences that explore archives of gender and sexuality. Our project, “Button Portraits,” invites individuals to listen to oral histories from prominent queer activists by pinning archival buttons to a wearable audio player, eliciting moving personal impressions. We observed 17 participants’ experiences with “Button Portraits,” and with semi-structured interviews, surfaced reflections on how our design evoked personal connections to history, queer self-identification, and relatability to archival materials. We offer the following design directions: (1) designing tangible archives of feeling; (2) queering tangible, wearable interactions in design; (3) designing for personal, archival experiences; and (4) designing within difference. Through this work, we foreground queer stories to affect emotional reflections on marginalized histories, entangling the complex connections between bodies, feelings, histories, and shared queer experiences.</p>
<h3>Designing Diverse Pathways for Participation</h3>
<p>Authors: Lisa Hofer, Ralf Vetter, Anna Blumenkranz, Jeanette Falk, Moritz Kubesch, Christopher Frauenberger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146734">Link</a></p>
<p>Abstract: In HCI there have been calls for diversity-driven research and insights into how this may be carried out in practice. One way of conducting diversity-driven HCI research is by doing participatory design. In this paper we contribute with lessons identified from organizing a PD workshop that enabled diverse ways of participating for our participants. The workshop design is based on insights from two years of doing diversity-driven PD with two middle school classes, which are particularly interesting settings to  explore as diverse children spend substantial time together in a period of their development that is formative for their socialisation. We describe the workshop itself before reflecting on its structure and facilitation as well as the role of the physical space and the choice of design materials with the aim to distil insights and recommendations about what researchers can do to enable diverse pathways of participation in design processes. </p>
<h3>SustAInable: How Values in the Form of Individual Motivation Shape Algorithms’ Outcomes. An Example Promoting Ecological and Social Sustainability</h3>
<p>Authors: Siegmar Otto, Sarah Zabel</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147851">Link</a></p>
<p>Abstract: When thinking about algorithms, cold lines of code and purely rational decisions may come to mind. However, this picture is incomplete. Numerous examples illustrate how human aspects shape algorithmic output (e.g., via biased training data). This study delves into how developers’ and users’ individual differences can influence algorithmic output, focusing on environmental and altruistic motivation. In an online survey, (N = 766) participants rated different emails on their likelihood of being spam as input for a hypothetical spam-filter algorithm. Participants’ environmental motivation was negatively correlated with classifying emails from environmental and humanitarian organizations as spam. Thus, individuals with a stronger environmental motivation rated the emails in such a way that the spam filter was biased toward the common good. However, altruistic motivation had no impact on the ratings. These findings suggest that environmental motivation extends beyond pro-environmental behaviors by also influencing prosocial behaviors, thus offering insights for developing sustainable algorithms.</p>
<h3>Conceptualising Fatness within HCI: A Call for Fat Liberation</h3>
<p>Authors: Aisha Sobey</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147550">Link</a></p>
<p>Abstract: Fatness sits at the intersection of many systems of oppression, such as race, gender, class, and (dis)ability. Anti-fat bias happens out in the open and is prevalent in Western society, yet there has been little to no consideration for the wider impact of digital systems in exacerbating, recreating, and repurposing anti-fat bias, or any engagement with designing for fat justice. Therefore, this paper argues that there needs to be a consideration for fat dignity in the design of digital systems, and an investigation of the (un)intended consequences of the datafication of fat lives. This paper offers a scoping literature review of HCI and Fat Studies to identify research gaps and argues that both disciplines would benefit from collaboration. Specifically, the standard of design justice would be increased through radical acceptance, and new questions could be asked to critique how technologies have been leveraged to exercise control over our bodies.</p>
<h3>Blueprints: Systematizing Behavior Change Designs - The Case of Social Comparison Theory</h3>
<p>Authors: Geke Ludden, Mailin Lemke, Roelof de Vries</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150871">Link</a></p>
<p>Abstract: To improve people’s lives, human-computer interaction researchers are increasingly designing technological solutions based on behavior change theory, such as social comparison theory. However, how researchers operationalize such a theory as a design remains largely unclear. One way to clarify this methodological step is to clearly state which functional elements of a design are aimed at operationalizing a specific behavior change theory construct to evaluate if such aims were successful. In this paper, we investigate how the operationalization of functional elements of theories and designs can be more easily conveyed. First, we present a scoping review of the literature to determine the state of operationalizations of social comparison theory as behavior change designs. Second, we introduce a new tool to facilitate the operationalization process. We term the tool: Blueprints. A blueprint explicates essential functional elements of a behavior change theory by describing it in relation to necessary, and sufficient building blocks incorporated in a design. We describe the process of developing a blueprint for social comparison theory. Lastly, we illustrate how the blueprint can be used during the design refinement and reflection process.</p>
<h2>Highlight on Communities and Online Platforms</h2>
<h3>Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool</h3>
<p>Authors: Zoya Katashinskaya, Liudmila Zavolokina, Daniel Gordon Jones, Kilian Sprenkamp, Gerhard Schwabe</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147239">Link</a></p>
<p>Abstract: In today’s digital age, characterized by rapid news consumption and increasing vulnerability to propaganda, fostering citizens' critical thinking is crucial for stable democracies. This paper introduces the design of ClarifAI, a novel automated propaganda detection tool designed to nudge readers towards more critical news consumption by activating the analytical mode of thinking, following Kahneman's dual-system theory of cognition. Using Large Language Models, ClarifAI detects propaganda in news articles and provides context-rich explanations, enhancing users' understanding and critical thinking. Our contribution is threefold: first, we propose the design of ClarifAI; second, in an online experiment, we demonstrate that this design effectively encourages news readers to engage in more critical reading; and third, we emphasize the value of explanations for fostering critical thinking. The study thus offers both a practical tool and useful design knowledge for mitigating propaganda in digital news.</p>
<h3>"Caption it in an Accessible Way That is Also Enjoyable": Characterizing User-Driven Captioning Practices on TikTok</h3>
<p>Authors: Jon Froehlich, Tessa Eagle, Emma McDonnell, Leah Findlater, Kathryn Ringland, Soo Hyun Moon, Pitch Sinlapanuntakul</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147777">Link</a></p>
<p>Abstract: As user-generated video dominates media landscapes, it poses an accessibility challenge. While disability advocacy groups globally have secured hard-won accessibility regulations for broadcast media, no such regulation of user-generated content exists. Yet, one major player in this shift, TikTok, has a culture of user-generated, creative captioning.  We sought to understand how TikTok videos are captioned and the impact current practices have on those who need captions to access audio content. Therefore, we conducted a content analysis of 300 open-captioned TikToks and contextualized these findings by interviewing nine caption users. We found that the current state of TikTok captioning does facilitate access to the platform but that a user-generated, social video-specific standard for captioning could improve caption quality and expand access. We contribute an empirical account of the state of TikTok captioning and outline steps toward a standard for user-generated captioning. </p>
<h3>SolarClub: Supporting Renewable Energy Communities through an Interactive Coordination System</h3>
<p>Authors: Hannah Knox, Georgia Panagiotidou, Kyrill Potapov, Michael Fell, Farhan Samanani, Enrico Costanza, Sonia Nkatha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146855">Link</a></p>
<p>Abstract: Energy communities are a key focus for governments around the world in support of more sustainable energy practices. However, interactive systems for supporting energy communities to coordinate around renewable energy resources are still lacking. We present SolarClub, a demand-shifting visualization system that supported households in coordinating their energy usage by booking energy-hungry activities when solar energy was available. We deployed SolarClub with four groups of neighbors (N=15) for a month. SolarClub  successfully enabled neighbors to coordinate, even when some of those participating households were less flexible. While participants reported that SolarClub did not foster a feeling of community, it helped them empathize with their neighbors. Our findings demonstrate the potential of sensor- and visualization-based technology to help understand the relation between everyday practices and resources consumption, beyond individual eco-feedback. This work thus contributes to the development of a next generation of practices and technologies that support collective action for environmental sustainability.</p>
<h3>Examining the Role of Peer Acknowledgements on Social Annotations: Unraveling the Psychological Underpinnings</h3>
<p>Authors: Haolun Wu, Susanne Lajoie, Xiaoshan Huang, Xue Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147427">Link</a></p>
<p>Abstract: This study explores the impact of peer acknowledgement on learner engagement and implicit psychological attributes in written annotations on an online social reading platform. Participants included 91 undergraduates from a large North American University. Using log file data, we analyzed the relationship between learners’ received peer acknowledgement and their subsequent annotation behaviours using cross-lag regression. Higher peer acknowledgements correlate with increased initiation of annotations and responses to peer annotations. By applying text mining techniques and calculating Shapley values to analyze 1,969 social annotation entries, we identified prominent psychological themes within three dimensions (i.e., affect, cognition, and motivation) that foster peer acknowledgment in digital social annotation. These themes include positive affect, openness to learning and discussion, and expression of motivation. The findings assist educators in improving online learning communities and provide guidance to technology developers in designing effective prompts, drawing from both implicit psychological cues and explicit learning behaviours.</p>
<h3>"Community Guidelines Make this the Best Party on the Internet": An In-Depth Study of Online Platforms' Content Moderation Policies</h3>
<p>Authors: Brennan Schaffner, Jay Shen, Genevieve Lakier, Chenhao Tan, Jacqueline Mei, Siyuan Cheng, Marshini Chetty, Arjun Nitin Bhagoji, Grace Wang, Nick Feamster</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148026">Link</a></p>
<p>Abstract: Moderating user-generated content on online platforms is crucial for balancing user safety and freedom of speech. Particularly in the United States, platforms are not subject to legal constraints prescribing permissible content. Each platform has thus developed bespoke content moderation policies, but there is little work towards a comparative understanding of these policies across platforms and topics. This paper presents the first systematic study of these policies from the 43 largest online platforms hosting user-generated content, focusing on policies around copyright infringement, harmful speech, and misleading content. We build a custom web-scraper to obtain policy text and develop a unified annotation scheme to analyze the text for the presence of critical components. We find significant structural and compositional variation in policies across topics and platforms, with some variation attributable to disparate legal groundings. We lay the groundwork for future studies of ever-evolving content moderation policies and their impact on users.</p>
<h3>A Quantitative Approach to Identifying Emergent Editor Roles in Open Street Map</h3>
<p>Authors: Bowen Zhang, Dipto Sarkar, Jennings Anderson, Robert Soden</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147183">Link</a></p>
<p>Abstract: The objective of this study was to investigate and classify the roles, or distinct contribution styles, adopted by participants within the OpenStreetMap (OSM) community. Using a quantitative analysis of mapping behaviors, we devised a methodology to identify distinct features associated with specific roles. We used an unsupervised clustering approach and unveiled eight discernible roles, or types of mapper in OSM. Each role displays specific patterns of mapping behaviors related to their habits and preferences for adding or editing map objects over time. We validated our roles, in part, using known affiliations with humanitarian and corporate organizations. Using these roles, we examine community composition and contributor retention over time. Our contributions include applying existing methods on the analysis of contributor behavior in online platforms to OSM, the identification of eight roles that can guide future research and design within OSM, and further understanding into the overall trajectory of the world's largest geospatial peer production community.</p>
<h3>Insights Into Legacy: Issues of Handover from a Partner-Initiated Project</h3>
<p>Authors: Boriana Koleva, Jocelyn Spence, Steven Benford, Emily Thorn</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146665">Link</a></p>
<p>Abstract: We report on a six-year collaboration with a small community organisation to develop and deploy a permanent physical / digital locative media experience as part on an ongoing community regeneration project. We describe how this unfolded over four phases: approach and pilot; public deployment; supporting subsequent community-led spin-off experiences; and planning legacy and technology handovers. The project was distinctive for being a Knowledge Exchange project in which we were approached and formally contracted by the community to deliver the digital technology, rather than instigating and leading a research project. We identify seven considerations for handing over technologies that combine both digital and physical elements to communities of stakeholders that encompass businesses, councils, and volunteers, and how this illuminates the unique strengths and weaknesses of Knowledge Exchange projects within the wider design research landscape.</p>
<h2>Highlight on Creative HCI</h2>
<h3>Thinking with Sound: Exploring the Experience of Listening to an Ultrasonic Art Installation</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Nick Bryan-Kinns, Andrew McPherson, Nicole Robson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147210">Link</a></p>
<p>Abstract: Entanglement theories are well established in HCI discourse. These involve a commitment to view human experience in encounters with technology as relational and contingent, and research apparatuses as co-producers rather than passive observers of phenomena. In this paper, we argue that sound is the sensory modality best suited to the investigation of entanglements. Materialist theories of sound and listening guide both the design of a novel interactive sound installation and the methodological approach of a participant study exploring the experience of listening. We present a diffractive analysis whereby micro-phenomenological interview data is read with sonic theories, generating accounts that might otherwise remain mute: the temporal fluctuation and physical feeling of proximity in listener entanglements with sound, somatic intention setting, and plural interpretations of interactivity. Finally, we offer a series of provocations for HCI to embrace qualities of the sonic and consider epistemological positions grounded in other sense modalities.</p>
<h3>What Counts as ‘Creative’ Work? Articulating Four Epistemic Positions in Creativity-Oriented HCI Research</h3>
<p>BEST_PAPER</p>
<p>Authors: Sarah Fdili Alaoui, Marianela Ciolfi Felice, Wendy Mackay, Stacy Hsueh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148122">Link</a></p>
<p>Abstract: This paper examines prevailing understandings of creativity within creative computing research through the lens of feminist epistemology. We analyze creativity support as a construct that encodes different definitions of creative work. Drawing on existing literature and practices, the paper surfaces four views about creative work that underpin current creative technologies and HCI research: problem-solving, cognitive emergence, embodied action, and tool-mediate expert activity. Each view makes different claims about the role of computing in creative work and the creative subject assumed. We articulate the attendant politics of each view and illustrate how critical feminist epistemology can serve as an analytical tool to reason about the trade-offs of various creativity definitions. The paper concludes with suggestions on integrating feminist values into creativity-oriented HCI research.</p>
<h3>The Illusion of Increased Customization: Framing Choices as a Creative Process Increases Perceived Customization</h3>
<p>Authors: Maarten Bos, Alice Moon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146702">Link</a></p>
<p>Abstract: People are increasingly able to receive customized options. Despite this abundance of options, people may not view products as customized to their wants and needs. Across five experiments, we provide evidence for a possible solution. We find evidence for the Illusion of increased customization: Framing choices as a creative process increases a chosen option’s perceived customization. Even with a constant choice set, choosing by (creative) attributes rather than choosing from all available options produces the Illusion of increased customization. The Illusion of increased customization arises in part because people feel a greater sense of co-creation when choosing via a seemingly creative process. Consequently, the Illusion of increased customization extends to choices that express preferences (e.g., liking blue over red) but is significantly diminished with choices that describe objective needs (e.g., needing a small versus large T-shirt). Additionally, heightened perceived customization from the Illusion of increased customization results in greater willingness-to-pay for the chosen option.</p>
<h3>Heart and Soul: The Ethics of Biometric Capture in Immersive Artistic Performance</h3>
<p>Authors: Ryan Kelly, Margaret Osborne, Lucy Sparrow, Ben Loveridge, Solange Glasser, Caiti Galwey</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147399">Link</a></p>
<p>Abstract: Biometric data plays a multifaceted role in innovative artistic endeavours. As artists continue to break new ground by integrating performers’ biometric data into live performances, others collect biometric data from audiences to measure engagement. Given the sensitive and personal nature of biometric data, particularly in relation to immersive technology, it is imperative to ethically consider how this data should be handled in performative contexts. To clarify these ethical considerations, we conducted a scoping review of sources related to immersive biometric performance in HCI, Performing Arts, and Social Sciences published over the past 30+ years. We detail how and why biometric data is being used in immersive artistic performance, identify associated ethical questions and concerns, and develop a framework of ethical considerations for artists and researchers in this space. In doing so, we emphasise an ‘ethics by design’ approach that considers values such as privacy and autonomy alongside artistic merit.</p>
<h3>Entangling Entanglement: A Diffractive Dialogue on HCI and Musical Interactions</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Landon Morrison, Andrew McPherson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147415">Link</a></p>
<p>Abstract: If, as several recent papers claim, we have entered a new wave of “Entanglement HCI,” then we are still at a liminal stage prior to consensus around which sources underpin this paradigm shift or how they might inform actionable approaches to design practice. Now is the time to interpret technosocial mediation from a range of disciplinary perspectives, rather than settling on a narrow canon of literature. To this end, our paper enacts a di￿ractive dialogue between researchers from di￿erent disciplines, focusing on digital musical instruments to examine how technical knowledge from design and engineering can be read against the grain of critical theories from music, media, and cultural studies. Drawing on two object lessons—keyboards and step sequencers, plus their remediations in recent musical interaction research—we highlight interdependencies of theory, design, and practice, and we show how the idea of entanglement is itself entangled in a cross-disciplinary web.</p>
<h3>Living with Cyanobacteria: Exploring Materiality in Caring for Microbes in Everyday Life</h3>
<p>Authors: Jiwei Zhou, Elvin Karana, Zjenja Doubrovski, Elisa Giaccardi</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147186">Link</a></p>
<p>Abstract: Materiality of artefacts holds the potential to intricately and dynamically shape our daily practices. We posit this capacity can be harnessed in fostering creative unfolding of everyday care practices towards living artefacts. To explore this premise, we designed a cyanobacterial living artefact with air purifying capacity, and invited eight participants to live with and care for it for two weeks. The artefact can be situated in diverse locations within domestic spaces, wherever the participant would consider air purification necessary and certain lighting conditions beneficial for the artefact’s vitality. This versatility is supported by the artefact’s colour-changing, pliable, adhesive, and suspendable nature. We analysed visual documentation and semi-structured interviews of participants’ experiences of the artefact. Our findings suggest distinct roles of materiality for care regarding labour, knowledge, and exploration. We further highlight the intricate design space encompassing openness, temporalities and semantic fitness towards nurturing mutualistic care in human-microbe interactions.</p>
<h3>PhotoScout: Synthesis-Powered Multi-Modal Image Search</h3>
<p>Authors: Qiaochu Chen, Celeste Barnaby, Chenglong Wang, Isil Dillig</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147573">Link</a></p>
<p>Abstract: Due to the availability of increasingly large amounts of visual data, there is a growing need for tools that can help users  find relevant images. While existing tools can perform image retrieval based on similarity or metadata, they fall short in scenarios that necessitate semantic reasoning about the  content of the image. This paper explores a new multi-modal image search approach that allows users to conveniently specify and perform semantic image search tasks. With our tool, PhotoScout, the user interactively provides natural language descriptions, positive and negative examples, and object tags to specify their search tasks. Under the hood, PhotoScout is powered by a program synthesis engine that generates visual queries in a domain-specific language and executes the synthesized program to retrieve the desired images. In a study with 25 participants, we observed that PhotoScout allows users to perform image retrieval tasks more accurately and with less manual effort.</p>
<h3>"Please Be Nice": Robot Responses to User Bullying - Measuring Performance Across Aggression Levels</h3>
<p>Authors: Yushan Pan, Di Wu, Yiming Luo, Hao Wang, Shihao Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147077">Link</a></p>
<p>Abstract: As robots become integral to public services, addressing harmful user behaviors like bullying is crucial. Existing research often overlooks the gradual nature of human bullying. This study fills this gap by exploring how robots can counter bullying through optimized responses. Using a simulated human-robot interaction study, we manipulated robot response behaviors and styles across escalating bullying severity. Results show that empathetic verbal responses promptly reduce users' bullying tendencies by eliciting remorse and redirecting attention to social awareness. However, users' underlying dispositions may override these reflexive reactions, emphasizing the need for a holistic understanding. In conclusion, a comprehensive approach is essential, involving immediate reaction optimization, emotional state assessment, and ongoing behavioral adjustment through empathetic dialogue. By implementing such strategies, we can transform human-robot relationships from potential bullying situations to harmonious interactions. This study provides an empirical foundation for response protocols that discourage bullying and enhance mutual understanding.</p>
<h3>GustosonicSense: Towards understanding the design of playful gustosonic eating experiences</h3>
<p>Authors: Florian Mueller, Flora Salim, Zhuying Li, Yan Wang, Humphrey Obie, John Grundy</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148023">Link</a></p>
<p>Abstract: The pleasure that often comes with eating can be further enhanced with intelligent technology, as the field of human-food interaction suggests. However, knowledge on how to design such pleasure-supporting eating systems is limited. To begin filling this knowledge gap, we designed “GustosonicSense”, a novel gustosonic eating system that utilizes wireless earbuds for sensing different eating and drinking actions with a machine learning algorithm and trigger playful sounds as a way to facilitate pleasurable eating experiences. We present the findings from our design and a study that revealed how we can support the "stimulation", "hedonism", and "reflexivity" for playful human-food interactions. Ultimately, with our work, we aim to support interaction designers in facilitating playful experiences with food.</p>
<h3>A Design Framework for Ingestible Play</h3>
<p>Authors: Florian Mueller, Zhuying Li, Nathan Semertzidis, Yan Wang, Josh Andres, Stefan Greuter</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150650">Link</a></p>
<p>Abstract: Ingestible sensors have become smaller and more powerful and allow us to envisage new human-computer interactions and bodily play experiences inside our bodies. Users can swallow ingestible sensors, which facilitate interior body sensing functions that provide data on which play experiences can be built. We call bodily play that uses ingestible sensors as play technologies “ingestible play”, and we have adopted a research-through-design (RtD) approach to investigate three prototypes. For each prototype, we conducted a field study to understand the player experiences. Based upon these results and practical design experiences, we have developed a design framework for ingestible play. We hope this work can guide the future design of ingestible play; inspire the design of play technologies inside the human body to expand the current bodily play design space; and ultimately extend our understanding of how to design for the human body by considering the bodily experience of one’s interior body.</p>
<h3>Algorithmic Ways of Seeing: Using Object Detection to Facilitate Art Exploration</h3>
<p>Authors: Peter Kun, Louie Meyer, Johanne Engel Aaen, Anitamalina Regitse Tranberg, Sebastian Risi, Anders Løvlie, Matthias Freiberger</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147105">Link</a></p>
<p>Abstract: This Research through Design paper explores how object detection may be applied to a large digital art museum collection to facilitate new ways of encountering and experiencing art. We present the design and evaluation of an interactive application called SMKExplore, which allows users to explore a museum's digital collection of paintings by browsing through objects detected in the images, as a novel form of open-ended exploration. We provide three contributions. First, we show how an object detection pipeline can be integrated into a design process for visual exploration. Second, we present the design and development of an app that enables exploration of an art museum's collection. Third, we offer reflections on future possibilities for museums and HCI researchers to incorporate object detection techniques into the digitalization of museums.</p>
<h2>Highlight on Design and Design Methods</h2>
<h3>What's the Rush?: Alternative Values in Navigation Technologies for Urban Placemaking</h3>
<p>Authors: Carolina Nobre, Taneea Agrawaal, Robert Soden, Aarjav Chauhan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147044">Link</a></p>
<p>Abstract: In the design of contemporary mapping technologies, effective navigation has become synonymous with the quickest route, limiting the extent to which people engage with the places they move in and around. This paper unsettles the prevalent focus on efficiency and explores opportunities to support placemaking during everyday practices of navigation. Drawing on 16 interviews and using the Value Sensitive Design framework, we identify seven alternative values, beyond efficiency, that hold significance for people navigating the city. Through a series of two design workshops, we further examine how and when these values come to matter during navigation. Our findings suggest four ways in which the prevalent design standards of navigational apps work against these values, and highlight their potential contribution to placemaking during technology mediated navigation. In doing so, this paper contributes to placemaking research and ongoing questions of efficiency and optimization within HCI.</p>
<h3>Input Visualization: Collecting and Modifying Data with Visual Representations</h3>
<p>Authors: Jordan Louis, Nathalie Bressa, Wesley Willett, Samuel Huron</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147820">Link</a></p>
<p>Abstract: We examine input visualizations, visual representations that are designed to collect (and represent) new data rather than encode preexisting datasets. Information visualization is commonly used to reveal insights and stories within existing data. As a result, most contemporary visualization approaches assume existing datasets as the starting point for design, through which that data is mapped to visual encodings. Meanwhile, the implications of visualizations as inputs and as data sources have received little attention—despite the existence of visual and physical examples stretching back centuries. In this paper, we present a design space of 50 input visualizations analyzing their visual representation, data, artifact, context, and input. Based on this, we identify input modalities, purposes of input visualizations, and a set of design considerations. Finally, we discuss the relationship between input visualization and traditional visualization design and suggest opportunities for future research to better understand these visual representations and their potential.</p>
<h3>Multimedia-Enabled 911: Exploring 911 Callers’ Experience of Call Taker Controlled Video Calling in Simulated Emergencies</h3>
<p>Authors: Wolfgang Stuerzlinger, Punyashlok Dash, Benett Axtell, Carman Neustaedter, Denise Y. Geiskkovitch</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148116">Link</a></p>
<p>Abstract: Emergency response to large-scale disasters is often supported with multimedia from social media. However, while these features are common in everyday video calls, the complex needs of 911 and other systems make it difficult to directly incorporate these features. We assess an ME911 (Multimedia-Enabled 911) app to understand how the design will need to deviate from common norms and how callers will respond to those non-standard choices. We expand the role of 911 call taker control over emergency situations to the calling interface while incorporating key features like map-based location finding. Participants’ experiences in mock emergencies show the non-standard design helps callers in the unfamiliar setting of emergency calling yet it also causes confusion and delays. We find the need for emergency-specific deviations from design norms is supported by participant feedback. We discuss how broader system changes will support callers to use these non-standard designs during emergencies.</p>
<h3>eKichabi v2: Designing and Scaling a Dual-Platform Technology in Rural Tanzania</h3>
<p>Authors: Yunqi Wang, Richard Anderson, Fanchong Wang, Yunwei Zhao, Hosea Mpogole, Alexander Metzger, Hans Easton, Ananditha Raghunath, XunMei Liu</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147861">Link</a></p>
<p>Abstract: Although farmers in Sub-Saharan Africa are accessing feature phones and smartphones at historically high rates, they face challenges finding a robust network of agricultural contacts. With local collaborators, we conduct a quantitative survey of 1014 agricultural households in Kagera, Tanzania to characterize technology access, use, and comfort levels in the region. Recognizing the paucity of research on dual-platform technologies that cater to both feature phone and smartphone users, we develop and deploy eKichabi v2, a searchable directory of 9833 agriculture-related enterprises accessible via a USSD application and an Android application. To bridge the gap in affordances between the two applications, we conduct a mixed methods pilot leveraging mobile money agents as intermediators for our USSD application's users. Through our investigations, we identify the advantages, obstacles, and critical considerations in the design, implementation, and scalability of agricultural information systems tailored to both feature phone \textit{and} smartphone users in Sub-Saharan Africa.</p>
<h3>Designing a Data-Driven Survey System: Leveraging Participants' Online Data to Personalize Surveys</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Michelle Mazurek, Kévin Huguenin, Bertil Chapuis, Lev Velykoivanenko, Kavous Salehzadeh Niksirat, Stefan Teofanovic</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147705">Link</a></p>
<p>Abstract: User surveys are essential to user-centered research in many fields, including human-computer interaction (HCI). Survey personalization—specifically, adapting questionnaires to the respondents' profiles and experiences—can improve reliability and quality of responses. However, popular survey platforms lack usable mechanisms for seamlessly importing participants’ data from other systems. This paper explores the design of a data-driven survey system to fill this gap. First, we conducted formative research, including a literature review and a survey of researchers (𝑁 = 52), to understand researchers’ practices, experiences, needs, and interests in a data-driven survey system. Then, we designed and implemented a minimum viable product called Data-Driven Surveys (DDS), which enables including respondents’ data from online service accounts (Fitbit, Instagram, and GitHub) in survey questions, answers, and flow/logic on existing survey platforms (Qualtrics and SurveyMonkey). Our system is open source and can be extended to work with more online service accounts and survey platforms. It can enhance the survey research experience for both researchers and respondents.</p>
<p>A demonstration video is available here:</p>
<p>https://doi.org/10.17605/osf.io/vedbj</p>
<h3>“Is Text-Based Music Search Enough to Satisfy Your Needs?” A New Way to Discover Music with Images</h3>
<p>Authors: Hyorim Shin, Jeongeun Park, Ha Young Kim, Changhoon Oh</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148282">Link</a></p>
<p>Abstract: Music is intrinsically connected to human experience, yet the plethora of choices often renders the search for the ideal piece perplexing, especially when the search terms are ambiguous. This study questions the viability of employing visual data, specifically images, in innovative queries for music search, and it aims to better align search results with users' moods and situational context. We designed and evaluated three prototype systems for music search—TTTune (text-based), VisTune (image-based), and VTTune (hybrid)—to comparatively assess user experience and system usability. In a comprehensive user study involving 236 participants, each participant interacted with one of the systems and subsequently completed post-experimental surveys. A subset of participants also participated in in-depth interviews to further elucidate the potential and the advantages of image-based music retrieval (IMR) systems. Our findings reveal a marked preference for the user experience and usability offered by the IMR approach, as compared with the traditional text-based method. This underscores the potential of the image in an effective search query. Based on these findings, we discuss interface design guidelines tailored for IMR systems and factors affecting system performance, contributing to the evolving landscape of music search methods.</p>
<h3>Writing out the Storm: Designing and Evaluating Tools for Weather Risk Messaging</h3>
<p>Authors: Priyank Chandra, Lydia Chilton, Sophia Jit, Robert Soden, Jennifer Spinney</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147048">Link</a></p>
<p>Abstract: Communicating risk to the public in the lead-up to and during severe weather events has the potential to reduce the impacts of these events on lives and property. Globally, these events are anticipated to increase due to climate change, rendering effective risk communication an integral component of climate adaptation policies. Research in risk communications literature has developed substantial knowledge and best practices for the design of risk messaging. This study considers the potential for quantifying the compliance of severe weather risk messages with these best practices, individually and at scale, and developing tools to improve risk communication messaging. The current work makes two contributions. First, we develop a string-matching approach to evaluate whether messaging complies with best practices and suggest areas for improvement. Second, we conduct an interview study with risk communication professionals to inform the design space of authoring tools and other technologies to support severe weather risk communicators. </p>
<h3>“What’s Your Name Again?”: How Race and Gender Dynamics Impact Codesign Processes and Output</h3>
<p>Authors: Judith Uchidiuno, Erik Harpstead, Ross Higashi, Jonaya Kemper, Jessica Hammer, Jaemarie Solyst</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150848">Link</a></p>
<p>Abstract: Creating technology products using codesign techniques often results in higher end-user engagement compared to expert-driven designs. Codesign sessions are typically structured in flexible and informal ways to achieve equal design partnerships, especially in adult-child interactions. This generally leads to better design output; however, it may also increase the enactment of socially constructed stereotypes and biases in ways that negatively affect the experiences of racial minorities and girls/women in design spaces. We codesigned a video game with a K-5 afterschool program located in a working-class, rural, predominantly white county over 20 weeks. We uncover ways that the codesign process and different activity types can create a permissive environment for enacting behaviors that are harmful to minorities. We discuss ways to manage and restructure codesign programs to be more conducive for children and adults from diverse backgrounds, ultimately leading to healthier design partnerships. </p>
<h2>Highlight on HCI For Caring</h2>
<h3>CareJournal: A Voice-Based Conversational Agent for Supporting Care Communications</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Mingyi Li, John Rudnik, Sharadhi Raghuraj, Robin Brewer</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147253">Link</a></p>
<p>Abstract: Effective communication between older adult care recipients and unpaid caregivers is essential to both care partners' well-being. To understand communication in care relationships, we conducted a two-part study with older adult care recipients and caregivers. First, we conducted a two-week diary study to gain insight into care-related communication challenges. While caregivers discussed the benefits of emotional attachment, care recipients expressed concerns about emotional fluctuation and losing autonomy. These findings, along with literature on self-disclosure and conversational scaffolding informed our design of CareJournal—a voice-based conversational agent that supports care-related disclosure between care partners. We evaluated CareJournal with 40 care partners to inform future design considerations and learn more about their communication practices. Our findings highlight the impact of distance and tensions between care and independence, providing insight into how care partners imagine computer-mediated care communication impacting their relationships.</p>
<h3>Let’s Talk About Death: Existential Conversations with Chatbots</h3>
<p>Authors: Ruben Albers, Marc Hassenzahl</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147858">Link</a></p>
<p>Abstract: Many people prefer not to think about their own death, let alone talk about it. This contributes to fear of death and reduces the acceptance of its inevitability. We hypothesized that talking about one’s own death with  a specially designed chatbot reduces fear of death and strengthens the confidence to discuss the topic further with loved ones. Participants (N=100) talked with the chatbot for an average of 25 minutes. It offered conversations about planning for one's own death, end-of-life preferences, and hopes for the afterlife. We measured participants’ fear and acceptance of death (DAP-R questionnaire) and readiness for end-of-life conversation (REOLC questionnaire) before and after the chat. Overall, attitudes toward death improved and fear decreased, while readiness for end-of-life conversations increased. Bigger changes in attitude corresponded with longer, more reflective responses in the conversations, commitment to plans, finding meaning in death, and some notion of legacy or afterlife.</p>
<h3>Unpacking ICT-supported Social Connections and Support of Late-life Migration: From the Lens of Social Convoys</h3>
<p>Authors: Shuai Ma, Yuling Sun, Ying Lei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147033">Link</a></p>
<p>Abstract: Migration and aging-related dilemmas have limited the opportunities for late-life migrants to rebuild social connections and access support. While research on migrants has drawn increasing attention in HCI, limited attention has been paid to the increasing number of late-life migrants. This paper reports a qualitative study examining the social connections and support of late-life migrants. In particular, drawing on the social convoy model, we pay specific attention to the dynamic changes of late-life migrants' social convoy, the supporting roles each convoy plays, the functions ICT plays in the process, as well as the encountered challenges and expectations of late-life migrants regarding ICT-supported social convoys. Based on these findings, we deeply discuss the role of the social convoy in supporting more targeted social support for late-life migrants, as well as broader migrant communities. Finally, we offer late-life migrant-oriented design considerations. </p>
<h3>Networks of care in digital domestic labour economies</h3>
<p>Authors: Adrian Petterson, Olivia Doggett, Priyank Chandra, Isabella Jaimes Rodriguez</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147318">Link</a></p>
<p>Abstract:  Care work has long been relegated to private households and small communities, however, with the entry of digital marketplaces, it is becoming part of public economic spheres. While care work has been generally devalued and understudied, it is a complex practice embedded in a network of economic transactions, social relations, material conditions, and socio-cultural norms. This paper explores the care giving networks among migrant house-cleaners guided by Tronto’s ‘care ethics’ and Puig de la Bellacasa’s ‘matters of care’. We interviewed 19 Latino house-cleaners in Toronto to understand their care practices and networks. Our analysis identifies gaps in our participants’ care networks. We create a new term, lateral care, to explicate the digital communities of care practice our participants formed. We conclude with implications for the future design of technologies for labor economies that attend to concerns of care.</p>
<h3>Hostile Systems: A Taxonomy of Harms Articulated by Citizens Living with Socio-Economic Deprivation</h3>
<p>Authors: Adam Parnaby, Clara Crivellaro, Ahmed Kharrufa, Colin Watson</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148328">Link</a></p>
<p>Abstract: There is increasing interest in how digitalisation variously impacts different socio-economic demographics’ ability to access, and realise benefits from, public services. Centring citizens’ lived experience in the identification of harms and benefits is critical for the evaluation of digital services, and more broadly for responsible innovation. Yet this poses significant challenges, particularly when engaging those living in precarious conditions. This paper reports on a study that engaged citizens living with poverty (n=76) to articulate harms arising from digitalisation in the context of an e-government social protection service. Interviews and surveys supported by speculative scenarios of ongoing changes helped surface and express citizen-centric harm characteristics within wider ecosystems before, during and after access, beyond a narrower service-lifecycle viewpoint. Drawing on the findings, we develop a taxonomy of harms and discuss how this can be utilised by HCI practitioners concerned with responsible innovation in digital welfare contexts.</p>
<h3>Digital Comprehensibility Assessment of Simplified Texts among Persons with Intellectual Disabilities</h3>
<p>Authors: Sarah Ebling, Andreas Säuberli, Silvana Deilen, Silvia Hansen-Schirra, Laura Schiffl, Patrick Haller, Franz Holzknecht</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147152">Link</a></p>
<p>Abstract: Text simplification refers to the process of increasing the comprehensibility of texts. Automatic text simplification models are most commonly evaluated by experts or crowdworkers instead of the primary target groups of simplified texts, such as persons with intellectual disabilities. We conducted an evaluation study of text comprehensibility including participants with and without intellectual disabilities reading unsimplified, automatically and manually simplified German texts on a tablet computer. We explored four different approaches to measuring comprehensibility: multiple-choice comprehension questions, perceived difficulty ratings, response time, and reading speed. The results revealed significant variations in these measurements, depending on the reader group and whether the text had undergone automatic or manual simplification. For the target group of persons with intellectual disabilities, comprehension questions emerged as the most reliable measure, while analyzing reading speed provided valuable insights into participants' reading behavior.</p>
<h3>Understanding Antenatal Care Needs through Co-Creation with Roma Women to Inform the Design of mHealth Technologies</h3>
<p>Authors: Caroline Claisse, Mabel Lie, Abigail Durrant</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146924">Link</a></p>
<p>Abstract: Women from the Roma community experience significant health disparities during their pregnancy. Whilst Mobile Health (mHealth) technologies have the potential to improve antenatal care experiences and health outcomes, research on women from ethnically marginalised backgrounds in developed countries remains limited. We report on a series of Co-creation Workshops with 11 Roma women who have settled in the North of England. In this paper, we present thematic insights about their experiences and needs during pregnancy, and their perceptions and attitudes towards digital technologies to inform the design of culturally sensitive mHealth. We contribute to Human Computer Interaction (HCI) with new empirical research to discourses on Critical Digital Health, Intersectional HCI and Women-centred Design, highlight implications for design and encourage a more critical and intersectional design approach to accommodate better the experiences of ethnically marginalised groups whose needs arguably tend to be overlooked and stereotyped.</p>
<h2>Highlight on Chatbots and LLMs</h2>
<h3>AI is Entering Regulated Territory: Understanding the Supervisors' Perspective for Model Justifiability in Financial Crime Detection</h3>
<p>Authors: Astrid Bertrand, James Eagan, Winston Maxwell, Joshua Brand</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147023">Link</a></p>
<p>Abstract: Artificial intelligence (AI) has the potential to bring significant benefits to highly regulated industries such as healthcare or banking. Adoption, however, remains low. AI's entry into complex socio-techno-legal systems raises issues of transparency, specifically for regulators. However, the perspective of supervisors, regulators who monitor compliance with applicable financial regulations, has rarely been studied. This paper focuses on understanding the needs of supervisors in anti-money laundering (AML) to better inform the design of AI justifications and explanations in highly regulated fields. Through scenario-based workshops with 13 supervisors and 6 banking professionals, we outline the auditing practices and socio-technical context of the supervisor. By combining the workshops’ insights with an analysis of compliance requirements, we identify the AML obligations that conflict with AI opacity. We then formulate seven needs that supervisors have for model justifiability. We discuss the role of explanations as reliable evidence on which to base justifications.</p>
<h3>HILL: A Hallucination Identifier for Large Language Models</h3>
<p>Authors: Sven Eckhardt, Florian Leiser, Ali Sunyaev, Alexander Mädche, Valentin Leuthe, Gerhard Schwabe, Merlin Knaeble</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147556">Link</a></p>
<p>Abstract: Large language models (LLMs) are prone to hallucinations, i.e., nonsensical, unfaithful, and undesirable text. Users tend to overrely on LLMs and corresponding hallucinations which can lead to misinterpretations and errors. To tackle the problem of overreliance, we propose HILL, the Hallucination Identifier for Large Language Models. First, we identified design features for HILL with a Wizard of Oz approach with nine participants. Subsequently, we implemented HILL based on the identified design features and evaluated HILL's interface design by surveying 17 participants. Further, we investigated HILL's functionality to identify hallucinations based on an existing question-answering dataset and five user interviews. We find that HILL can correctly identify and highlight hallucinations in LLM responses which enables users to handle LLM responses with more caution. With that, we propose an easy-to-implement adaptation to existing LLMs and demonstrate the relevance of user-centered designs of AI artifacts.</p>
<h3>Synlogue with Aizuchi-bot: Investigating the Co-Adaptive and Open-Ended Interaction Paradigm</h3>
<p>HONORABLE_MENTION</p>
<p>Authors: Dominique Chen, Olaf Witkowski, Kazumi Yoshimura</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147480">Link</a></p>
<p>Abstract: In contrast to dialogue, wherein the exchange of completed messages occurs through turn-taking, synlogue is a mode of conversation characterized by co-creative processes, such as mutually complementing incomplete utterances and cooperative overlaps of backchannelings. Such co-creative conversations have the potential to alleviate social divisions in contemporary information environments. This study proposed the design concept of a synlogue based on literature in linguistics and anthropology and explored features that facilitate synlogic interactions in computer-mediated interfaces. Through an experiment, we focused on aizuchi, an important backchanneling element that drives synlogic conversation, and compared the speech and perceptual changes of participants when a bot dynamically uttered aizuchi or otherwise silent in a situation simulating an online video call. Consequently, we discussed the implications for interaction design based on our qualitative and quantitative analysis of the experiment. The synlogic perspective presented in this study is expected to facilitate HCI researchers to achieve more convivial forms of communication.</p>
<h3>Empowering Calibrated (Dis-)Trust in Conversational Agents: A User Study on the Persuasive Power of Limitation Disclaimers vs. Authoritative Style</h3>
<p>Authors: Luise Metzger, Johannes Kraus, Linda Miller, Martin Baumann</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148239">Link</a></p>
<p>Abstract: While conversational agents based on Large Language Models (LLMs) can drive progress in many domains, they are prone to generating faulty information. To ensure an efficient, safe, and satisfactory user experience maximizing benefits of these systems, users must be empowered to judge the reliability of system outputs. In this, both disclaimers and agents' communicative style are pivotal design instances. </p>
<p>In an online study with 594 participants, we investigated how these affect users' trust and a mock-up agent's persuasiveness, based on an established framework from social psychology. While prior information on potential inaccuracies or faulty information did not affect trust, an authoritative communicative style elicited more trust. Also, a trusted agent was more persuasive resulting in more positive attitudes regarding the subject of the conversation. Results imply that disclaimers on agents' limitations fail to effectively alter users' trust but can be supported by appropriate communicative style during interaction.</p>
<h3>DiaryMate: Understanding User Perceptions and Experience in Human-AI Collaboration for Personal Journaling</h3>
<p>Authors: Hwajung Hong, Donghoon Shin, Taewan Kim, Young-Ho Kim</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148343">Link</a></p>
<p>Abstract: With their generative capabilities, large language models (LLMs) have transformed the role of technological writing assistants from simple editors to writing collaborators. Such a transition emphasizes the need for understanding user perception and experience, such as balancing user intent and the involvement of LLMs across various writing domains in designing writing assistants. In this study, we delve into the less explored domain of personal writing, focusing on the use of LLMs in introspective activities. Specifically, we designed DiaryMate, a system that assists users in journal writing with LLM. Through a 10-day field study (N=24), we observed that participants used the diverse sentences generated by the LLM to reflect on their past experiences from multiple perspectives. However, we also observed that they are over-relying on the LLM, often prioritizing its emotional expressions over their own. Drawing from these findings, we discuss design considerations when leveraging LLMs in a personal writing practice.</p>
<h2>Text Entry Techniques</h2>
<h3>PonDeFlick: A Japanese Text Entry on Smartwatch Commonalizing Flick Operation with Smartphone Interface</h3>
<p>Authors: Kai Akamine, Akihiro Tamura, Tsuneo Kato, Ryotaro Tsuchida</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147586">Link</a></p>
<p>Abstract: While the QWERTY keyboard is a standard text entry for Latin script languages on smart devices, it is not always true for non-Latin script languages. In Japanese, the most popular text entry on smartphones is a flick-based interface that systematically assigns more than fifty kana characters to twelve keys of a numeric keypad in combination with flick directions. Under these circumstances, studies on Japanese text entry on smartwatches have focused on an efficient interface design that takes advantage of the regularity of the kana consonant and vowel structure, but overlooked commonality with familiar interfaces. Thus, we propose PonDeFlick, a Japanese text entry that commonalizes the flick directions with the familiar smartphone interface while providing the entire touchscreen for gestural operation. A ten-day user study showed that PonDeFlick reached a text-entry speed of 57.7 characters per minute, significantly faster than the numeric-keypad-based interface and a modification of PonDeFlick without the commonality.</p>
<h3>ARTiST: Automated Text Simplification for Task Guidance in Augmented Reality</h3>
<p>Authors: Jing Qian, Guande Wu, Sonia Castelo Quispe, Shaoyu Chen, João Rulff, Claudio Silva</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147808">Link</a></p>
<p>Abstract: Text presented in augmented reality provides in-situ, real-time information for users. However, this content can be challenging to apprehend quickly when engaging in cognitively demanding AR tasks, especially when it is presented on a head-mounted display. We propose ARTiST, an automatic text simplification system that uses a few-shot prompt and GPT-3 models to specifically optimize the text length and semantic content for augmented reality. Developed out of a formative study that included seven users and three experts, our system combines a customized error calibration model with a few-shot prompt to integrate the syntactic, lexical, elaborative, and content simplification techniques, and generate simplified AR text for head-worn displays. Results from a 16-user empirical study showed that ARTiST lightens the cognitive load and improves performance significantly over both unmodified text and text modified via traditional methods. Our work constitutes a step towards automating the optimization of batch text data for readability and performance in augmented reality.</p>
<h3>Exploration of Foot-based Text Entry Techniques for Virtual Reality Environments</h3>
<p>Authors: Liangyuting Zhang, Hongyu Yang, Hai-Ning Liang, Pourang Irani, Lingyun Yu, Tingjie Wan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146722">Link</a></p>
<p>Abstract: Foot-based input can serve as a supplementary or alternative approach to text entry in virtual reality (VR). This work explores the feasibility and design of foot-based techniques that are hands-free. We first conducted a preliminary study to assess foot-based text entry in standing and seated positions with tap and swipe input approaches. The findings showed that foot-based text input was feasible, with the possibility for performance and usability improvements. We then developed three foot-based techniques, including two tap-based techniques (FeetSymTap and FeetAsymTap) and one swipe-based technique (FeetGestureTap), and evaluated their performance via another user study. The results show that the two tap-based techniques supported entry rates of 11.12 WPM and 10.80 WPM, while the swipe-based technique led to 9.16 WPM. Our findings provide a solid foundation for the future design and implementation of foot-based text entry in VR and have the potential to be extended to MR and AR.</p>
<h3>A Tool for Capturing Smartphone Screen Text</h3>
<p>Authors: Songyan Teng, Simon D'Alfonso, Vassilis Kostakos</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147910">Link</a></p>
<p>Abstract: Context sensing on smartphones is often used to understand user behaviour. Amongst the many available sensors, the collection of text is crucial due to its richness. However, previous work has been limited to collecting text only from keyboard input, or intermittently collecting screen text indirectly by taking screenshots and applying optical character recognition. Here, we present a novel software sensor that unobtrusively and continuously captures all screen text on smartphones. We conducted a validation study with 21 participants over a two-week period, where they used our software on their personal smartphones. Our findings demonstrate how data from our sensor can be used to understand user behaviour and categorise mobile apps. We also show how smartphone sensing can be enhanced by using our sensor in conjunction with other sensors. We discuss the strengths and limitations of our sensor, highlighting potential areas for improvement and providing recommendations for its use.</p>
<h2>Writing and AI C</h2>
<h3>CharacterMeet: Supporting Creative Writers' Entire Story Character Construction Processes Through Conversation with LLM-Powered Chatbot Avatars</h3>
<p>Authors: Mingming Fan, Pan Hui, Shan Jin, Hua Xuan Qin, Ze Gao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146770">Link</a></p>
<p>Abstract: Support for story character construction is as essential as characters are for stories. Building upon past research on early character construction stages, we explore how conversation with chatbot avatars embodying characters powered by more recent technologies could support the entire character construction process for creative writing. Through a user study (N=14) with creative writers, we examine thinking and usage patterns of CharacterMeet, a prototype system allowing writers to progressively manifest characters through conversation while customizing context, character appearance, voice, and background image. We discover that CharacterMeet facilitates iterative character construction. Specifically, participants, including those with more linear usual approaches, alternated between writing and personalized exploration through visualization of ideas on CharacterMeet while visuals and audio enhanced immersion. Our findings support research on iterative creative processes and the growing potential of personalizable generative AI creativity support tools. We present design implications for leveraging chatbot avatars in the creative writing process.</p>
<h3>PANDALens: Towards AI-Assisted In-Context Writing on OHMD During Travels</h3>
<p>Authors: Can Liu, Yang Chen, Shengdong Zhao, Lucia Wang, Runze Cai, Nuwan Janaka</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146640">Link</a></p>
<p>Abstract: While effective for recording and sharing experiences, traditional in-context writing tools are relatively passive and unintelligent, serving more like instruments rather than companions. This reduces primary task (e.g., travel) enjoyment and hinders high-quality writing. Through formative study and iterative development, we introduce PANDALens, a Proactive AI Narrative Documentation Assistant built on an Optical See-Through Head Mounted Display that supports personalized documentation in everyday activities. PANDALens observes multimodal contextual information from user behaviors and environment to confirm interests and elicit contemplation, and employs Large Language Models to transform such multimodal information into coherent narratives with significantly reduced user effort. A real-world travel scenario comparing PANDALens with a smartphone alternative confirmed its effectiveness in improving writing quality and travel enjoyment while minimizing user effort. Accordingly, we propose design guidelines for AI-assisted in-context writing, highlighting the potential of transforming them from tools to intelligent companions.</p>
<h3>AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation</h3>
<p>Authors: Angelora Cooper, Osnat Mokryn, Andrew Kun, Orit Shaer, Hagit Ben Shoshan</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147572">Link</a></p>
<p>Abstract: The growing availability of generative AI technologies such as large language models (LLMs) has significant implications for creative work. This paper explores twofold aspects of integrating LLMs into the creative process – the divergence stage of idea generation, and the convergence stage of evaluation and selection of ideas. We devised a collaborative group-AI Brainwriting ideation framework,  which incorporated  an LLM as an enhancement into the group ideation process, and evaluated the idea generation process and the resulted solution space. To assess the potential of using LLMs in the idea evaluation process, we design an evaluation engine and compared it to idea ratings assigned by three expert and six novice evaluators. Our findings suggest that integrating LLM in Brainwriting could enhance both the ideation process and its outcome. We also provide evidence that LLMs can support idea evaluation.  We conclude by discussing implications for HCI education and practice.</p>
<h3>LegalWriter: An Intelligent Writing Support System for Structured and Persuasive Legal Case Writing for Novice Law Students</h3>
<p>Authors: Thiemo Wambsganss, Florian Weber, Matthias Soellner, Seyed Parsa Neshaei</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147647">Link</a></p>
<p>Abstract: Novice students in law courses or students who encounter legal education face the challenge of acquiring specialized and highly concept-oriented knowledge. Structured and persuasive writing combined with the necessary domain knowledge is challenging for many learners. Recent advances in machine learning (ML) have shown the potential to support learners in complex writing tasks. To test the effects of ML-based support on students' legal writing skills, we developed the intelligent writing support system \textit{LegalWriter}. We evaluated the system's effectiveness with 62 students. We showed that students who received intelligent writing support based on their errors wrote more structured and persuasive case solutions with a better quality of legal writing than the current benchmark. At the same time, our results demonstrated the positive effects on the students' writing processes.</p>
<h2>Social Activism C</h2>
<h3>Social Justice in HCI: A Systematic Literature Review</h3>
<p>Authors: Alyssa Sheehan, Ashley Boone, Christopher Le Dantec, Lynn Dombrowski, Kathryn Ringland, Ishita Chordia, Angela D. R. Smith, Leya Breanna Baltaxe-Admony</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148051">Link</a></p>
<p>Abstract: Given the renewed attention on politics, values, and ethics within our field and the wider cultural milieu, now is the time to take stock of social justice research in HCI. We surveyed 124 papers explicitly pursuing social justice between 2009 and 2022 to better reflect on the current state of justice-oriented work within our discipline. We identified (1) how researchers understood the social justice-relevant harms and benefits, (2) the approaches researchers used to address harm, and (3) the tools that researchers leveraged to pursue justice. Our analysis highlights gaps in social justice work, such as the need for our community to conceptualize benefits, and identifies concrete steps the HCI community can take to pursue just futures. By providing a comprehensive overview of and reflection on HCI's current social justice landscape, we seek to help our research community strategize, collaborate, and collectively act toward justice.</p>
<h3>Seam Work and Simulacra of Societal Impact in Networking Research: A Critical Technical Practice Approach</h3>
<p>Authors: Jen Liu, Phoebe Sengers, Gloire Rubambiza, Hakim Weatherspoon</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/146610">Link</a></p>
<p>Abstract: This paper explores how conceptions of societal impact are produced and performed during academic computer science research, by leveraging critical technical practice while building a digital agriculture networking platform. Our findings reveal how everyday practices of envisioning and building infrastructure require working across disciplinary and institutional seams, leading us as computer scientists to continuously reconceptualize the intended societal impact. By self-reflectively analyzing how we accrue resources for projects, produce research systems, write about them, and maintain alignments with stakeholders, we demonstrate that this seam work produces shifting simulacra of societal impact around which the system’s success is narrated. HCI researchers frequently suggest that technical systems’ impact could be improved by motivating computer scientists to consider impact in system-building. Our findings show that institutional and disciplinary structures significantly shape how computer scientists can enact societal impact in their work. This work suggests opportunities for structural interventions to shape the impact of computing systems.</p>
<h3>Addressing Interpersonal Harm in Online Gaming Communities: The Opportunities and Challenges for a Restorative Justice Approach</h3>
<p>Authors: Niloufar Salehi, Shagun Jhaver, Sijia Xiao</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/150929">Link</a></p>
<p>Abstract: Most social media platforms implement content moderation to address interpersonal harms such as harassment. Content moderation relies on offender-centered, punitive approaches, such as bans and content removal. We consider an alternative justice framework, restorative justice, which aids victims in healing, supports offenders in repairing the harm, and engages community members in addressing the harm collectively. To assess the utility of restorative justice in addressing online harm, we interviewed 23 users from Overwatch gaming communities, including moderators, victims, and offenders; such communities are particularly susceptible to harm, with nearly three quarters of all online game players suffering from some form of online abuse. We study how the communities currently handle harm cases through the lens of restorative justice and examine their attitudes toward implementing restorative justice processes. Our analysis reveals that cultural, technical, and resource-related obstacles hinder the implementation of restorative justice within the existing punitive framework despite online community needs and existing structures to support it. We discuss how current content moderation systems can embed restorative justice goals and practices and overcome these challenges.</p>
<h3>A Human-Centered Review of Algorithms in Homelessness Research</h3>
<p>Authors: Erina Seh-Young Moon, Shion Guha</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147715">Link</a></p>
<p>Abstract: Homelessness is a humanitarian challenge affecting an estimated 1.6 billion people worldwide. In the face of rising homeless populations in developed nations and a strain on social services, government agencies are increasingly adopting data-driven models to determine one’s risk of experiencing homelessness and assigning scarce resources to those in need. We conducted a systematic literature review of 57 papers to understand the evolution of these decision-making algorithms. We investigated trends in computational methods, predictor variables, and target outcomes used to develop the models using a human-centered lens and found that only 9 papers (15.7%) investigated model fairness and bias. We uncovered tensions between explainability and ecological validity wherein predictive risk models (53.4%) unduly focused on reductive explainability while resource allocation models (25.9%) were dependent on unrealistic assumptions and simulated data that are not useful in practice. Further, we discuss research challenges and opportunities for developing human-centered algorithms in this area. </p>
<h2>Designing with Users</h2>
<h3>Older Adults Imagining Future Technologies in Participatory Design Workshops: Supporting Continuity in the Pursuit of Meaningful Activities</h3>
<p>Authors: Ryan Kelly, Wei Zhao, Melissa Rogerson, Jenny Waycott</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147953">Link</a></p>
<p>Abstract: Recent innovations in digital technology offer significant opportunities for older adults to engage in meaningful activities. To investigate older adults' perceptions of using existing and emerging technologies for meaningful activities, we conducted three participatory design workshops and follow-up interviews with adults aged over 65. The workshops encompassed discussions on existing technologies for meaningful activities, demonstrations of emerging technologies such as VR, AR, and AI, and design activities including prototyping and storyboarding. Our findings show that while participants had diverse interpretations of meaningful activities, they sought to use technologies to support continuity in the pursuit of these activities. Specifically, participants highlighted the importance of safe aging at home, which provides a pathway for meaningful activities in later life. We further discuss participants' discerning attitudes when assessing the use of different technologies for meaningful activities and several values and attributes they desire when envisioning future technologies, including simplicity, positivity, proactivity, and integration.</p>
<h3>Co-design Partners as Transformative Learners: Imagining Ideal Technology for Schools by Centering Speculative Relationships</h3>
<p>Authors: Michael Chang, Arturo Cortez, Sidney D'Mello, Thomas Breideband, Thomas M Philip, Richmond Wong, Ashieda McKoy</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147225">Link</a></p>
<p>Abstract: Emergent technologies like artificial intelligence have been proposed to address issues of inequity in schools, yet tend to ossify the status quo because they address needs within an already inequitable system. In this paper, we draw from speculative participatory approaches across HCI and the learning sciences, and present a novel approach to co-design that forefronts supporting historically minoritized youth in developing transformative agency to change their schools based on their valued hopes, practices, and concerns. We argue that when co-design spaces forefront relational development, expansive technological objects emerge as a byproduct. We present a case study of expansive dreaming with U.S. historically minoritized students about the use of artificial intelligence to support classroom collaboration. Methodologically, we demonstrate how physically visiting spaces of collective agency serves as a powerful perceptual bridge to imagining joyful, equitable possibilities for schooling. Our approach yields new visions for schooling and new metaphors for artificial intelligence.</p>
<h3>Co-Designing Situated Displays for Family Co-Regulation with ADHD Children</h3>
<p>Authors: Clarisse Bonang, Kimberley Lakes, Jesus Beltran, Lucas Silva, Aehong Min, Elissa Monteiro, Arpita Bhattacharya, Gillian Hayes, Franceli Cibrian, Sabrina Schuck, Daniel Epstein</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148144">Link</a></p>
<p>Abstract: Family informatics often uses shared data dashboards to promote awareness of each other's health-related behaviors. However, these interfaces often stop short of providing families with needed guidance around how to improve family functioning and health behaviors. We consider the needs of family co-regulation with ADHD children to understand how in-home displays can support family well-being. We conducted three co-design sessions with each of eight families with ADHD children who had used a smartwatch for self-tracking. Results indicate that situated displays could nudge families to jointly use their data for learning and skill-building. Accommodating individual needs and preferences when family members are alone is also important, particularly to support parents exploring their co-regulation role, and assisting children with data interpretation and guidance on self and co-regulation. We discuss opportunities for displays to nurture multiple intents of use, such as joint or independent use, while potentially connecting with external expertise.</p>
<h3>Guidelines for Integrating Value Sensitive Design in Responsible AI Toolkits</h3>
<p>Authors: Celine Mougenot, Marios Constantinides, Malak Sadek, Daniele Quercia</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/148342">Link</a></p>
<p>Abstract: Value Sensitive Design (VSD) is a framework for integrating human values throughout the technology design process. In parallel, Responsible AI (RAI) advocates for the development of systems aligning with ethical values, such as fairness and transparency. In this study, we posit that a VSD approach is not only compatible, but also advantageous to the development of RAI toolkits. To empirically assess this hypothesis, we conducted four workshops involving 17 early-career AI researchers. Our aim was to establish links between VSD and RAI values while examining how existing toolkits incorporate VSD principles in their design. Our findings show that collaborative and educational design features within these toolkits, including illustrative examples and open-ended cues, facilitate an understanding of human and ethical values, and empower researchers to incorporate values into AI systems. Drawing on these insights, we formulated six design guidelines for integrating VSD values into the development of RAI toolkits.</p>
<h3>Co-design Accessible Public Robots: Insights from People with Mobility Disability, Robotic Practitioners and Their Collaborations</h3>
<p>Authors: Sarah Fox, Nikolas Martelaro, Alesandra Baca Vazquez, Franklin Mingzhe Li, Howard Han, Daragh Byrne</p>
<p><a href="https://programs.sigchi.org/chi/2024/program/content/147032">Link</a></p>
<p>Abstract: Sidewalk robots are increasingly common across the globe. Yet, their operation on public paths poses challenges for people with mobility disabilities (PwMD) who face barriers to accessibility, such as insufficient curb cuts. We interviewed 15 PwMD to understand how they perceive sidewalk robots. Findings indicated that PwMD feel they have to compete for space on the sidewalk when robots are introduced. We next interviewed eight robotics practitioners to learn about their attitudes towards accessibility. Practitioners described how issues often stem from robotic companies addressing accessibility only after problems arise. Both interview groups underscored the importance of integrating accessibility from the outset. Building on this finding, we held four co-design workshops with PwMD and practitioners in pairs. These convenings brought to bear accessibility needs around robots operating in public spaces and in the public interest. Our study aims to set the stage for a more inclusive future around public service robots.</p>